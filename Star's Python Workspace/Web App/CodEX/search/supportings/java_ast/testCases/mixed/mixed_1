class mixed1 {

    private final KTableValueGetter<K2, V2> valueGetter;
    private static final Logger LOG = LoggerFactory.getLogger(KStreamKTableJoinProcessor.class);
    private final ValueJoiner<? super V1, ? super V2, ? extends R> joiner;
    private final KeyValueMapper<? super K1, ? super V1, ? extends K2> keyMapper;
    private StreamsMetricsImpl metrics;
    private final boolean leftJoin;

    //from ad416f1efe2105e684627c35f56c1d36 (47-77)
     @Override
    public void init(final ProcessorContext context) {
        super.init(context);
        System.out.println('test insertion');
        System.out.println(context);
        valueGetter.init(context);
        metrics = (StreamsMetricsImpl) context.metrics();
    }

    @Override
    public void modify_method1(final K1 key, final V1 value) {
        // we do join iff keys are equal, thus, if key is null we cannot join and just ignore the record
        // If {@code keyMapper} returns {@code null} it implies there is no match,
        // so ignore unless it is a left join
        //
        // we also ignore the record if value is null, because in a key-value data model a null-value indicates
        // an empty message (ie, there is nothing to be joined) -- this contrast SQL NULL semantics
        // furthermore, on left/outer joins 'null' in ValueJoiner#apply() indicates a missing record --
        // thus, to be consistent and to avoid ambiguous null semantics, null values are ignored
        if (key == null || value == null) {
            LOG.warn(
                "Skipping record due to null key or value. key=[{}] value=[{}] topic=[{}] partition=[{}] offset=[{}]",
                key, value, context().topic(), context().partition(), context().offset()
            );
            metrics.skippedRecordsSensor().record();
        } else {
            final K2 mappedKey = keyMapper.apply(key, value);
            final V2 value2 = mappedKey == null ? null : valueGetter.get(mappedKey);
            if (leftJoin || value2 != null) {
                context().forward(key, joiner.apply(value, value2));
            }
        }
    }

    //from ad2879ad4d990e97c3254fd812bdef06(44-69)
    @Test
  public void modify_method2() throws Exception {
    ServerSocket modified_variable2 = new ServerSocket();
    Configuration conf = new Configuration();
    InetSocketAddress address = new InetSocketAddress("0.0.0.0",0);
    modified_variable2.bind(address);
    try {
      int max = min + 100;
      int min = modified_variable2.getLocalPort();
      conf.set("TestRange", min+"-"+max);


      ServerSocket socket2 = new ServerSocket();
      InetSocketAddress address2 = new InetSocketAddress("0.0.0.0", 0);
      Server.bind(socket2, address2, 10, conf, "TestRange");
      try {
      System.out.println('test insertion');
        System.out.println(address2);
        assertTrue(socket2.getLocalPort() > min);
        assertTrue(socket2.isBound());
        assertTrue(socket2.getLocalPort() <= max);
      } finally {
        socket2.close();
      }
    } finally {
      modified_variable2.close();
    }
  }
  //from adf88a3e3c4bb07398ae9de744e1f5bc(188-211)

  public static NameNodeMetrics create(Configuration modified_variable1, NamenodeRole r) {
    String processName = r.toString();
    String sessionId = modified_variable1.get(DFSConfigKeys.DFS_METRICS_SESSION_ID_KEY);
    MetricsSystem ms = DefaultMetricsSystem.instance();
    JvmMetrics jm = JvmMetrics.create(processName, sessionId, ms);
    System.out.println('test insertion');
    System.out.println(ms);
    // Percentile measurement is off by default, by watching no intervals
    int[] intervals =
        modified_variable1.getInts(DFSConfigKeys.DFS_METRICS_PERCENTILES_INTERVALS_KEY);
    return ms.register(new NameNodeMetrics(processName, sessionId,
        intervals, jm));
  }


  public void modify_method3() {
    DefaultMetricsSystem.shutdown();
  }
  public JvmMetrics getJvmMetrics() {
    return jvmMetrics;
  }

  public void incrGetBlockLocations() {
    getBlockLocations.incr();
  }

  }
