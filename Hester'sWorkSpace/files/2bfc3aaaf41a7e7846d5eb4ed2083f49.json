{"author": "0xAX", "code": "\n\nfrom __future__ import print_function\nfrom socket import timeout\n\nimport os\nimport sys\nimport codecs\nimport re\n\nimport markdown\n\ntry:\n    \n    from urllib2 import urlopen\n    from urllib2 import HTTPError\n    from urllib2 import URLError\nexcept ImportError:\n    \n    from urllib.request import urlopen\n    from urllib.error import HTTPError\n    from urllib.error import URLError\n\ndef check_live_url(url):\n\n    result = False\n    try:\n        ret = urlopen(url, timeout=2)\n        result = (ret.code == 200)\n    except HTTPError as e:\n        print(e, file=sys.stderr)\n    except URLError as e:\n        print(e, file=sys.stderr)\n    except timeout as e:\n        print(e, file=sys.stderr)\n    except Exception as e:\n        print(e, file=sys.stderr)\n\n    return result\n\n\ndef main(path):\n\n    filenames = []\n    for (dirpath, dnames, fnames) in os.walk(path):\n        for fname in fnames:\n            if fname.endswith('.md'):\n                filenames.append(os.sep.join([dirpath, fname]))\n\n    urls = []\n\n    for filename in filenames:\n        fd = codecs.open(filename, mode=\"r\", encoding=\"utf-8\")\n        for line in fd.readlines():\n            refs = re.findall(r'(?<=<a href=\")[^\"]*', markdown.markdown(line))\n            for ref in refs:\n                if ref not in urls:\n                    urls.append(ref)\n\n    #print(len(urls))\n\n    for url in urls:\n        if not url.startswith(\"http\"):\n            print(\"markdown file name: \" + url)\n            continue\n        if check_live_url(url):\n            print(url)\n        else:\n            print(url, file=sys.stderr)\n\n\nif __name__ == '__main__':\n\n    if len(sys.argv) == 2:\n        main(sys.argv[1])\n    else:\n        print(\"Choose one path as argument one\")\n", "comments": "   usr bin env python    compatible python2    compatible python3   print(len(urls)) ", "content": "#!/usr/bin/env python\n\nfrom __future__ import print_function\nfrom socket import timeout\n\nimport os\nimport sys\nimport codecs\nimport re\n\nimport markdown\n\ntry:\n    # compatible for python2\n    from urllib2 import urlopen\n    from urllib2 import HTTPError\n    from urllib2 import URLError\nexcept ImportError:\n    # compatible for python3\n    from urllib.request import urlopen\n    from urllib.error import HTTPError\n    from urllib.error import URLError\n\ndef check_live_url(url):\n\n    result = False\n    try:\n        ret = urlopen(url, timeout=2)\n        result = (ret.code == 200)\n    except HTTPError as e:\n        print(e, file=sys.stderr)\n    except URLError as e:\n        print(e, file=sys.stderr)\n    except timeout as e:\n        print(e, file=sys.stderr)\n    except Exception as e:\n        print(e, file=sys.stderr)\n\n    return result\n\n\ndef main(path):\n\n    filenames = []\n    for (dirpath, dnames, fnames) in os.walk(path):\n        for fname in fnames:\n            if fname.endswith('.md'):\n                filenames.append(os.sep.join([dirpath, fname]))\n\n    urls = []\n\n    for filename in filenames:\n        fd = codecs.open(filename, mode=\"r\", encoding=\"utf-8\")\n        for line in fd.readlines():\n            refs = re.findall(r'(?<=<a href=\")[^\"]*', markdown.markdown(line))\n            for ref in refs:\n                if ref not in urls:\n                    urls.append(ref)\n\n    #print(len(urls))\n\n    for url in urls:\n        if not url.startswith(\"http\"):\n            print(\"markdown file name: \" + url)\n            continue\n        if check_live_url(url):\n            print(url)\n        else:\n            print(url, file=sys.stderr)\n\n\nif __name__ == '__main__':\n\n    if len(sys.argv) == 2:\n        main(sys.argv[1])\n    else:\n        print(\"Choose one path as argument one\")\n", "description": "A little bit about a linux kernel", "file_name": "get_all_links.py", "id": "2bfc3aaaf41a7e7846d5eb4ed2083f49", "language": "Python", "project_name": "linux-insides", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/0xAX-linux-insides/0xAX-linux-insides-1c37c4b/Scripts/get_all_links.py", "save_time": "", "source": "", "update_at": "2018-03-18T08:34:00Z", "url": "https://github.com/0xAX/linux-insides", "wiki": false}