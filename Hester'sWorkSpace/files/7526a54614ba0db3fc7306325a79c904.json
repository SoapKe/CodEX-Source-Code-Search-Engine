{"author": "apache", "code": "# -*- coding: utf-8 -*-\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport json\nimport os\nimport subprocess\nimport time\nimport unittest\n\nimport pandas as pd\nfrom past.builtins import basestring\n\nfrom superset import app, appbuilder, cli, dataframe, db\nfrom superset.models.helpers import QueryStatus\nfrom superset.models.sql_lab import Query\nfrom superset.security import sync_role_definitions\nfrom superset.sql_parse import SupersetQuery\nfrom .base_tests import SupersetTestCase\n\n\nBASE_DIR = app.config.get('BASE_DIR')\n\n\nclass CeleryConfig(object):\n    BROKER_URL = 'sqla+sqlite:///' + app.config.get('SQL_CELERY_DB_FILE_PATH')\n    CELERY_IMPORTS = ('superset.sql_lab', )\n    CELERY_RESULT_BACKEND = (\n        'db+sqlite:///' + app.config.get('SQL_CELERY_RESULTS_DB_FILE_PATH'))\n    CELERY_ANNOTATIONS = {'sql_lab.add': {'rate_limit': '10/s'}}\n    CONCURRENCY = 1\n\n\napp.config['CELERY_CONFIG'] = CeleryConfig\n\n\nclass UtilityFunctionTests(SupersetTestCase):\n\n    # TODO(bkyryliuk): support more cases in CTA function.\n    def test_create_table_as(self):\n        q = SupersetQuery('SELECT * FROM outer_space;')\n\n        self.assertEqual(\n            'CREATE TABLE tmp AS \\nSELECT * FROM outer_space',\n            q.as_create_table('tmp'))\n\n        self.assertEqual(\n            'DROP TABLE IF EXISTS tmp;\\n'\n            'CREATE TABLE tmp AS \\nSELECT * FROM outer_space',\n            q.as_create_table('tmp', overwrite=True))\n\n        \n        q = SupersetQuery('SELECT * FROM outer_space')\n        self.assertEqual(\n            'CREATE TABLE tmp AS \\nSELECT * FROM outer_space',\n            q.as_create_table('tmp'))\n\n        \n        multi_line_query = (\n            'SELECT * FROM planets WHERE\\n'\n            \"Luke_Father = 'Darth Vader'\")\n        q = SupersetQuery(multi_line_query)\n        self.assertEqual(\n            'CREATE TABLE tmp AS \\nSELECT * FROM planets WHERE\\n'\n            \"Luke_Father = 'Darth Vader'\",\n            q.as_create_table('tmp'),\n        )\n\n\nclass CeleryTestCase(SupersetTestCase):\n    def __init__(self, *args, **kwargs):\n        super(CeleryTestCase, self).__init__(*args, **kwargs)\n        self.client = app.test_client()\n\n    def get_query_by_name(self, sql):\n        session = db.session\n        query = session.query(Query).filter_by(sql=sql).first()\n        session.close()\n        return query\n\n    def get_query_by_id(self, id):\n        session = db.session\n        query = session.query(Query).filter_by(id=id).first()\n        session.close()\n        return query\n\n    @classmethod\n    def setUpClass(cls):\n        try:\n            os.remove(app.config.get('SQL_CELERY_DB_FILE_PATH'))\n        except OSError as e:\n            app.logger.warn(str(e))\n        try:\n            os.remove(app.config.get('SQL_CELERY_RESULTS_DB_FILE_PATH'))\n        except OSError as e:\n            app.logger.warn(str(e))\n\n        sync_role_definitions()\n\n        worker_command = BASE_DIR + '/bin/superset worker'\n        subprocess.Popen(\n            worker_command, shell=True, stdout=subprocess.PIPE)\n\n        admin = appbuilder.sm.find_user('admin')\n        if not admin:\n            appbuilder.sm.add_user(\n                'admin', 'admin', ' user', 'admin@fab.org',\n                appbuilder.sm.find_role('Admin'),\n                password='general')\n        cli.load_examples(load_test_data=True)\n\n    @classmethod\n    def tearDownClass(cls):\n        subprocess.call(\n            \"ps auxww | grep 'celeryd' | awk '{print $2}' | xargs kill -9\",\n            shell=True,\n        )\n        subprocess.call(\n            \"ps auxww | grep 'superset worker' | awk '{print $2}' | xargs kill -9\",\n            shell=True,\n        )\n\n    def run_sql(self, db_id, sql, client_id, cta='false', tmp_table='tmp',\n                async='false'):\n        self.login()\n        resp = self.client.post(\n            '/superset/sql_json/',\n            data=dict(\n                database_id=db_id,\n                sql=sql,\n                async=async,\n                select_as_cta=cta,\n                tmp_table_name=tmp_table,\n                client_id=client_id,\n            ),\n        )\n        self.logout()\n        return json.loads(resp.data.decode('utf-8'))\n\n    def test_add_limit_to_the_query(self):\n        main_db = self.get_main_database(db.session)\n\n        select_query = 'SELECT * FROM outer_space;'\n        updated_select_query = main_db.wrap_sql_limit(select_query, 100)\n        \n        # the queries, that's why ' '.join(query.split()) is used.\n        \n        self.assertTrue(\n            'SELECT * FROM (SELECT * FROM outer_space;) AS inner_qry '\n            'LIMIT 100' in ' '.join(updated_select_query.split()),\n        )\n\n        select_query_no_semicolon = 'SELECT * FROM outer_space'\n        updated_select_query_no_semicolon = main_db.wrap_sql_limit(\n            select_query_no_semicolon, 100)\n        self.assertTrue(\n            'SELECT * FROM (SELECT * FROM outer_space) AS inner_qry '\n            'LIMIT 100' in\n            ' '.join(updated_select_query_no_semicolon.split()),\n        )\n\n        multi_line_query = (\n            \"SELECT * FROM planets WHERE\\n Luke_Father = 'Darth Vader';\"\n        )\n        updated_multi_line_query = main_db.wrap_sql_limit(multi_line_query, 100)\n        self.assertTrue(\n            'SELECT * FROM (SELECT * FROM planets WHERE '\n            \"Luke_Father = 'Darth Vader';) AS inner_qry LIMIT 100\" in\n            ' '.join(updated_multi_line_query.split()),\n        )\n\n    def test_run_sync_query_dont_exist(self):\n        main_db = self.get_main_database(db.session)\n        db_id = main_db.id\n        sql_dont_exist = 'SELECT name FROM table_dont_exist'\n        result1 = self.run_sql(db_id, sql_dont_exist, '1', cta='true')\n        self.assertTrue('error' in result1)\n\n    def test_run_sync_query_cta(self):\n        main_db = self.get_main_database(db.session)\n        db_id = main_db.id\n        eng = main_db.get_sqla_engine()\n        perm_name = 'can_sql_json'\n        sql_where = (\n            \"SELECT name FROM ab_permission WHERE name='{}'\".format(perm_name))\n        result2 = self.run_sql(\n            db_id, sql_where, '2', tmp_table='tmp_table_2', cta='true')\n        self.assertEqual(QueryStatus.SUCCESS, result2['query']['state'])\n        self.assertEqual([], result2['data'])\n        self.assertEqual([], result2['columns'])\n        query2 = self.get_query_by_id(result2['query']['serverId'])\n\n        \n        df2 = pd.read_sql_query(sql=query2.select_sql, con=eng)\n        data2 = df2.to_dict(orient='records')\n        self.assertEqual([{'name': perm_name}], data2)\n\n    def test_run_sync_query_cta_no_data(self):\n        main_db = self.get_main_database(db.session)\n        db_id = main_db.id\n        sql_empty_result = 'SELECT * FROM ab_user WHERE id=666'\n        result3 = self.run_sql(\n            db_id, sql_empty_result, '3', tmp_table='tmp_table_3', cta='true')\n        self.assertEqual(QueryStatus.SUCCESS, result3['query']['state'])\n        self.assertEqual([], result3['data'])\n        self.assertEqual([], result3['columns'])\n\n        query3 = self.get_query_by_id(result3['query']['serverId'])\n        self.assertEqual(QueryStatus.SUCCESS, query3.status)\n\n    def test_run_async_query(self):\n        main_db = self.get_main_database(db.session)\n        eng = main_db.get_sqla_engine()\n        sql_where = \"SELECT name FROM ab_role WHERE name='Admin'\"\n        result = self.run_sql(\n            main_db.id, sql_where, '4', async='true', tmp_table='tmp_async_1',\n            cta='true')\n        assert result['query']['state'] in (\n            QueryStatus.PENDING, QueryStatus.RUNNING, QueryStatus.SUCCESS)\n\n        time.sleep(1)\n\n        query = self.get_query_by_id(result['query']['serverId'])\n        df = pd.read_sql_query(query.select_sql, con=eng)\n        self.assertEqual(QueryStatus.SUCCESS, query.status)\n        self.assertEqual([{'name': 'Admin'}], df.to_dict(orient='records'))\n        self.assertEqual(QueryStatus.SUCCESS, query.status)\n        self.assertTrue('FROM tmp_async_1' in query.select_sql)\n        self.assertTrue('LIMIT 666' in query.select_sql)\n        self.assertEqual(\n            'CREATE TABLE tmp_async_1 AS \\nSELECT name FROM ab_role '\n            \"WHERE name='Admin'\", query.executed_sql)\n        self.assertEqual(sql_where, query.sql)\n        self.assertEqual(0, query.rows)\n        self.assertEqual(666, query.limit)\n        self.assertEqual(False, query.limit_used)\n        self.assertEqual(True, query.select_as_cta)\n        self.assertEqual(True, query.select_as_cta_used)\n\n    @staticmethod\n    def de_unicode_dict(d):\n        def str_if_basestring(o):\n            if isinstance(o, basestring):\n                return str(o)\n            return o\n        return {str_if_basestring(k): str_if_basestring(d[k]) for k in d}\n\n    @classmethod\n    def dictify_list_of_dicts(cls, l, k):\n        return {str(o[k]): cls.de_unicode_dict(o) for o in l}\n\n    def test_get_columns(self):\n        main_db = self.get_main_database(db.session)\n        df = main_db.get_df('SELECT * FROM multiformat_time_series', None)\n        cdf = dataframe.SupersetDataFrame(df)\n\n        \n        cols = self.dictify_list_of_dicts(cdf.columns, 'name')\n\n        if main_db.sqlalchemy_uri.startswith('sqlite'):\n            self.assertEqual(self.dictify_list_of_dicts([\n                {'is_date': True, 'type': 'STRING', 'name': 'ds',\n                    'is_dim': False},\n                {'is_date': True, 'type': 'STRING', 'name': 'ds2',\n                    'is_dim': False},\n                {'agg': 'sum', 'is_date': False, 'type': 'INT',\n                    'name': 'epoch_ms', 'is_dim': False},\n                {'agg': 'sum', 'is_date': False, 'type': 'INT',\n                    'name': 'epoch_s', 'is_dim': False},\n                {'is_date': True, 'type': 'STRING', 'name': 'string0',\n                    'is_dim': False},\n                {'is_date': False, 'type': 'STRING',\n                    'name': 'string1', 'is_dim': True},\n                {'is_date': True, 'type': 'STRING', 'name': 'string2',\n                    'is_dim': False},\n                {'is_date': False, 'type': 'STRING',\n                    'name': 'string3', 'is_dim': True}], 'name'),\n                cols,\n            )\n        else:\n            self.assertEqual(self.dictify_list_of_dicts([\n                {'is_date': True, 'type': 'DATETIME', 'name': 'ds',\n                    'is_dim': False},\n                {'is_date': True, 'type': 'DATETIME',\n                    'name': 'ds2', 'is_dim': False},\n                {'agg': 'sum', 'is_date': False, 'type': 'INT',\n                    'name': 'epoch_ms', 'is_dim': False},\n                {'agg': 'sum', 'is_date': False, 'type': 'INT',\n                    'name': 'epoch_s', 'is_dim': False},\n                {'is_date': True, 'type': 'STRING', 'name': 'string0',\n                    'is_dim': False},\n                {'is_date': False, 'type': 'STRING',\n                    'name': 'string1', 'is_dim': True},\n                {'is_date': True, 'type': 'STRING', 'name': 'string2',\n                    'is_dim': False},\n                {'is_date': False, 'type': 'STRING',\n                    'name': 'string3', 'is_dim': True}], 'name'),\n                cols,\n            )\n\n\nif __name__ == '__main__':\n    unittest.main()\n", "comments": "   unit tests superset celery worker           coding  utf 8        todo(bkyryliuk)  support cases cta function     without semicolon    multi line query    different db engines spacing compiling    queries      join(query split()) used     in addition engines include offset 0     check data tmp table     making ordering non deterministic ", "content": "# -*- coding: utf-8 -*-\n\"\"\"Unit tests for Superset Celery worker\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport json\nimport os\nimport subprocess\nimport time\nimport unittest\n\nimport pandas as pd\nfrom past.builtins import basestring\n\nfrom superset import app, appbuilder, cli, dataframe, db\nfrom superset.models.helpers import QueryStatus\nfrom superset.models.sql_lab import Query\nfrom superset.security import sync_role_definitions\nfrom superset.sql_parse import SupersetQuery\nfrom .base_tests import SupersetTestCase\n\n\nBASE_DIR = app.config.get('BASE_DIR')\n\n\nclass CeleryConfig(object):\n    BROKER_URL = 'sqla+sqlite:///' + app.config.get('SQL_CELERY_DB_FILE_PATH')\n    CELERY_IMPORTS = ('superset.sql_lab', )\n    CELERY_RESULT_BACKEND = (\n        'db+sqlite:///' + app.config.get('SQL_CELERY_RESULTS_DB_FILE_PATH'))\n    CELERY_ANNOTATIONS = {'sql_lab.add': {'rate_limit': '10/s'}}\n    CONCURRENCY = 1\n\n\napp.config['CELERY_CONFIG'] = CeleryConfig\n\n\nclass UtilityFunctionTests(SupersetTestCase):\n\n    # TODO(bkyryliuk): support more cases in CTA function.\n    def test_create_table_as(self):\n        q = SupersetQuery('SELECT * FROM outer_space;')\n\n        self.assertEqual(\n            'CREATE TABLE tmp AS \\nSELECT * FROM outer_space',\n            q.as_create_table('tmp'))\n\n        self.assertEqual(\n            'DROP TABLE IF EXISTS tmp;\\n'\n            'CREATE TABLE tmp AS \\nSELECT * FROM outer_space',\n            q.as_create_table('tmp', overwrite=True))\n\n        # now without a semicolon\n        q = SupersetQuery('SELECT * FROM outer_space')\n        self.assertEqual(\n            'CREATE TABLE tmp AS \\nSELECT * FROM outer_space',\n            q.as_create_table('tmp'))\n\n        # now a multi-line query\n        multi_line_query = (\n            'SELECT * FROM planets WHERE\\n'\n            \"Luke_Father = 'Darth Vader'\")\n        q = SupersetQuery(multi_line_query)\n        self.assertEqual(\n            'CREATE TABLE tmp AS \\nSELECT * FROM planets WHERE\\n'\n            \"Luke_Father = 'Darth Vader'\",\n            q.as_create_table('tmp'),\n        )\n\n\nclass CeleryTestCase(SupersetTestCase):\n    def __init__(self, *args, **kwargs):\n        super(CeleryTestCase, self).__init__(*args, **kwargs)\n        self.client = app.test_client()\n\n    def get_query_by_name(self, sql):\n        session = db.session\n        query = session.query(Query).filter_by(sql=sql).first()\n        session.close()\n        return query\n\n    def get_query_by_id(self, id):\n        session = db.session\n        query = session.query(Query).filter_by(id=id).first()\n        session.close()\n        return query\n\n    @classmethod\n    def setUpClass(cls):\n        try:\n            os.remove(app.config.get('SQL_CELERY_DB_FILE_PATH'))\n        except OSError as e:\n            app.logger.warn(str(e))\n        try:\n            os.remove(app.config.get('SQL_CELERY_RESULTS_DB_FILE_PATH'))\n        except OSError as e:\n            app.logger.warn(str(e))\n\n        sync_role_definitions()\n\n        worker_command = BASE_DIR + '/bin/superset worker'\n        subprocess.Popen(\n            worker_command, shell=True, stdout=subprocess.PIPE)\n\n        admin = appbuilder.sm.find_user('admin')\n        if not admin:\n            appbuilder.sm.add_user(\n                'admin', 'admin', ' user', 'admin@fab.org',\n                appbuilder.sm.find_role('Admin'),\n                password='general')\n        cli.load_examples(load_test_data=True)\n\n    @classmethod\n    def tearDownClass(cls):\n        subprocess.call(\n            \"ps auxww | grep 'celeryd' | awk '{print $2}' | xargs kill -9\",\n            shell=True,\n        )\n        subprocess.call(\n            \"ps auxww | grep 'superset worker' | awk '{print $2}' | xargs kill -9\",\n            shell=True,\n        )\n\n    def run_sql(self, db_id, sql, client_id, cta='false', tmp_table='tmp',\n                async='false'):\n        self.login()\n        resp = self.client.post(\n            '/superset/sql_json/',\n            data=dict(\n                database_id=db_id,\n                sql=sql,\n                async=async,\n                select_as_cta=cta,\n                tmp_table_name=tmp_table,\n                client_id=client_id,\n            ),\n        )\n        self.logout()\n        return json.loads(resp.data.decode('utf-8'))\n\n    def test_add_limit_to_the_query(self):\n        main_db = self.get_main_database(db.session)\n\n        select_query = 'SELECT * FROM outer_space;'\n        updated_select_query = main_db.wrap_sql_limit(select_query, 100)\n        # Different DB engines have their own spacing while compiling\n        # the queries, that's why ' '.join(query.split()) is used.\n        # In addition some of the engines do not include OFFSET 0.\n        self.assertTrue(\n            'SELECT * FROM (SELECT * FROM outer_space;) AS inner_qry '\n            'LIMIT 100' in ' '.join(updated_select_query.split()),\n        )\n\n        select_query_no_semicolon = 'SELECT * FROM outer_space'\n        updated_select_query_no_semicolon = main_db.wrap_sql_limit(\n            select_query_no_semicolon, 100)\n        self.assertTrue(\n            'SELECT * FROM (SELECT * FROM outer_space) AS inner_qry '\n            'LIMIT 100' in\n            ' '.join(updated_select_query_no_semicolon.split()),\n        )\n\n        multi_line_query = (\n            \"SELECT * FROM planets WHERE\\n Luke_Father = 'Darth Vader';\"\n        )\n        updated_multi_line_query = main_db.wrap_sql_limit(multi_line_query, 100)\n        self.assertTrue(\n            'SELECT * FROM (SELECT * FROM planets WHERE '\n            \"Luke_Father = 'Darth Vader';) AS inner_qry LIMIT 100\" in\n            ' '.join(updated_multi_line_query.split()),\n        )\n\n    def test_run_sync_query_dont_exist(self):\n        main_db = self.get_main_database(db.session)\n        db_id = main_db.id\n        sql_dont_exist = 'SELECT name FROM table_dont_exist'\n        result1 = self.run_sql(db_id, sql_dont_exist, '1', cta='true')\n        self.assertTrue('error' in result1)\n\n    def test_run_sync_query_cta(self):\n        main_db = self.get_main_database(db.session)\n        db_id = main_db.id\n        eng = main_db.get_sqla_engine()\n        perm_name = 'can_sql_json'\n        sql_where = (\n            \"SELECT name FROM ab_permission WHERE name='{}'\".format(perm_name))\n        result2 = self.run_sql(\n            db_id, sql_where, '2', tmp_table='tmp_table_2', cta='true')\n        self.assertEqual(QueryStatus.SUCCESS, result2['query']['state'])\n        self.assertEqual([], result2['data'])\n        self.assertEqual([], result2['columns'])\n        query2 = self.get_query_by_id(result2['query']['serverId'])\n\n        # Check the data in the tmp table.\n        df2 = pd.read_sql_query(sql=query2.select_sql, con=eng)\n        data2 = df2.to_dict(orient='records')\n        self.assertEqual([{'name': perm_name}], data2)\n\n    def test_run_sync_query_cta_no_data(self):\n        main_db = self.get_main_database(db.session)\n        db_id = main_db.id\n        sql_empty_result = 'SELECT * FROM ab_user WHERE id=666'\n        result3 = self.run_sql(\n            db_id, sql_empty_result, '3', tmp_table='tmp_table_3', cta='true')\n        self.assertEqual(QueryStatus.SUCCESS, result3['query']['state'])\n        self.assertEqual([], result3['data'])\n        self.assertEqual([], result3['columns'])\n\n        query3 = self.get_query_by_id(result3['query']['serverId'])\n        self.assertEqual(QueryStatus.SUCCESS, query3.status)\n\n    def test_run_async_query(self):\n        main_db = self.get_main_database(db.session)\n        eng = main_db.get_sqla_engine()\n        sql_where = \"SELECT name FROM ab_role WHERE name='Admin'\"\n        result = self.run_sql(\n            main_db.id, sql_where, '4', async='true', tmp_table='tmp_async_1',\n            cta='true')\n        assert result['query']['state'] in (\n            QueryStatus.PENDING, QueryStatus.RUNNING, QueryStatus.SUCCESS)\n\n        time.sleep(1)\n\n        query = self.get_query_by_id(result['query']['serverId'])\n        df = pd.read_sql_query(query.select_sql, con=eng)\n        self.assertEqual(QueryStatus.SUCCESS, query.status)\n        self.assertEqual([{'name': 'Admin'}], df.to_dict(orient='records'))\n        self.assertEqual(QueryStatus.SUCCESS, query.status)\n        self.assertTrue('FROM tmp_async_1' in query.select_sql)\n        self.assertTrue('LIMIT 666' in query.select_sql)\n        self.assertEqual(\n            'CREATE TABLE tmp_async_1 AS \\nSELECT name FROM ab_role '\n            \"WHERE name='Admin'\", query.executed_sql)\n        self.assertEqual(sql_where, query.sql)\n        self.assertEqual(0, query.rows)\n        self.assertEqual(666, query.limit)\n        self.assertEqual(False, query.limit_used)\n        self.assertEqual(True, query.select_as_cta)\n        self.assertEqual(True, query.select_as_cta_used)\n\n    @staticmethod\n    def de_unicode_dict(d):\n        def str_if_basestring(o):\n            if isinstance(o, basestring):\n                return str(o)\n            return o\n        return {str_if_basestring(k): str_if_basestring(d[k]) for k in d}\n\n    @classmethod\n    def dictify_list_of_dicts(cls, l, k):\n        return {str(o[k]): cls.de_unicode_dict(o) for o in l}\n\n    def test_get_columns(self):\n        main_db = self.get_main_database(db.session)\n        df = main_db.get_df('SELECT * FROM multiformat_time_series', None)\n        cdf = dataframe.SupersetDataFrame(df)\n\n        # Making ordering non-deterministic\n        cols = self.dictify_list_of_dicts(cdf.columns, 'name')\n\n        if main_db.sqlalchemy_uri.startswith('sqlite'):\n            self.assertEqual(self.dictify_list_of_dicts([\n                {'is_date': True, 'type': 'STRING', 'name': 'ds',\n                    'is_dim': False},\n                {'is_date': True, 'type': 'STRING', 'name': 'ds2',\n                    'is_dim': False},\n                {'agg': 'sum', 'is_date': False, 'type': 'INT',\n                    'name': 'epoch_ms', 'is_dim': False},\n                {'agg': 'sum', 'is_date': False, 'type': 'INT',\n                    'name': 'epoch_s', 'is_dim': False},\n                {'is_date': True, 'type': 'STRING', 'name': 'string0',\n                    'is_dim': False},\n                {'is_date': False, 'type': 'STRING',\n                    'name': 'string1', 'is_dim': True},\n                {'is_date': True, 'type': 'STRING', 'name': 'string2',\n                    'is_dim': False},\n                {'is_date': False, 'type': 'STRING',\n                    'name': 'string3', 'is_dim': True}], 'name'),\n                cols,\n            )\n        else:\n            self.assertEqual(self.dictify_list_of_dicts([\n                {'is_date': True, 'type': 'DATETIME', 'name': 'ds',\n                    'is_dim': False},\n                {'is_date': True, 'type': 'DATETIME',\n                    'name': 'ds2', 'is_dim': False},\n                {'agg': 'sum', 'is_date': False, 'type': 'INT',\n                    'name': 'epoch_ms', 'is_dim': False},\n                {'agg': 'sum', 'is_date': False, 'type': 'INT',\n                    'name': 'epoch_s', 'is_dim': False},\n                {'is_date': True, 'type': 'STRING', 'name': 'string0',\n                    'is_dim': False},\n                {'is_date': False, 'type': 'STRING',\n                    'name': 'string1', 'is_dim': True},\n                {'is_date': True, 'type': 'STRING', 'name': 'string2',\n                    'is_dim': False},\n                {'is_date': False, 'type': 'STRING',\n                    'name': 'string3', 'is_dim': True}], 'name'),\n                cols,\n            )\n\n\nif __name__ == '__main__':\n    unittest.main()\n", "description": "Apache Superset (incubating) is a modern, enterprise-ready business intelligence web application", "file_name": "celery_tests.py", "id": "7526a54614ba0db3fc7306325a79c904", "language": "Python", "project_name": "incubator-superset", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/apache-incubator-superset/apache-incubator-superset-95a9b04/tests/celery_tests.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:41:03Z", "url": "https://github.com/apache/incubator-superset", "wiki": false}