{"author": "rushter", "code": "import logging\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.datasets import make_regression\nfrom sklearn.metrics import roc_auc_score\ntry:\n    from sklearn.model_selection import train_test_split\nexcept ImportError:\n    from sklearn.cross_validation import train_test_split\n\nfrom mla.ensemble.gbm import GradientBoostingClassifier, GradientBoostingRegressor\nfrom mla.metrics.metrics import mean_squared_error\n\nlogging.basicConfig(level=logging.DEBUG)\n\n\ndef classification():\n    \n    X, y = make_classification(n_samples=350, n_features=15, n_informative=10,\n                               random_state=1111, n_classes=2,\n                               class_sep=1., n_redundant=0)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15,\n                                                        random_state=1111)\n\n    model = GradientBoostingClassifier(n_estimators=50, max_depth=4,\n                                       max_features=8, learning_rate=0.1)\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    print(predictions)\n    print(predictions.min())\n    print(predictions.max())\n    print('classification, roc auc score: %s'\n          % roc_auc_score(y_test, predictions))\n\n\ndef regression():\n    \n    X, y = make_regression(n_samples=500, n_features=5, n_informative=5,\n                           n_targets=1, noise=0.05, random_state=1111,\n                           bias=0.5)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,\n                                                        random_state=1111)\n\n    model = GradientBoostingRegressor(n_estimators=25, max_depth=5,\n                                      max_features=3, )\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    print('regression, mse: %s'\n          % mean_squared_error(y_test.flatten(), predictions.flatten()))\n\n\nif __name__ == '__main__':\n    classification()\n    ()\n", "comments": "  generate random binary classification problem     generate random regression problem    regression() ", "content": "import logging\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.datasets import make_regression\nfrom sklearn.metrics import roc_auc_score\ntry:\n    from sklearn.model_selection import train_test_split\nexcept ImportError:\n    from sklearn.cross_validation import train_test_split\n\nfrom mla.ensemble.gbm import GradientBoostingClassifier, GradientBoostingRegressor\nfrom mla.metrics.metrics import mean_squared_error\n\nlogging.basicConfig(level=logging.DEBUG)\n\n\ndef classification():\n    # Generate a random binary classification problem.\n    X, y = make_classification(n_samples=350, n_features=15, n_informative=10,\n                               random_state=1111, n_classes=2,\n                               class_sep=1., n_redundant=0)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15,\n                                                        random_state=1111)\n\n    model = GradientBoostingClassifier(n_estimators=50, max_depth=4,\n                                       max_features=8, learning_rate=0.1)\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    print(predictions)\n    print(predictions.min())\n    print(predictions.max())\n    print('classification, roc auc score: %s'\n          % roc_auc_score(y_test, predictions))\n\n\ndef regression():\n    # Generate a random regression problem\n    X, y = make_regression(n_samples=500, n_features=5, n_informative=5,\n                           n_targets=1, noise=0.05, random_state=1111,\n                           bias=0.5)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,\n                                                        random_state=1111)\n\n    model = GradientBoostingRegressor(n_estimators=25, max_depth=5,\n                                      max_features=3, )\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    print('regression, mse: %s'\n          % mean_squared_error(y_test.flatten(), predictions.flatten()))\n\n\nif __name__ == '__main__':\n    classification()\n    # regression()\n", "description": "Minimal and clean examples of machine learning algorithms", "file_name": "gbm.py", "id": "ce83d0efc3eb758885efb08822747df5", "language": "Python", "project_name": "MLAlgorithms", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/rushter-MLAlgorithms/rushter-MLAlgorithms-d398777/examples/gbm.py", "save_time": "", "source": "", "update_at": "2018-03-18T15:25:48Z", "url": "https://github.com/rushter/MLAlgorithms", "wiki": false}