{"author": "deepfakes", "code": "# Based on the https://github.com/shaoanlu/faceswap-GAN repo (master/temp/faceswap_GAN_keras.ipynb)\n\nfrom keras.models import Model\nfrom keras.layers import *\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.activations import relu\nfrom keras.initializers import RandomNormal\nfrom keras.applications import *\nfrom keras.optimizers import Adam\n\nfrom lib.PixelShuffler import PixelShuffler\nfrom .instance_normalization import InstanceNormalization\n\nfrom keras.utils import multi_gpu_model\n\nnetGAH5 = 'netGA_GAN.h5'\nnetGBH5 = 'netGB_GAN.h5'\nnetDAH5 = 'netDA_GAN.h5'\nnetDBH5 = 'netDB_GAN.h5'\n\ndef __conv_init(a):\n    print(\"conv_init\", a)\n    k = RandomNormal(0, 0.02)(a) \n    k.conv_weight = True\n    return k\n\n#def batchnorm():\n#    return BatchNormalization(momentum=0.9, axis=channel_axis, epsilon=1.01e-5, gamma_initializer = gamma_init)\n\ndef inst_norm():\n    return InstanceNormalization()\n\nconv_init = RandomNormal(0, 0.02)\ngamma_init = RandomNormal(1., 0.02) \n\nclass GANModel():\n    img_size = 64\n    channels = 3\n    img_shape = (img_size, img_size, channels)\n    encoded_dim = 1024\n    nc_in = 3 \n    nc_D_inp = 6 \n\n    def __init__(self, model_dir, gpus):\n        self.model_dir = model_dir\n        self.gpus = gpus\n\n        optimizer = Adam(1e-4, 0.5)\n\n        \n        self.netDA, self.netDB = self.build_discriminator()\n\n        \n        self.netGA, self.netGB = self.build_generator()\n\n    def converter(self, swap):\n        predictor = self.netGB if not swap else self.netGA\n        return lambda img: predictor.predict(img)\n\n    def build_generator(self):\n\n        def conv_block(input_tensor, f):\n            x = input_tensor\n            x = Conv2D(f, kernel_size=3, strides=2, kernel_initializer=conv_init, use_bias=False, padding=\"same\")(x)\n            x = Activation(\"relu\")(x)\n            return x\n\n        def res_block(input_tensor, f):\n            x = input_tensor\n            x = Conv2D(f, kernel_size=3, kernel_initializer=conv_init, use_bias=False, padding=\"same\")(x)\n            x = LeakyReLU(alpha=0.2)(x)\n            x = Conv2D(f, kernel_size=3, kernel_initializer=conv_init, use_bias=False, padding=\"same\")(x)\n            x = add([x, input_tensor])\n            x = LeakyReLU(alpha=0.2)(x)\n            return x\n\n        def upscale_ps(filters, use_instance_norm=True):\n            def block(x):\n                x = Conv2D(filters*4, kernel_size=3, use_bias=False, kernel_initializer=RandomNormal(0, 0.02), padding='same')(x)\n                x = LeakyReLU(0.1)(x)\n                x = PixelShuffler()(x)\n                return x\n            return block\n\n        def Encoder(nc_in=3, input_size=64):\n            inp = Input(shape=(input_size, input_size, nc_in))\n            x = Conv2D(64, kernel_size=5, kernel_initializer=conv_init, use_bias=False, padding=\"same\")(inp)\n            x = conv_block(x,128)\n            x = conv_block(x,256)\n            x = conv_block(x,512)\n            x = conv_block(x,1024)\n            x = Dense(1024)(Flatten()(x))\n            x = Dense(4*4*1024)(x)\n            x = Reshape((4, 4, 1024))(x)\n            out = upscale_ps(512)(x)\n            return Model(inputs=inp, outputs=out)\n\n        def Decoder_ps(nc_in=512, input_size=8):\n            input_ = Input(shape=(input_size, input_size, nc_in))\n            x = input_\n            x = upscale_ps(256)(x)\n            x = upscale_ps(128)(x)\n            x = upscale_ps(64)(x)\n            x = res_block(x, 64)\n            x = res_block(x, 64)\n            #x = Conv2D(4, kernel_size=5, padding='same')(x)\n            alpha = Conv2D(1, kernel_size=5, padding='same', activation=\"sigmoid\")(x)\n            rgb = Conv2D(3, kernel_size=5, padding='same', activation=\"tanh\")(x)\n            out = concatenate([alpha, rgb])\n            return Model(input_, out )\n\n        encoder = Encoder()\n        decoder_A = Decoder_ps()\n        decoder_B = Decoder_ps()\n        x = Input(shape=self.img_shape)\n        netGA = Model(x, decoder_A(encoder(x)))\n        netGB = Model(x, decoder_B(encoder(x)))\n\n        self.netGA_sm = netGA\n        self.netGB_sm = netGB\n\n        try:\n            netGA.load_weights(str(self.model_dir / netGAH5))\n            netGB.load_weights(str(self.model_dir / netGBH5))\n            print (\"Generator models loaded.\")\n        except:\n            print (\"Generator weights files not found.\")\n            pass\n\n        if self.gpus > 1:\n            netGA = multi_gpu_model( self.netGA_sm , self.gpus)\n            netGB = multi_gpu_model( self.netGB_sm , self.gpus)\n\n        return netGA, netGB\n\n    def build_discriminator(self):\n        def conv_block_d(input_tensor, f, use_instance_norm=True):\n            x = input_tensor\n            x = Conv2D(f, kernel_size=4, strides=2, kernel_initializer=conv_init, use_bias=False, padding=\"same\")(x)\n            x = LeakyReLU(alpha=0.2)(x)\n            return x\n\n        def Discriminator(nc_in, input_size=64):\n            inp = Input(shape=(input_size, input_size, nc_in))\n            #x = GaussianNoise(0.05)(inp)\n            x = conv_block_d(inp, 64, False)\n            x = conv_block_d(x, 128, False)\n            x = conv_block_d(x, 256, False)\n            out = Conv2D(1, kernel_size=4, kernel_initializer=conv_init, use_bias=False, padding=\"same\", activation=\"sigmoid\")(x)\n            return Model(inputs=[inp], outputs=out)\n\n        netDA = Discriminator(self.nc_D_inp)\n        netDB = Discriminator(self.nc_D_inp)\n        try:\n            netDA.load_weights(str(self.model_dir / netDAH5))\n            netDB.load_weights(str(self.model_dir / netDBH5))\n            print (\"Discriminator models loaded.\")\n        except:\n            print (\"Discriminator weights files not found.\")\n            pass\n        return netDA, netDB\n\n    def load(self, swapped):\n        if swapped:\n            print(\"swapping not supported on GAN\")\n            \n        return True\n\n    def save_weights(self):\n        if self.gpus > 1:\n            self.netGA_sm.save_weights(str(self.model_dir / netGAH5))\n            self.netGB_sm.save_weights(str(self.model_dir / netGBH5))\n        else:\n            self.netGA.save_weights(str(self.model_dir / netGAH5))\n            self.netGB.save_weights(str(self.model_dir / netGBH5))\n        self.netDA.save_weights(str(self.model_dir / netDAH5))\n        self.netDB.save_weights(str(self.model_dir / netDBH5))\n        print (\"Models saved.\")\n", "comments": "  based https   github com shaoanlu faceswap gan repo (master temp faceswap gan keras ipynb)    convolution kernel   def batchnorm()        return batchnormalization(momentum 0 9  axis channel axis  epsilon 1 01e 5  gamma initializer   gamma init)    batch normalization    number input channels generators    number input channels discriminators    build compile discriminator    build compile generator   x   conv2d(4  kernel size 5  padding  )(x)   x   gaussiannoise(0 05)(inp)    todo load done   init      look swap possible ", "content": "# Based on the https://github.com/shaoanlu/faceswap-GAN repo (master/temp/faceswap_GAN_keras.ipynb)\n\nfrom keras.models import Model\nfrom keras.layers import *\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.activations import relu\nfrom keras.initializers import RandomNormal\nfrom keras.applications import *\nfrom keras.optimizers import Adam\n\nfrom lib.PixelShuffler import PixelShuffler\nfrom .instance_normalization import InstanceNormalization\n\nfrom keras.utils import multi_gpu_model\n\nnetGAH5 = 'netGA_GAN.h5'\nnetGBH5 = 'netGB_GAN.h5'\nnetDAH5 = 'netDA_GAN.h5'\nnetDBH5 = 'netDB_GAN.h5'\n\ndef __conv_init(a):\n    print(\"conv_init\", a)\n    k = RandomNormal(0, 0.02)(a) # for convolution kernel\n    k.conv_weight = True\n    return k\n\n#def batchnorm():\n#    return BatchNormalization(momentum=0.9, axis=channel_axis, epsilon=1.01e-5, gamma_initializer = gamma_init)\n\ndef inst_norm():\n    return InstanceNormalization()\n\nconv_init = RandomNormal(0, 0.02)\ngamma_init = RandomNormal(1., 0.02) # for batch normalization\n\nclass GANModel():\n    img_size = 64\n    channels = 3\n    img_shape = (img_size, img_size, channels)\n    encoded_dim = 1024\n    nc_in = 3 # number of input channels of generators\n    nc_D_inp = 6 # number of input channels of discriminators\n\n    def __init__(self, model_dir, gpus):\n        self.model_dir = model_dir\n        self.gpus = gpus\n\n        optimizer = Adam(1e-4, 0.5)\n\n        # Build and compile the discriminator\n        self.netDA, self.netDB = self.build_discriminator()\n\n        # Build and compile the generator\n        self.netGA, self.netGB = self.build_generator()\n\n    def converter(self, swap):\n        predictor = self.netGB if not swap else self.netGA\n        return lambda img: predictor.predict(img)\n\n    def build_generator(self):\n\n        def conv_block(input_tensor, f):\n            x = input_tensor\n            x = Conv2D(f, kernel_size=3, strides=2, kernel_initializer=conv_init, use_bias=False, padding=\"same\")(x)\n            x = Activation(\"relu\")(x)\n            return x\n\n        def res_block(input_tensor, f):\n            x = input_tensor\n            x = Conv2D(f, kernel_size=3, kernel_initializer=conv_init, use_bias=False, padding=\"same\")(x)\n            x = LeakyReLU(alpha=0.2)(x)\n            x = Conv2D(f, kernel_size=3, kernel_initializer=conv_init, use_bias=False, padding=\"same\")(x)\n            x = add([x, input_tensor])\n            x = LeakyReLU(alpha=0.2)(x)\n            return x\n\n        def upscale_ps(filters, use_instance_norm=True):\n            def block(x):\n                x = Conv2D(filters*4, kernel_size=3, use_bias=False, kernel_initializer=RandomNormal(0, 0.02), padding='same')(x)\n                x = LeakyReLU(0.1)(x)\n                x = PixelShuffler()(x)\n                return x\n            return block\n\n        def Encoder(nc_in=3, input_size=64):\n            inp = Input(shape=(input_size, input_size, nc_in))\n            x = Conv2D(64, kernel_size=5, kernel_initializer=conv_init, use_bias=False, padding=\"same\")(inp)\n            x = conv_block(x,128)\n            x = conv_block(x,256)\n            x = conv_block(x,512)\n            x = conv_block(x,1024)\n            x = Dense(1024)(Flatten()(x))\n            x = Dense(4*4*1024)(x)\n            x = Reshape((4, 4, 1024))(x)\n            out = upscale_ps(512)(x)\n            return Model(inputs=inp, outputs=out)\n\n        def Decoder_ps(nc_in=512, input_size=8):\n            input_ = Input(shape=(input_size, input_size, nc_in))\n            x = input_\n            x = upscale_ps(256)(x)\n            x = upscale_ps(128)(x)\n            x = upscale_ps(64)(x)\n            x = res_block(x, 64)\n            x = res_block(x, 64)\n            #x = Conv2D(4, kernel_size=5, padding='same')(x)\n            alpha = Conv2D(1, kernel_size=5, padding='same', activation=\"sigmoid\")(x)\n            rgb = Conv2D(3, kernel_size=5, padding='same', activation=\"tanh\")(x)\n            out = concatenate([alpha, rgb])\n            return Model(input_, out )\n\n        encoder = Encoder()\n        decoder_A = Decoder_ps()\n        decoder_B = Decoder_ps()\n        x = Input(shape=self.img_shape)\n        netGA = Model(x, decoder_A(encoder(x)))\n        netGB = Model(x, decoder_B(encoder(x)))\n\n        self.netGA_sm = netGA\n        self.netGB_sm = netGB\n\n        try:\n            netGA.load_weights(str(self.model_dir / netGAH5))\n            netGB.load_weights(str(self.model_dir / netGBH5))\n            print (\"Generator models loaded.\")\n        except:\n            print (\"Generator weights files not found.\")\n            pass\n\n        if self.gpus > 1:\n            netGA = multi_gpu_model( self.netGA_sm , self.gpus)\n            netGB = multi_gpu_model( self.netGB_sm , self.gpus)\n\n        return netGA, netGB\n\n    def build_discriminator(self):\n        def conv_block_d(input_tensor, f, use_instance_norm=True):\n            x = input_tensor\n            x = Conv2D(f, kernel_size=4, strides=2, kernel_initializer=conv_init, use_bias=False, padding=\"same\")(x)\n            x = LeakyReLU(alpha=0.2)(x)\n            return x\n\n        def Discriminator(nc_in, input_size=64):\n            inp = Input(shape=(input_size, input_size, nc_in))\n            #x = GaussianNoise(0.05)(inp)\n            x = conv_block_d(inp, 64, False)\n            x = conv_block_d(x, 128, False)\n            x = conv_block_d(x, 256, False)\n            out = Conv2D(1, kernel_size=4, kernel_initializer=conv_init, use_bias=False, padding=\"same\", activation=\"sigmoid\")(x)\n            return Model(inputs=[inp], outputs=out)\n\n        netDA = Discriminator(self.nc_D_inp)\n        netDB = Discriminator(self.nc_D_inp)\n        try:\n            netDA.load_weights(str(self.model_dir / netDAH5))\n            netDB.load_weights(str(self.model_dir / netDBH5))\n            print (\"Discriminator models loaded.\")\n        except:\n            print (\"Discriminator weights files not found.\")\n            pass\n        return netDA, netDB\n\n    def load(self, swapped):\n        if swapped:\n            print(\"swapping not supported on GAN\")\n            # TODO load is done in __init__ => look how to swap if possible\n        return True\n\n    def save_weights(self):\n        if self.gpus > 1:\n            self.netGA_sm.save_weights(str(self.model_dir / netGAH5))\n            self.netGB_sm.save_weights(str(self.model_dir / netGBH5))\n        else:\n            self.netGA.save_weights(str(self.model_dir / netGAH5))\n            self.netGB.save_weights(str(self.model_dir / netGBH5))\n        self.netDA.save_weights(str(self.model_dir / netDAH5))\n        self.netDB.save_weights(str(self.model_dir / netDBH5))\n        print (\"Models saved.\")\n", "description": "Non official project based on original /r/Deepfakes thread. Many thanks to him!", "file_name": "Model.py", "id": "bb5f5ace7d27431afdd46ff3e1efd03c", "language": "Python", "project_name": "faceswap", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/deepfakes-faceswap/deepfakes-faceswap-6ff64ef/plugins/Model_GAN/Model.py", "save_time": "", "source": "", "update_at": "2018-03-18T16:27:43Z", "url": "https://github.com/deepfakes/faceswap", "wiki": true}