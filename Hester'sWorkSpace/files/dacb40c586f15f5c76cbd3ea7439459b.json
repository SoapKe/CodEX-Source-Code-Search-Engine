{"author": "rg3", "code": "from __future__ import unicode_literals\n\nimport re\n\nfrom .common import InfoExtractor\nfrom ..utils import (\n    determine_ext,\n    ExtractorError,\n    int_or_none,\n    lowercase_escape,\n    update_url_query,\n)\n\n\nclass GoogleDriveIE(InfoExtractor):\n    _VALID_URL = r\n    _TESTS = [{\n        'url': 'https://drive.google.com/file/d/0ByeS4oOUV-49Zzh4R1J6R09zazQ/edit?pli=1',\n        'md5': '5c602afbbf2c1db91831f5d82f678554',\n        'info_dict': {\n            'id': '0ByeS4oOUV-49Zzh4R1J6R09zazQ',\n            'ext': 'mp4',\n            'title': 'Big Buck Bunny.mp4',\n            'duration': 45,\n        }\n    }, {\n        \n        \n        'url': 'https://drive.google.com/file/d/0B-vUyvmDLdWDcEt4WjBqcmI2XzQ/view',\n        'md5': 'bfbd670d03a470bb1e6d4a257adec12e',\n        'info_dict': {\n            'id': '0B-vUyvmDLdWDcEt4WjBqcmI2XzQ',\n            'ext': 'mp4',\n            'title': 'Annabelle Creation (2017)- Z.V1 [TH].MP4',\n        }\n    }, {\n        \n        'url': 'https://drive.google.com/file/d/1ENcQ_jeCuj7y19s66_Ou9dRP4GKGsodiDQ/edit',\n        'info_dict': {\n            'id': '1ENcQ_jeCuj7y19s66_Ou9dRP4GKGsodiDQ',\n            'ext': 'mp4',\n            'title': 'Andreea Banica feat Smiley - Hooky Song (Official Video).mp4',\n            'duration': 189,\n        },\n        'only_matching': True,\n    }, {\n        'url': 'https://drive.google.com/open?id=0B2fjwgkl1A_CX083Tkowdmt6d28',\n        'only_matching': True,\n    }, {\n        'url': 'https://drive.google.com/uc?id=0B2fjwgkl1A_CX083Tkowdmt6d28',\n        'only_matching': True,\n    }]\n    _FORMATS_EXT = {\n        '5': 'flv',\n        '6': 'flv',\n        '13': '3gp',\n        '17': '3gp',\n        '18': 'mp4',\n        '22': 'mp4',\n        '34': 'flv',\n        '35': 'flv',\n        '36': '3gp',\n        '37': 'mp4',\n        '38': 'mp4',\n        '43': 'webm',\n        '44': 'webm',\n        '45': 'webm',\n        '46': 'webm',\n        '59': 'mp4',\n    }\n    _BASE_URL_CAPTIONS = 'https://drive.google.com/timedtext'\n    _CAPTIONS_ENTRY_TAG = {\n        'subtitles': 'track',\n        'automatic_captions': 'target',\n    }\n    _caption_formats_ext = []\n    _captions_xml = None\n\n    @staticmethod\n    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+src=\"https?://(?:video\\.google\\.com/get_player\\?.*?docid=|(?:docs|drive)\\.google\\.com/file/d/)(?P<id>[a-zA-Z0-9_-]{28,})',\n            webpage)\n        if mobj:\n            return 'https://drive.google.com/file/d/%s' % mobj.group('id')\n\n    def _download_subtitles_xml(self, video_id, subtitles_id, hl):\n        if self._captions_xml:\n            return\n        self._captions_xml = self._download_xml(\n            self._BASE_URL_CAPTIONS, video_id, query={\n                'id': video_id,\n                'vid': subtitles_id,\n                'hl': hl,\n                'v': video_id,\n                'type': 'list',\n                'tlangs': '1',\n                'fmts': '1',\n                'vssids': '1',\n            }, note='Downloading subtitles XML',\n            errnote='Unable to download subtitles XML', fatal=False)\n        if self._captions_xml:\n            for f in self._captions_xml.findall('format'):\n                if f.attrib.get('fmt_code') and not f.attrib.get('default'):\n                    self._caption_formats_ext.append(f.attrib['fmt_code'])\n\n    def _get_captions_by_type(self, video_id, subtitles_id, caption_type,\n                              origin_lang_code=None):\n        if not subtitles_id or not caption_type:\n            return\n        captions = {}\n        for caption_entry in self._captions_xml.findall(\n                self._CAPTIONS_ENTRY_TAG[caption_type]):\n            caption_lang_code = caption_entry.attrib.get('lang_code')\n            if not caption_lang_code:\n                continue\n            caption_format_data = []\n            for caption_format in self._caption_formats_ext:\n                query = {\n                    'vid': subtitles_id,\n                    'v': video_id,\n                    'fmt': caption_format,\n                    'lang': (caption_lang_code if origin_lang_code is None\n                             else origin_lang_code),\n                    'type': 'track',\n                    'name': '',\n                    'kind': '',\n                }\n                if origin_lang_code is not None:\n                    query.update({'tlang': caption_lang_code})\n                caption_format_data.append({\n                    'url': update_url_query(self._BASE_URL_CAPTIONS, query),\n                    'ext': caption_format,\n                })\n            captions[caption_lang_code] = caption_format_data\n        return captions\n\n    def _get_subtitles(self, video_id, subtitles_id, hl):\n        if not subtitles_id or not hl:\n            return\n        self._download_subtitles_xml(video_id, subtitles_id, hl)\n        if not self._captions_xml:\n            return\n        return self._get_captions_by_type(video_id, subtitles_id, 'subtitles')\n\n    def _get_automatic_captions(self, video_id, subtitles_id, hl):\n        if not subtitles_id or not hl:\n            return\n        self._download_subtitles_xml(video_id, subtitles_id, hl)\n        if not self._captions_xml:\n            return\n        track = self._captions_xml.find('track')\n        if track is None:\n            return\n        origin_lang_code = track.attrib.get('lang_code')\n        if not origin_lang_code:\n            return\n        return self._get_captions_by_type(\n            video_id, subtitles_id, 'automatic_captions', origin_lang_code)\n\n    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(\n            'http://docs.google.com/file/d/%s' % video_id, video_id)\n\n        title = self._search_regex(\n            r'\"title\"\\s*,\\s*\"([^\"]+)', webpage, 'title',\n            default=None) or self._og_search_title(webpage)\n        duration = int_or_none(self._search_regex(\n            r'\"length_seconds\"\\s*,\\s*\"([^\"]+)', webpage, 'length seconds',\n            default=None))\n\n        formats = []\n        fmt_stream_map = self._search_regex(\n            r'\"fmt_stream_map\"\\s*,\\s*\"([^\"]+)', webpage,\n            'fmt stream map', default='').split(',')\n        fmt_list = self._search_regex(\n            r'\"fmt_list\"\\s*,\\s*\"([^\"]+)', webpage,\n            'fmt_list', default='').split(',')\n        if fmt_stream_map and fmt_list:\n            resolutions = {}\n            for fmt in fmt_list:\n                mobj = re.search(\n                    r'^(?P<format_id>\\d+)/(?P<width>\\d+)[xX](?P<height>\\d+)', fmt)\n                if mobj:\n                    resolutions[mobj.group('format_id')] = (\n                        int(mobj.group('width')), int(mobj.group('height')))\n\n            for fmt_stream in fmt_stream_map:\n                fmt_stream_split = fmt_stream.split('|')\n                if len(fmt_stream_split) < 2:\n                    continue\n                format_id, format_url = fmt_stream_split[:2]\n                f = {\n                    'url': lowercase_escape(format_url),\n                    'format_id': format_id,\n                    'ext': self._FORMATS_EXT[format_id],\n                }\n                resolution = resolutions.get(format_id)\n                if resolution:\n                    f.update({\n                        'width': resolution[0],\n                        'height': resolution[1],\n                    })\n                formats.append(f)\n\n        source_url = update_url_query(\n            'https://drive.google.com/uc', {\n                'id': video_id,\n                'export': 'download',\n            })\n        urlh = self._request_webpage(\n            source_url, video_id, note='Requesting source file',\n            errnote='Unable to request source file', fatal=False)\n        if urlh:\n            def add_source_format(src_url):\n                formats.append({\n                    'url': src_url,\n                    'ext': determine_ext(title, 'mp4').lower(),\n                    'format_id': 'source',\n                    'quality': 1,\n                })\n            if urlh.headers.get('Content-Disposition'):\n                add_source_format(source_url)\n            else:\n                confirmation_webpage = self._webpage_read_content(\n                    urlh, url, video_id, note='Downloading confirmation page',\n                    errnote='Unable to confirm download', fatal=False)\n                if confirmation_webpage:\n                    confirm = self._search_regex(\n                        r'confirm=([^&\"\\']+)', confirmation_webpage,\n                        'confirmation code', fatal=False)\n                    if confirm:\n                        add_source_format(update_url_query(source_url, {\n                            'confirm': confirm,\n                        }))\n\n        if not formats:\n            reason = self._search_regex(\n                r'\"reason\"\\s*,\\s*\"([^\"]+)', webpage, 'reason', default=None)\n            if reason:\n                raise ExtractorError(reason, expected=True)\n\n        self._sort_formats(formats)\n\n        hl = self._search_regex(\n            r'\"hl\"\\s*,\\s*\"([^\"]+)', webpage, 'hl', default=None)\n        subtitles_id = None\n        ttsurl = self._search_regex(\n            r'\"ttsurl\"\\s*,\\s*\"([^\"]+)', webpage, 'ttsurl', default=None)\n        if ttsurl:\n            \n            \n            subtitles_id = ttsurl.encode('utf-8').decode(\n                'unicode_escape').split('=')[-1]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': self._og_search_thumbnail(webpage, default=None),\n            'duration': duration,\n            'formats': formats,\n            'subtitles': self.extract_subtitles(video_id, subtitles_id, hl),\n            'automatic_captions': self.extract_automatic_captions(\n                video_id, subtitles_id, hl),\n        }\n", "comments": "(?x)\n                        https?://\n                            (?:\n                                (?:docs|drive)\\.google\\.com/\n                                (?:\n                                    (?:uc|open)\\?.*?id=|\n                                    file/d/\n                                )|\n                                video\\.google\\.com/get_player\\?.*?docid=\n                            )\n                            (?P<id>[a-zA-Z0-9_-]{28,})\n                    \n \n# video can't be watched anonymously due to view count limit reached,\n# but can be downloaded (see https://github.com/rg3/youtube-dl/issues/14046)\n# video id is longer than 28 characters\n# the video Id for subtitles will be the last value in the ttsurl\n# query string\n", "content": "from __future__ import unicode_literals\n\nimport re\n\nfrom .common import InfoExtractor\nfrom ..utils import (\n    determine_ext,\n    ExtractorError,\n    int_or_none,\n    lowercase_escape,\n    update_url_query,\n)\n\n\nclass GoogleDriveIE(InfoExtractor):\n    _VALID_URL = r'''(?x)\n                        https?://\n                            (?:\n                                (?:docs|drive)\\.google\\.com/\n                                (?:\n                                    (?:uc|open)\\?.*?id=|\n                                    file/d/\n                                )|\n                                video\\.google\\.com/get_player\\?.*?docid=\n                            )\n                            (?P<id>[a-zA-Z0-9_-]{28,})\n                    '''\n    _TESTS = [{\n        'url': 'https://drive.google.com/file/d/0ByeS4oOUV-49Zzh4R1J6R09zazQ/edit?pli=1',\n        'md5': '5c602afbbf2c1db91831f5d82f678554',\n        'info_dict': {\n            'id': '0ByeS4oOUV-49Zzh4R1J6R09zazQ',\n            'ext': 'mp4',\n            'title': 'Big Buck Bunny.mp4',\n            'duration': 45,\n        }\n    }, {\n        # video can't be watched anonymously due to view count limit reached,\n        # but can be downloaded (see https://github.com/rg3/youtube-dl/issues/14046)\n        'url': 'https://drive.google.com/file/d/0B-vUyvmDLdWDcEt4WjBqcmI2XzQ/view',\n        'md5': 'bfbd670d03a470bb1e6d4a257adec12e',\n        'info_dict': {\n            'id': '0B-vUyvmDLdWDcEt4WjBqcmI2XzQ',\n            'ext': 'mp4',\n            'title': 'Annabelle Creation (2017)- Z.V1 [TH].MP4',\n        }\n    }, {\n        # video id is longer than 28 characters\n        'url': 'https://drive.google.com/file/d/1ENcQ_jeCuj7y19s66_Ou9dRP4GKGsodiDQ/edit',\n        'info_dict': {\n            'id': '1ENcQ_jeCuj7y19s66_Ou9dRP4GKGsodiDQ',\n            'ext': 'mp4',\n            'title': 'Andreea Banica feat Smiley - Hooky Song (Official Video).mp4',\n            'duration': 189,\n        },\n        'only_matching': True,\n    }, {\n        'url': 'https://drive.google.com/open?id=0B2fjwgkl1A_CX083Tkowdmt6d28',\n        'only_matching': True,\n    }, {\n        'url': 'https://drive.google.com/uc?id=0B2fjwgkl1A_CX083Tkowdmt6d28',\n        'only_matching': True,\n    }]\n    _FORMATS_EXT = {\n        '5': 'flv',\n        '6': 'flv',\n        '13': '3gp',\n        '17': '3gp',\n        '18': 'mp4',\n        '22': 'mp4',\n        '34': 'flv',\n        '35': 'flv',\n        '36': '3gp',\n        '37': 'mp4',\n        '38': 'mp4',\n        '43': 'webm',\n        '44': 'webm',\n        '45': 'webm',\n        '46': 'webm',\n        '59': 'mp4',\n    }\n    _BASE_URL_CAPTIONS = 'https://drive.google.com/timedtext'\n    _CAPTIONS_ENTRY_TAG = {\n        'subtitles': 'track',\n        'automatic_captions': 'target',\n    }\n    _caption_formats_ext = []\n    _captions_xml = None\n\n    @staticmethod\n    def _extract_url(webpage):\n        mobj = re.search(\n            r'<iframe[^>]+src=\"https?://(?:video\\.google\\.com/get_player\\?.*?docid=|(?:docs|drive)\\.google\\.com/file/d/)(?P<id>[a-zA-Z0-9_-]{28,})',\n            webpage)\n        if mobj:\n            return 'https://drive.google.com/file/d/%s' % mobj.group('id')\n\n    def _download_subtitles_xml(self, video_id, subtitles_id, hl):\n        if self._captions_xml:\n            return\n        self._captions_xml = self._download_xml(\n            self._BASE_URL_CAPTIONS, video_id, query={\n                'id': video_id,\n                'vid': subtitles_id,\n                'hl': hl,\n                'v': video_id,\n                'type': 'list',\n                'tlangs': '1',\n                'fmts': '1',\n                'vssids': '1',\n            }, note='Downloading subtitles XML',\n            errnote='Unable to download subtitles XML', fatal=False)\n        if self._captions_xml:\n            for f in self._captions_xml.findall('format'):\n                if f.attrib.get('fmt_code') and not f.attrib.get('default'):\n                    self._caption_formats_ext.append(f.attrib['fmt_code'])\n\n    def _get_captions_by_type(self, video_id, subtitles_id, caption_type,\n                              origin_lang_code=None):\n        if not subtitles_id or not caption_type:\n            return\n        captions = {}\n        for caption_entry in self._captions_xml.findall(\n                self._CAPTIONS_ENTRY_TAG[caption_type]):\n            caption_lang_code = caption_entry.attrib.get('lang_code')\n            if not caption_lang_code:\n                continue\n            caption_format_data = []\n            for caption_format in self._caption_formats_ext:\n                query = {\n                    'vid': subtitles_id,\n                    'v': video_id,\n                    'fmt': caption_format,\n                    'lang': (caption_lang_code if origin_lang_code is None\n                             else origin_lang_code),\n                    'type': 'track',\n                    'name': '',\n                    'kind': '',\n                }\n                if origin_lang_code is not None:\n                    query.update({'tlang': caption_lang_code})\n                caption_format_data.append({\n                    'url': update_url_query(self._BASE_URL_CAPTIONS, query),\n                    'ext': caption_format,\n                })\n            captions[caption_lang_code] = caption_format_data\n        return captions\n\n    def _get_subtitles(self, video_id, subtitles_id, hl):\n        if not subtitles_id or not hl:\n            return\n        self._download_subtitles_xml(video_id, subtitles_id, hl)\n        if not self._captions_xml:\n            return\n        return self._get_captions_by_type(video_id, subtitles_id, 'subtitles')\n\n    def _get_automatic_captions(self, video_id, subtitles_id, hl):\n        if not subtitles_id or not hl:\n            return\n        self._download_subtitles_xml(video_id, subtitles_id, hl)\n        if not self._captions_xml:\n            return\n        track = self._captions_xml.find('track')\n        if track is None:\n            return\n        origin_lang_code = track.attrib.get('lang_code')\n        if not origin_lang_code:\n            return\n        return self._get_captions_by_type(\n            video_id, subtitles_id, 'automatic_captions', origin_lang_code)\n\n    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage = self._download_webpage(\n            'http://docs.google.com/file/d/%s' % video_id, video_id)\n\n        title = self._search_regex(\n            r'\"title\"\\s*,\\s*\"([^\"]+)', webpage, 'title',\n            default=None) or self._og_search_title(webpage)\n        duration = int_or_none(self._search_regex(\n            r'\"length_seconds\"\\s*,\\s*\"([^\"]+)', webpage, 'length seconds',\n            default=None))\n\n        formats = []\n        fmt_stream_map = self._search_regex(\n            r'\"fmt_stream_map\"\\s*,\\s*\"([^\"]+)', webpage,\n            'fmt stream map', default='').split(',')\n        fmt_list = self._search_regex(\n            r'\"fmt_list\"\\s*,\\s*\"([^\"]+)', webpage,\n            'fmt_list', default='').split(',')\n        if fmt_stream_map and fmt_list:\n            resolutions = {}\n            for fmt in fmt_list:\n                mobj = re.search(\n                    r'^(?P<format_id>\\d+)/(?P<width>\\d+)[xX](?P<height>\\d+)', fmt)\n                if mobj:\n                    resolutions[mobj.group('format_id')] = (\n                        int(mobj.group('width')), int(mobj.group('height')))\n\n            for fmt_stream in fmt_stream_map:\n                fmt_stream_split = fmt_stream.split('|')\n                if len(fmt_stream_split) < 2:\n                    continue\n                format_id, format_url = fmt_stream_split[:2]\n                f = {\n                    'url': lowercase_escape(format_url),\n                    'format_id': format_id,\n                    'ext': self._FORMATS_EXT[format_id],\n                }\n                resolution = resolutions.get(format_id)\n                if resolution:\n                    f.update({\n                        'width': resolution[0],\n                        'height': resolution[1],\n                    })\n                formats.append(f)\n\n        source_url = update_url_query(\n            'https://drive.google.com/uc', {\n                'id': video_id,\n                'export': 'download',\n            })\n        urlh = self._request_webpage(\n            source_url, video_id, note='Requesting source file',\n            errnote='Unable to request source file', fatal=False)\n        if urlh:\n            def add_source_format(src_url):\n                formats.append({\n                    'url': src_url,\n                    'ext': determine_ext(title, 'mp4').lower(),\n                    'format_id': 'source',\n                    'quality': 1,\n                })\n            if urlh.headers.get('Content-Disposition'):\n                add_source_format(source_url)\n            else:\n                confirmation_webpage = self._webpage_read_content(\n                    urlh, url, video_id, note='Downloading confirmation page',\n                    errnote='Unable to confirm download', fatal=False)\n                if confirmation_webpage:\n                    confirm = self._search_regex(\n                        r'confirm=([^&\"\\']+)', confirmation_webpage,\n                        'confirmation code', fatal=False)\n                    if confirm:\n                        add_source_format(update_url_query(source_url, {\n                            'confirm': confirm,\n                        }))\n\n        if not formats:\n            reason = self._search_regex(\n                r'\"reason\"\\s*,\\s*\"([^\"]+)', webpage, 'reason', default=None)\n            if reason:\n                raise ExtractorError(reason, expected=True)\n\n        self._sort_formats(formats)\n\n        hl = self._search_regex(\n            r'\"hl\"\\s*,\\s*\"([^\"]+)', webpage, 'hl', default=None)\n        subtitles_id = None\n        ttsurl = self._search_regex(\n            r'\"ttsurl\"\\s*,\\s*\"([^\"]+)', webpage, 'ttsurl', default=None)\n        if ttsurl:\n            # the video Id for subtitles will be the last value in the ttsurl\n            # query string\n            subtitles_id = ttsurl.encode('utf-8').decode(\n                'unicode_escape').split('=')[-1]\n\n        return {\n            'id': video_id,\n            'title': title,\n            'thumbnail': self._og_search_thumbnail(webpage, default=None),\n            'duration': duration,\n            'formats': formats,\n            'subtitles': self.extract_subtitles(video_id, subtitles_id, hl),\n            'automatic_captions': self.extract_automatic_captions(\n                video_id, subtitles_id, hl),\n        }\n", "description": "Command-line program to download videos from YouTube.com and other video sites", "file_name": "googledrive.py", "language": "Python", "project_name": "youtube-dl", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/rg3_youtube-dl/rg3-youtube-dl-6202f08/youtube_dl/extractor/googledrive.py", "save_time": "", "source": "", "update_at": "2018-03-07T09:18:39Z", "url": "https://github.com/rg3/youtube-dl", "wiki": false}