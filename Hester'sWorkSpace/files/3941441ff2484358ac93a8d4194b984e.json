{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\n\"\"\"CIFAR dataset input module.\n\"\"\"\n\nimport tensorflow as tf\n\ndef build_input(dataset, data_path, batch_size, mode):\n  \"\"\"Build CIFAR image and labels.\n\n  Args:\n    dataset: Either 'cifar10' or 'cifar100'.\n    data_path: Filename for data.\n    batch_size: Input batch size.\n    mode: Either 'train' or 'eval'.\n  Returns:\n    images: Batches of images. [batch_size, image_size, image_size, 3]\n    labels: Batches of labels. [batch_size, num_classes]\n  Raises:\n    ValueError: when the specified dataset is not supported.\n  \"\"\"\n  image_size = 32\n  if dataset == 'cifar10':\n    label_bytes = 1\n    label_offset = 0\n    num_classes = 10\n  elif dataset == 'cifar100':\n    label_bytes = 1\n    label_offset = 1\n    num_classes = 100\n  else:\n    raise ValueError('Not supported dataset %s', dataset)\n\n  depth = 3\n  image_bytes = image_size * image_size * depth\n  record_bytes = label_bytes + label_offset + image_bytes\n\n  data_files = tf.gfile.Glob(data_path)\n  file_queue = tf.train.string_input_producer(data_files, shuffle=True)\n   Read examples from files in the filename queue.\n  reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n  _, value = reader.read(file_queue)\n\n   Convert these examples to dense labels and processed images.\n  record = tf.reshape(tf.decode_raw(value, tf.uint8), [record_bytes])\n  label = tf.cast(tf.slice(record, [label_offset], [label_bytes]), tf.int32)\n   Convert from string to [depth * height * width] to [depth, height, width].\n  depth_major = tf.reshape(tf.slice(record, [label_offset + label_bytes], [image_bytes]),\n                           [depth, image_size, image_size])\n   Convert from [depth, height, width] to [height, width, depth].\n  image = tf.cast(tf.transpose(depth_major, [1, 2, 0]), tf.float32)\n\n  if mode == 'train':\n    image = tf.image.resize_image_with_crop_or_pad(\n        image, image_size+4, image_size+4)\n    image = tf.random_crop(image, [image_size, image_size, 3])\n    image = tf.image.random_flip_left_right(image)\n     Brightness/saturation/constrast provides small gains .2%~.5% on cifar.\n     image = tf.image.random_brightness(image, max_delta=63. / 255.)\n     image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n     image = tf.image.random_contrast(image, lower=0.2, upper=1.8)\n    image = tf.image.per_image_standardization(image)\n\n    example_queue = tf.RandomShuffleQueue(\n        capacity=16 * batch_size,\n        min_after_dequeue=8 * batch_size,\n        dtypes=[tf.float32, tf.int32],\n        shapes=[[image_size, image_size, depth], [1]])\n    num_threads = 16\n  else:\n    image = tf.image.resize_image_with_crop_or_pad(\n        image, image_size, image_size)\n    image = tf.image.per_image_standardization(image)\n\n    example_queue = tf.FIFOQueue(\n        3 * batch_size,\n        dtypes=[tf.float32, tf.int32],\n        shapes=[[image_size, image_size, depth], [1]])\n    num_threads = 1\n\n  example_enqueue_op = example_queue.enqueue([image, label])\n  tf.train.add_queue_runner(tf.train.queue_runner.QueueRunner(\n      example_queue, [example_enqueue_op] * num_threads))\n\n   Read 'batch' labels + images from the example queue.\n  images, labels = example_queue.dequeue_many(batch_size)\n  labels = tf.reshape(labels, [batch_size, 1])\n  indices = tf.reshape(tf.range(0, batch_size, 1), [batch_size, 1])\n  labels = tf.sparse_to_dense(\n      tf.concat(values=[indices, labels], axis=1),\n      [batch_size, num_classes], 1.0, 0.0)\n\n  assert len(images.get_shape()) == 4\n  assert images.get_shape()[0] == batch_size\n  assert images.get_shape()[-1] == 3\n  assert len(labels.get_shape()) == 2\n  assert labels.get_shape()[0] == batch_size\n  assert labels.get_shape()[1] == num_classes\n\n   Display the training images in the visualizer.\n  tf.summary.image('images', images)\n  return images, labels\n", "comments": "   cifar dataset input module       import tensorflow tf  def build input(dataset  data path  batch size  mode)       build cifar image labels     args      dataset  either  cifar10   cifar100       data path  filename data      batch size  input batch size      mode  either  train   eval     returns      images  batches images   batch size  image size  image size  3      labels  batches labels   batch size  num classes    raises      valueerror  specified dataset supported           copyright 2016 the tensorflow authors  all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                       read examples files filename queue     convert examples dense labels processed images     convert string  depth   height   width   depth  height  width      convert  depth  height  width   height  width  depth      brightness saturation constrast provides small gains  2   5  cifar     image   tf image random brightness(image  max delta 63    255 )    image   tf image random saturation(image  lower 0 5  upper 1 5)    image   tf image random contrast(image  lower 0 2  upper 1 8)    read  batch  labels   images example queue     display training images visualizer  ", "content": "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n\"\"\"CIFAR dataset input module.\n\"\"\"\n\nimport tensorflow as tf\n\ndef build_input(dataset, data_path, batch_size, mode):\n  \"\"\"Build CIFAR image and labels.\n\n  Args:\n    dataset: Either 'cifar10' or 'cifar100'.\n    data_path: Filename for data.\n    batch_size: Input batch size.\n    mode: Either 'train' or 'eval'.\n  Returns:\n    images: Batches of images. [batch_size, image_size, image_size, 3]\n    labels: Batches of labels. [batch_size, num_classes]\n  Raises:\n    ValueError: when the specified dataset is not supported.\n  \"\"\"\n  image_size = 32\n  if dataset == 'cifar10':\n    label_bytes = 1\n    label_offset = 0\n    num_classes = 10\n  elif dataset == 'cifar100':\n    label_bytes = 1\n    label_offset = 1\n    num_classes = 100\n  else:\n    raise ValueError('Not supported dataset %s', dataset)\n\n  depth = 3\n  image_bytes = image_size * image_size * depth\n  record_bytes = label_bytes + label_offset + image_bytes\n\n  data_files = tf.gfile.Glob(data_path)\n  file_queue = tf.train.string_input_producer(data_files, shuffle=True)\n  # Read examples from files in the filename queue.\n  reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n  _, value = reader.read(file_queue)\n\n  # Convert these examples to dense labels and processed images.\n  record = tf.reshape(tf.decode_raw(value, tf.uint8), [record_bytes])\n  label = tf.cast(tf.slice(record, [label_offset], [label_bytes]), tf.int32)\n  # Convert from string to [depth * height * width] to [depth, height, width].\n  depth_major = tf.reshape(tf.slice(record, [label_offset + label_bytes], [image_bytes]),\n                           [depth, image_size, image_size])\n  # Convert from [depth, height, width] to [height, width, depth].\n  image = tf.cast(tf.transpose(depth_major, [1, 2, 0]), tf.float32)\n\n  if mode == 'train':\n    image = tf.image.resize_image_with_crop_or_pad(\n        image, image_size+4, image_size+4)\n    image = tf.random_crop(image, [image_size, image_size, 3])\n    image = tf.image.random_flip_left_right(image)\n    # Brightness/saturation/constrast provides small gains .2%~.5% on cifar.\n    # image = tf.image.random_brightness(image, max_delta=63. / 255.)\n    # image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n    # image = tf.image.random_contrast(image, lower=0.2, upper=1.8)\n    image = tf.image.per_image_standardization(image)\n\n    example_queue = tf.RandomShuffleQueue(\n        capacity=16 * batch_size,\n        min_after_dequeue=8 * batch_size,\n        dtypes=[tf.float32, tf.int32],\n        shapes=[[image_size, image_size, depth], [1]])\n    num_threads = 16\n  else:\n    image = tf.image.resize_image_with_crop_or_pad(\n        image, image_size, image_size)\n    image = tf.image.per_image_standardization(image)\n\n    example_queue = tf.FIFOQueue(\n        3 * batch_size,\n        dtypes=[tf.float32, tf.int32],\n        shapes=[[image_size, image_size, depth], [1]])\n    num_threads = 1\n\n  example_enqueue_op = example_queue.enqueue([image, label])\n  tf.train.add_queue_runner(tf.train.queue_runner.QueueRunner(\n      example_queue, [example_enqueue_op] * num_threads))\n\n  # Read 'batch' labels + images from the example queue.\n  images, labels = example_queue.dequeue_many(batch_size)\n  labels = tf.reshape(labels, [batch_size, 1])\n  indices = tf.reshape(tf.range(0, batch_size, 1), [batch_size, 1])\n  labels = tf.sparse_to_dense(\n      tf.concat(values=[indices, labels], axis=1),\n      [batch_size, num_classes], 1.0, 0.0)\n\n  assert len(images.get_shape()) == 4\n  assert images.get_shape()[0] == batch_size\n  assert images.get_shape()[-1] == 3\n  assert len(labels.get_shape()) == 2\n  assert labels.get_shape()[0] == batch_size\n  assert labels.get_shape()[1] == num_classes\n\n  # Display the training images in the visualizer.\n  tf.summary.image('images', images)\n  return images, labels\n", "description": "Models and examples built with TensorFlow", "file_name": "cifar_input.py", "id": "3941441ff2484358ac93a8d4194b984e", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tensorflow-models/tensorflow-models-7e4c66b/research/resnet/cifar_input.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:59:36Z", "url": "https://github.com/tensorflow/models", "wiki": true}