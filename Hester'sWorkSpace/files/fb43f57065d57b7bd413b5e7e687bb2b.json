{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\n\"\"\"A factory-pattern class which returns image/label pairs.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n Dependency imports\nimport tensorflow as tf\n\nfrom slim.datasets import mnist\nfrom domain_adaptation.datasets import mnist_m\n\nslim = tf.contrib.slim\n\n\ndef get_dataset(dataset_name,\n                split_name,\n                dataset_dir,\n                file_pattern=None,\n                reader=None):\n  \"\"\"Given a dataset name and a split_name returns a Dataset.\n\n  Args:\n    dataset_name: String, the name of the dataset.\n    split_name: A train/test split name.\n    dataset_dir: The directory where the dataset files are stored.\n    file_pattern: The file pattern to use for matching the dataset source files.\n    reader: The subclass of tf.ReaderBase. If left as `None`, then the default\n      reader defined by each dataset is used.\n\n  Returns:\n    A tf-slim `Dataset` class.\n\n  Raises:\n    ValueError: if `dataset_name` isn't recognized.\n  \"\"\"\n  dataset_name_to_module = {'mnist': mnist, 'mnist_m': mnist_m}\n  if dataset_name not in dataset_name_to_module:\n    raise ValueError('Name of dataset unknown %s.' % dataset_name)\n\n  return dataset_name_to_module[dataset_name].get_split(split_name, dataset_dir,\n                                                        file_pattern, reader)\n\n\ndef provide_batch(dataset_name, split_name, dataset_dir, num_readers,\n                  batch_size, num_preprocessing_threads):\n  \"\"\"Provides a batch of images and corresponding labels.\n\n    Args:\n    dataset_name: String, the name of the dataset.\n    split_name: A train/test split name.\n    dataset_dir: The directory where the dataset files are stored.\n    num_readers: The number of readers used by DatasetDataProvider.\n    batch_size: The size of the batch requested.\n    num_preprocessing_threads: The number of preprocessing threads for\n      tf.train.batch.\n    file_pattern: The file pattern to use for matching the dataset source files.\n    reader: The subclass of tf.ReaderBase. If left as `None`, then the default\n      reader defined by each dataset is used.\n\n  Returns:\n    A batch of\n      images: tensor of [batch_size, height, width, channels].\n      labels: dictionary of labels.\n  \"\"\"\n  dataset = get_dataset(dataset_name, split_name, dataset_dir)\n  provider = slim.dataset_data_provider.DatasetDataProvider(\n      dataset,\n      num_readers=num_readers,\n      common_queue_capacity=20 * batch_size,\n      common_queue_min=10 * batch_size)\n  [image, label] = provider.get(['image', 'label'])\n\n   Convert images to float32\n  image = tf.image.convert_image_dtype(image, tf.float32)\n  image -= 0.5\n  image *= 2\n\n   Load the data.\n  labels = {}\n  images, labels['classes'] = tf.train.batch(\n      [image, label],\n      batch_size=batch_size,\n      num_threads=num_preprocessing_threads,\n      capacity=5 * batch_size)\n  labels['classes'] = slim.one_hot_encoding(labels['classes'],\n                                            dataset.num_classes)\n\n   Convert mnist to RGB and 32x32 so that it can match mnist_m.\n  if dataset_name == 'mnist':\n    images = tf.image.grayscale_to_rgb(images)\n    images = tf.image.resize_images(images, [32, 32])\n  return images, labels\n", "comments": "   a factory pattern class returns image label pairs        future   import absolute import   future   import division   future   import print function    dependency imports import tensorflow tf  slim datasets import mnist domain adaptation datasets import mnist  slim   tf contrib slim   def get dataset(dataset name                  split name                  dataset dir                  file pattern none                  reader none)       given dataset name split name returns dataset     args      dataset name  string  name dataset      split name  a train test split name      dataset dir  the directory dataset files stored      file pattern  the file pattern use matching dataset source files      reader  the subclass tf readerbase  if left  none   default       reader defined dataset used     returns      a tf slim  dataset  class     raises      valueerror   dataset name  recognized          dataset name module     mnist   mnist   mnist   mnist    dataset name dataset name module      raise valueerror( name dataset unknown      dataset name)    return dataset name module dataset name  get split(split name  dataset dir                                                          file pattern  reader)   def provide batch(dataset name  split name  dataset dir  num readers                    batch size  num preprocessing threads)       provides batch images corresponding labels       args      dataset name  string  name dataset      split name  a train test split name      dataset dir  the directory dataset files stored      num readers  the number readers used datasetdataprovider      batch size  the size batch requested      num preprocessing threads  the number preprocessing threads       tf train batch      file pattern  the file pattern use matching dataset source files      reader  the subclass tf readerbase  if left  none   default       reader defined dataset used     returns      a batch       images  tensor  batch size  height  width  channels         labels  dictionary labels           copyright 2017 google inc        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license     dependency imports    convert images float32    load data     convert mnist rgb 32x32 match mnist  ", "content": "# Copyright 2017 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"A factory-pattern class which returns image/label pairs.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# Dependency imports\nimport tensorflow as tf\n\nfrom slim.datasets import mnist\nfrom domain_adaptation.datasets import mnist_m\n\nslim = tf.contrib.slim\n\n\ndef get_dataset(dataset_name,\n                split_name,\n                dataset_dir,\n                file_pattern=None,\n                reader=None):\n  \"\"\"Given a dataset name and a split_name returns a Dataset.\n\n  Args:\n    dataset_name: String, the name of the dataset.\n    split_name: A train/test split name.\n    dataset_dir: The directory where the dataset files are stored.\n    file_pattern: The file pattern to use for matching the dataset source files.\n    reader: The subclass of tf.ReaderBase. If left as `None`, then the default\n      reader defined by each dataset is used.\n\n  Returns:\n    A tf-slim `Dataset` class.\n\n  Raises:\n    ValueError: if `dataset_name` isn't recognized.\n  \"\"\"\n  dataset_name_to_module = {'mnist': mnist, 'mnist_m': mnist_m}\n  if dataset_name not in dataset_name_to_module:\n    raise ValueError('Name of dataset unknown %s.' % dataset_name)\n\n  return dataset_name_to_module[dataset_name].get_split(split_name, dataset_dir,\n                                                        file_pattern, reader)\n\n\ndef provide_batch(dataset_name, split_name, dataset_dir, num_readers,\n                  batch_size, num_preprocessing_threads):\n  \"\"\"Provides a batch of images and corresponding labels.\n\n    Args:\n    dataset_name: String, the name of the dataset.\n    split_name: A train/test split name.\n    dataset_dir: The directory where the dataset files are stored.\n    num_readers: The number of readers used by DatasetDataProvider.\n    batch_size: The size of the batch requested.\n    num_preprocessing_threads: The number of preprocessing threads for\n      tf.train.batch.\n    file_pattern: The file pattern to use for matching the dataset source files.\n    reader: The subclass of tf.ReaderBase. If left as `None`, then the default\n      reader defined by each dataset is used.\n\n  Returns:\n    A batch of\n      images: tensor of [batch_size, height, width, channels].\n      labels: dictionary of labels.\n  \"\"\"\n  dataset = get_dataset(dataset_name, split_name, dataset_dir)\n  provider = slim.dataset_data_provider.DatasetDataProvider(\n      dataset,\n      num_readers=num_readers,\n      common_queue_capacity=20 * batch_size,\n      common_queue_min=10 * batch_size)\n  [image, label] = provider.get(['image', 'label'])\n\n  # Convert images to float32\n  image = tf.image.convert_image_dtype(image, tf.float32)\n  image -= 0.5\n  image *= 2\n\n  # Load the data.\n  labels = {}\n  images, labels['classes'] = tf.train.batch(\n      [image, label],\n      batch_size=batch_size,\n      num_threads=num_preprocessing_threads,\n      capacity=5 * batch_size)\n  labels['classes'] = slim.one_hot_encoding(labels['classes'],\n                                            dataset.num_classes)\n\n  # Convert mnist to RGB and 32x32 so that it can match mnist_m.\n  if dataset_name == 'mnist':\n    images = tf.image.grayscale_to_rgb(images)\n    images = tf.image.resize_images(images, [32, 32])\n  return images, labels\n", "description": "Models and examples built with TensorFlow", "file_name": "dataset_factory.py", "id": "fb43f57065d57b7bd413b5e7e687bb2b", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-models/tensorflow-models-086d914/research/domain_adaptation/datasets/dataset_factory.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:59:19Z", "url": "https://github.com/tensorflow/models", "wiki": true}