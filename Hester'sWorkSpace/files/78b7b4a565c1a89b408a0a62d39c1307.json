{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\nr\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport math\nimport os\n\n\nimport tensorflow as tf\n\nfrom im2txt import configuration\nfrom im2txt import inference_wrapper\nfrom im2txt.inference_utils import caption_generator\nfrom im2txt.inference_utils import vocabulary\n\nFLAGS = tf.flags.FLAGS\n\ntf.flags.DEFINE_string(\"checkpoint_path\", \"\",\n                       \"Model checkpoint file or directory containing a \"\n                       \"model checkpoint file.\")\ntf.flags.DEFINE_string(\"vocab_file\", \"\", \"Text file containing the vocabulary.\")\ntf.flags.DEFINE_string(\"input_files\", \"\",\n                       \"File pattern or comma-separated list of file patterns \"\n                       \"of image files.\")\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\n\ndef main(_):\n   Build the inference graph.\n  g = tf.Graph()\n  with g.as_default():\n    model = inference_wrapper.InferenceWrapper()\n    restore_fn = model.build_graph_from_config(configuration.ModelConfig(),\n                                               FLAGS.checkpoint_path)\n  g.finalize()\n\n   Create the vocabulary.\n  vocab = vocabulary.Vocabulary(FLAGS.vocab_file)\n\n  filenames = []\n  for file_pattern in FLAGS.input_files.split(\",\"):\n    filenames.extend(tf.gfile.Glob(file_pattern))\n  tf.logging.info(\"Running caption generation on %d files matching %s\",\n                  len(filenames), FLAGS.input_files)\n\n  with tf.Session(graph=g) as sess:\n     Load the model from checkpoint.\n    restore_fn(sess)\n\n     Prepare the caption generator. Here we are implicitly using the default\n     beam search parameters. See caption_generator.py for a description of the\n     available beam search parameters.\n    generator = caption_generator.CaptionGenerator(model, vocab)\n\n    for filename in filenames:\n      with tf.gfile.GFile(filename, \"rb\") as f:\n        image = f.read()\n      captions = generator.beam_search(sess, image)\n      print(\"Captions for image %s:\" % os.path.basename(filename))\n      for i, caption in enumerate(captions):\n         Ignore begin and end words.\n        sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n        sentence = \" \".join(sentence)\n        print(\"  %d) %s (p=%f)\" % (i, sentence, math.exp(caption.logprob)))\n\n\nif __name__ == \"__main__\":\n  tf.app.run()\n", "comments": "   generate captions images using default beam search parameters        copyright 2016 the tensorflow authors  all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                       build inference graph     create vocabulary     load model checkpoint     prepare caption generator  here implicitly using default    beam search parameters  see caption generator py description    available beam search parameters     ignore begin end words  ", "content": "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\nr\"\"\"Generate captions for images using default beam search parameters.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport math\nimport os\n\n\nimport tensorflow as tf\n\nfrom im2txt import configuration\nfrom im2txt import inference_wrapper\nfrom im2txt.inference_utils import caption_generator\nfrom im2txt.inference_utils import vocabulary\n\nFLAGS = tf.flags.FLAGS\n\ntf.flags.DEFINE_string(\"checkpoint_path\", \"\",\n                       \"Model checkpoint file or directory containing a \"\n                       \"model checkpoint file.\")\ntf.flags.DEFINE_string(\"vocab_file\", \"\", \"Text file containing the vocabulary.\")\ntf.flags.DEFINE_string(\"input_files\", \"\",\n                       \"File pattern or comma-separated list of file patterns \"\n                       \"of image files.\")\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\n\ndef main(_):\n  # Build the inference graph.\n  g = tf.Graph()\n  with g.as_default():\n    model = inference_wrapper.InferenceWrapper()\n    restore_fn = model.build_graph_from_config(configuration.ModelConfig(),\n                                               FLAGS.checkpoint_path)\n  g.finalize()\n\n  # Create the vocabulary.\n  vocab = vocabulary.Vocabulary(FLAGS.vocab_file)\n\n  filenames = []\n  for file_pattern in FLAGS.input_files.split(\",\"):\n    filenames.extend(tf.gfile.Glob(file_pattern))\n  tf.logging.info(\"Running caption generation on %d files matching %s\",\n                  len(filenames), FLAGS.input_files)\n\n  with tf.Session(graph=g) as sess:\n    # Load the model from checkpoint.\n    restore_fn(sess)\n\n    # Prepare the caption generator. Here we are implicitly using the default\n    # beam search parameters. See caption_generator.py for a description of the\n    # available beam search parameters.\n    generator = caption_generator.CaptionGenerator(model, vocab)\n\n    for filename in filenames:\n      with tf.gfile.GFile(filename, \"rb\") as f:\n        image = f.read()\n      captions = generator.beam_search(sess, image)\n      print(\"Captions for image %s:\" % os.path.basename(filename))\n      for i, caption in enumerate(captions):\n        # Ignore begin and end words.\n        sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n        sentence = \" \".join(sentence)\n        print(\"  %d) %s (p=%f)\" % (i, sentence, math.exp(caption.logprob)))\n\n\nif __name__ == \"__main__\":\n  tf.app.run()\n", "description": "Models and examples built with TensorFlow", "file_name": "run_inference.py", "id": "78b7b4a565c1a89b408a0a62d39c1307", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tensorflow-models/tensorflow-models-7e4c66b/research/im2txt/im2txt/run_inference.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:59:36Z", "url": "https://github.com/tensorflow/models", "wiki": true}