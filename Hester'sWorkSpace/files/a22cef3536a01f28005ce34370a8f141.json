{"author": "HelloZeroNet", "code": "\"\"\"For internal use only. It provides a slice-like file reader.\"\"\"\n\nimport os\n\ntry:\n    from multiprocessing import Lock\nexcept ImportError:\n    from threading import Lock\n\n\nclass FileBuffer(object):\n\n    \"\"\"A slice-able file reader\"\"\"\n\n    def __init__(self, database):\n        self._handle = open(database, 'rb')\n        self._size = os.fstat(self._handle.fileno()).st_size\n        if not hasattr(os, 'pread'):\n            self._lock = Lock()\n\n    def __getitem__(self, key):\n        if isinstance(key, slice):\n            return self._read(key.stop - key.start, key.start)\n        elif isinstance(key, int):\n            return self._read(1, key)\n        else:\n            raise TypeError(\"Invalid argument type.\")\n\n    def rfind(self, needle, start):\n        \"\"\"Reverse find needle from start\"\"\"\n        pos = self._read(self._size - start - 1, start).rfind(needle)\n        if pos == -1:\n            return pos\n        return start + pos\n\n    def size(self):\n        \"\"\"Size of file\"\"\"\n        return self._size\n\n    def close(self):\n        \"\"\"Close file\"\"\"\n        self._handle.close()\n\n    if hasattr(os, 'pread'):\n\n        def _read(self, buffersize, offset):\n            \"\"\"read that uses pread\"\"\"\n            \n            return os.pread(self._handle.fileno(), buffersize, offset)\n\n    else:\n\n        def _read(self, buffersize, offset):\n            \"\"\"read with a lock\n\n            This lock is necessary as after a fork, the different processes\n            will share the same file table entry, even if we dup the fd, and\n            as such the same offsets. There does not appear to be a way to\n            duplicate the file table entry and we cannot re-open based on the\n            original path as that file may have replaced with another or\n            unlinked.\n            \"\"\"\n            with self._lock:\n                self._handle.seek(offset)\n                return self._handle.read(buffersize)\n", "comments": "   for internal use  it provides slice like file reader      import os  try      multiprocessing import lock except importerror      threading import lock   class filebuffer(object)          a slice able file reader         def   init  (self  database)          self  handle   open(database   rb )         self  size   os fstat(self  handle fileno()) st size         hasattr(os   pread )              self  lock   lock()      def   getitem  (self  key)          isinstance(key  slice)              return self  read(key stop   key start  key start)         elif isinstance(key  int)              return self  read(1  key)         else              raise typeerror( invalid argument type  )      def rfind(self  needle  start)             reverse find needle start            pos   self  read(self  size   start   1  start) rfind(needle)         pos     1              return pos         return start   pos      def size(self)             size file            return self  size      def close(self)             close file            self  handle close()      hasattr(os   pread )           def  read(self  buffersize  offset)                 read uses pread                  pylint  disable member             return os pread(self  handle fileno()  buffersize  offset)      else           def  read(self  buffersize  offset)                 read lock              this lock necessary fork  different processes             share file table entry  even dup fd              offsets  there appear way             duplicate file table entry cannot open based             original path file may replaced another             unlinked                     pylint  disable member ", "content": "\"\"\"For internal use only. It provides a slice-like file reader.\"\"\"\n\nimport os\n\ntry:\n    from multiprocessing import Lock\nexcept ImportError:\n    from threading import Lock\n\n\nclass FileBuffer(object):\n\n    \"\"\"A slice-able file reader\"\"\"\n\n    def __init__(self, database):\n        self._handle = open(database, 'rb')\n        self._size = os.fstat(self._handle.fileno()).st_size\n        if not hasattr(os, 'pread'):\n            self._lock = Lock()\n\n    def __getitem__(self, key):\n        if isinstance(key, slice):\n            return self._read(key.stop - key.start, key.start)\n        elif isinstance(key, int):\n            return self._read(1, key)\n        else:\n            raise TypeError(\"Invalid argument type.\")\n\n    def rfind(self, needle, start):\n        \"\"\"Reverse find needle from start\"\"\"\n        pos = self._read(self._size - start - 1, start).rfind(needle)\n        if pos == -1:\n            return pos\n        return start + pos\n\n    def size(self):\n        \"\"\"Size of file\"\"\"\n        return self._size\n\n    def close(self):\n        \"\"\"Close file\"\"\"\n        self._handle.close()\n\n    if hasattr(os, 'pread'):\n\n        def _read(self, buffersize, offset):\n            \"\"\"read that uses pread\"\"\"\n            # pylint: disable=no-member\n            return os.pread(self._handle.fileno(), buffersize, offset)\n\n    else:\n\n        def _read(self, buffersize, offset):\n            \"\"\"read with a lock\n\n            This lock is necessary as after a fork, the different processes\n            will share the same file table entry, even if we dup the fd, and\n            as such the same offsets. There does not appear to be a way to\n            duplicate the file table entry and we cannot re-open based on the\n            original path as that file may have replaced with another or\n            unlinked.\n            \"\"\"\n            with self._lock:\n                self._handle.seek(offset)\n                return self._handle.read(buffersize)\n", "description": "ZeroNet - Decentralized websites using Bitcoin crypto and BitTorrent network", "file_name": "file.py", "id": "a22cef3536a01f28005ce34370a8f141", "language": "Python", "project_name": "ZeroNet", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/HelloZeroNet-ZeroNet/HelloZeroNet-ZeroNet-8828629/plugins/Sidebar/maxminddb/file.py", "save_time": "", "source": "", "update_at": "2018-03-18T12:17:52Z", "url": "https://github.com/HelloZeroNet/ZeroNet", "wiki": true}