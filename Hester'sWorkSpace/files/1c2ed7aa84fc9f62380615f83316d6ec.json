{"author": "facebookresearch", "code": "\n\n Copyright (c) 2017-present, Facebook, Inc.\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\n\n\"\"\"Script to convert the model (.yaml and .pkl) trained by train_net to a\nstandard Caffe2 model in pb format (model.pb and model_init.pb). The converted\nmodel is good for production usage, as it could run independently and efficiently\non CPU, GPU and mobile without depending on the detectron codebase.\n\nPlease see Caffe2 tutorial (\nhttps://caffe2.ai/docs/tutorial-loading-pre-trained-models.html) for loading\nthe converted model, and run_model_pb() for running the model for inference.\n\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\nimport cv2   NOQA (Must import before importing caffe2 due to bug in cv2)\n\nimport argparse\nimport copy\nimport pprint\nimport numpy as np\nimport os\nimport sys\n\nimport caffe2.python.utils as putils\nfrom caffe2.python import core, workspace\nfrom caffe2.proto import caffe2_pb2\n\nfrom core.config import assert_and_infer_cfg\nfrom core.config import cfg\nfrom core.config import merge_cfg_from_file\nfrom core.config import merge_cfg_from_list\nfrom modeling import generate_anchors\nimport core.test_engine as test_engine\nimport utils.c2 as c2_utils\nimport utils.vis as vis_utils\nimport utils.logging\nimport utils.model_convert_utils as mutils\nfrom utils.model_convert_utils import op_filter, convert_op_in_proto\n\nc2_utils.import_contrib_ops()\nc2_utils.import_detectron_ops()\n\nlogger = utils.logging.setup_logging(__name__)\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(\n        description='Convert a trained network to pb format'\n    )\n    parser.add_argument(\n        '--cfg', dest='cfg_file', help='optional config file', default=None,\n        type=str)\n    parser.add_argument(\n        '--net_name', dest='net_name', help='optional name for the net',\n        default=\"detectron\", type=str)\n    parser.add_argument(\n        '--out_dir', dest='out_dir', help='output dir', default=None,\n        type=str)\n    parser.add_argument(\n        '--test_img', dest='test_img',\n        help='optional test image, used to verify the model conversion',\n        default=None,\n        type=str)\n    parser.add_argument(\n        '--fuse_af', dest='fuse_af', help='1 to fuse_af',\n        default=1,\n        type=int)\n    parser.add_argument(\n        '--device', dest='device',\n        help='Device to run the model on',\n        choices=['cpu', 'gpu'],\n        default='cpu',\n        type=str)\n    parser.add_argument(\n        '--net_execution_type', dest='net_execution_type',\n        help='caffe2 net execution type',\n        choices=['simple', 'dag'],\n        default='simple',\n        type=str)\n    parser.add_argument(\n        '--use_nnpack', dest='use_nnpack',\n        help='Use nnpack for conv',\n        default=1,\n        type=int)\n    parser.add_argument(\n        'opts', help='See lib/core/config.py for all options', default=None,\n        nargs=argparse.REMAINDER)\n    if len(sys.argv) == 1:\n        parser.print_help()\n        sys.exit(1)\n    ret = parser.parse_args()\n    ret.out_dir = os.path.abspath(ret.out_dir)\n    if ret.device == 'gpu' and ret.use_nnpack:\n        logger.warn('Should not use mobile engine for gpu model.')\n        ret.use_nnpack = 0\n\n    return ret\n\n\ndef unscope_name(name):\n    return c2_utils.UnscopeName(name)\n\n\ndef reset_names(names):\n    for i in range(0, len(names)):\n        names[i] = unscope_name(names[i])\n\n\ndef convert_gen_proposals(\n    op, blobs,\n    rpn_pre_nms_topN,\n    rpn_post_nms_topN,\n    rpn_nms_thres,\n    rpn_min_size,\n):\n    print('Converting GenerateProposals Python -> C++:\\n{}'.format(op))\n    assert op.name.startswith(\"GenerateProposalsOp\"), \"Not valid GenerateProposalsOp\"\n\n    spatial_scale = mutils.get_op_arg_valf(op, \"spatial_scale\", None)\n    assert spatial_scale is not None\n\n    inputs = [x for x in op.input]\n    anchor_name = \"anchor\"\n    inputs.append(anchor_name)\n    blobs[anchor_name] = get_anchors(spatial_scale)\n    print('anchors {}'.format(blobs[anchor_name]))\n\n    ret = core.CreateOperator(\n        \"GenerateProposals\",\n        inputs,\n        list(op.output),\n        spatial_scale=spatial_scale,\n        pre_nms_topN=rpn_pre_nms_topN,\n        post_nms_topN=rpn_post_nms_topN,\n        nms_thres=rpn_nms_thres,\n        min_size=rpn_min_size,\n        correct_transform_coords=True,\n    )\n\n    return ret, anchor_name\n\n\ndef get_anchors(spatial_scale):\n    anchors = generate_anchors.generate_anchors(\n        stride=1. / spatial_scale,\n        sizes=cfg.RPN.SIZES,\n        aspect_ratios=cfg.RPN.ASPECT_RATIOS).astype(np.float32)\n    return anchors\n\n\ndef reset_blob_names(blobs):\n    ret = {unscope_name(x): blobs[x] for x in blobs}\n    blobs.clear()\n    blobs.update(ret)\n\n\ndef convert_net(args, net, blobs):\n\n    @op_filter()\n    def convert_op_name(op):\n        if args.device != 'gpu':\n            if op.engine != 'DEPTHWISE_3x3':\n                op.engine = ''\n            op.device_option.CopyFrom(caffe2_pb2.DeviceOption())\n        reset_names(op.input)\n        reset_names(op.output)\n        return [op]\n\n    @op_filter(type=\"Python\", inputs=['rpn_cls_probs', 'rpn_bbox_pred', 'im_info'])\n    def convert_gen_proposal(op_in):\n        gen_proposals_op, ext_input = convert_gen_proposals(\n            op_in, blobs,\n            rpn_min_size=float(cfg.TEST.RPN_MIN_SIZE),\n            rpn_post_nms_topN=cfg.TEST.RPN_POST_NMS_TOP_N,\n            rpn_pre_nms_topN=cfg.TEST.RPN_PRE_NMS_TOP_N,\n            rpn_nms_thres=cfg.TEST.RPN_NMS_THRESH,\n        )\n        net.external_input.extend([ext_input])\n        return [gen_proposals_op]\n\n    @op_filter(input_has='rois')\n    def convert_rpn_rois(op):\n        for j in range(0, len(op.input)):\n            if op.input[j] == 'rois':\n                print('Converting op {} input name: rois -> rpn_rois:\\n{}'.format(\n                    op.type, op))\n                op.input[j] = 'rpn_rois'\n        return [op]\n\n    @op_filter(type_in=['StopGradient', 'Alias'])\n    def convert_remove_op(op):\n        print('Removing op {}:\\n{}'.format(op.type, op))\n        return []\n\n    convert_op_in_proto(net, convert_op_name)\n    convert_op_in_proto(net, [\n        convert_gen_proposal, convert_rpn_rois, convert_remove_op\n    ])\n\n    reset_names(net.external_input)\n    reset_names(net.external_output)\n\n    reset_blob_names(blobs)\n\n\ndef add_bbox_ops(args, net, blobs):\n    new_ops = []\n    new_external_outputs = []\n\n     Operators for bboxes\n    op_box = core.CreateOperator(\n        \"BBoxTransform\",\n        ['rpn_rois', 'bbox_pred', 'im_info'],\n        ['pred_bbox'],\n        weights=cfg.MODEL.BBOX_REG_WEIGHTS,\n        apply_scale=False,\n        correct_transform_coords=True,\n    )\n    new_ops.extend([op_box])\n\n    blob_prob = 'cls_prob'\n    blob_box = 'pred_bbox'\n    op_nms = core.CreateOperator(\n        \"BoxWithNMSLimit\",\n        [blob_prob, blob_box],\n        ['score_nms', 'bbox_nms', 'class_nms'],\n        arg=[\n            putils.MakeArgument(\"score_thresh\", cfg.TEST.SCORE_THRESH),\n            putils.MakeArgument(\"nms\", cfg.TEST.NMS),\n            putils.MakeArgument(\"detections_per_im\", cfg.TEST.DETECTIONS_PER_IM),\n            putils.MakeArgument(\"soft_nms_enabled\", cfg.TEST.SOFT_NMS.ENABLED),\n            putils.MakeArgument(\"soft_nms_method\", cfg.TEST.SOFT_NMS.METHOD),\n            putils.MakeArgument(\"soft_nms_sigma\", cfg.TEST.SOFT_NMS.SIGMA),\n        ]\n    )\n    new_ops.extend([op_nms])\n    new_external_outputs.extend(['score_nms', 'bbox_nms', 'class_nms'])\n\n    net.Proto().op.extend(new_ops)\n    net.Proto().external_output.extend(new_external_outputs)\n\n\ndef convert_model_gpu(args, net, init_net):\n    assert args.device == 'gpu'\n\n    ret_net = copy.deepcopy(net)\n    ret_init_net = copy.deepcopy(init_net)\n\n    cdo_cuda = mutils.get_device_option_cuda()\n    cdo_cpu = mutils.get_device_option_cpu()\n\n    CPU_OPS = [\n        [\"GenerateProposals\", None],\n        [\"BBoxTransform\", None],\n        [\"BoxWithNMSLimit\", None],\n    ]\n    CPU_BLOBS = [\"im_info\", \"anchor\"]\n\n    @op_filter()\n    def convert_op_gpu(op):\n        for x in CPU_OPS:\n            if mutils.filter_op(op, type=x[0], inputs=x[1]):\n                return None\n        op.device_option.CopyFrom(cdo_cuda)\n        return [op]\n\n    @op_filter()\n    def convert_init_op_gpu(op):\n        if op.output[0] in CPU_BLOBS:\n            op.device_option.CopyFrom(cdo_cpu)\n        else:\n            op.device_option.CopyFrom(cdo_cuda)\n        return [op]\n\n    convert_op_in_proto(ret_init_net.Proto(), convert_init_op_gpu)\n    convert_op_in_proto(ret_net.Proto(), convert_op_gpu)\n\n    ret = core.InjectDeviceCopiesAmongNets([ret_init_net, ret_net])\n\n    return [ret[0][1], ret[0][0]]\n\n\ndef gen_init_net(net, blobs, empty_blobs):\n    blobs = copy.deepcopy(blobs)\n    for x in empty_blobs:\n        blobs[x] = np.array([], dtype=np.float32)\n    init_net = mutils.gen_init_net_from_blobs(\n        blobs, net.external_inputs)\n    init_net = core.Net(init_net)\n    return init_net\n\n\ndef _save_image_graphs(args, all_net, all_init_net):\n    print('Saving model graph...')\n    mutils.save_graph(\n        all_net.Proto(), os.path.join(args.out_dir, \"model_def.png\"),\n        op_only=False)\n    print('Model def image saved to {}.'.format(args.out_dir))\n\n\ndef _save_models(all_net, all_init_net, args):\n    print('Writing converted model to {}...'.format(args.out_dir))\n    fname = \"model\"\n\n    if not os.path.exists(args.out_dir):\n        os.makedirs(args.out_dir)\n\n    with open(os.path.join(args.out_dir, fname + '.pb'), 'w') as f:\n        f.write(all_net.Proto().SerializeToString())\n    with open(os.path.join(args.out_dir, fname + '.pbtxt'), 'w') as f:\n        f.write(str(all_net.Proto()))\n    with open(os.path.join(args.out_dir, fname + '_init.pb'), 'w') as f:\n        f.write(all_init_net.Proto().SerializeToString())\n\n    _save_image_graphs(args, all_net, all_init_net)\n\n\ndef load_model(args):\n    model = test_engine.initialize_model_from_cfg()\n    blobs = mutils.get_ws_blobs()\n\n    return model, blobs\n\n\ndef _get_result_blobs(check_blobs):\n    ret = {}\n    for x in check_blobs:\n        sn = core.ScopedName(x)\n        if workspace.HasBlob(sn):\n            ret[x] = workspace.FetchBlob(sn)\n        else:\n            ret[x] = None\n\n    return ret\n\n\ndef _sort_results(boxes, segms, keypoints, classes):\n    indices = np.argsort(boxes[:, -1])[::-1]\n    if boxes is not None:\n        boxes = boxes[indices, :]\n    if segms is not None:\n        segms = [segms[x] for x in indices]\n    if keypoints is not None:\n        keypoints = [keypoints[x] for x in indices]\n    if classes is not None:\n        if isinstance(classes, list):\n            classes = [classes[x] for x in indices]\n        else:\n            classes = classes[indices]\n\n    return boxes, segms, keypoints, classes\n\n\ndef run_model_cfg(args, im, check_blobs):\n    workspace.ResetWorkspace()\n    model, _ = load_model(args)\n    with c2_utils.NamedCudaScope(0):\n        cls_boxes, cls_segms, cls_keyps = test_engine.im_detect_all(\n            model, im, None, None,\n        )\n\n    boxes, segms, keypoints, classes = vis_utils.convert_from_cls_format(\n        cls_boxes, cls_segms, cls_keyps)\n\n     sort the results based on score for comparision\n    boxes, segms, keypoints, classes = _sort_results(\n        boxes, segms, keypoints, classes)\n\n     write final results back to workspace\n    def _ornone(res):\n        return np.array(res) if res is not None else np.array([], dtype=np.float32)\n    with c2_utils.NamedCudaScope(0):\n        workspace.FeedBlob(core.ScopedName('result_boxes'), _ornone(boxes))\n        workspace.FeedBlob(core.ScopedName('result_segms'), _ornone(segms))\n        workspace.FeedBlob(core.ScopedName('result_keypoints'), _ornone(keypoints))\n        workspace.FeedBlob(core.ScopedName('result_classids'), _ornone(classes))\n\n     get result blobs\n    with c2_utils.NamedCudaScope(0):\n        ret = _get_result_blobs(check_blobs)\n\n    return ret\n\n\ndef _prepare_blobs(\n    im,\n    pixel_means,\n    target_size,\n    max_size,\n):\n    ''' Reference: blob.prep_im_for_blob() '''\n\n    im = im.astype(np.float32, copy=False)\n    im -= pixel_means\n    im_shape = im.shape\n\n    im_size_min = np.min(im_shape[0:2])\n    im_size_max = np.max(im_shape[0:2])\n    im_scale = float(target_size) / float(im_size_min)\n    if np.round(im_scale * im_size_max) > max_size:\n        im_scale = float(max_size) / float(im_size_max)\n    im = cv2.resize(im, None, None, fx=im_scale, fy=im_scale,\n                    interpolation=cv2.INTER_LINEAR)\n\n    blob = np.zeros([1, im.shape[0], im.shape[1], 3], dtype=np.float32)\n    blob[0, :, :, :] = im\n    channel_swap = (0, 3, 1, 2)   swap channel to (k, c, h, w)\n    blob = blob.transpose(channel_swap)\n\n    blobs = {}\n    blobs['data'] = blob\n    blobs['im_info'] = np.array(\n        [[blob.shape[2], blob.shape[3], im_scale]],\n        dtype=np.float32\n    )\n    return blobs\n\n\ndef run_model_pb(args, net, init_net, im, check_blobs):\n    assert len(cfg.TEST.SCALES) == 1\n\n    workspace.ResetWorkspace()\n    workspace.RunNetOnce(init_net)\n    mutils.create_input_blobs_for_net(net.Proto())\n    workspace.CreateNet(net)\n\n     input_blobs, _ = core_test._get_blobs(im, None)\n    input_blobs = _prepare_blobs(\n        im,\n        cfg.PIXEL_MEANS,\n        cfg.TEST.SCALES[0], cfg.TEST.MAX_SIZE\n    )\n    gpu_blobs = []\n    if args.device == 'gpu':\n        gpu_blobs = ['data']\n    for k, v in input_blobs.items():\n        workspace.FeedBlob(\n            core.ScopedName(k),\n            v,\n            mutils.get_device_option_cuda() if k in gpu_blobs else\n            mutils.get_device_option_cpu()\n        )\n\n    try:\n        workspace.RunNet(net.Proto().name)\n        scores = workspace.FetchBlob('score_nms')\n        classids = workspace.FetchBlob('class_nms')\n        boxes = workspace.FetchBlob('bbox_nms')\n    except Exception as e:\n        print('Running pb model failed.\\n{}'.format(e))\n         may not detect anything at all\n        R = 0\n        scores = np.zeros((R,), dtype=np.float32)\n        boxes = np.zeros((R, 4), dtype=np.float32)\n        classids = np.zeros((R,), dtype=np.float32)\n\n    boxes = np.column_stack((boxes, scores))\n\n     sort the results based on score for comparision\n    boxes, _, _, classids = _sort_results(\n        boxes, None, None, classids)\n\n     write final result back to workspace\n    workspace.FeedBlob('result_boxes', boxes)\n    workspace.FeedBlob('result_classids', classids)\n\n    ret = _get_result_blobs(check_blobs)\n\n    return ret\n\n\ndef verify_model(args, model_pb, test_img_file):\n    check_blobs = [\n        \"result_boxes\", \"result_classids\",   result\n    ]\n\n    print('Loading test file {}...'.format(test_img_file))\n    test_img = cv2.imread(test_img_file)\n    assert test_img is not None\n\n    def _run_cfg_func(im, blobs):\n        return run_model_cfg(args, im, check_blobs)\n\n    def _run_pb_func(im, blobs):\n        return run_model_pb(args, model_pb[0], model_pb[1], im, check_blobs)\n\n    print('Checking models...')\n    assert mutils.compare_model(\n        _run_cfg_func, _run_pb_func, test_img, check_blobs)\n\n\ndef main():\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    args = parse_args()\n    logger.info('Called with args:')\n    logger.info(args)\n    if args.cfg_file is not None:\n        merge_cfg_from_file(args.cfg_file)\n    if args.opts is not None:\n        merge_cfg_from_list(args.opts)\n    cfg.NUM_GPUS = 1\n    assert_and_infer_cfg()\n    logger.info('Conerting model with config:')\n    logger.info(pprint.pformat(cfg))\n\n    assert not cfg.MODEL.KEYPOINTS_ON, \"Keypoint model not supported.\"\n    assert not cfg.MODEL.MASK_ON, \"Mask model not supported.\"\n    assert not cfg.FPN.FPN_ON, \"FPN not supported.\"\n    assert not cfg.RETINANET.RETINANET_ON, \"RetinaNet model not supported.\"\n\n     load model from cfg\n    model, blobs = load_model(args)\n\n    net = core.Net('')\n    net.Proto().op.extend(copy.deepcopy(model.net.Proto().op))\n    net.Proto().external_input.extend(\n        copy.deepcopy(model.net.Proto().external_input))\n    net.Proto().external_output.extend(\n        copy.deepcopy(model.net.Proto().external_output))\n    net.Proto().type = args.net_execution_type\n    net.Proto().num_workers = 1 if args.net_execution_type == 'simple' else 4\n\n     Reset the device_option, change to unscope name and replace python operators\n    convert_net(args, net.Proto(), blobs)\n\n     add operators for bbox\n    add_bbox_ops(args, net, blobs)\n\n    if args.fuse_af:\n        print('Fusing affine channel...')\n        net, blobs = mutils.fuse_net_affine(\n            net, blobs)\n\n    if args.use_nnpack:\n        mutils.update_mobile_engines(net.Proto())\n\n     generate init net\n    empty_blobs = ['data', 'im_info']\n    init_net = gen_init_net(net, blobs, empty_blobs)\n\n    if args.device == 'gpu':\n        [net, init_net] = convert_model_gpu(args, net, init_net)\n\n    net.Proto().name = args.net_name\n    init_net.Proto().name = args.net_name + \"_init\"\n\n    if args.test_img is not None:\n        verify_model(args, [net, init_net], args.test_img)\n\n    _save_models(net, init_net, args)\n\n\nif __name__ == '__main__':\n    main()\n", "comments": "   script convert model ( yaml  pkl) trained train net standard caffe2 model pb format (model pb model init pb)  the converted model good production usage  could run independently efficiently cpu  gpu mobile without depending detectron codebase   please see caffe2 tutorial ( https   caffe2 ai docs tutorial loading pre trained models html) loading converted model  run model pb() running model inference           reference  blob prep im blob()         usr bin env python2    copyright (c) 2017 present  facebook  inc        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                     noqa (must import importing caffe2 due bug cv2)    operators bboxes    sort results based score comparision    write final results back workspace    get result blobs    swap channel (k  c  h  w)    input blobs      core test  get blobs(im  none)    may detect anything    sort results based score comparision    write final result back workspace    result    load model cfg    reset device option  change unscope name replace python operators    add operators bbox    generate init net ", "content": "#!/usr/bin/env python2\n\n# Copyright (c) 2017-present, Facebook, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n##############################################################################\n\n\"\"\"Script to convert the model (.yaml and .pkl) trained by train_net to a\nstandard Caffe2 model in pb format (model.pb and model_init.pb). The converted\nmodel is good for production usage, as it could run independently and efficiently\non CPU, GPU and mobile without depending on the detectron codebase.\n\nPlease see Caffe2 tutorial (\nhttps://caffe2.ai/docs/tutorial-loading-pre-trained-models.html) for loading\nthe converted model, and run_model_pb() for running the model for inference.\n\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\nimport cv2  # NOQA (Must import before importing caffe2 due to bug in cv2)\n\nimport argparse\nimport copy\nimport pprint\nimport numpy as np\nimport os\nimport sys\n\nimport caffe2.python.utils as putils\nfrom caffe2.python import core, workspace\nfrom caffe2.proto import caffe2_pb2\n\nfrom core.config import assert_and_infer_cfg\nfrom core.config import cfg\nfrom core.config import merge_cfg_from_file\nfrom core.config import merge_cfg_from_list\nfrom modeling import generate_anchors\nimport core.test_engine as test_engine\nimport utils.c2 as c2_utils\nimport utils.vis as vis_utils\nimport utils.logging\nimport utils.model_convert_utils as mutils\nfrom utils.model_convert_utils import op_filter, convert_op_in_proto\n\nc2_utils.import_contrib_ops()\nc2_utils.import_detectron_ops()\n\nlogger = utils.logging.setup_logging(__name__)\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(\n        description='Convert a trained network to pb format'\n    )\n    parser.add_argument(\n        '--cfg', dest='cfg_file', help='optional config file', default=None,\n        type=str)\n    parser.add_argument(\n        '--net_name', dest='net_name', help='optional name for the net',\n        default=\"detectron\", type=str)\n    parser.add_argument(\n        '--out_dir', dest='out_dir', help='output dir', default=None,\n        type=str)\n    parser.add_argument(\n        '--test_img', dest='test_img',\n        help='optional test image, used to verify the model conversion',\n        default=None,\n        type=str)\n    parser.add_argument(\n        '--fuse_af', dest='fuse_af', help='1 to fuse_af',\n        default=1,\n        type=int)\n    parser.add_argument(\n        '--device', dest='device',\n        help='Device to run the model on',\n        choices=['cpu', 'gpu'],\n        default='cpu',\n        type=str)\n    parser.add_argument(\n        '--net_execution_type', dest='net_execution_type',\n        help='caffe2 net execution type',\n        choices=['simple', 'dag'],\n        default='simple',\n        type=str)\n    parser.add_argument(\n        '--use_nnpack', dest='use_nnpack',\n        help='Use nnpack for conv',\n        default=1,\n        type=int)\n    parser.add_argument(\n        'opts', help='See lib/core/config.py for all options', default=None,\n        nargs=argparse.REMAINDER)\n    if len(sys.argv) == 1:\n        parser.print_help()\n        sys.exit(1)\n    ret = parser.parse_args()\n    ret.out_dir = os.path.abspath(ret.out_dir)\n    if ret.device == 'gpu' and ret.use_nnpack:\n        logger.warn('Should not use mobile engine for gpu model.')\n        ret.use_nnpack = 0\n\n    return ret\n\n\ndef unscope_name(name):\n    return c2_utils.UnscopeName(name)\n\n\ndef reset_names(names):\n    for i in range(0, len(names)):\n        names[i] = unscope_name(names[i])\n\n\ndef convert_gen_proposals(\n    op, blobs,\n    rpn_pre_nms_topN,\n    rpn_post_nms_topN,\n    rpn_nms_thres,\n    rpn_min_size,\n):\n    print('Converting GenerateProposals Python -> C++:\\n{}'.format(op))\n    assert op.name.startswith(\"GenerateProposalsOp\"), \"Not valid GenerateProposalsOp\"\n\n    spatial_scale = mutils.get_op_arg_valf(op, \"spatial_scale\", None)\n    assert spatial_scale is not None\n\n    inputs = [x for x in op.input]\n    anchor_name = \"anchor\"\n    inputs.append(anchor_name)\n    blobs[anchor_name] = get_anchors(spatial_scale)\n    print('anchors {}'.format(blobs[anchor_name]))\n\n    ret = core.CreateOperator(\n        \"GenerateProposals\",\n        inputs,\n        list(op.output),\n        spatial_scale=spatial_scale,\n        pre_nms_topN=rpn_pre_nms_topN,\n        post_nms_topN=rpn_post_nms_topN,\n        nms_thres=rpn_nms_thres,\n        min_size=rpn_min_size,\n        correct_transform_coords=True,\n    )\n\n    return ret, anchor_name\n\n\ndef get_anchors(spatial_scale):\n    anchors = generate_anchors.generate_anchors(\n        stride=1. / spatial_scale,\n        sizes=cfg.RPN.SIZES,\n        aspect_ratios=cfg.RPN.ASPECT_RATIOS).astype(np.float32)\n    return anchors\n\n\ndef reset_blob_names(blobs):\n    ret = {unscope_name(x): blobs[x] for x in blobs}\n    blobs.clear()\n    blobs.update(ret)\n\n\ndef convert_net(args, net, blobs):\n\n    @op_filter()\n    def convert_op_name(op):\n        if args.device != 'gpu':\n            if op.engine != 'DEPTHWISE_3x3':\n                op.engine = ''\n            op.device_option.CopyFrom(caffe2_pb2.DeviceOption())\n        reset_names(op.input)\n        reset_names(op.output)\n        return [op]\n\n    @op_filter(type=\"Python\", inputs=['rpn_cls_probs', 'rpn_bbox_pred', 'im_info'])\n    def convert_gen_proposal(op_in):\n        gen_proposals_op, ext_input = convert_gen_proposals(\n            op_in, blobs,\n            rpn_min_size=float(cfg.TEST.RPN_MIN_SIZE),\n            rpn_post_nms_topN=cfg.TEST.RPN_POST_NMS_TOP_N,\n            rpn_pre_nms_topN=cfg.TEST.RPN_PRE_NMS_TOP_N,\n            rpn_nms_thres=cfg.TEST.RPN_NMS_THRESH,\n        )\n        net.external_input.extend([ext_input])\n        return [gen_proposals_op]\n\n    @op_filter(input_has='rois')\n    def convert_rpn_rois(op):\n        for j in range(0, len(op.input)):\n            if op.input[j] == 'rois':\n                print('Converting op {} input name: rois -> rpn_rois:\\n{}'.format(\n                    op.type, op))\n                op.input[j] = 'rpn_rois'\n        return [op]\n\n    @op_filter(type_in=['StopGradient', 'Alias'])\n    def convert_remove_op(op):\n        print('Removing op {}:\\n{}'.format(op.type, op))\n        return []\n\n    convert_op_in_proto(net, convert_op_name)\n    convert_op_in_proto(net, [\n        convert_gen_proposal, convert_rpn_rois, convert_remove_op\n    ])\n\n    reset_names(net.external_input)\n    reset_names(net.external_output)\n\n    reset_blob_names(blobs)\n\n\ndef add_bbox_ops(args, net, blobs):\n    new_ops = []\n    new_external_outputs = []\n\n    # Operators for bboxes\n    op_box = core.CreateOperator(\n        \"BBoxTransform\",\n        ['rpn_rois', 'bbox_pred', 'im_info'],\n        ['pred_bbox'],\n        weights=cfg.MODEL.BBOX_REG_WEIGHTS,\n        apply_scale=False,\n        correct_transform_coords=True,\n    )\n    new_ops.extend([op_box])\n\n    blob_prob = 'cls_prob'\n    blob_box = 'pred_bbox'\n    op_nms = core.CreateOperator(\n        \"BoxWithNMSLimit\",\n        [blob_prob, blob_box],\n        ['score_nms', 'bbox_nms', 'class_nms'],\n        arg=[\n            putils.MakeArgument(\"score_thresh\", cfg.TEST.SCORE_THRESH),\n            putils.MakeArgument(\"nms\", cfg.TEST.NMS),\n            putils.MakeArgument(\"detections_per_im\", cfg.TEST.DETECTIONS_PER_IM),\n            putils.MakeArgument(\"soft_nms_enabled\", cfg.TEST.SOFT_NMS.ENABLED),\n            putils.MakeArgument(\"soft_nms_method\", cfg.TEST.SOFT_NMS.METHOD),\n            putils.MakeArgument(\"soft_nms_sigma\", cfg.TEST.SOFT_NMS.SIGMA),\n        ]\n    )\n    new_ops.extend([op_nms])\n    new_external_outputs.extend(['score_nms', 'bbox_nms', 'class_nms'])\n\n    net.Proto().op.extend(new_ops)\n    net.Proto().external_output.extend(new_external_outputs)\n\n\ndef convert_model_gpu(args, net, init_net):\n    assert args.device == 'gpu'\n\n    ret_net = copy.deepcopy(net)\n    ret_init_net = copy.deepcopy(init_net)\n\n    cdo_cuda = mutils.get_device_option_cuda()\n    cdo_cpu = mutils.get_device_option_cpu()\n\n    CPU_OPS = [\n        [\"GenerateProposals\", None],\n        [\"BBoxTransform\", None],\n        [\"BoxWithNMSLimit\", None],\n    ]\n    CPU_BLOBS = [\"im_info\", \"anchor\"]\n\n    @op_filter()\n    def convert_op_gpu(op):\n        for x in CPU_OPS:\n            if mutils.filter_op(op, type=x[0], inputs=x[1]):\n                return None\n        op.device_option.CopyFrom(cdo_cuda)\n        return [op]\n\n    @op_filter()\n    def convert_init_op_gpu(op):\n        if op.output[0] in CPU_BLOBS:\n            op.device_option.CopyFrom(cdo_cpu)\n        else:\n            op.device_option.CopyFrom(cdo_cuda)\n        return [op]\n\n    convert_op_in_proto(ret_init_net.Proto(), convert_init_op_gpu)\n    convert_op_in_proto(ret_net.Proto(), convert_op_gpu)\n\n    ret = core.InjectDeviceCopiesAmongNets([ret_init_net, ret_net])\n\n    return [ret[0][1], ret[0][0]]\n\n\ndef gen_init_net(net, blobs, empty_blobs):\n    blobs = copy.deepcopy(blobs)\n    for x in empty_blobs:\n        blobs[x] = np.array([], dtype=np.float32)\n    init_net = mutils.gen_init_net_from_blobs(\n        blobs, net.external_inputs)\n    init_net = core.Net(init_net)\n    return init_net\n\n\ndef _save_image_graphs(args, all_net, all_init_net):\n    print('Saving model graph...')\n    mutils.save_graph(\n        all_net.Proto(), os.path.join(args.out_dir, \"model_def.png\"),\n        op_only=False)\n    print('Model def image saved to {}.'.format(args.out_dir))\n\n\ndef _save_models(all_net, all_init_net, args):\n    print('Writing converted model to {}...'.format(args.out_dir))\n    fname = \"model\"\n\n    if not os.path.exists(args.out_dir):\n        os.makedirs(args.out_dir)\n\n    with open(os.path.join(args.out_dir, fname + '.pb'), 'w') as f:\n        f.write(all_net.Proto().SerializeToString())\n    with open(os.path.join(args.out_dir, fname + '.pbtxt'), 'w') as f:\n        f.write(str(all_net.Proto()))\n    with open(os.path.join(args.out_dir, fname + '_init.pb'), 'w') as f:\n        f.write(all_init_net.Proto().SerializeToString())\n\n    _save_image_graphs(args, all_net, all_init_net)\n\n\ndef load_model(args):\n    model = test_engine.initialize_model_from_cfg()\n    blobs = mutils.get_ws_blobs()\n\n    return model, blobs\n\n\ndef _get_result_blobs(check_blobs):\n    ret = {}\n    for x in check_blobs:\n        sn = core.ScopedName(x)\n        if workspace.HasBlob(sn):\n            ret[x] = workspace.FetchBlob(sn)\n        else:\n            ret[x] = None\n\n    return ret\n\n\ndef _sort_results(boxes, segms, keypoints, classes):\n    indices = np.argsort(boxes[:, -1])[::-1]\n    if boxes is not None:\n        boxes = boxes[indices, :]\n    if segms is not None:\n        segms = [segms[x] for x in indices]\n    if keypoints is not None:\n        keypoints = [keypoints[x] for x in indices]\n    if classes is not None:\n        if isinstance(classes, list):\n            classes = [classes[x] for x in indices]\n        else:\n            classes = classes[indices]\n\n    return boxes, segms, keypoints, classes\n\n\ndef run_model_cfg(args, im, check_blobs):\n    workspace.ResetWorkspace()\n    model, _ = load_model(args)\n    with c2_utils.NamedCudaScope(0):\n        cls_boxes, cls_segms, cls_keyps = test_engine.im_detect_all(\n            model, im, None, None,\n        )\n\n    boxes, segms, keypoints, classes = vis_utils.convert_from_cls_format(\n        cls_boxes, cls_segms, cls_keyps)\n\n    # sort the results based on score for comparision\n    boxes, segms, keypoints, classes = _sort_results(\n        boxes, segms, keypoints, classes)\n\n    # write final results back to workspace\n    def _ornone(res):\n        return np.array(res) if res is not None else np.array([], dtype=np.float32)\n    with c2_utils.NamedCudaScope(0):\n        workspace.FeedBlob(core.ScopedName('result_boxes'), _ornone(boxes))\n        workspace.FeedBlob(core.ScopedName('result_segms'), _ornone(segms))\n        workspace.FeedBlob(core.ScopedName('result_keypoints'), _ornone(keypoints))\n        workspace.FeedBlob(core.ScopedName('result_classids'), _ornone(classes))\n\n    # get result blobs\n    with c2_utils.NamedCudaScope(0):\n        ret = _get_result_blobs(check_blobs)\n\n    return ret\n\n\ndef _prepare_blobs(\n    im,\n    pixel_means,\n    target_size,\n    max_size,\n):\n    ''' Reference: blob.prep_im_for_blob() '''\n\n    im = im.astype(np.float32, copy=False)\n    im -= pixel_means\n    im_shape = im.shape\n\n    im_size_min = np.min(im_shape[0:2])\n    im_size_max = np.max(im_shape[0:2])\n    im_scale = float(target_size) / float(im_size_min)\n    if np.round(im_scale * im_size_max) > max_size:\n        im_scale = float(max_size) / float(im_size_max)\n    im = cv2.resize(im, None, None, fx=im_scale, fy=im_scale,\n                    interpolation=cv2.INTER_LINEAR)\n\n    blob = np.zeros([1, im.shape[0], im.shape[1], 3], dtype=np.float32)\n    blob[0, :, :, :] = im\n    channel_swap = (0, 3, 1, 2)  # swap channel to (k, c, h, w)\n    blob = blob.transpose(channel_swap)\n\n    blobs = {}\n    blobs['data'] = blob\n    blobs['im_info'] = np.array(\n        [[blob.shape[2], blob.shape[3], im_scale]],\n        dtype=np.float32\n    )\n    return blobs\n\n\ndef run_model_pb(args, net, init_net, im, check_blobs):\n    assert len(cfg.TEST.SCALES) == 1\n\n    workspace.ResetWorkspace()\n    workspace.RunNetOnce(init_net)\n    mutils.create_input_blobs_for_net(net.Proto())\n    workspace.CreateNet(net)\n\n    # input_blobs, _ = core_test._get_blobs(im, None)\n    input_blobs = _prepare_blobs(\n        im,\n        cfg.PIXEL_MEANS,\n        cfg.TEST.SCALES[0], cfg.TEST.MAX_SIZE\n    )\n    gpu_blobs = []\n    if args.device == 'gpu':\n        gpu_blobs = ['data']\n    for k, v in input_blobs.items():\n        workspace.FeedBlob(\n            core.ScopedName(k),\n            v,\n            mutils.get_device_option_cuda() if k in gpu_blobs else\n            mutils.get_device_option_cpu()\n        )\n\n    try:\n        workspace.RunNet(net.Proto().name)\n        scores = workspace.FetchBlob('score_nms')\n        classids = workspace.FetchBlob('class_nms')\n        boxes = workspace.FetchBlob('bbox_nms')\n    except Exception as e:\n        print('Running pb model failed.\\n{}'.format(e))\n        # may not detect anything at all\n        R = 0\n        scores = np.zeros((R,), dtype=np.float32)\n        boxes = np.zeros((R, 4), dtype=np.float32)\n        classids = np.zeros((R,), dtype=np.float32)\n\n    boxes = np.column_stack((boxes, scores))\n\n    # sort the results based on score for comparision\n    boxes, _, _, classids = _sort_results(\n        boxes, None, None, classids)\n\n    # write final result back to workspace\n    workspace.FeedBlob('result_boxes', boxes)\n    workspace.FeedBlob('result_classids', classids)\n\n    ret = _get_result_blobs(check_blobs)\n\n    return ret\n\n\ndef verify_model(args, model_pb, test_img_file):\n    check_blobs = [\n        \"result_boxes\", \"result_classids\",  # result\n    ]\n\n    print('Loading test file {}...'.format(test_img_file))\n    test_img = cv2.imread(test_img_file)\n    assert test_img is not None\n\n    def _run_cfg_func(im, blobs):\n        return run_model_cfg(args, im, check_blobs)\n\n    def _run_pb_func(im, blobs):\n        return run_model_pb(args, model_pb[0], model_pb[1], im, check_blobs)\n\n    print('Checking models...')\n    assert mutils.compare_model(\n        _run_cfg_func, _run_pb_func, test_img, check_blobs)\n\n\ndef main():\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    args = parse_args()\n    logger.info('Called with args:')\n    logger.info(args)\n    if args.cfg_file is not None:\n        merge_cfg_from_file(args.cfg_file)\n    if args.opts is not None:\n        merge_cfg_from_list(args.opts)\n    cfg.NUM_GPUS = 1\n    assert_and_infer_cfg()\n    logger.info('Conerting model with config:')\n    logger.info(pprint.pformat(cfg))\n\n    assert not cfg.MODEL.KEYPOINTS_ON, \"Keypoint model not supported.\"\n    assert not cfg.MODEL.MASK_ON, \"Mask model not supported.\"\n    assert not cfg.FPN.FPN_ON, \"FPN not supported.\"\n    assert not cfg.RETINANET.RETINANET_ON, \"RetinaNet model not supported.\"\n\n    # load model from cfg\n    model, blobs = load_model(args)\n\n    net = core.Net('')\n    net.Proto().op.extend(copy.deepcopy(model.net.Proto().op))\n    net.Proto().external_input.extend(\n        copy.deepcopy(model.net.Proto().external_input))\n    net.Proto().external_output.extend(\n        copy.deepcopy(model.net.Proto().external_output))\n    net.Proto().type = args.net_execution_type\n    net.Proto().num_workers = 1 if args.net_execution_type == 'simple' else 4\n\n    # Reset the device_option, change to unscope name and replace python operators\n    convert_net(args, net.Proto(), blobs)\n\n    # add operators for bbox\n    add_bbox_ops(args, net, blobs)\n\n    if args.fuse_af:\n        print('Fusing affine channel...')\n        net, blobs = mutils.fuse_net_affine(\n            net, blobs)\n\n    if args.use_nnpack:\n        mutils.update_mobile_engines(net.Proto())\n\n    # generate init net\n    empty_blobs = ['data', 'im_info']\n    init_net = gen_init_net(net, blobs, empty_blobs)\n\n    if args.device == 'gpu':\n        [net, init_net] = convert_model_gpu(args, net, init_net)\n\n    net.Proto().name = args.net_name\n    init_net.Proto().name = args.net_name + \"_init\"\n\n    if args.test_img is not None:\n        verify_model(args, [net, init_net], args.test_img)\n\n    _save_models(net, init_net, args)\n\n\nif __name__ == '__main__':\n    main()\n", "description": "FAIR's research platform for object detection research, implementing popular algorithms like Mask R-CNN and RetinaNet.", "file_name": "convert_pkl_to_pb.py", "id": "1c2ed7aa84fc9f62380615f83316d6ec", "language": "Python", "project_name": "Detectron", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/facebookresearch-Detectron/facebookresearch-Detectron-958b0ad/tools/convert_pkl_to_pb.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:01:25Z", "url": "https://github.com/facebookresearch/Detectron", "wiki": false}