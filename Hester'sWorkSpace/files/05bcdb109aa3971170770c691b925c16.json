{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\"\"\"Provides flags that are common to scripts.\n\nCommon flags from train/eval/vis/export_model.py are collected in this script.\n\"\"\"\nimport collections\n\nimport tensorflow as tf\n\nflags = tf.app.flags\n\n Flags for input preprocessing.\n\nflags.DEFINE_integer('min_resize_value', None,\n                     'Desired size of the smaller image side.')\n\nflags.DEFINE_integer('max_resize_value', None,\n                     'Maximum allowed size of the larger image side.')\n\nflags.DEFINE_integer('resize_factor', None,\n                     'Resized dimensions are multiple of factor plus one.')\n\n Model dependent flags.\n\nflags.DEFINE_integer('logits_kernel_size', 1,\n                     'The kernel size for the convolutional kernel that '\n                     'generates logits.')\n\n We will support `mobilenet_v2' in the coming update. When using\n 'xception_65', we set atrous_rates = [6, 12, 18] (output stride 16) and\n decoder_output_stride = 4.\nflags.DEFINE_enum('model_variant', 'xception_65', ['xception_65'],\n                  'DeepLab model variants.')\n\nflags.DEFINE_multi_float('image_pyramid', None,\n                         'Input scales for multi-scale feature extraction.')\n\nflags.DEFINE_boolean('add_image_level_feature', True,\n                     'Add image level feature.')\n\nflags.DEFINE_boolean('aspp_with_batch_norm', True,\n                     'Use batch norm parameters for ASPP or not.')\n\nflags.DEFINE_boolean('aspp_with_separable_conv', True,\n                     'Use separable convolution for ASPP or not.')\n\nflags.DEFINE_multi_integer('multi_grid', None,\n                           'Employ a hierarchy of atrous rates for ResNet.')\n\n For `xception_65`, use decoder_output_stride = 4.\nflags.DEFINE_integer('decoder_output_stride', None,\n                     'The ratio of input to output spatial resolution when '\n                     'employing decoder to refine segmentation results.')\n\nflags.DEFINE_boolean('decoder_use_separable_conv', True,\n                     'Employ separable convolution for decoder or not.')\n\nflags.DEFINE_enum('merge_method', 'max', ['max', 'avg'],\n                  'Scheme to merge multi scale features.')\n\nFLAGS = flags.FLAGS\n\n Constants\n\n Perform semantic segmentation predictions.\nOUTPUT_TYPE = 'semantic'\n\n Semantic segmentation item names.\nLABELS_CLASS = 'labels_class'\nIMAGE = 'image'\nHEIGHT = 'height'\nWIDTH = 'width'\nIMAGE_NAME = 'image_name'\nLABEL = 'label'\nORIGINAL_IMAGE = 'original_image'\n\n Test set name.\nTEST_SET = 'test'\n\n\nclass ModelOptions(\n    collections.namedtuple('ModelOptions', [\n        'outputs_to_num_classes',\n        'crop_size',\n        'atrous_rates',\n        'output_stride',\n        'merge_method',\n        'add_image_level_feature',\n        'aspp_with_batch_norm',\n        'aspp_with_separable_conv',\n        'multi_grid',\n        'decoder_output_stride',\n        'decoder_use_separable_conv',\n        'logits_kernel_size',\n        'model_variant'\n    ])):\n  \"\"\"Immutable class to hold model options.\"\"\"\n\n  __slots__ = ()\n\n  def __new__(cls,\n              outputs_to_num_classes,\n              crop_size=None,\n              atrous_rates=None,\n              output_stride=8):\n    \"\"\"Constructor to set default values.\n\n    Args:\n      outputs_to_num_classes: A dictionary from output type to the number of\n        classes. For example, for the task of semantic segmentation with 21\n        semantic classes, we would have outputs_to_num_classes['semantic'] = 21.\n      crop_size: A tuple [crop_height, crop_width].\n      atrous_rates: A list of atrous convolution rates for ASPP.\n      output_stride: The ratio of input to output spatial resolution.\n\n    Returns:\n      A new ModelOptions instance.\n    \"\"\"\n    return super(ModelOptions, cls).__new__(\n        cls, outputs_to_num_classes, crop_size, atrous_rates, output_stride,\n        FLAGS.merge_method, FLAGS.add_image_level_feature,\n        FLAGS.aspp_with_batch_norm, FLAGS.aspp_with_separable_conv,\n        FLAGS.multi_grid, FLAGS.decoder_output_stride,\n        FLAGS.decoder_use_separable_conv, FLAGS.logits_kernel_size,\n        FLAGS.model_variant)\n", "comments": "   provides flags common scripts   common flags train eval vis export model py collected script      import collections  import tensorflow tf  flags   tf app flags    flags input preprocessing   flags define integer( min resize value   none                        desired size smaller image side  )  flags define integer( max resize value   none                        maximum allowed size larger image side  )  flags define integer( resize factor   none                        resized dimensions multiple factor plus one  )    model dependent flags   flags define integer( logits kernel size   1                        the kernel size convolutional kernel                         generates logits  )    we support  mobilenet v2  coming update  when using    xception 65   set atrous rates    6  12  18  (output stride 16)   decoder output stride   4  flags define enum( model variant    xception 65     xception 65                       deeplab model variants  )  flags define multi float( image pyramid   none                            input scales multi scale feature extraction  )  flags define boolean( add image level feature   true                        add image level feature  )  flags define boolean( aspp batch norm   true                        use batch norm parameters aspp  )  flags define boolean( aspp separable conv   true                        use separable convolution aspp  )  flags define multi integer( multi grid   none                              employ hierarchy atrous rates resnet  )    for  xception 65   use decoder output stride   4  flags define integer( decoder output stride   none                        the ratio input output spatial resolution                         employing decoder refine segmentation results  )  flags define boolean( decoder use separable conv   true                        employ separable convolution decoder  )  flags define enum( merge method    max     max    avg                       scheme merge multi scale features  )  flags   flags flags    constants    perform semantic segmentation predictions  output type    semantic     semantic segmentation item names  labels class    labels class  image    image  height    height  width    width  image name    image name  label    label  original image    original image     test set name  test set    test    class modeloptions(     collections namedtuple( modeloptions              outputs num classes            crop size            atrous rates            output stride            merge method            add image level feature            aspp batch norm            aspp separable conv            multi grid            decoder output stride            decoder use separable conv            logits kernel size            model variant       ))       immutable class hold model options          slots     ()    def   new  (cls                outputs num classes                crop size none                atrous rates none                output stride 8)         constructor set default values       args        outputs num classes  a dictionary output type number         classes  for example  task semantic segmentation 21         semantic classes  would outputs num classes  semantic     21        crop size  a tuple  crop height  crop width         atrous rates  a list atrous convolution rates aspp        output stride  the ratio input output spatial resolution       returns        a new modeloptions instance             copyright 2018 the tensorflow authors all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                       flags input preprocessing     model dependent flags     we support  mobilenet v2  coming update  when using     xception 65   set atrous rates    6  12  18  (output stride 16)    decoder output stride   4     for  xception 65   use decoder output stride   4     constants    perform semantic segmentation predictions     semantic segmentation item names     test set name  ", "content": "# Copyright 2018 The TensorFlow Authors All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Provides flags that are common to scripts.\n\nCommon flags from train/eval/vis/export_model.py are collected in this script.\n\"\"\"\nimport collections\n\nimport tensorflow as tf\n\nflags = tf.app.flags\n\n# Flags for input preprocessing.\n\nflags.DEFINE_integer('min_resize_value', None,\n                     'Desired size of the smaller image side.')\n\nflags.DEFINE_integer('max_resize_value', None,\n                     'Maximum allowed size of the larger image side.')\n\nflags.DEFINE_integer('resize_factor', None,\n                     'Resized dimensions are multiple of factor plus one.')\n\n# Model dependent flags.\n\nflags.DEFINE_integer('logits_kernel_size', 1,\n                     'The kernel size for the convolutional kernel that '\n                     'generates logits.')\n\n# We will support `mobilenet_v2' in the coming update. When using\n# 'xception_65', we set atrous_rates = [6, 12, 18] (output stride 16) and\n# decoder_output_stride = 4.\nflags.DEFINE_enum('model_variant', 'xception_65', ['xception_65'],\n                  'DeepLab model variants.')\n\nflags.DEFINE_multi_float('image_pyramid', None,\n                         'Input scales for multi-scale feature extraction.')\n\nflags.DEFINE_boolean('add_image_level_feature', True,\n                     'Add image level feature.')\n\nflags.DEFINE_boolean('aspp_with_batch_norm', True,\n                     'Use batch norm parameters for ASPP or not.')\n\nflags.DEFINE_boolean('aspp_with_separable_conv', True,\n                     'Use separable convolution for ASPP or not.')\n\nflags.DEFINE_multi_integer('multi_grid', None,\n                           'Employ a hierarchy of atrous rates for ResNet.')\n\n# For `xception_65`, use decoder_output_stride = 4.\nflags.DEFINE_integer('decoder_output_stride', None,\n                     'The ratio of input to output spatial resolution when '\n                     'employing decoder to refine segmentation results.')\n\nflags.DEFINE_boolean('decoder_use_separable_conv', True,\n                     'Employ separable convolution for decoder or not.')\n\nflags.DEFINE_enum('merge_method', 'max', ['max', 'avg'],\n                  'Scheme to merge multi scale features.')\n\nFLAGS = flags.FLAGS\n\n# Constants\n\n# Perform semantic segmentation predictions.\nOUTPUT_TYPE = 'semantic'\n\n# Semantic segmentation item names.\nLABELS_CLASS = 'labels_class'\nIMAGE = 'image'\nHEIGHT = 'height'\nWIDTH = 'width'\nIMAGE_NAME = 'image_name'\nLABEL = 'label'\nORIGINAL_IMAGE = 'original_image'\n\n# Test set name.\nTEST_SET = 'test'\n\n\nclass ModelOptions(\n    collections.namedtuple('ModelOptions', [\n        'outputs_to_num_classes',\n        'crop_size',\n        'atrous_rates',\n        'output_stride',\n        'merge_method',\n        'add_image_level_feature',\n        'aspp_with_batch_norm',\n        'aspp_with_separable_conv',\n        'multi_grid',\n        'decoder_output_stride',\n        'decoder_use_separable_conv',\n        'logits_kernel_size',\n        'model_variant'\n    ])):\n  \"\"\"Immutable class to hold model options.\"\"\"\n\n  __slots__ = ()\n\n  def __new__(cls,\n              outputs_to_num_classes,\n              crop_size=None,\n              atrous_rates=None,\n              output_stride=8):\n    \"\"\"Constructor to set default values.\n\n    Args:\n      outputs_to_num_classes: A dictionary from output type to the number of\n        classes. For example, for the task of semantic segmentation with 21\n        semantic classes, we would have outputs_to_num_classes['semantic'] = 21.\n      crop_size: A tuple [crop_height, crop_width].\n      atrous_rates: A list of atrous convolution rates for ASPP.\n      output_stride: The ratio of input to output spatial resolution.\n\n    Returns:\n      A new ModelOptions instance.\n    \"\"\"\n    return super(ModelOptions, cls).__new__(\n        cls, outputs_to_num_classes, crop_size, atrous_rates, output_stride,\n        FLAGS.merge_method, FLAGS.add_image_level_feature,\n        FLAGS.aspp_with_batch_norm, FLAGS.aspp_with_separable_conv,\n        FLAGS.multi_grid, FLAGS.decoder_output_stride,\n        FLAGS.decoder_use_separable_conv, FLAGS.logits_kernel_size,\n        FLAGS.model_variant)\n", "description": "Models and examples built with TensorFlow", "file_name": "common.py", "id": "05bcdb109aa3971170770c691b925c16", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-models/tensorflow-models-086d914/research/deeplab/common.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:59:19Z", "url": "https://github.com/tensorflow/models", "wiki": true}