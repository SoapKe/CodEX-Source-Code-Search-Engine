{"author": "binux", "code": "\n# -*- encoding: utf-8 -*-\n\n\n\n\n\n\nimport os\nimport copy\nimport time\nimport httpbin\nimport unittest2 as unittest\n\nimport logging\nimport logging.config\nlogging.config.fileConfig(\"pyspider/logging.conf\")\n\nfrom pyspider.libs import utils\nfrom pyspider.libs.response import rebuild_response\nfrom pyspider.fetcher.tornado_fetcher import Fetcher\n\nclass TestResponse(unittest.TestCase):\n    sample_task_http = {\n        'taskid': 'taskid',\n        'project': 'project',\n        'url': '',\n    }\n\n    @classmethod\n    def setUpClass(self):\n        self.fetcher = Fetcher(None, None, async=False)\n        self.httpbin_thread = utils.run_in_subprocess(httpbin.app.run, port=14887, passthrough_errors=False)\n        self.httpbin = 'http://127.0.0.1:14887'\n        time.sleep(0.5)\n\n    @classmethod\n    def tearDownClass(self):\n        self.httpbin_thread.terminate()\n\n    def get(self, url, **kwargs):\n        if not url.startswith('http://'):\n            url = self.httpbin + url\n        request = copy.deepcopy(self.sample_task_http)\n        request['url'] = url\n        request.update(kwargs)\n        result = self.fetcher.fetch(request)\n        response = rebuild_response(result)\n        return response\n\n    def test_10_html(self):\n        response = self.get('/html')\n        self.assertEqual(response.status_code, 200)\n        self.assertIsNotNone(response.doc('h1'))\n\n    def test_20_xml(self):\n        response = self.get('/xml')\n        self.assertEqual(response.status_code, 200)\n        self.assertIsNotNone(response.doc('item'))\n\n    def test_30_gzip(self):\n        response = self.get('/gzip')\n        self.assertEqual(response.status_code, 200)\n        self.assertIn('gzipped', response.text)\n\n    def test_40_deflate(self):\n        response = self.get('/deflate')\n        self.assertEqual(response.status_code, 200)\n        self.assertIn('deflated', response.text)\n\n    def test_50_ok(self):\n        response = self.get('/status/200')\n        self.assertTrue(response.ok)\n        self.assertTrue(response)\n        response = self.get('/status/302')\n        self.assertTrue(response.ok)\n        self.assertTrue(response)\n        with self.assertRaises(Exception):\n            self.raise_for_status(allow_redirects=False)\n\n    def test_60_not_ok(self):\n        response = self.get('/status/400')\n        self.assertFalse(response.ok)\n        self.assertFalse(response)\n        response = self.get('/status/500')\n        self.assertFalse(response.ok)\n        self.assertFalse(response)\n        response = self.get('/status/600')\n        self.assertFalse(response.ok)\n        self.assertFalse(response)\n\n    def test_70_reraise_exception(self):\n        response = self.get('file://abc')\n        with self.assertRaisesRegexp(Exception, 'HTTP 599'):\n            response.raise_for_status()\n", "comments": "   usr bin env python        encoding  utf 8        vim  set et sw 4 ts 4 sts 4 ff unix fenc utf8     author  binux roy binux             http   binux    created 2015 01 18 11 10 27 ", "content": "#!/usr/bin/env python\n# -*- encoding: utf-8 -*-\n# vim: set et sw=4 ts=4 sts=4 ff=unix fenc=utf8:\n# Author: Binux<roy@binux.me>\n#         http://binux.me\n# Created on 2015-01-18 11:10:27\n\n\nimport os\nimport copy\nimport time\nimport httpbin\nimport unittest2 as unittest\n\nimport logging\nimport logging.config\nlogging.config.fileConfig(\"pyspider/logging.conf\")\n\nfrom pyspider.libs import utils\nfrom pyspider.libs.response import rebuild_response\nfrom pyspider.fetcher.tornado_fetcher import Fetcher\n\nclass TestResponse(unittest.TestCase):\n    sample_task_http = {\n        'taskid': 'taskid',\n        'project': 'project',\n        'url': '',\n    }\n\n    @classmethod\n    def setUpClass(self):\n        self.fetcher = Fetcher(None, None, async=False)\n        self.httpbin_thread = utils.run_in_subprocess(httpbin.app.run, port=14887, passthrough_errors=False)\n        self.httpbin = 'http://127.0.0.1:14887'\n        time.sleep(0.5)\n\n    @classmethod\n    def tearDownClass(self):\n        self.httpbin_thread.terminate()\n\n    def get(self, url, **kwargs):\n        if not url.startswith('http://'):\n            url = self.httpbin + url\n        request = copy.deepcopy(self.sample_task_http)\n        request['url'] = url\n        request.update(kwargs)\n        result = self.fetcher.fetch(request)\n        response = rebuild_response(result)\n        return response\n\n    def test_10_html(self):\n        response = self.get('/html')\n        self.assertEqual(response.status_code, 200)\n        self.assertIsNotNone(response.doc('h1'))\n\n    def test_20_xml(self):\n        response = self.get('/xml')\n        self.assertEqual(response.status_code, 200)\n        self.assertIsNotNone(response.doc('item'))\n\n    def test_30_gzip(self):\n        response = self.get('/gzip')\n        self.assertEqual(response.status_code, 200)\n        self.assertIn('gzipped', response.text)\n\n    def test_40_deflate(self):\n        response = self.get('/deflate')\n        self.assertEqual(response.status_code, 200)\n        self.assertIn('deflated', response.text)\n\n    def test_50_ok(self):\n        response = self.get('/status/200')\n        self.assertTrue(response.ok)\n        self.assertTrue(response)\n        response = self.get('/status/302')\n        self.assertTrue(response.ok)\n        self.assertTrue(response)\n        with self.assertRaises(Exception):\n            self.raise_for_status(allow_redirects=False)\n\n    def test_60_not_ok(self):\n        response = self.get('/status/400')\n        self.assertFalse(response.ok)\n        self.assertFalse(response)\n        response = self.get('/status/500')\n        self.assertFalse(response.ok)\n        self.assertFalse(response)\n        response = self.get('/status/600')\n        self.assertFalse(response.ok)\n        self.assertFalse(response)\n\n    def test_70_reraise_exception(self):\n        response = self.get('file://abc')\n        with self.assertRaisesRegexp(Exception, 'HTTP 599'):\n            response.raise_for_status()\n", "description": "A Powerful Spider(Web Crawler) System in Python.", "file_name": "test_response.py", "id": "f4f1acf8904f32e9df2df3527166e438", "language": "Python", "project_name": "pyspider", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/binux-pyspider/binux-pyspider-87337e7/tests/test_response.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:53:12Z", "url": "https://github.com/binux/pyspider", "wiki": false}