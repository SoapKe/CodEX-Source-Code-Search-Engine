{"author": "Theano", "code": "\n\n\nfrom __future__ import absolute_import, print_function, division\n\nimport unittest\n\nimport theano\n\n\n# 1. Op returns x * y\n\nclass ProdOp(theano.Op):\n    def __eq__(self, other):\n        return type(self) == type(other)\n\n    def __hash__(self):\n        return hash(type(self))\n\n    def __str__(self):\n        return self.__class__.__name__\n\n    def make_node(self, x, y):\n        x = theano.tensor.as_tensor_variable(x)\n        y = theano.tensor.as_tensor_variable(y)\n        outdim = x.ndim\n        output = (theano.tensor.TensorType\n                  (dtype=theano.scalar.upcast(x.dtype, y.dtype),\n                      broadcastable=[False] * outdim)())\n        return theano.Apply(self, inputs=[x, y], outputs=[output])\n\n    def perform(self, node, inputs, output_storage):\n        x, y = inputs\n        z = output_storage[0]\n        z[0] = x * y\n\n    def infer_shape(self, node, i0_shapes):\n        return [i0_shapes[0]]\n\n    def grad(self, inputs, output_grads):\n        return [output_grads[0] * inputs[1], output_grads[0] * inputs[0]]\n\n\n# 2. Op returns x + y and x - y\n\nclass SumDiffOp(theano.Op):\n    def __eq__(self, other):\n        return type(self) == type(other)\n\n    def __hash__(self):\n        return hash(type(self))\n\n    def __str__(self):\n        return self.__class__.__name__\n\n    def make_node(self, x, y):\n        x = theano.tensor.as_tensor_variable(x)\n        y = theano.tensor.as_tensor_variable(y)\n        outdim = x.ndim\n        output1 = (theano.tensor.TensorType\n                  (dtype=theano.scalar.upcast(x.dtype, y.dtype),\n                      broadcastable=[False] * outdim)())\n        output2 = (theano.tensor.TensorType\n                  (dtype=theano.scalar.upcast(x.dtype, y.dtype),\n                      broadcastable=[False] * outdim)())\n        return theano.Apply(self, inputs=[x, y], outputs=[output1, output2])\n\n    def perform(self, node, inputs, output_storage):\n        x, y = inputs\n        z1, z2 = output_storage\n        z1[0] = x + y\n        z2[0] = x - y\n\n    def infer_shape(self, node, i0_shapes):\n        return [i0_shapes[0], i0_shapes[0]]\n\n    def grad(self, inputs, output_grads):\n        og1, og2 = output_grads\n        if og1 is None:\n            og1 = theano.tensor.zeros_like(og2)\n        if og2 is None:\n            og2 = theano.tensor.zeros_like(og1)\n        return [og1 + og2, og1 - og2]\n\n\n\n\nimport numpy as np\nfrom theano.gof import Op, Apply\nfrom theano import tensor, function, printing\nfrom theano.tests import unittest_tools as utt\n\n\nclass TestProdOp(utt.InferShapeTester):\n\n    rng = np.random.RandomState(43)\n\n    def setUp(self):\n        super(TestProdOp, self).setUp()\n        self.op_class = ProdOp  \n\n    def test_perform(self):\n        x = theano.tensor.matrix()\n        y = theano.tensor.matrix()\n        f = theano.function([x, y], self.op_class()(x, y))\n        x_val = np.random.rand(5, 4)\n        y_val = np.random.rand(5, 4)\n        out = f(x_val, y_val)\n        assert np.allclose(x_val * y_val, out)\n\n    def test_gradient(self):\n        utt.verify_grad(self.op_class(), [np.random.rand(5, 4),\n                                np.random.rand(5, 4)],\n                        n_tests=1, rng=TestProdOp.rng)\n\n    def test_infer_shape(self):\n        x = tensor.dmatrix()\n        y = tensor.dmatrix()\n\n        self._compile_and_check([x, y], [self.op_class()(x, y)],\n                                [np.random.rand(5, 6),\n                                 np.random.rand(5, 6)],\n                                self.op_class)\n\n\nclass TestSumDiffOp(utt.InferShapeTester):\n\n    rng = np.random.RandomState(43)\n\n    def setUp(self):\n        super(TestSumDiffOp, self).setUp()\n        self.op_class = SumDiffOp\n\n    def test_perform(self):\n        x = theano.tensor.matrix()\n        y = theano.tensor.matrix()\n        f = theano.function([x, y], self.op_class()(x, y))\n        x_val = np.random.rand(5, 4)\n        y_val = np.random.rand(5, 4)\n        out = f(x_val, y_val)\n        assert np.allclose([x_val + y_val, x_val - y_val], out)\n\n    def test_gradient(self):\n        def output_0(x, y):\n            return self.op_class()(x, y)[0]\n\n        def output_1(x, y):\n            return self.op_class()(x, y)[1]\n\n        utt.verify_grad(output_0, [np.random.rand(5, 4),\n                                np.random.rand(5, 4)],\n                        n_tests=1, rng=TestSumDiffOp.rng)\n        utt.verify_grad(output_1, [np.random.rand(5, 4),\n                                np.random.rand(5, 4)],\n                        n_tests=1, rng=TestSumDiffOp.rng)\n\n    def test_infer_shape(self):\n        x = tensor.dmatrix()\n        y = tensor.dmatrix()\n\n        \n\n        self._compile_and_check([x, y], self.op_class()(x, y),\n                                [np.random.rand(5, 6),\n                                 np.random.rand(5, 6)],\n                                self.op_class)\n\n\n\nimport theano\nimport numpy as np\nfrom theano.compile.ops import as_op\n\n\ndef infer_shape_numpy_dot(node, input_shapes):\n    ashp, bshp = input_shapes\n    return [ashp[:-1] + bshp[-1:]]\n\n\n@as_op(itypes=[theano.tensor.fmatrix, theano.tensor.fmatrix],\n       otypes=[theano.tensor.fmatrix], infer_shape=infer_shape_numpy_dot)\ndef numpy_add(a, b):\n    return np.add(a, b)\n\n\ndef infer_shape_numpy_add_sub(node, input_shapes):\n    ashp, bshp = input_shapes\n    \n    return [ashp[0]]\n\n\n@as_op(itypes=[theano.tensor.fmatrix, theano.tensor.fmatrix],\n       otypes=[theano.tensor.fmatrix], infer_shape=infer_shape_numpy_add_sub)\ndef numpy_add(a, b):\n    return np.add(a, b)\n\n\n@as_op(itypes=[theano.tensor.fmatrix, theano.tensor.fmatrix],\n       otypes=[theano.tensor.fmatrix], infer_shape=infer_shape_numpy_add_sub)\ndef numpy_sub(a, b):\n    return np.sub(a, b)\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n", "comments": "   usr bin env python    theano tutorial    solution exercise section  extending theano     1  op returns x      2  op returns x   x      3  testing apparatus    case 1    adapt choice next instruction op test    op exercice    both inputs shape  return one  ", "content": "#!/usr/bin/env python\n# Theano tutorial\n# Solution to Exercise in section 'Extending Theano'\nfrom __future__ import absolute_import, print_function, division\n\nimport unittest\n\nimport theano\n\n\n# 1. Op returns x * y\n\nclass ProdOp(theano.Op):\n    def __eq__(self, other):\n        return type(self) == type(other)\n\n    def __hash__(self):\n        return hash(type(self))\n\n    def __str__(self):\n        return self.__class__.__name__\n\n    def make_node(self, x, y):\n        x = theano.tensor.as_tensor_variable(x)\n        y = theano.tensor.as_tensor_variable(y)\n        outdim = x.ndim\n        output = (theano.tensor.TensorType\n                  (dtype=theano.scalar.upcast(x.dtype, y.dtype),\n                      broadcastable=[False] * outdim)())\n        return theano.Apply(self, inputs=[x, y], outputs=[output])\n\n    def perform(self, node, inputs, output_storage):\n        x, y = inputs\n        z = output_storage[0]\n        z[0] = x * y\n\n    def infer_shape(self, node, i0_shapes):\n        return [i0_shapes[0]]\n\n    def grad(self, inputs, output_grads):\n        return [output_grads[0] * inputs[1], output_grads[0] * inputs[0]]\n\n\n# 2. Op returns x + y and x - y\n\nclass SumDiffOp(theano.Op):\n    def __eq__(self, other):\n        return type(self) == type(other)\n\n    def __hash__(self):\n        return hash(type(self))\n\n    def __str__(self):\n        return self.__class__.__name__\n\n    def make_node(self, x, y):\n        x = theano.tensor.as_tensor_variable(x)\n        y = theano.tensor.as_tensor_variable(y)\n        outdim = x.ndim\n        output1 = (theano.tensor.TensorType\n                  (dtype=theano.scalar.upcast(x.dtype, y.dtype),\n                      broadcastable=[False] * outdim)())\n        output2 = (theano.tensor.TensorType\n                  (dtype=theano.scalar.upcast(x.dtype, y.dtype),\n                      broadcastable=[False] * outdim)())\n        return theano.Apply(self, inputs=[x, y], outputs=[output1, output2])\n\n    def perform(self, node, inputs, output_storage):\n        x, y = inputs\n        z1, z2 = output_storage\n        z1[0] = x + y\n        z2[0] = x - y\n\n    def infer_shape(self, node, i0_shapes):\n        return [i0_shapes[0], i0_shapes[0]]\n\n    def grad(self, inputs, output_grads):\n        og1, og2 = output_grads\n        if og1 is None:\n            og1 = theano.tensor.zeros_like(og2)\n        if og2 is None:\n            og2 = theano.tensor.zeros_like(og1)\n        return [og1 + og2, og1 - og2]\n\n\n# 3. Testing apparatus\n\nimport numpy as np\nfrom theano.gof import Op, Apply\nfrom theano import tensor, function, printing\nfrom theano.tests import unittest_tools as utt\n\n\nclass TestProdOp(utt.InferShapeTester):\n\n    rng = np.random.RandomState(43)\n\n    def setUp(self):\n        super(TestProdOp, self).setUp()\n        self.op_class = ProdOp  # case 1\n\n    def test_perform(self):\n        x = theano.tensor.matrix()\n        y = theano.tensor.matrix()\n        f = theano.function([x, y], self.op_class()(x, y))\n        x_val = np.random.rand(5, 4)\n        y_val = np.random.rand(5, 4)\n        out = f(x_val, y_val)\n        assert np.allclose(x_val * y_val, out)\n\n    def test_gradient(self):\n        utt.verify_grad(self.op_class(), [np.random.rand(5, 4),\n                                np.random.rand(5, 4)],\n                        n_tests=1, rng=TestProdOp.rng)\n\n    def test_infer_shape(self):\n        x = tensor.dmatrix()\n        y = tensor.dmatrix()\n\n        self._compile_and_check([x, y], [self.op_class()(x, y)],\n                                [np.random.rand(5, 6),\n                                 np.random.rand(5, 6)],\n                                self.op_class)\n\n\nclass TestSumDiffOp(utt.InferShapeTester):\n\n    rng = np.random.RandomState(43)\n\n    def setUp(self):\n        super(TestSumDiffOp, self).setUp()\n        self.op_class = SumDiffOp\n\n    def test_perform(self):\n        x = theano.tensor.matrix()\n        y = theano.tensor.matrix()\n        f = theano.function([x, y], self.op_class()(x, y))\n        x_val = np.random.rand(5, 4)\n        y_val = np.random.rand(5, 4)\n        out = f(x_val, y_val)\n        assert np.allclose([x_val + y_val, x_val - y_val], out)\n\n    def test_gradient(self):\n        def output_0(x, y):\n            return self.op_class()(x, y)[0]\n\n        def output_1(x, y):\n            return self.op_class()(x, y)[1]\n\n        utt.verify_grad(output_0, [np.random.rand(5, 4),\n                                np.random.rand(5, 4)],\n                        n_tests=1, rng=TestSumDiffOp.rng)\n        utt.verify_grad(output_1, [np.random.rand(5, 4),\n                                np.random.rand(5, 4)],\n                        n_tests=1, rng=TestSumDiffOp.rng)\n\n    def test_infer_shape(self):\n        x = tensor.dmatrix()\n        y = tensor.dmatrix()\n\n        # adapt the choice of the next instruction to the op under test\n\n        self._compile_and_check([x, y], self.op_class()(x, y),\n                                [np.random.rand(5, 6),\n                                 np.random.rand(5, 6)],\n                                self.op_class)\n\n\n# as_op exercice\nimport theano\nimport numpy as np\nfrom theano.compile.ops import as_op\n\n\ndef infer_shape_numpy_dot(node, input_shapes):\n    ashp, bshp = input_shapes\n    return [ashp[:-1] + bshp[-1:]]\n\n\n@as_op(itypes=[theano.tensor.fmatrix, theano.tensor.fmatrix],\n       otypes=[theano.tensor.fmatrix], infer_shape=infer_shape_numpy_dot)\ndef numpy_add(a, b):\n    return np.add(a, b)\n\n\ndef infer_shape_numpy_add_sub(node, input_shapes):\n    ashp, bshp = input_shapes\n    # Both inputs should have that same shape, so we just return one of them.\n    return [ashp[0]]\n\n\n@as_op(itypes=[theano.tensor.fmatrix, theano.tensor.fmatrix],\n       otypes=[theano.tensor.fmatrix], infer_shape=infer_shape_numpy_add_sub)\ndef numpy_add(a, b):\n    return np.add(a, b)\n\n\n@as_op(itypes=[theano.tensor.fmatrix, theano.tensor.fmatrix],\n       otypes=[theano.tensor.fmatrix], infer_shape=infer_shape_numpy_add_sub)\ndef numpy_sub(a, b):\n    return np.sub(a, b)\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n", "description": "Theano is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation.", "file_name": "extending_theano_solution_1.py", "id": "5b0cec94f9ddc968de7b2b3e05af6dae", "language": "Python", "project_name": "Theano", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/Theano-Theano/Theano-Theano-546067d/doc/extending/extending_theano_solution_1.py", "save_time": "", "source": "", "update_at": "2018-03-18T03:16:17Z", "url": "https://github.com/Theano/Theano", "wiki": true}