{"author": "tensorflow", "code": "import tensorflow as tf\n\nclass AdditiveGaussianNoiseAutoencoder(object):\n    def __init__(self, n_input, n_hidden, transfer_function = tf.nn.softplus, optimizer = tf.train.AdamOptimizer(),\n                 scale = 0.1):\n        self.n_input = n_input\n        self.n_hidden = n_hidden\n        self.transfer = transfer_function\n        self.scale = tf.placeholder(tf.float32)\n        self.training_scale = scale\n        network_weights = self._initialize_weights()\n        self.weights = network_weights\n\n        \n        self.x = tf.placeholder(tf.float32, [None, self.n_input])\n        self.hidden = self.transfer(tf.add(tf.matmul(self.x + scale * tf.random_normal((n_input,)),\n                self.weights['w1']),\n                self.weights['b1']))\n        self.reconstruction = tf.add(tf.matmul(self.hidden, self.weights['w2']), self.weights['b2'])\n\n        \n        self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n        self.optimizer = optimizer.minimize(self.cost)\n\n        init = tf.global_variables_initializer()\n        self.sess = tf.Session()\n        self.sess.run(init)\n\n    def _initialize_weights(self):\n        all_weights = dict()\n        all_weights['w1'] = tf.get_variable(\"w1\", shape=[self.n_input, self.n_hidden],\n            initializer=tf.contrib.layers.xavier_initializer())\n        all_weights['b1'] = tf.Variable(tf.zeros([self.n_hidden], dtype = tf.float32))\n        all_weights['w2'] = tf.Variable(tf.zeros([self.n_hidden, self.n_input], dtype = tf.float32))\n        all_weights['b2'] = tf.Variable(tf.zeros([self.n_input], dtype = tf.float32))\n        return all_weights\n\n    def partial_fit(self, X):\n        cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict = {self.x: X,\n                                                                            self.scale: self.training_scale\n                                                                            })\n        return cost\n\n    def calc_total_cost(self, X):\n        return self.sess.run(self.cost, feed_dict = {self.x: X,\n                                                     self.scale: self.training_scale\n                                                     })\n\n    def transform(self, X):\n        return self.sess.run(self.hidden, feed_dict = {self.x: X,\n                                                       self.scale: self.training_scale\n                                                       })\n\n    def generate(self, hidden=None):\n        if hidden is None:\n            hidden = self.sess.run(tf.random_normal([1, self.n_hidden]))\n        return self.sess.run(self.reconstruction, feed_dict = {self.hidden: hidden})\n\n    def reconstruct(self, X):\n        return self.sess.run(self.reconstruction, feed_dict = {self.x: X,\n                                                               self.scale: self.training_scale\n                                                               })\n\n    def getWeights(self):\n        return self.sess.run(self.weights['w1'])\n\n    def getBiases(self):\n        return self.sess.run(self.weights['b1'])\n\n\nclass MaskingNoiseAutoencoder(object):\n    def __init__(self, n_input, n_hidden, transfer_function = tf.nn.softplus, optimizer = tf.train.AdamOptimizer(),\n                 dropout_probability = 0.95):\n        self.n_input = n_input\n        self.n_hidden = n_hidden\n        self.transfer = transfer_function\n        self.dropout_probability = dropout_probability\n        self.keep_prob = tf.placeholder(tf.float32)\n\n        network_weights = self._initialize_weights()\n        self.weights = network_weights\n\n        \n        self.x = tf.placeholder(tf.float32, [None, self.n_input])\n        self.hidden = self.transfer(tf.add(tf.matmul(tf.nn.dropout(self.x, self.keep_prob), self.weights['w1']),\n                                           self.weights['b1']))\n        self.reconstruction = tf.add(tf.matmul(self.hidden, self.weights['w2']), self.weights['b2'])\n\n        \n        self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n        self.optimizer = optimizer.minimize(self.cost)\n\n        init = tf.global_variables_initializer()\n        self.sess = tf.Session()\n        self.sess.run(init)\n\n    def _initialize_weights(self):\n        all_weights = dict()\n        all_weights['w1'] = tf.get_variable(\"w1\", shape=[self.n_input, self.n_hidden],\n            initializer=tf.contrib.layers.xavier_initializer())\n        all_weights['b1'] = tf.Variable(tf.zeros([self.n_hidden], dtype = tf.float32))\n        all_weights['w2'] = tf.Variable(tf.zeros([self.n_hidden, self.n_input], dtype = tf.float32))\n        all_weights['b2'] = tf.Variable(tf.zeros([self.n_input], dtype = tf.float32))\n        return all_weights\n\n    def partial_fit(self, X):\n        cost, opt = self.sess.run((self.cost, self.optimizer),\n                                  feed_dict = {self.x: X, self.keep_prob: self.dropout_probability})\n        return cost\n\n    def calc_total_cost(self, X):\n        return self.sess.run(self.cost, feed_dict = {self.x: X, self.keep_prob: 1.0})\n\n    def transform(self, X):\n        return self.sess.run(self.hidden, feed_dict = {self.x: X, self.keep_prob: 1.0})\n\n    def generate(self, hidden=None):\n        if hidden is None:\n            hidden = self.sess.run(tf.random_normal([1, self.n_hidden]))\n        return self.sess.run(self.reconstruction, feed_dict = {self.hidden: hidden})\n\n    def reconstruct(self, X):\n        return self.sess.run(self.reconstruction, feed_dict = {self.x: X, self.keep_prob: 1.0})\n\n    def getWeights(self):\n        return self.sess.run(self.weights['w1'])\n\n    def getBiases(self):\n        return self.sess.run(self.weights['b1'])\n", "comments": "model cost model cost", "content": "import tensorflow as tf\n\nclass AdditiveGaussianNoiseAutoencoder(object):\n    def __init__(self, n_input, n_hidden, transfer_function = tf.nn.softplus, optimizer = tf.train.AdamOptimizer(),\n                 scale = 0.1):\n        self.n_input = n_input\n        self.n_hidden = n_hidden\n        self.transfer = transfer_function\n        self.scale = tf.placeholder(tf.float32)\n        self.training_scale = scale\n        network_weights = self._initialize_weights()\n        self.weights = network_weights\n\n        # model\n        self.x = tf.placeholder(tf.float32, [None, self.n_input])\n        self.hidden = self.transfer(tf.add(tf.matmul(self.x + scale * tf.random_normal((n_input,)),\n                self.weights['w1']),\n                self.weights['b1']))\n        self.reconstruction = tf.add(tf.matmul(self.hidden, self.weights['w2']), self.weights['b2'])\n\n        # cost\n        self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n        self.optimizer = optimizer.minimize(self.cost)\n\n        init = tf.global_variables_initializer()\n        self.sess = tf.Session()\n        self.sess.run(init)\n\n    def _initialize_weights(self):\n        all_weights = dict()\n        all_weights['w1'] = tf.get_variable(\"w1\", shape=[self.n_input, self.n_hidden],\n            initializer=tf.contrib.layers.xavier_initializer())\n        all_weights['b1'] = tf.Variable(tf.zeros([self.n_hidden], dtype = tf.float32))\n        all_weights['w2'] = tf.Variable(tf.zeros([self.n_hidden, self.n_input], dtype = tf.float32))\n        all_weights['b2'] = tf.Variable(tf.zeros([self.n_input], dtype = tf.float32))\n        return all_weights\n\n    def partial_fit(self, X):\n        cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict = {self.x: X,\n                                                                            self.scale: self.training_scale\n                                                                            })\n        return cost\n\n    def calc_total_cost(self, X):\n        return self.sess.run(self.cost, feed_dict = {self.x: X,\n                                                     self.scale: self.training_scale\n                                                     })\n\n    def transform(self, X):\n        return self.sess.run(self.hidden, feed_dict = {self.x: X,\n                                                       self.scale: self.training_scale\n                                                       })\n\n    def generate(self, hidden=None):\n        if hidden is None:\n            hidden = self.sess.run(tf.random_normal([1, self.n_hidden]))\n        return self.sess.run(self.reconstruction, feed_dict = {self.hidden: hidden})\n\n    def reconstruct(self, X):\n        return self.sess.run(self.reconstruction, feed_dict = {self.x: X,\n                                                               self.scale: self.training_scale\n                                                               })\n\n    def getWeights(self):\n        return self.sess.run(self.weights['w1'])\n\n    def getBiases(self):\n        return self.sess.run(self.weights['b1'])\n\n\nclass MaskingNoiseAutoencoder(object):\n    def __init__(self, n_input, n_hidden, transfer_function = tf.nn.softplus, optimizer = tf.train.AdamOptimizer(),\n                 dropout_probability = 0.95):\n        self.n_input = n_input\n        self.n_hidden = n_hidden\n        self.transfer = transfer_function\n        self.dropout_probability = dropout_probability\n        self.keep_prob = tf.placeholder(tf.float32)\n\n        network_weights = self._initialize_weights()\n        self.weights = network_weights\n\n        # model\n        self.x = tf.placeholder(tf.float32, [None, self.n_input])\n        self.hidden = self.transfer(tf.add(tf.matmul(tf.nn.dropout(self.x, self.keep_prob), self.weights['w1']),\n                                           self.weights['b1']))\n        self.reconstruction = tf.add(tf.matmul(self.hidden, self.weights['w2']), self.weights['b2'])\n\n        # cost\n        self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n        self.optimizer = optimizer.minimize(self.cost)\n\n        init = tf.global_variables_initializer()\n        self.sess = tf.Session()\n        self.sess.run(init)\n\n    def _initialize_weights(self):\n        all_weights = dict()\n        all_weights['w1'] = tf.get_variable(\"w1\", shape=[self.n_input, self.n_hidden],\n            initializer=tf.contrib.layers.xavier_initializer())\n        all_weights['b1'] = tf.Variable(tf.zeros([self.n_hidden], dtype = tf.float32))\n        all_weights['w2'] = tf.Variable(tf.zeros([self.n_hidden, self.n_input], dtype = tf.float32))\n        all_weights['b2'] = tf.Variable(tf.zeros([self.n_input], dtype = tf.float32))\n        return all_weights\n\n    def partial_fit(self, X):\n        cost, opt = self.sess.run((self.cost, self.optimizer),\n                                  feed_dict = {self.x: X, self.keep_prob: self.dropout_probability})\n        return cost\n\n    def calc_total_cost(self, X):\n        return self.sess.run(self.cost, feed_dict = {self.x: X, self.keep_prob: 1.0})\n\n    def transform(self, X):\n        return self.sess.run(self.hidden, feed_dict = {self.x: X, self.keep_prob: 1.0})\n\n    def generate(self, hidden=None):\n        if hidden is None:\n            hidden = self.sess.run(tf.random_normal([1, self.n_hidden]))\n        return self.sess.run(self.reconstruction, feed_dict = {self.hidden: hidden})\n\n    def reconstruct(self, X):\n        return self.sess.run(self.reconstruction, feed_dict = {self.x: X, self.keep_prob: 1.0})\n\n    def getWeights(self):\n        return self.sess.run(self.weights['w1'])\n\n    def getBiases(self):\n        return self.sess.run(self.weights['b1'])\n", "description": "Models and examples built with TensorFlow", "file_name": "DenoisingAutoencoder.py", "id": "37bd15bfa01b1b9e0bc610e0e42bc5c8", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-models/tensorflow-models-086d914/research/autoencoder/autoencoder_models/DenoisingAutoencoder.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:59:19Z", "url": "https://github.com/tensorflow/models", "wiki": true}