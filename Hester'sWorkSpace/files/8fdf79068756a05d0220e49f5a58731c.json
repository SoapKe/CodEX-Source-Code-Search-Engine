{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\nimport pprint\nimport os\nimport numpy as np\nfrom tensorflow.python.platform import app\nfrom tensorflow.python.platform import flags\nimport logging\nimport src.utils as utils\nimport cfgs.config_common as cc\nimport datasets.nav_env_config as nec\n\n\nimport tensorflow as tf\n\nFLAGS = flags.FLAGS\n\nget_solver_vars = cc.get_solver_vars\nget_navtask_vars = cc.get_navtask_vars\n\n\nrgb_resnet_v2_50_path = 'data/init_models/resnet_v2_50/model.ckpt-5136169'\nd_resnet_v2_50_path = 'data/init_models/distill_rgb_to_d_resnet_v2_50/model.ckpt-120002'\n\ndef get_default_args():\n  summary_args = utils.Foo(display_interval=1, test_iters=26,\n                           arop_full_summary_iters=14)\n\n  control_args = utils.Foo(train=False, test=False,\n                           force_batchnorm_is_training_at_test=False,\n                           reset_rng_seed=False, only_eval_when_done=False,\n                           test_mode=None)\n  return summary_args, control_args\n\ndef get_default_baseline_args():\n  batch_norm_param = {'center': True, 'scale': True,\n                      'activation_fn':tf.nn.relu}\n  arch_args = utils.Foo(\n      pred_neurons=[], goal_embed_neurons=[], img_embed_neurons=[],\n      batch_norm_param=batch_norm_param, dim_reduce_neurons=64, combine_type='',\n      encoder='resnet_v2_50', action_sample_type='sample',\n      action_sample_combine_type='one_or_other',\n      sample_gt_prob_type='inverse_sigmoid_decay', dagger_sample_bn_false=True,\n      isd_k=750., use_visit_count=False, lstm_output=False, lstm_ego=False,\n      lstm_img=False, fc_dropout=0.0, embed_goal_for_state=False,\n      lstm_output_init_state_from_goal=False)\n  return arch_args\n\ndef get_arch_vars(arch_str):\n  if arch_str == '': vals = []\n  else: vals = arch_str.split('_')\n  \n  ks = ['ver', 'lstm_dim', 'dropout']\n  \n   Exp Ver\n  if len(vals) == 0: vals.append('v0')\n   LSTM dimentsions\n  if len(vals) == 1: vals.append('lstm2048')\n   Dropout\n  if len(vals) == 2: vals.append('noDO')\n  \n  assert(len(vals) == 3)\n  \n  vars = utils.Foo()\n  for k, v in zip(ks, vals):\n    setattr(vars, k, v)\n  \n  logging.error('arch_vars: %s', vars)\n  return vars\n\ndef process_arch_str(args, arch_str):\n   This function modifies args.\n  args.arch = get_default_baseline_args()\n  arch_vars = get_arch_vars(arch_str)\n\n  args.navtask.task_params.outputs.rel_goal_loc = True\n  args.navtask.task_params.input_type = 'vision'\n  args.navtask.task_params.outputs.images = True\n  \n  if args.navtask.camera_param.modalities[0] == 'rgb':\n    args.solver.pretrained_path = rgb_resnet_v2_50_path\n  elif args.navtask.camera_param.modalities[0] == 'depth':\n    args.solver.pretrained_path = d_resnet_v2_50_path\n  else:\n    logging.fatal('Neither of rgb or d')\n\n  if arch_vars.dropout == 'DO': \n    args.arch.fc_dropout = 0.5\n\n  args.tfcode = 'B'\n  \n  exp_ver = arch_vars.ver\n  if exp_ver == 'v0':\n     Multiplicative interaction between goal loc and image features.\n    args.arch.combine_type = 'multiply'\n    args.arch.pred_neurons = [256, 256]\n    args.arch.goal_embed_neurons = [64, 8]\n    args.arch.img_embed_neurons = [1024, 512, 256*8]\n  \n  elif exp_ver == 'v1':\n     Additive interaction between goal and image features.\n    args.arch.combine_type = 'add'\n    args.arch.pred_neurons = [256, 256]\n    args.arch.goal_embed_neurons = [64, 256]\n    args.arch.img_embed_neurons = [1024, 512, 256]\n  \n  elif exp_ver == 'v2':\n     LSTM at the output on top of multiple interactions.\n    args.arch.combine_type = 'multiply'\n    args.arch.goal_embed_neurons = [64, 8]\n    args.arch.img_embed_neurons = [1024, 512, 256*8]\n    args.arch.lstm_output = True\n    args.arch.lstm_output_dim = int(arch_vars.lstm_dim[4:])\n    args.arch.pred_neurons = [256]  The other is inside the LSTM.\n  \n  elif exp_ver == 'v0blind':\n     LSTM only on the goal location.\n    args.arch.combine_type = 'goalonly'\n    args.arch.goal_embed_neurons = [64, 256]\n    args.arch.img_embed_neurons = [2]  I dont know what it will do otherwise.\n    args.arch.lstm_output = True\n    args.arch.lstm_output_dim = 256\n    args.arch.pred_neurons = [256]  The other is inside the LSTM.\n  \n  else:\n    logging.fatal('exp_ver: %s undefined', exp_ver)\n    assert(False)\n\n   Log the arguments\n  logging.error('%s', args)\n  return args\n\ndef get_args_for_config(config_name):\n  args = utils.Foo()\n\n  args.summary, args.control = get_default_args()\n\n  exp_name, mode_str = config_name.split('+')\n  arch_str, solver_str, navtask_str = exp_name.split('.')\n  logging.error('config_name: %s', config_name)\n  logging.error('arch_str: %s', arch_str)\n  logging.error('navtask_str: %s', navtask_str)\n  logging.error('solver_str: %s', solver_str)\n  logging.error('mode_str: %s', mode_str)\n\n  args.solver = cc.process_solver_str(solver_str)\n  args.navtask = cc.process_navtask_str(navtask_str)\n\n  args = process_arch_str(args, arch_str)\n  args.arch.isd_k = args.solver.isd_k\n\n   Train, test, etc.\n  mode, imset = mode_str.split('_')\n  args = cc.adjust_args_for_mode(args, mode)\n  args.navtask.building_names = args.navtask.dataset.get_split(imset)\n  args.control.test_name = '{:s}_on_{:s}'.format(mode, imset)\n\n   Log the arguments\n  logging.error('%s', args)\n  return args\n", "comments": "  copyright 2016 the tensorflow authors all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                       exp ver    lstm dimentsions    dropout    this function modifies args     multiplicative interaction goal loc image features     additive interaction goal image features     lstm output top multiple interactions     the inside lstm     lstm goal location     i dont know otherwise     the inside lstm     log arguments    train  test  etc     log arguments ", "content": "# Copyright 2016 The TensorFlow Authors All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport pprint\nimport os\nimport numpy as np\nfrom tensorflow.python.platform import app\nfrom tensorflow.python.platform import flags\nimport logging\nimport src.utils as utils\nimport cfgs.config_common as cc\nimport datasets.nav_env_config as nec\n\n\nimport tensorflow as tf\n\nFLAGS = flags.FLAGS\n\nget_solver_vars = cc.get_solver_vars\nget_navtask_vars = cc.get_navtask_vars\n\n\nrgb_resnet_v2_50_path = 'data/init_models/resnet_v2_50/model.ckpt-5136169'\nd_resnet_v2_50_path = 'data/init_models/distill_rgb_to_d_resnet_v2_50/model.ckpt-120002'\n\ndef get_default_args():\n  summary_args = utils.Foo(display_interval=1, test_iters=26,\n                           arop_full_summary_iters=14)\n\n  control_args = utils.Foo(train=False, test=False,\n                           force_batchnorm_is_training_at_test=False,\n                           reset_rng_seed=False, only_eval_when_done=False,\n                           test_mode=None)\n  return summary_args, control_args\n\ndef get_default_baseline_args():\n  batch_norm_param = {'center': True, 'scale': True,\n                      'activation_fn':tf.nn.relu}\n  arch_args = utils.Foo(\n      pred_neurons=[], goal_embed_neurons=[], img_embed_neurons=[],\n      batch_norm_param=batch_norm_param, dim_reduce_neurons=64, combine_type='',\n      encoder='resnet_v2_50', action_sample_type='sample',\n      action_sample_combine_type='one_or_other',\n      sample_gt_prob_type='inverse_sigmoid_decay', dagger_sample_bn_false=True,\n      isd_k=750., use_visit_count=False, lstm_output=False, lstm_ego=False,\n      lstm_img=False, fc_dropout=0.0, embed_goal_for_state=False,\n      lstm_output_init_state_from_goal=False)\n  return arch_args\n\ndef get_arch_vars(arch_str):\n  if arch_str == '': vals = []\n  else: vals = arch_str.split('_')\n  \n  ks = ['ver', 'lstm_dim', 'dropout']\n  \n  # Exp Ver\n  if len(vals) == 0: vals.append('v0')\n  # LSTM dimentsions\n  if len(vals) == 1: vals.append('lstm2048')\n  # Dropout\n  if len(vals) == 2: vals.append('noDO')\n  \n  assert(len(vals) == 3)\n  \n  vars = utils.Foo()\n  for k, v in zip(ks, vals):\n    setattr(vars, k, v)\n  \n  logging.error('arch_vars: %s', vars)\n  return vars\n\ndef process_arch_str(args, arch_str):\n  # This function modifies args.\n  args.arch = get_default_baseline_args()\n  arch_vars = get_arch_vars(arch_str)\n\n  args.navtask.task_params.outputs.rel_goal_loc = True\n  args.navtask.task_params.input_type = 'vision'\n  args.navtask.task_params.outputs.images = True\n  \n  if args.navtask.camera_param.modalities[0] == 'rgb':\n    args.solver.pretrained_path = rgb_resnet_v2_50_path\n  elif args.navtask.camera_param.modalities[0] == 'depth':\n    args.solver.pretrained_path = d_resnet_v2_50_path\n  else:\n    logging.fatal('Neither of rgb or d')\n\n  if arch_vars.dropout == 'DO': \n    args.arch.fc_dropout = 0.5\n\n  args.tfcode = 'B'\n  \n  exp_ver = arch_vars.ver\n  if exp_ver == 'v0':\n    # Multiplicative interaction between goal loc and image features.\n    args.arch.combine_type = 'multiply'\n    args.arch.pred_neurons = [256, 256]\n    args.arch.goal_embed_neurons = [64, 8]\n    args.arch.img_embed_neurons = [1024, 512, 256*8]\n  \n  elif exp_ver == 'v1':\n    # Additive interaction between goal and image features.\n    args.arch.combine_type = 'add'\n    args.arch.pred_neurons = [256, 256]\n    args.arch.goal_embed_neurons = [64, 256]\n    args.arch.img_embed_neurons = [1024, 512, 256]\n  \n  elif exp_ver == 'v2':\n    # LSTM at the output on top of multiple interactions.\n    args.arch.combine_type = 'multiply'\n    args.arch.goal_embed_neurons = [64, 8]\n    args.arch.img_embed_neurons = [1024, 512, 256*8]\n    args.arch.lstm_output = True\n    args.arch.lstm_output_dim = int(arch_vars.lstm_dim[4:])\n    args.arch.pred_neurons = [256] # The other is inside the LSTM.\n  \n  elif exp_ver == 'v0blind':\n    # LSTM only on the goal location.\n    args.arch.combine_type = 'goalonly'\n    args.arch.goal_embed_neurons = [64, 256]\n    args.arch.img_embed_neurons = [2] # I dont know what it will do otherwise.\n    args.arch.lstm_output = True\n    args.arch.lstm_output_dim = 256\n    args.arch.pred_neurons = [256] # The other is inside the LSTM.\n  \n  else:\n    logging.fatal('exp_ver: %s undefined', exp_ver)\n    assert(False)\n\n  # Log the arguments\n  logging.error('%s', args)\n  return args\n\ndef get_args_for_config(config_name):\n  args = utils.Foo()\n\n  args.summary, args.control = get_default_args()\n\n  exp_name, mode_str = config_name.split('+')\n  arch_str, solver_str, navtask_str = exp_name.split('.')\n  logging.error('config_name: %s', config_name)\n  logging.error('arch_str: %s', arch_str)\n  logging.error('navtask_str: %s', navtask_str)\n  logging.error('solver_str: %s', solver_str)\n  logging.error('mode_str: %s', mode_str)\n\n  args.solver = cc.process_solver_str(solver_str)\n  args.navtask = cc.process_navtask_str(navtask_str)\n\n  args = process_arch_str(args, arch_str)\n  args.arch.isd_k = args.solver.isd_k\n\n  # Train, test, etc.\n  mode, imset = mode_str.split('_')\n  args = cc.adjust_args_for_mode(args, mode)\n  args.navtask.building_names = args.navtask.dataset.get_split(imset)\n  args.control.test_name = '{:s}_on_{:s}'.format(mode, imset)\n\n  # Log the arguments\n  logging.error('%s', args)\n  return args\n", "description": "Models and examples built with TensorFlow", "file_name": "config_vision_baseline.py", "id": "8fdf79068756a05d0220e49f5a58731c", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tensorflow-models/tensorflow-models-7e4c66b/research/cognitive_mapping_and_planning/cfgs/config_vision_baseline.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:59:36Z", "url": "https://github.com/tensorflow/models", "wiki": true}