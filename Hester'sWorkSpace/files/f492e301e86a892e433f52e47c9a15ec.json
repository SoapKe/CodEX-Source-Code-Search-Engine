{"author": "tflearn", "code": "# -*- coding: utf-8 -*-\n\"\"\" DCGAN Example\n\nUse a deep convolutional generative adversarial network (DCGAN) to generate\ndigit images from a noise distribution.\n\nReferences:\n    - Unsupervised representation learning with deep convolutional generative\n    adversarial networks. A Radford, L Metz, S Chintala. arXiv:1511.06434.\n\nLinks:\n    - [DCGAN Paper](https://arxiv.org/abs/1511.06434).\n\n\"\"\"\n\nfrom __future__ import division, print_function, absolute_import\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport tflearn\n\n\nimport tflearn.datasets.mnist as mnist\nX, Y, testX, testY = mnist.load_data()\nX = np.reshape(X, newshape=[-1, 28, 28, 1])\n\nz_dim = 200 \ntotal_samples = len(X)\n\n\n\ndef generator(x, reuse=False):\n    with tf.variable_scope('Generator', reuse=reuse):\n        x = tflearn.fully_connected(x, n_units=7 * 7 * 128)\n        x = tflearn.batch_normalization(x)\n        x = tf.nn.tanh(x)\n        x = tf.reshape(x, shape=[-1, 7, 7, 128])\n        x = tflearn.upsample_2d(x, 2)\n        x = tflearn.conv_2d(x, 64, 5, activation='tanh')\n        x = tflearn.upsample_2d(x, 2)\n        x = tflearn.conv_2d(x, 1, 5, activation='sigmoid')\n        return x\n\n\n\ndef discriminator(x, reuse=False):\n    with tf.variable_scope('Discriminator', reuse=reuse):\n        x = tflearn.conv_2d(x, 64, 5, activation='tanh')\n        x = tflearn.avg_pool_2d(x, 2)\n        x = tflearn.conv_2d(x, 128, 5, activation='tanh')\n        x = tflearn.avg_pool_2d(x, 2)\n        x = tflearn.fully_connected(x, 1024, activation='tanh')\n        x = tflearn.fully_connected(x, 2)\n        x = tf.nn.softmax(x)\n        return x\n\n\n\ngen_input = tflearn.input_data(shape=[None, z_dim], name='input_gen_noise')\ninput_disc_noise = tflearn.input_data(shape=[None, z_dim], name='input_disc_noise')\ninput_disc_real = tflearn.input_data(shape=[None, 28, 28, 1], name='input_disc_real')\n\n\ndisc_fake = discriminator(generator(input_disc_noise))\ndisc_real = discriminator(input_disc_real, reuse=True)\ndisc_net = tf.concat([disc_fake, disc_real], axis=0)\n\ngen_net = generator(gen_input, reuse=True)\nstacked_gan_net = discriminator(gen_net, reuse=True)\n\n\n\n# to retrieve each network variables (with get_layer_variables_by_scope).\ndisc_vars = tflearn.get_layer_variables_by_scope('Discriminator')\n\ndisc_target = tflearn.multi_target_data(['target_disc_fake', 'target_disc_real'],\n                                        shape=[None, 2])\ndisc_model = tflearn.regression(disc_net, optimizer='adam',\n                                placeholder=disc_target,\n                                loss='categorical_crossentropy',\n                                trainable_vars=disc_vars,\n                                batch_size=64, name='target_disc',\n                                op_name='DISC')\n\ngen_vars = tflearn.get_layer_variables_by_scope('Generator')\ngan_model = tflearn.regression(stacked_gan_net, optimizer='adam',\n                               loss='categorical_crossentropy',\n                               trainable_vars=gen_vars,\n                               batch_size=64, name='target_gen',\n                               op_name='GEN')\n\n\ngan = tflearn.DNN(gan_model)\n\n\n\ndisc_noise = np.random.uniform(-1., 1., size=[total_samples, z_dim])\n (0: fake image, 1: real image)\ny_disc_fake = np.zeros(shape=[total_samples])\ny_disc_real = np.ones(shape=[total_samples])\ny_disc_fake = tflearn.data_utils.to_categorical(y_disc_fake, 2)\ny_disc_real = tflearn.data_utils.to_categorical(y_disc_real, 2)\n\n\ngen_noise = np.random.uniform(-1., 1., size=[total_samples, z_dim])\n\n tries to fool the discriminator, thus target is 1 (e.g. real images)\ny_gen = np.ones(shape=[total_samples])\ny_gen = tflearn.data_utils.to_categorical(y_gen, 2)\n\n\ngan.fit(X_inputs={'input_gen_noise': gen_noise,\n                  'input_disc_noise': disc_noise,\n                  'input_disc_real': X},\n        Y_targets={'target_gen': y_gen,\n                   'target_disc_fake': y_disc_fake,\n                   'target_disc_real': y_disc_real},\n        n_epoch=10)\n\n\n# for testing (re-using same session to re-use the weights learnt).\ngen = tflearn.DNN(gen_net, session=gan.session)\n\nf, a = plt.subplots(4, 10, figsize=(10, 4))\nfor i in range(10):\n    \n    z = np.random.uniform(-1., 1., size=[4, z_dim])\n    g = np.array(gen.predict({'input_gen_noise': z}))\n    for j in range(4):\n        \n        img = np.reshape(np.repeat(g[j][:, :, np.newaxis], 3, axis=2),\n                         newshape=(28, 28, 3))\n        a[j][i].imshow(img)\n\nf.show()\nplt.draw()\nplt.waitforbuttonpress()\n", "comments": "    dcgan example  use deep convolutional generative adversarial network (dcgan) generate digit images noise distribution   references        unsupervised representation learning deep convolutional generative     adversarial networks  a radford  l metz  s chintala  arxiv 1511 06434   links         dcgan paper (https   arxiv org abs 1511 06434)              coding  utf 8        data loading preprocessing    noise data points    generator    discriminator    input data    build discriminator    build stacked generator discriminator    build training ops generator discriminator     each network optimization update variable  thus need    retrieve network variables (with get layer variables scope)     we need 2 target placeholders  real fake image target     define gan model  output generated images     training    prepare input data feed discriminator    prepare target data feed discriminator (0  fake image  1  real image)    prepare input data feed stacked generator discriminator    prepare target data feed discriminator    generator tries fool discriminator  thus target 1 (e g  real images)    start training  feed noise real images     create another model generator graph generate samples    testing (re using session use weights learnt)     noise input     generate image noise  extend 3 channels matplot figure  ", "content": "# -*- coding: utf-8 -*-\n\"\"\" DCGAN Example\n\nUse a deep convolutional generative adversarial network (DCGAN) to generate\ndigit images from a noise distribution.\n\nReferences:\n    - Unsupervised representation learning with deep convolutional generative\n    adversarial networks. A Radford, L Metz, S Chintala. arXiv:1511.06434.\n\nLinks:\n    - [DCGAN Paper](https://arxiv.org/abs/1511.06434).\n\n\"\"\"\n\nfrom __future__ import division, print_function, absolute_import\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport tflearn\n\n# Data loading and preprocessing\nimport tflearn.datasets.mnist as mnist\nX, Y, testX, testY = mnist.load_data()\nX = np.reshape(X, newshape=[-1, 28, 28, 1])\n\nz_dim = 200 # Noise data points\ntotal_samples = len(X)\n\n\n# Generator\ndef generator(x, reuse=False):\n    with tf.variable_scope('Generator', reuse=reuse):\n        x = tflearn.fully_connected(x, n_units=7 * 7 * 128)\n        x = tflearn.batch_normalization(x)\n        x = tf.nn.tanh(x)\n        x = tf.reshape(x, shape=[-1, 7, 7, 128])\n        x = tflearn.upsample_2d(x, 2)\n        x = tflearn.conv_2d(x, 64, 5, activation='tanh')\n        x = tflearn.upsample_2d(x, 2)\n        x = tflearn.conv_2d(x, 1, 5, activation='sigmoid')\n        return x\n\n\n# Discriminator\ndef discriminator(x, reuse=False):\n    with tf.variable_scope('Discriminator', reuse=reuse):\n        x = tflearn.conv_2d(x, 64, 5, activation='tanh')\n        x = tflearn.avg_pool_2d(x, 2)\n        x = tflearn.conv_2d(x, 128, 5, activation='tanh')\n        x = tflearn.avg_pool_2d(x, 2)\n        x = tflearn.fully_connected(x, 1024, activation='tanh')\n        x = tflearn.fully_connected(x, 2)\n        x = tf.nn.softmax(x)\n        return x\n\n\n# Input Data\ngen_input = tflearn.input_data(shape=[None, z_dim], name='input_gen_noise')\ninput_disc_noise = tflearn.input_data(shape=[None, z_dim], name='input_disc_noise')\ninput_disc_real = tflearn.input_data(shape=[None, 28, 28, 1], name='input_disc_real')\n\n# Build Discriminator\ndisc_fake = discriminator(generator(input_disc_noise))\ndisc_real = discriminator(input_disc_real, reuse=True)\ndisc_net = tf.concat([disc_fake, disc_real], axis=0)\n# Build Stacked Generator/Discriminator\ngen_net = generator(gen_input, reuse=True)\nstacked_gan_net = discriminator(gen_net, reuse=True)\n\n# Build Training Ops for both Generator and Discriminator.\n# Each network optimization should only update its own variable, thus we need\n# to retrieve each network variables (with get_layer_variables_by_scope).\ndisc_vars = tflearn.get_layer_variables_by_scope('Discriminator')\n# We need 2 target placeholders, for both the real and fake image target.\ndisc_target = tflearn.multi_target_data(['target_disc_fake', 'target_disc_real'],\n                                        shape=[None, 2])\ndisc_model = tflearn.regression(disc_net, optimizer='adam',\n                                placeholder=disc_target,\n                                loss='categorical_crossentropy',\n                                trainable_vars=disc_vars,\n                                batch_size=64, name='target_disc',\n                                op_name='DISC')\n\ngen_vars = tflearn.get_layer_variables_by_scope('Generator')\ngan_model = tflearn.regression(stacked_gan_net, optimizer='adam',\n                               loss='categorical_crossentropy',\n                               trainable_vars=gen_vars,\n                               batch_size=64, name='target_gen',\n                               op_name='GEN')\n\n# Define GAN model, that output the generated images.\ngan = tflearn.DNN(gan_model)\n\n# Training\n# Prepare input data to feed to the discriminator\ndisc_noise = np.random.uniform(-1., 1., size=[total_samples, z_dim])\n# Prepare target data to feed to the discriminator (0: fake image, 1: real image)\ny_disc_fake = np.zeros(shape=[total_samples])\ny_disc_real = np.ones(shape=[total_samples])\ny_disc_fake = tflearn.data_utils.to_categorical(y_disc_fake, 2)\ny_disc_real = tflearn.data_utils.to_categorical(y_disc_real, 2)\n\n# Prepare input data to feed to the stacked generator/discriminator\ngen_noise = np.random.uniform(-1., 1., size=[total_samples, z_dim])\n# Prepare target data to feed to the discriminator\n# Generator tries to fool the discriminator, thus target is 1 (e.g. real images)\ny_gen = np.ones(shape=[total_samples])\ny_gen = tflearn.data_utils.to_categorical(y_gen, 2)\n\n# Start training, feed both noise and real images.\ngan.fit(X_inputs={'input_gen_noise': gen_noise,\n                  'input_disc_noise': disc_noise,\n                  'input_disc_real': X},\n        Y_targets={'target_gen': y_gen,\n                   'target_disc_fake': y_disc_fake,\n                   'target_disc_real': y_disc_real},\n        n_epoch=10)\n\n# Create another model from the generator graph to generate some samples\n# for testing (re-using same session to re-use the weights learnt).\ngen = tflearn.DNN(gen_net, session=gan.session)\n\nf, a = plt.subplots(4, 10, figsize=(10, 4))\nfor i in range(10):\n    # Noise input.\n    z = np.random.uniform(-1., 1., size=[4, z_dim])\n    g = np.array(gen.predict({'input_gen_noise': z}))\n    for j in range(4):\n        # Generate image from noise. Extend to 3 channels for matplot figure.\n        img = np.reshape(np.repeat(g[j][:, :, np.newaxis], 3, axis=2),\n                         newshape=(28, 28, 3))\n        a[j][i].imshow(img)\n\nf.show()\nplt.draw()\nplt.waitforbuttonpress()\n", "description": "Deep learning library featuring a higher-level API for TensorFlow.", "file_name": "dcgan.py", "id": "f492e301e86a892e433f52e47c9a15ec", "language": "Python", "project_name": "tflearn", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tflearn-tflearn/tflearn-tflearn-70fb38a/examples/images/dcgan.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:15:41Z", "url": "https://github.com/tflearn/tflearn", "wiki": true}