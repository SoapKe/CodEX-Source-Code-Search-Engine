{"author": "tensorflow", "code": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport os\nimport numpy as np\nimport logging\nimport src.utils as utils\nimport datasets.nav_env_config as nec\nfrom datasets import factory\n\ndef adjust_args_for_mode(args, mode):\n  if mode == 'train':\n    args.control.train = True\n  \n  elif mode == 'val1':\n    \n    \n    args.control.test = True\n    args.control.test_mode = 'val'\n    args.navtask.task_params.batch_size = 32\n\n  elif mode == 'val2':\n    \n    \n    args.control.test = True\n    args.arch.action_sample_type = 'argmax'\n    args.arch.sample_gt_prob_type = 'zero'\n    args.navtask.task_params.data_augment = \\\n      utils.Foo(lr_flip=0, delta_angle=0, delta_xy=0, relight=False,\n                relight_fast=False, structured=False)\n    args.control.test_mode = 'val'\n    args.navtask.task_params.batch_size = 32\n\n  elif mode == 'bench':\n    \n    \n    args.navtask.task_params.batch_size = 16\n    args.control.test = True\n    args.arch.action_sample_type = 'argmax'\n    args.arch.sample_gt_prob_type = 'zero'\n    args.navtask.task_params.data_augment = \\\n      utils.Foo(lr_flip=0, delta_angle=0, delta_xy=0, relight=False,\n                relight_fast=False, structured=False)\n    args.summary.test_iters = 250\n    args.control.only_eval_when_done = True\n    args.control.reset_rng_seed = True\n    args.control.test_mode = 'test'\n  else:\n    logging.fatal('Unknown mode: %s.', mode)\n    assert(False)\n  return args\n\ndef get_solver_vars(solver_str):\n  if solver_str == '': vals = []; \n  else: vals = solver_str.split('_')\n  ks = ['clip', 'dlw', 'long', 'typ', 'isdk', 'adam_eps', 'init_lr'];\n  ks = ks[:len(vals)]\n\n  \n  if len(vals) == 0: ks.append('clip'); vals.append('noclip');\n  \n  if len(vals) == 1: ks.append('dlw');  vals.append('dlw20')\n  \n  if len(vals) == 2: ks.append('long');  vals.append('nolong')\n  \n  if len(vals) == 3: ks.append('typ');  vals.append('adam2')\n  \n  if len(vals) == 4: ks.append('rlw');  vals.append('rlw1')\n  \n  if len(vals) == 5: ks.append('isdk');  vals.append('isdk415') \n  \n  if len(vals) == 6: ks.append('adam_eps');  vals.append('aeps1en8')\n  \n  if len(vals) == 7: ks.append('init_lr');  vals.append('lr1en3')\n\n  assert(len(vals) == 8)\n  \n  vars = utils.Foo()\n  for k, v in zip(ks, vals):\n    setattr(vars, k, v)\n  logging.error('solver_vars: %s', vars)\n  return vars\n\ndef process_solver_str(solver_str):\n  solver = utils.Foo(\n      seed=0, learning_rate_decay=None, clip_gradient_norm=None, max_steps=None,\n      initial_learning_rate=None, momentum=None, steps_per_decay=None,\n      logdir=None, sync=False, adjust_lr_sync=True, wt_decay=0.0001,\n      data_loss_wt=None, reg_loss_wt=None, freeze_conv=True, num_workers=1,\n      task=0, ps_tasks=0, master='local', typ=None, momentum2=None,\n      adam_eps=None)\n\n  \n  solver_vars = get_solver_vars(solver_str)\n\n  solver.data_loss_wt          = float(solver_vars.dlw[3:].replace('x', '.'))\n  solver.adam_eps              = float(solver_vars.adam_eps[4:].replace('x', '.').replace('n', '-'))\n  solver.initial_learning_rate = float(solver_vars.init_lr[2:].replace('x', '.').replace('n', '-'))\n  solver.reg_loss_wt           = float(solver_vars.rlw[3:].replace('x', '.'))\n  solver.isd_k                 = float(solver_vars.isdk[4:].replace('x', '.'))\n\n  long = solver_vars.long\n  if long == 'long':\n    solver.steps_per_decay = 40000\n    solver.max_steps = 120000\n  elif long == 'long2':\n    solver.steps_per_decay = 80000\n    solver.max_steps = 120000\n  elif long == 'nolong' or long == 'nol':\n    solver.steps_per_decay = 20000\n    solver.max_steps = 60000\n  else:\n    logging.fatal('solver_vars.long should be long, long2, nolong or nol.')\n    assert(False)\n\n  clip = solver_vars.clip\n  if clip == 'noclip' or clip == 'nocl':\n    solver.clip_gradient_norm = 0\n  elif clip[:4] == 'clip':\n    solver.clip_gradient_norm = float(clip[4:].replace('x', '.'))\n  else:\n    logging.fatal('Unknown solver_vars.clip: %s', clip)\n    assert(False)\n\n  typ = solver_vars.typ\n  if typ == 'adam':\n    solver.typ = 'adam'\n    solver.momentum = 0.9\n    solver.momentum2 = 0.999\n    solver.learning_rate_decay = 1.0\n  elif typ == 'adam2':\n    solver.typ = 'adam'\n    solver.momentum = 0.9\n    solver.momentum2 = 0.999\n    solver.learning_rate_decay = 0.1\n  elif typ == 'sgd':\n    solver.typ = 'sgd'\n    solver.momentum = 0.99\n    solver.momentum2 = None\n    solver.learning_rate_decay = 0.1\n  else:\n    logging.fatal('Unknown solver_vars.typ: %s', typ)\n    assert(False)\n\n  logging.error('solver: %s', solver)\n  return solver\n\ndef get_navtask_vars(navtask_str):\n  if navtask_str == '': vals = []\n  else: vals = navtask_str.split('_')\n\n  ks_all = ['dataset_name', 'modality', 'task', 'history', 'max_dist',\n            'num_steps', 'step_size', 'n_ori', 'aux_views', 'data_aug']\n  ks = ks_all[:len(vals)]\n\n  \n  if len(vals) == 0: ks.append('dataset_name'); vals.append('sbpd')\n  \n  if len(vals) == 1: ks.append('modality'); vals.append('rgb')\n  \n  if len(vals) == 2: ks.append('task'); vals.append('r2r')\n  \n  if len(vals) == 3: ks.append('history'); vals.append('h0')\n  \n  if len(vals) == 4: ks.append('max_dist'); vals.append('32')\n  \n  if len(vals) == 5: ks.append('num_steps'); vals.append('40')\n  \n  if len(vals) == 6: ks.append('step_size'); vals.append('8')\n  \n  if len(vals) == 7: ks.append('n_ori'); vals.append('4')\n  \n  if len(vals) == 8: ks.append('aux_views'); vals.append('nv0')\n  \n  \n  if len(vals) == 9: ks.append('data_aug'); vals.append('straug')\n\n  assert(len(vals) == 10)\n  for i in range(len(ks)):\n    assert(ks[i] == ks_all[i])\n\n  vars = utils.Foo()\n  for k, v in zip(ks, vals):\n    setattr(vars, k, v)\n  logging.error('navtask_vars: %s', vals)\n  return vars\n\ndef process_navtask_str(navtask_str):\n  navtask = nec.nav_env_base_config()\n  \n  \n  navtask_vars = get_navtask_vars(navtask_str)\n\n  navtask.task_params.n_ori = int(navtask_vars.n_ori)\n  navtask.task_params.max_dist = int(navtask_vars.max_dist)\n  navtask.task_params.num_steps = int(navtask_vars.num_steps)\n  navtask.task_params.step_size = int(navtask_vars.step_size)\n  navtask.task_params.data_augment.delta_xy = int(navtask_vars.step_size)/2.\n  n_aux_views_each = int(navtask_vars.aux_views[2])\n  aux_delta_thetas = np.concatenate((np.arange(n_aux_views_each) + 1,\n                                     -1 -np.arange(n_aux_views_each)))\n  aux_delta_thetas = aux_delta_thetas*np.deg2rad(navtask.camera_param.fov)\n  navtask.task_params.aux_delta_thetas = aux_delta_thetas\n  \n  if navtask_vars.data_aug == 'aug':\n    navtask.task_params.data_augment.structured = False\n  elif navtask_vars.data_aug == 'straug':\n    navtask.task_params.data_augment.structured = True\n  else:\n    logging.fatal('Unknown navtask_vars.data_aug %s.', navtask_vars.data_aug)\n    assert(False)\n\n  navtask.task_params.num_history_frames = int(navtask_vars.history[1:])\n  navtask.task_params.n_views = 1+navtask.task_params.num_history_frames\n  \n  navtask.task_params.goal_channels = int(navtask_vars.n_ori)\n  \n  if navtask_vars.task == 'hard': \n    navtask.task_params.type = 'rng_rejection_sampling_many'\n    navtask.task_params.rejection_sampling_M = 2000\n    navtask.task_params.min_dist = 10\n  elif navtask_vars.task == 'r2r':\n    navtask.task_params.type = 'room_to_room_many'\n  elif navtask_vars.task == 'ST':\n    \n    navtask.task_params.goal_channels = \\\n        len(navtask.task_params.semantic_task.class_map_names)\n    navtask.task_params.rel_goal_loc_dim = \\\n        len(navtask.task_params.semantic_task.class_map_names)\n    navtask.task_params.type = 'to_nearest_obj_acc'\n  else:\n    logging.fatal('navtask_vars.task: should be hard or r2r, ST')\n    assert(False)\n  \n  if navtask_vars.modality == 'rgb':\n    navtask.camera_param.modalities = ['rgb']\n    navtask.camera_param.img_channels = 3\n  elif navtask_vars.modality == 'd':\n    navtask.camera_param.modalities = ['depth']\n    navtask.camera_param.img_channels = 2\n  \n  navtask.task_params.img_height   = navtask.camera_param.height\n  navtask.task_params.img_width    = navtask.camera_param.width\n  navtask.task_params.modalities   = navtask.camera_param.modalities\n  navtask.task_params.img_channels = navtask.camera_param.img_channels\n  navtask.task_params.img_fov      = navtask.camera_param.fov\n  \n  navtask.dataset = factory.get_dataset(navtask_vars.dataset_name)\n  return navtask\n", "comments": "copyright 2016 the tensorflow authors all rights reserved licensed apache license version 2.0 (the \"license\"); may use file except compliance license you may obtain copy license http://www.apache.org/licenses/license-2.0 unless required applicable law agreed writing software distributed license distributed \"as is\" basis without warranties or conditions of any kind either express implied see license specific language governing permissions limitations license ============================================================================== same settings training make sure nothing wonky happening no data augmentation sampling taking argmax action sampling ground truth actually testing agent settings kept different runs gradient clipping data loss weight long train adam reg loss wt isd_k 415 inflexion 2.5k adam eps init lr clobber overrides solver str all data modality semantic task? number history frames max steps num steps step size n_ori auxiliary views normal data augmentation opposed structured data augmentation (if set straug clobber overrides strings semantic task hand", "content": "# Copyright 2016 The TensorFlow Authors All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport numpy as np\nimport logging\nimport src.utils as utils\nimport datasets.nav_env_config as nec\nfrom datasets import factory\n\ndef adjust_args_for_mode(args, mode):\n  if mode == 'train':\n    args.control.train = True\n  \n  elif mode == 'val1':\n    # Same settings as for training, to make sure nothing wonky is happening\n    # there.\n    args.control.test = True\n    args.control.test_mode = 'val'\n    args.navtask.task_params.batch_size = 32\n\n  elif mode == 'val2':\n    # No data augmentation, not sampling but taking the argmax action, not\n    # sampling from the ground truth at all.\n    args.control.test = True\n    args.arch.action_sample_type = 'argmax'\n    args.arch.sample_gt_prob_type = 'zero'\n    args.navtask.task_params.data_augment = \\\n      utils.Foo(lr_flip=0, delta_angle=0, delta_xy=0, relight=False,\n                relight_fast=False, structured=False)\n    args.control.test_mode = 'val'\n    args.navtask.task_params.batch_size = 32\n\n  elif mode == 'bench':\n    # Actually testing the agent in settings that are kept same between\n    # different runs.\n    args.navtask.task_params.batch_size = 16\n    args.control.test = True\n    args.arch.action_sample_type = 'argmax'\n    args.arch.sample_gt_prob_type = 'zero'\n    args.navtask.task_params.data_augment = \\\n      utils.Foo(lr_flip=0, delta_angle=0, delta_xy=0, relight=False,\n                relight_fast=False, structured=False)\n    args.summary.test_iters = 250\n    args.control.only_eval_when_done = True\n    args.control.reset_rng_seed = True\n    args.control.test_mode = 'test'\n  else:\n    logging.fatal('Unknown mode: %s.', mode)\n    assert(False)\n  return args\n\ndef get_solver_vars(solver_str):\n  if solver_str == '': vals = []; \n  else: vals = solver_str.split('_')\n  ks = ['clip', 'dlw', 'long', 'typ', 'isdk', 'adam_eps', 'init_lr'];\n  ks = ks[:len(vals)]\n\n  # Gradient clipping or not.\n  if len(vals) == 0: ks.append('clip'); vals.append('noclip');\n  # data loss weight.\n  if len(vals) == 1: ks.append('dlw');  vals.append('dlw20')\n  # how long to train for.\n  if len(vals) == 2: ks.append('long');  vals.append('nolong')\n  # Adam\n  if len(vals) == 3: ks.append('typ');  vals.append('adam2')\n  # reg loss wt\n  if len(vals) == 4: ks.append('rlw');  vals.append('rlw1')\n  # isd_k\n  if len(vals) == 5: ks.append('isdk');  vals.append('isdk415') # 415, inflexion at 2.5k.\n  # adam eps\n  if len(vals) == 6: ks.append('adam_eps');  vals.append('aeps1en8')\n  # init lr\n  if len(vals) == 7: ks.append('init_lr');  vals.append('lr1en3')\n\n  assert(len(vals) == 8)\n  \n  vars = utils.Foo()\n  for k, v in zip(ks, vals):\n    setattr(vars, k, v)\n  logging.error('solver_vars: %s', vars)\n  return vars\n\ndef process_solver_str(solver_str):\n  solver = utils.Foo(\n      seed=0, learning_rate_decay=None, clip_gradient_norm=None, max_steps=None,\n      initial_learning_rate=None, momentum=None, steps_per_decay=None,\n      logdir=None, sync=False, adjust_lr_sync=True, wt_decay=0.0001,\n      data_loss_wt=None, reg_loss_wt=None, freeze_conv=True, num_workers=1,\n      task=0, ps_tasks=0, master='local', typ=None, momentum2=None,\n      adam_eps=None)\n\n  # Clobber with overrides from solver str.\n  solver_vars = get_solver_vars(solver_str)\n\n  solver.data_loss_wt          = float(solver_vars.dlw[3:].replace('x', '.'))\n  solver.adam_eps              = float(solver_vars.adam_eps[4:].replace('x', '.').replace('n', '-'))\n  solver.initial_learning_rate = float(solver_vars.init_lr[2:].replace('x', '.').replace('n', '-'))\n  solver.reg_loss_wt           = float(solver_vars.rlw[3:].replace('x', '.'))\n  solver.isd_k                 = float(solver_vars.isdk[4:].replace('x', '.'))\n\n  long = solver_vars.long\n  if long == 'long':\n    solver.steps_per_decay = 40000\n    solver.max_steps = 120000\n  elif long == 'long2':\n    solver.steps_per_decay = 80000\n    solver.max_steps = 120000\n  elif long == 'nolong' or long == 'nol':\n    solver.steps_per_decay = 20000\n    solver.max_steps = 60000\n  else:\n    logging.fatal('solver_vars.long should be long, long2, nolong or nol.')\n    assert(False)\n\n  clip = solver_vars.clip\n  if clip == 'noclip' or clip == 'nocl':\n    solver.clip_gradient_norm = 0\n  elif clip[:4] == 'clip':\n    solver.clip_gradient_norm = float(clip[4:].replace('x', '.'))\n  else:\n    logging.fatal('Unknown solver_vars.clip: %s', clip)\n    assert(False)\n\n  typ = solver_vars.typ\n  if typ == 'adam':\n    solver.typ = 'adam'\n    solver.momentum = 0.9\n    solver.momentum2 = 0.999\n    solver.learning_rate_decay = 1.0\n  elif typ == 'adam2':\n    solver.typ = 'adam'\n    solver.momentum = 0.9\n    solver.momentum2 = 0.999\n    solver.learning_rate_decay = 0.1\n  elif typ == 'sgd':\n    solver.typ = 'sgd'\n    solver.momentum = 0.99\n    solver.momentum2 = None\n    solver.learning_rate_decay = 0.1\n  else:\n    logging.fatal('Unknown solver_vars.typ: %s', typ)\n    assert(False)\n\n  logging.error('solver: %s', solver)\n  return solver\n\ndef get_navtask_vars(navtask_str):\n  if navtask_str == '': vals = []\n  else: vals = navtask_str.split('_')\n\n  ks_all = ['dataset_name', 'modality', 'task', 'history', 'max_dist',\n            'num_steps', 'step_size', 'n_ori', 'aux_views', 'data_aug']\n  ks = ks_all[:len(vals)]\n\n  # All data or not.\n  if len(vals) == 0: ks.append('dataset_name'); vals.append('sbpd')\n  # modality\n  if len(vals) == 1: ks.append('modality'); vals.append('rgb')\n  # semantic task?\n  if len(vals) == 2: ks.append('task'); vals.append('r2r')\n  # number of history frames.\n  if len(vals) == 3: ks.append('history'); vals.append('h0')\n  # max steps\n  if len(vals) == 4: ks.append('max_dist'); vals.append('32')\n  # num steps\n  if len(vals) == 5: ks.append('num_steps'); vals.append('40')\n  # step size\n  if len(vals) == 6: ks.append('step_size'); vals.append('8')\n  # n_ori\n  if len(vals) == 7: ks.append('n_ori'); vals.append('4')\n  # Auxiliary views.\n  if len(vals) == 8: ks.append('aux_views'); vals.append('nv0')\n  # Normal data augmentation as opposed to structured data augmentation (if set\n  # to straug.\n  if len(vals) == 9: ks.append('data_aug'); vals.append('straug')\n\n  assert(len(vals) == 10)\n  for i in range(len(ks)):\n    assert(ks[i] == ks_all[i])\n\n  vars = utils.Foo()\n  for k, v in zip(ks, vals):\n    setattr(vars, k, v)\n  logging.error('navtask_vars: %s', vals)\n  return vars\n\ndef process_navtask_str(navtask_str):\n  navtask = nec.nav_env_base_config()\n  \n  # Clobber with overrides from strings.\n  navtask_vars = get_navtask_vars(navtask_str)\n\n  navtask.task_params.n_ori = int(navtask_vars.n_ori)\n  navtask.task_params.max_dist = int(navtask_vars.max_dist)\n  navtask.task_params.num_steps = int(navtask_vars.num_steps)\n  navtask.task_params.step_size = int(navtask_vars.step_size)\n  navtask.task_params.data_augment.delta_xy = int(navtask_vars.step_size)/2.\n  n_aux_views_each = int(navtask_vars.aux_views[2])\n  aux_delta_thetas = np.concatenate((np.arange(n_aux_views_each) + 1,\n                                     -1 -np.arange(n_aux_views_each)))\n  aux_delta_thetas = aux_delta_thetas*np.deg2rad(navtask.camera_param.fov)\n  navtask.task_params.aux_delta_thetas = aux_delta_thetas\n  \n  if navtask_vars.data_aug == 'aug':\n    navtask.task_params.data_augment.structured = False\n  elif navtask_vars.data_aug == 'straug':\n    navtask.task_params.data_augment.structured = True\n  else:\n    logging.fatal('Unknown navtask_vars.data_aug %s.', navtask_vars.data_aug)\n    assert(False)\n\n  navtask.task_params.num_history_frames = int(navtask_vars.history[1:])\n  navtask.task_params.n_views = 1+navtask.task_params.num_history_frames\n  \n  navtask.task_params.goal_channels = int(navtask_vars.n_ori)\n  \n  if navtask_vars.task == 'hard': \n    navtask.task_params.type = 'rng_rejection_sampling_many'\n    navtask.task_params.rejection_sampling_M = 2000\n    navtask.task_params.min_dist = 10\n  elif navtask_vars.task == 'r2r':\n    navtask.task_params.type = 'room_to_room_many'\n  elif navtask_vars.task == 'ST':\n    # Semantic task at hand.\n    navtask.task_params.goal_channels = \\\n        len(navtask.task_params.semantic_task.class_map_names)\n    navtask.task_params.rel_goal_loc_dim = \\\n        len(navtask.task_params.semantic_task.class_map_names)\n    navtask.task_params.type = 'to_nearest_obj_acc'\n  else:\n    logging.fatal('navtask_vars.task: should be hard or r2r, ST')\n    assert(False)\n  \n  if navtask_vars.modality == 'rgb':\n    navtask.camera_param.modalities = ['rgb']\n    navtask.camera_param.img_channels = 3\n  elif navtask_vars.modality == 'd':\n    navtask.camera_param.modalities = ['depth']\n    navtask.camera_param.img_channels = 2\n  \n  navtask.task_params.img_height   = navtask.camera_param.height\n  navtask.task_params.img_width    = navtask.camera_param.width\n  navtask.task_params.modalities   = navtask.camera_param.modalities\n  navtask.task_params.img_channels = navtask.camera_param.img_channels\n  navtask.task_params.img_fov      = navtask.camera_param.fov\n  \n  navtask.dataset = factory.get_dataset(navtask_vars.dataset_name)\n  return navtask\n", "description": "Models and examples built with TensorFlow", "file_name": "config_common.py", "id": "34bcee61228b4dcd4657102bb377e5f8", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-models/tensorflow-models-086d914/research/cognitive_mapping_and_planning/cfgs/config_common.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:59:19Z", "url": "https://github.com/tensorflow/models", "wiki": true}