{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\n\"\"\"Tests for RLTuner and by proxy NoteRNNLoader.\n\nTo run this code:\n$ bazel test rl_tuner:rl_tuner_test\n\"\"\"\n\nimport os\nimport os.path\nimport tempfile\n\n internal imports\n\nimport matplotlib\n Need to use 'Agg' option for plotting and saving files from command line.\n Can't use 'Agg' in RL Tuner because it breaks plotting in notebooks.\n pylint: disable=g-import-not-at-top\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt   pylint: disable=unused-import\nimport tensorflow as tf\n\nfrom magenta.models.rl_tuner import note_rnn_loader\nfrom magenta.models.rl_tuner import rl_tuner\n pylint: enable=g-import-not-at-top\n\n\nclass RLTunerTest(tf.test.TestCase):\n\n  def setUp(self):\n    self.output_dir = tempfile.mkdtemp(dir=self.get_temp_dir())\n    self.checkpoint_dir = tempfile.mkdtemp(dir=self.get_temp_dir())\n    graph = tf.Graph()\n    self.session = tf.Session(graph=graph)\n    note_rnn = note_rnn_loader.NoteRNNLoader(\n        graph, scope='test', checkpoint_dir=None)\n    note_rnn.initialize_new(self.session)\n    with graph.as_default():\n      saver = tf.train.Saver(var_list=note_rnn.get_variable_name_dict())\n      saver.save(\n          self.session,\n          os.path.join(self.checkpoint_dir, 'model.ckpt'))\n\n  def tearDown(self):\n    self.session.close()\n\n  def testInitializationAndPriming(self):\n    rlt = rl_tuner.RLTuner(\n        self.output_dir, note_rnn_checkpoint_dir=self.checkpoint_dir)\n\n    initial_note = rlt.prime_internal_models()\n    self.assertTrue(initial_note is not None)\n\n  def testInitialGeneration(self):\n    rlt = rl_tuner.RLTuner(\n        self.output_dir, note_rnn_checkpoint_dir=self.checkpoint_dir)\n\n    plot_name = 'test_initial_plot.png'\n    rlt.generate_music_sequence(visualize_probs=True,\n                                prob_image_name=plot_name)\n    output_path = os.path.join(self.output_dir, plot_name)\n    self.assertTrue(os.path.exists(output_path))\n\n  def testAction(self):\n    rlt = rl_tuner.RLTuner(\n        self.output_dir, note_rnn_checkpoint_dir=self.checkpoint_dir)\n\n    initial_note = rlt.prime_internal_models()\n\n    action = rlt.action(initial_note, 100, enable_random=False)\n    self.assertTrue(action is not None)\n\n  def testRewardNetwork(self):\n    rlt = rl_tuner.RLTuner(\n        self.output_dir, note_rnn_checkpoint_dir=self.checkpoint_dir)\n\n    zero_state = rlt.q_network.get_zero_state()\n    priming_note = rlt.get_random_note()\n\n    reward_scores = rlt.get_reward_rnn_scores(priming_note, zero_state)\n    self.assertTrue(reward_scores is not None)\n\n  def testTraining(self):\n    rlt = rl_tuner.RLTuner(\n        self.output_dir, note_rnn_checkpoint_dir=self.checkpoint_dir,\n        output_every_nth=30)\n    rlt.train(num_steps=31, exploration_period=3)\n\n    checkpoint_dir = os.path.dirname(rlt.save_path)\n    checkpoint_files = [\n        f for f in os.listdir(checkpoint_dir)\n        if os.path.isfile(os.path.join(checkpoint_dir, f))]\n    checkpoint_step_30 = [\n        f for f in checkpoint_files\n        if os.path.basename(rlt.save_path) + '-30' in f]\n\n    self.assertTrue(len(checkpoint_step_30))\n\n    self.assertTrue(len(rlt.rewards_batched) >= 1)\n    self.assertTrue(len(rlt.eval_avg_reward) >= 1)\n\n  def testCompositionStats(self):\n    rlt = rl_tuner.RLTuner(\n        self.output_dir, note_rnn_checkpoint_dir=self.checkpoint_dir,\n        output_every_nth=30)\n    stat_dict = rlt.evaluate_music_theory_metrics(num_compositions=10)\n\n    self.assertTrue(stat_dict['num_repeated_notes'] >= 0)\n    self.assertTrue(len(stat_dict['autocorrelation1']) > 1)\n\nif __name__ == '__main__':\n  tf.test.main()\n", "comments": "   tests rltuner proxy noternnloader   to run code    bazel test rl tuner rl tuner test        copyright 2016 google inc  all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license          http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license     internal imports    need use  agg  option plotting saving files command line     can use  agg  rl tuner breaks plotting notebooks     pylint  disable g import top    pylint  disable unused import    pylint  enable g import top ", "content": "# Copyright 2016 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Tests for RLTuner and by proxy NoteRNNLoader.\n\nTo run this code:\n$ bazel test rl_tuner:rl_tuner_test\n\"\"\"\n\nimport os\nimport os.path\nimport tempfile\n\n# internal imports\n\nimport matplotlib\n# Need to use 'Agg' option for plotting and saving files from command line.\n# Can't use 'Agg' in RL Tuner because it breaks plotting in notebooks.\n# pylint: disable=g-import-not-at-top\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt  # pylint: disable=unused-import\nimport tensorflow as tf\n\nfrom magenta.models.rl_tuner import note_rnn_loader\nfrom magenta.models.rl_tuner import rl_tuner\n# pylint: enable=g-import-not-at-top\n\n\nclass RLTunerTest(tf.test.TestCase):\n\n  def setUp(self):\n    self.output_dir = tempfile.mkdtemp(dir=self.get_temp_dir())\n    self.checkpoint_dir = tempfile.mkdtemp(dir=self.get_temp_dir())\n    graph = tf.Graph()\n    self.session = tf.Session(graph=graph)\n    note_rnn = note_rnn_loader.NoteRNNLoader(\n        graph, scope='test', checkpoint_dir=None)\n    note_rnn.initialize_new(self.session)\n    with graph.as_default():\n      saver = tf.train.Saver(var_list=note_rnn.get_variable_name_dict())\n      saver.save(\n          self.session,\n          os.path.join(self.checkpoint_dir, 'model.ckpt'))\n\n  def tearDown(self):\n    self.session.close()\n\n  def testInitializationAndPriming(self):\n    rlt = rl_tuner.RLTuner(\n        self.output_dir, note_rnn_checkpoint_dir=self.checkpoint_dir)\n\n    initial_note = rlt.prime_internal_models()\n    self.assertTrue(initial_note is not None)\n\n  def testInitialGeneration(self):\n    rlt = rl_tuner.RLTuner(\n        self.output_dir, note_rnn_checkpoint_dir=self.checkpoint_dir)\n\n    plot_name = 'test_initial_plot.png'\n    rlt.generate_music_sequence(visualize_probs=True,\n                                prob_image_name=plot_name)\n    output_path = os.path.join(self.output_dir, plot_name)\n    self.assertTrue(os.path.exists(output_path))\n\n  def testAction(self):\n    rlt = rl_tuner.RLTuner(\n        self.output_dir, note_rnn_checkpoint_dir=self.checkpoint_dir)\n\n    initial_note = rlt.prime_internal_models()\n\n    action = rlt.action(initial_note, 100, enable_random=False)\n    self.assertTrue(action is not None)\n\n  def testRewardNetwork(self):\n    rlt = rl_tuner.RLTuner(\n        self.output_dir, note_rnn_checkpoint_dir=self.checkpoint_dir)\n\n    zero_state = rlt.q_network.get_zero_state()\n    priming_note = rlt.get_random_note()\n\n    reward_scores = rlt.get_reward_rnn_scores(priming_note, zero_state)\n    self.assertTrue(reward_scores is not None)\n\n  def testTraining(self):\n    rlt = rl_tuner.RLTuner(\n        self.output_dir, note_rnn_checkpoint_dir=self.checkpoint_dir,\n        output_every_nth=30)\n    rlt.train(num_steps=31, exploration_period=3)\n\n    checkpoint_dir = os.path.dirname(rlt.save_path)\n    checkpoint_files = [\n        f for f in os.listdir(checkpoint_dir)\n        if os.path.isfile(os.path.join(checkpoint_dir, f))]\n    checkpoint_step_30 = [\n        f for f in checkpoint_files\n        if os.path.basename(rlt.save_path) + '-30' in f]\n\n    self.assertTrue(len(checkpoint_step_30))\n\n    self.assertTrue(len(rlt.rewards_batched) >= 1)\n    self.assertTrue(len(rlt.eval_avg_reward) >= 1)\n\n  def testCompositionStats(self):\n    rlt = rl_tuner.RLTuner(\n        self.output_dir, note_rnn_checkpoint_dir=self.checkpoint_dir,\n        output_every_nth=30)\n    stat_dict = rlt.evaluate_music_theory_metrics(num_compositions=10)\n\n    self.assertTrue(stat_dict['num_repeated_notes'] >= 0)\n    self.assertTrue(len(stat_dict['autocorrelation1']) > 1)\n\nif __name__ == '__main__':\n  tf.test.main()\n", "description": "Magenta: Music and Art Generation with Machine Intelligence", "file_name": "rl_tuner_test.py", "id": "4918b54880e7756225070c2c5a605956", "language": "Python", "project_name": "magenta", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-magenta/tensorflow-magenta-c3eda3d/magenta/models/rl_tuner/rl_tuner_test.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:52:33Z", "url": "https://github.com/tensorflow/magenta", "wiki": false}