{"author": "sloria", "code": "# -*- coding: utf-8 -*-\nimport unittest\nfrom nose.plugins.attrib import attr\nfrom nose.tools import *  \n\nfrom textblob.tokenizers import WordTokenizer, SentenceTokenizer, word_tokenize, sent_tokenize\nfrom textblob.compat import PY2\n\n\ndef is_generator(obj):\n    if PY2:\n        return hasattr(obj, 'next')\n    else:\n        return hasattr(obj, '__next__')\n\n\nclass TestWordTokenizer(unittest.TestCase):\n\n    def setUp(self):\n        self.tokenizer = WordTokenizer()\n        self.text = \"Python is a high-level programming language.\"\n\n    def tearDown(self):\n        pass\n\n    def test_tokenize(self):\n        assert_equal(self.tokenizer.tokenize(self.text),\n            ['Python', 'is', 'a', 'high-level', 'programming',\n            'language', '.'])\n\n    def test_exclude_punc(self):\n        assert_equal(self.tokenizer.tokenize(self.text, include_punc=False),\n            ['Python', 'is', 'a', 'high-level', 'programming',\n            'language'])\n\n    def test_itokenize(self):\n        gen = self.tokenizer.itokenize(self.text)\n        assert_equal(next(gen), \"Python\")\n        assert_equal(next(gen), \"is\")\n\n    def test_word_tokenize(self):\n        tokens = word_tokenize(self.text)\n        assert_true(is_generator(tokens))\n        assert_equal(list(tokens), self.tokenizer.tokenize(self.text))\n\n\nclass TestSentenceTokenizer(unittest.TestCase):\n\n    def setUp(self):\n        self.tokenizer = SentenceTokenizer()\n        self.text = \"Beautiful is better than ugly. Simple is better than complex.\"\n\n    def test_tokenize(self):\n        assert_equal(self.tokenizer.tokenize(self.text),\n            [\"Beautiful is better than ugly.\", \"Simple is better than complex.\"])\n\n    @attr(\"skip\")  \n    def test_tokenize_with_multiple_punctuation(self):\n        text = \"Hello world. How do you do?! My name's Steve...\"\n        assert_equal(self.tokenizer.tokenize(text),\n            [\"Hello world.\", \"How do you do?!\", \"My name's Steve...\"])\n        text2 = 'OMG! I am soooo LOL!!!'\n        tokens = self.tokenizer.tokenize(text2)\n        assert_equal(len(tokens), 2)\n        assert_equal(tokens,\n            [\"OMG!\", \"I am soooo LOL!!!\"])\n\n    def test_itokenize(self):\n        gen = self.tokenizer.itokenize(self.text)\n        assert_equal(next(gen), \"Beautiful is better than ugly.\")\n        assert_equal(next(gen), \"Simple is better than complex.\")\n\n    def test_sent_tokenize(self):\n        tokens = sent_tokenize(self.text)\n        assert_true(is_generator(tokens))  \n        assert_equal(list(tokens), self.tokenizer.tokenize(self.text))\n\nif __name__ == '__main__':\n    unittest.main()\n", "comments": "      coding  utf 8        pep8 asserts    this known problem sentence tokenizer     it generator ", "content": "# -*- coding: utf-8 -*-\nimport unittest\nfrom nose.plugins.attrib import attr\nfrom nose.tools import *  # PEP8 asserts\n\nfrom textblob.tokenizers import WordTokenizer, SentenceTokenizer, word_tokenize, sent_tokenize\nfrom textblob.compat import PY2\n\n\ndef is_generator(obj):\n    if PY2:\n        return hasattr(obj, 'next')\n    else:\n        return hasattr(obj, '__next__')\n\n\nclass TestWordTokenizer(unittest.TestCase):\n\n    def setUp(self):\n        self.tokenizer = WordTokenizer()\n        self.text = \"Python is a high-level programming language.\"\n\n    def tearDown(self):\n        pass\n\n    def test_tokenize(self):\n        assert_equal(self.tokenizer.tokenize(self.text),\n            ['Python', 'is', 'a', 'high-level', 'programming',\n            'language', '.'])\n\n    def test_exclude_punc(self):\n        assert_equal(self.tokenizer.tokenize(self.text, include_punc=False),\n            ['Python', 'is', 'a', 'high-level', 'programming',\n            'language'])\n\n    def test_itokenize(self):\n        gen = self.tokenizer.itokenize(self.text)\n        assert_equal(next(gen), \"Python\")\n        assert_equal(next(gen), \"is\")\n\n    def test_word_tokenize(self):\n        tokens = word_tokenize(self.text)\n        assert_true(is_generator(tokens))\n        assert_equal(list(tokens), self.tokenizer.tokenize(self.text))\n\n\nclass TestSentenceTokenizer(unittest.TestCase):\n\n    def setUp(self):\n        self.tokenizer = SentenceTokenizer()\n        self.text = \"Beautiful is better than ugly. Simple is better than complex.\"\n\n    def test_tokenize(self):\n        assert_equal(self.tokenizer.tokenize(self.text),\n            [\"Beautiful is better than ugly.\", \"Simple is better than complex.\"])\n\n    @attr(\"skip\")  # This is a known problem with the sentence tokenizer.\n    def test_tokenize_with_multiple_punctuation(self):\n        text = \"Hello world. How do you do?! My name's Steve...\"\n        assert_equal(self.tokenizer.tokenize(text),\n            [\"Hello world.\", \"How do you do?!\", \"My name's Steve...\"])\n        text2 = 'OMG! I am soooo LOL!!!'\n        tokens = self.tokenizer.tokenize(text2)\n        assert_equal(len(tokens), 2)\n        assert_equal(tokens,\n            [\"OMG!\", \"I am soooo LOL!!!\"])\n\n    def test_itokenize(self):\n        gen = self.tokenizer.itokenize(self.text)\n        assert_equal(next(gen), \"Beautiful is better than ugly.\")\n        assert_equal(next(gen), \"Simple is better than complex.\")\n\n    def test_sent_tokenize(self):\n        tokens = sent_tokenize(self.text)\n        assert_true(is_generator(tokens))  # It's a generator\n        assert_equal(list(tokens), self.tokenizer.tokenize(self.text))\n\nif __name__ == '__main__':\n    unittest.main()\n", "description": "Simple, Pythonic, text processing--Sentiment analysis, part-of-speech tagging, noun phrase extraction, translation, and more.", "file_name": "test_tokenizers.py", "id": "51a9e1d69de9c8d78826a460ddd08414", "language": "Python", "project_name": "TextBlob", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/sloria-TextBlob/sloria-TextBlob-124d0f9/tests/test_tokenizers.py", "save_time": "", "source": "", "update_at": "2018-03-18T10:52:04Z", "url": "https://github.com/sloria/TextBlob", "wiki": true}