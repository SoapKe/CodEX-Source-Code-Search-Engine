{"author": "deepfakes", "code": "\n\nfrom keras.models import Model as KerasModel\nfrom keras.layers import Input, Dense, Flatten, Reshape, Concatenate\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import Conv2D\nfrom keras.optimizers import Adam\n\nfrom .AutoEncoder import AutoEncoder\nfrom lib.PixelShuffler import PixelShuffler\n\nfrom keras.utils import multi_gpu_model\n\nIMAGE_SHAPE = (64, 64, 3)\nENCODER_DIM = 1024\n\nclass Model(AutoEncoder):\n    def initModel(self):\n        optimizer = Adam(lr=5e-5, beta_1=0.5, beta_2=0.999)\n        x = Input(shape=IMAGE_SHAPE)\n\n        self.autoencoder_A = KerasModel(x, self.decoder(Concatenate()([self.inter_A(self.encoder(x)), self.inter_both(self.encoder(x))])))\n        self.autoencoder_B = KerasModel(x, self.decoder(Concatenate()([self.inter_B(self.encoder(x)), self.inter_both(self.encoder(x))])))\n\n        if self.gpus > 1:\n            self.autoencoder_A = multi_gpu_model( self.autoencoder_A , self.gpus)\n            self.autoencoder_B = multi_gpu_model( self.autoencoder_B , self.gpus)\n\n        self.autoencoder_A.compile(optimizer=optimizer, loss='mean_absolute_error')\n        self.autoencoder_B.compile(optimizer=optimizer, loss='mean_absolute_error')\n\n    def converter(self, swap):\n        autoencoder = self.autoencoder_B if not swap else self.autoencoder_A\n        return lambda img: autoencoder.predict(img)\n\n    def conv(self, filters):\n        def block(x):\n            x = Conv2D(filters, kernel_size=5, strides=2, padding='same')(x)\n            x = LeakyReLU(0.1)(x)\n            return x\n        return block\n\n    def upscale(self, filters):\n        def block(x):\n            x = Conv2D(filters * 4, kernel_size=3, padding='same')(x)\n            x = LeakyReLU(0.1)(x)\n            x = PixelShuffler()(x)\n            return x\n        return block\n\n    def Encoder(self):\n        input_ = Input(shape=IMAGE_SHAPE)\n        x = input_\n        x = self.conv(128)(x)\n        x = self.conv(256)(x)\n        x = self.conv(512)(x)\n        x = self.conv(1024)(x)\n        x = Flatten()(x)\n        return KerasModel(input_, x)\n\n    def Intermidiate(self):\n        input_ = Input(shape=(None, 4 * 4 * 1024))\n        x = input_\n        x = Dense(ENCODER_DIM)(x)\n        x = Dense(4 * 4 * int(ENCODER_DIM/2))(x)\n        x = Reshape((4, 4, int(ENCODER_DIM/2)))(x)\n        return KerasModel(input_, x)\n\n    def Decoder(self):\n        input_ = Input(shape=(4, 4, ENCODER_DIM))\n        x = input_\n        x = self.upscale(512)(x)\n        x = self.upscale(256)(x)\n        x = self.upscale(128)(x)\n        x = self.upscale(64)(x)\n        x = Conv2D(3, kernel_size=5, padding='same', activation='sigmoid')(x)\n        return KerasModel(input_, x)\n", "comments": "  improved autoencoder faceswap  ", "content": "# Improved autoencoder for faceswap.\n\nfrom keras.models import Model as KerasModel\nfrom keras.layers import Input, Dense, Flatten, Reshape, Concatenate\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import Conv2D\nfrom keras.optimizers import Adam\n\nfrom .AutoEncoder import AutoEncoder\nfrom lib.PixelShuffler import PixelShuffler\n\nfrom keras.utils import multi_gpu_model\n\nIMAGE_SHAPE = (64, 64, 3)\nENCODER_DIM = 1024\n\nclass Model(AutoEncoder):\n    def initModel(self):\n        optimizer = Adam(lr=5e-5, beta_1=0.5, beta_2=0.999)\n        x = Input(shape=IMAGE_SHAPE)\n\n        self.autoencoder_A = KerasModel(x, self.decoder(Concatenate()([self.inter_A(self.encoder(x)), self.inter_both(self.encoder(x))])))\n        self.autoencoder_B = KerasModel(x, self.decoder(Concatenate()([self.inter_B(self.encoder(x)), self.inter_both(self.encoder(x))])))\n\n        if self.gpus > 1:\n            self.autoencoder_A = multi_gpu_model( self.autoencoder_A , self.gpus)\n            self.autoencoder_B = multi_gpu_model( self.autoencoder_B , self.gpus)\n\n        self.autoencoder_A.compile(optimizer=optimizer, loss='mean_absolute_error')\n        self.autoencoder_B.compile(optimizer=optimizer, loss='mean_absolute_error')\n\n    def converter(self, swap):\n        autoencoder = self.autoencoder_B if not swap else self.autoencoder_A\n        return lambda img: autoencoder.predict(img)\n\n    def conv(self, filters):\n        def block(x):\n            x = Conv2D(filters, kernel_size=5, strides=2, padding='same')(x)\n            x = LeakyReLU(0.1)(x)\n            return x\n        return block\n\n    def upscale(self, filters):\n        def block(x):\n            x = Conv2D(filters * 4, kernel_size=3, padding='same')(x)\n            x = LeakyReLU(0.1)(x)\n            x = PixelShuffler()(x)\n            return x\n        return block\n\n    def Encoder(self):\n        input_ = Input(shape=IMAGE_SHAPE)\n        x = input_\n        x = self.conv(128)(x)\n        x = self.conv(256)(x)\n        x = self.conv(512)(x)\n        x = self.conv(1024)(x)\n        x = Flatten()(x)\n        return KerasModel(input_, x)\n\n    def Intermidiate(self):\n        input_ = Input(shape=(None, 4 * 4 * 1024))\n        x = input_\n        x = Dense(ENCODER_DIM)(x)\n        x = Dense(4 * 4 * int(ENCODER_DIM/2))(x)\n        x = Reshape((4, 4, int(ENCODER_DIM/2)))(x)\n        return KerasModel(input_, x)\n\n    def Decoder(self):\n        input_ = Input(shape=(4, 4, ENCODER_DIM))\n        x = input_\n        x = self.upscale(512)(x)\n        x = self.upscale(256)(x)\n        x = self.upscale(128)(x)\n        x = self.upscale(64)(x)\n        x = Conv2D(3, kernel_size=5, padding='same', activation='sigmoid')(x)\n        return KerasModel(input_, x)\n", "description": "Non official project based on original /r/Deepfakes thread. Many thanks to him!", "file_name": "Model.py", "id": "e26fa536e47e7ce2afa194eb76352e9b", "language": "Python", "project_name": "faceswap", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/deepfakes-faceswap/deepfakes-faceswap-6ff64ef/plugins/Model_IAE/Model.py", "save_time": "", "source": "", "update_at": "2018-03-18T16:27:43Z", "url": "https://github.com/deepfakes/faceswap", "wiki": true}