{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\"\"\"Wrapper for providing semantic segmentation data.\"\"\"\n\nimport tensorflow as tf\nfrom deeplab import common\nfrom deeplab import input_preprocess\n\nslim = tf.contrib.slim\n\ndataset_data_provider = slim.dataset_data_provider\n\n\ndef _get_data(data_provider, dataset_split):\n  \"\"\"Gets data from data provider.\n\n  Args:\n    data_provider: An object of slim.data_provider.\n    dataset_split: Dataset split.\n\n  Returns:\n    image: Image Tensor.\n    label: Label Tensor storing segmentation annotations.\n    image_name: Image name.\n    height: Image height.\n    width: Image width.\n\n  Raises:\n    ValueError: Failed to find label.\n  \"\"\"\n  if common.LABELS_CLASS not in data_provider.list_items():\n    raise ValueError('Failed to find labels.')\n\n  image, height, width = data_provider.get(\n      [common.IMAGE, common.HEIGHT, common.WIDTH])\n\n   Some datasets do not contain image_name.\n  if common.IMAGE_NAME in data_provider.list_items():\n    image_name, = data_provider.get([common.IMAGE_NAME])\n  else:\n    image_name = tf.constant('')\n\n  label = None\n  if dataset_split != common.TEST_SET:\n    label, = data_provider.get([common.LABELS_CLASS])\n\n  return image, label, image_name, height, width\n\n\ndef get(dataset,\n        crop_size,\n        batch_size,\n        min_resize_value=None,\n        max_resize_value=None,\n        resize_factor=None,\n        min_scale_factor=1.,\n        max_scale_factor=1.,\n        scale_factor_step_size=0,\n        num_readers=1,\n        num_threads=1,\n        dataset_split=None,\n        is_training=True,\n        model_variant=None):\n  \"\"\"Gets the dataset split for semantic segmentation.\n\n  This functions gets the dataset split for semantic segmentation. In\n  particular, it is a wrapper of (1) dataset_data_provider which returns the raw\n  dataset split, (2) input_preprcess which preprocess the raw data, and (3) the\n  Tensorflow operation of batching the preprocessed data. Then, the output could\n  be directly used by training, evaluation or visualization.\n\n  Args:\n    dataset: An instance of slim Dataset.\n    crop_size: Image crop size [height, width].\n    batch_size: Batch size.\n    min_resize_value: Desired size of the smaller image side.\n    max_resize_value: Maximum allowed size of the larger image side.\n    resize_factor: Resized dimensions are multiple of factor plus one.\n    min_scale_factor: Minimum scale factor value.\n    max_scale_factor: Maximum scale factor value.\n    scale_factor_step_size: The step size from min scale factor to max scale\n      factor. The input is randomly scaled based on the value of\n      (min_scale_factor, max_scale_factor, scale_factor_step_size).\n    num_readers: Number of readers for data provider.\n    num_threads: Number of threads for batching data.\n    dataset_split: Dataset split.\n    is_training: Is training or not.\n    model_variant: Model variant (string) for choosing how to mean-subtract the\n      images. See feature_extractor.network_map for supported model variants.\n\n  Returns:\n    A dictionary of batched Tensors for semantic segmentation.\n\n  Raises:\n    ValueError: dataset_split is None, failed to find labels, or label shape\n      is not valid.\n  \"\"\"\n  if dataset_split is None:\n    raise ValueError('Unknown dataset split.')\n  if model_variant is None:\n    tf.logging.warning('Please specify a model_variant. See '\n                       'feature_extractor.network_map for supported model '\n                       'variants.')\n\n  data_provider = dataset_data_provider.DatasetDataProvider(\n      dataset,\n      num_readers=num_readers,\n      num_epochs=None if is_training else 1,\n      shuffle=is_training)\n  image, label, image_name, height, width = _get_data(data_provider,\n                                                      dataset_split)\n  if label is not None:\n    if label.shape.ndims == 2:\n      label = tf.expand_dims(label, 2)\n    elif label.shape.ndims == 3 and label.shape.dims[2] == 1:\n      pass\n    else:\n      raise ValueError('Input label shape must be [height, width], or '\n                       '[height, width, 1].')\n\n    label.set_shape([None, None, 1])\n  original_image, image, label = input_preprocess.preprocess_image_and_label(\n      image,\n      label,\n      crop_height=crop_size[0],\n      crop_width=crop_size[1],\n      min_resize_value=min_resize_value,\n      max_resize_value=max_resize_value,\n      resize_factor=resize_factor,\n      min_scale_factor=min_scale_factor,\n      max_scale_factor=max_scale_factor,\n      scale_factor_step_size=scale_factor_step_size,\n      ignore_label=dataset.ignore_label,\n      is_training=is_training,\n      model_variant=model_variant)\n  sample = {\n      common.IMAGE: image,\n      common.IMAGE_NAME: image_name,\n      common.HEIGHT: height,\n      common.WIDTH: width\n  }\n  if label is not None:\n    sample[common.LABEL] = label\n\n  if not is_training:\n     Original image is only used during visualization.\n    sample[common.ORIGINAL_IMAGE] = original_image,\n    num_threads = 1\n\n  return tf.train.batch(\n      sample,\n      batch_size=batch_size,\n      num_threads=num_threads,\n      capacity=32 * batch_size,\n      allow_smaller_final_batch=not is_training,\n      dynamic_pad=True)\n", "comments": "   wrapper providing semantic segmentation data      import tensorflow tf deeplab import common deeplab import input preprocess  slim   tf contrib slim  dataset data provider   slim dataset data provider   def  get data(data provider  dataset split)       gets data data provider     args      data provider  an object slim data provider      dataset split  dataset split     returns      image  image tensor      label  label tensor storing segmentation annotations      image name  image name      height  image height      width  image width     raises      valueerror  failed find label          common labels class data provider list items()      raise valueerror( failed find labels  )    image  height  width   data provider get(        common image  common height  common width )      some datasets contain image name    common image name data provider list items()      image name    data provider get( common image name )   else      image name   tf constant(  )    label   none   dataset split    common test set      label    data provider get( common labels class )    return image  label  image name  height  width   def get(dataset          crop size          batch size          min resize value none          max resize value none          resize factor none          min scale factor 1           max scale factor 1           scale factor step size 0          num readers 1          num threads 1          dataset split none          training true          model variant none)       gets dataset split semantic segmentation     this functions gets dataset split semantic segmentation  in   particular  wrapper (1) dataset data provider returns raw   dataset split  (2) input preprcess preprocess raw data  (3)   tensorflow operation batching preprocessed data  then  output could   directly used training  evaluation visualization     args      dataset  an instance slim dataset      crop size  image crop size  height  width       batch size  batch size      min resize value  desired size smaller image side      max resize value  maximum allowed size larger image side      resize factor  resized dimensions multiple factor plus one      min scale factor  minimum scale factor value      max scale factor  maximum scale factor value      scale factor step size  the step size min scale factor max scale       factor  the input randomly scaled based value       (min scale factor  max scale factor  scale factor step size)      num readers  number readers data provider      num threads  number threads batching data      dataset split  dataset split      training  is training      model variant  model variant (string) choosing mean subtract       images  see feature extractor network map supported model variants     returns      a dictionary batched tensors semantic segmentation     raises      valueerror  dataset split none  failed find labels  label shape       valid           copyright 2018 the tensorflow authors all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                       some datasets contain image name     original image used visualization  ", "content": "# Copyright 2018 The TensorFlow Authors All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Wrapper for providing semantic segmentation data.\"\"\"\n\nimport tensorflow as tf\nfrom deeplab import common\nfrom deeplab import input_preprocess\n\nslim = tf.contrib.slim\n\ndataset_data_provider = slim.dataset_data_provider\n\n\ndef _get_data(data_provider, dataset_split):\n  \"\"\"Gets data from data provider.\n\n  Args:\n    data_provider: An object of slim.data_provider.\n    dataset_split: Dataset split.\n\n  Returns:\n    image: Image Tensor.\n    label: Label Tensor storing segmentation annotations.\n    image_name: Image name.\n    height: Image height.\n    width: Image width.\n\n  Raises:\n    ValueError: Failed to find label.\n  \"\"\"\n  if common.LABELS_CLASS not in data_provider.list_items():\n    raise ValueError('Failed to find labels.')\n\n  image, height, width = data_provider.get(\n      [common.IMAGE, common.HEIGHT, common.WIDTH])\n\n  # Some datasets do not contain image_name.\n  if common.IMAGE_NAME in data_provider.list_items():\n    image_name, = data_provider.get([common.IMAGE_NAME])\n  else:\n    image_name = tf.constant('')\n\n  label = None\n  if dataset_split != common.TEST_SET:\n    label, = data_provider.get([common.LABELS_CLASS])\n\n  return image, label, image_name, height, width\n\n\ndef get(dataset,\n        crop_size,\n        batch_size,\n        min_resize_value=None,\n        max_resize_value=None,\n        resize_factor=None,\n        min_scale_factor=1.,\n        max_scale_factor=1.,\n        scale_factor_step_size=0,\n        num_readers=1,\n        num_threads=1,\n        dataset_split=None,\n        is_training=True,\n        model_variant=None):\n  \"\"\"Gets the dataset split for semantic segmentation.\n\n  This functions gets the dataset split for semantic segmentation. In\n  particular, it is a wrapper of (1) dataset_data_provider which returns the raw\n  dataset split, (2) input_preprcess which preprocess the raw data, and (3) the\n  Tensorflow operation of batching the preprocessed data. Then, the output could\n  be directly used by training, evaluation or visualization.\n\n  Args:\n    dataset: An instance of slim Dataset.\n    crop_size: Image crop size [height, width].\n    batch_size: Batch size.\n    min_resize_value: Desired size of the smaller image side.\n    max_resize_value: Maximum allowed size of the larger image side.\n    resize_factor: Resized dimensions are multiple of factor plus one.\n    min_scale_factor: Minimum scale factor value.\n    max_scale_factor: Maximum scale factor value.\n    scale_factor_step_size: The step size from min scale factor to max scale\n      factor. The input is randomly scaled based on the value of\n      (min_scale_factor, max_scale_factor, scale_factor_step_size).\n    num_readers: Number of readers for data provider.\n    num_threads: Number of threads for batching data.\n    dataset_split: Dataset split.\n    is_training: Is training or not.\n    model_variant: Model variant (string) for choosing how to mean-subtract the\n      images. See feature_extractor.network_map for supported model variants.\n\n  Returns:\n    A dictionary of batched Tensors for semantic segmentation.\n\n  Raises:\n    ValueError: dataset_split is None, failed to find labels, or label shape\n      is not valid.\n  \"\"\"\n  if dataset_split is None:\n    raise ValueError('Unknown dataset split.')\n  if model_variant is None:\n    tf.logging.warning('Please specify a model_variant. See '\n                       'feature_extractor.network_map for supported model '\n                       'variants.')\n\n  data_provider = dataset_data_provider.DatasetDataProvider(\n      dataset,\n      num_readers=num_readers,\n      num_epochs=None if is_training else 1,\n      shuffle=is_training)\n  image, label, image_name, height, width = _get_data(data_provider,\n                                                      dataset_split)\n  if label is not None:\n    if label.shape.ndims == 2:\n      label = tf.expand_dims(label, 2)\n    elif label.shape.ndims == 3 and label.shape.dims[2] == 1:\n      pass\n    else:\n      raise ValueError('Input label shape must be [height, width], or '\n                       '[height, width, 1].')\n\n    label.set_shape([None, None, 1])\n  original_image, image, label = input_preprocess.preprocess_image_and_label(\n      image,\n      label,\n      crop_height=crop_size[0],\n      crop_width=crop_size[1],\n      min_resize_value=min_resize_value,\n      max_resize_value=max_resize_value,\n      resize_factor=resize_factor,\n      min_scale_factor=min_scale_factor,\n      max_scale_factor=max_scale_factor,\n      scale_factor_step_size=scale_factor_step_size,\n      ignore_label=dataset.ignore_label,\n      is_training=is_training,\n      model_variant=model_variant)\n  sample = {\n      common.IMAGE: image,\n      common.IMAGE_NAME: image_name,\n      common.HEIGHT: height,\n      common.WIDTH: width\n  }\n  if label is not None:\n    sample[common.LABEL] = label\n\n  if not is_training:\n    # Original image is only used during visualization.\n    sample[common.ORIGINAL_IMAGE] = original_image,\n    num_threads = 1\n\n  return tf.train.batch(\n      sample,\n      batch_size=batch_size,\n      num_threads=num_threads,\n      capacity=32 * batch_size,\n      allow_smaller_final_batch=not is_training,\n      dynamic_pad=True)\n", "description": "Models and examples built with TensorFlow", "file_name": "input_generator.py", "id": "7442101b4740a4b035c1304ae7b1d396", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-models/tensorflow-models-086d914/research/deeplab/utils/input_generator.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:59:19Z", "url": "https://github.com/tensorflow/models", "wiki": true}