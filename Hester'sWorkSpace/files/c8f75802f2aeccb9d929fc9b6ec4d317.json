{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\n\"\"\"Convolutional LSTM implementation.\"\"\"\n\nimport tensorflow as tf\n\nfrom tensorflow.contrib.slim import add_arg_scope\nfrom tensorflow.contrib.slim import layers\n\n\ndef init_state(inputs,\n               state_shape,\n               state_initializer=tf.zeros_initializer(),\n               dtype=tf.float32):\n  \"\"\"Helper function to create an initial state given inputs.\n\n  Args:\n    inputs: input Tensor, at least 2D, the first dimension being batch_size\n    state_shape: the shape of the state.\n    state_initializer: Initializer(shape, dtype) for state Tensor.\n    dtype: Optional dtype, needed when inputs is None.\n  Returns:\n     A tensors representing the initial state.\n  \"\"\"\n  if inputs is not None:\n     Handle both the dynamic shape as well as the inferred shape.\n    inferred_batch_size = inputs.get_shape().with_rank_at_least(1)[0]\n    dtype = inputs.dtype\n  else:\n    inferred_batch_size = 0\n  initial_state = state_initializer(\n      [inferred_batch_size] + state_shape, dtype=dtype)\n  return initial_state\n\n\n@add_arg_scope\ndef basic_conv_lstm_cell(inputs,\n                         state,\n                         num_channels,\n                         filter_size=5,\n                         forget_bias=1.0,\n                         scope=None,\n                         reuse=None):\n  \"\"\"Basic LSTM recurrent network cell, with 2D convolution connctions.\n\n  We add forget_bias (default: 1) to the biases of the forget gate in order to\n  reduce the scale of forgetting in the beginning of the training.\n\n  It does not allow cell clipping, a projection layer, and does not\n  use peep-hole connections: it is the basic baseline.\n\n  Args:\n    inputs: input Tensor, 4D, batch x height x width x channels.\n    state: state Tensor, 4D, batch x height x width x channels.\n    num_channels: the number of output channels in the layer.\n    filter_size: the shape of the each convolution filter.\n    forget_bias: the initial value of the forget biases.\n    scope: Optional scope for variable_scope.\n    reuse: whether or not the layer and the variables should be reused.\n\n  Returns:\n     a tuple of tensors representing output and the new state.\n  \"\"\"\n  spatial_size = inputs.get_shape()[1:3]\n  if state is None:\n    state = init_state(inputs, list(spatial_size) + [2 * num_channels])\n  with tf.variable_scope(scope,\n                         'BasicConvLstmCell',\n                         [inputs, state],\n                         reuse=reuse):\n    inputs.get_shape().assert_has_rank(4)\n    state.get_shape().assert_has_rank(4)\n    c, h = tf.split(axis=3, num_or_size_splits=2, value=state)\n    inputs_h = tf.concat(axis=3, values=[inputs, h])\n     Parameters of gates are concatenated into one conv for efficiency.\n    i_j_f_o = layers.conv2d(inputs_h,\n                            4 * num_channels, [filter_size, filter_size],\n                            stride=1,\n                            activation_fn=None,\n                            scope='Gates')\n\n     i = input_gate, j = new_input, f = forget_gate, o = output_gate\n    i, j, f, o = tf.split(axis=3, num_or_size_splits=4, value=i_j_f_o)\n\n    new_c = c * tf.sigmoid(f + forget_bias) + tf.sigmoid(i) * tf.tanh(j)\n    new_h = tf.tanh(new_c) * tf.sigmoid(o)\n\n    return new_h, tf.concat(axis=3, values=[new_c, new_h])\n\n\n\n", "comments": "   convolutional lstm implementation      import tensorflow tf  tensorflow contrib slim import add arg scope tensorflow contrib slim import layers   def init state(inputs                 state shape                 state initializer tf zeros initializer()                 dtype tf float32)       helper function create initial state given inputs     args      inputs  input tensor  least 2d  first dimension batch size     state shape  shape state      state initializer  initializer(shape  dtype) state tensor      dtype  optional dtype  needed inputs none    returns       a tensors representing initial state          inputs none        handle dynamic shape well inferred shape      inferred batch size   inputs get shape() rank least(1) 0      dtype   inputs dtype   else      inferred batch size   0   initial state   state initializer(        inferred batch size    state shape  dtype dtype)   return initial state    add arg scope def basic conv lstm cell(inputs                           state                           num channels                           filter size 5                           forget bias 1 0                           scope none                           reuse none)       basic lstm recurrent network cell  2d convolution connctions     we add forget bias (default  1) biases forget gate order   reduce scale forgetting beginning training     it allow cell clipping  projection layer    use peep hole connections  basic baseline     args      inputs  input tensor  4d  batch x height x width x channels      state  state tensor  4d  batch x height x width x channels      num channels  number output channels layer      filter size  shape convolution filter      forget bias  initial value forget biases      scope  optional scope variable scope      reuse  whether layer variables reused     returns       tuple tensors representing output new state           copyright 2016 the tensorflow authors all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                       handle dynamic shape well inferred shape     parameters gates concatenated one conv efficiency       input gate  j   new input  f   forget gate    output gate ", "content": "# Copyright 2016 The TensorFlow Authors All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n\"\"\"Convolutional LSTM implementation.\"\"\"\n\nimport tensorflow as tf\n\nfrom tensorflow.contrib.slim import add_arg_scope\nfrom tensorflow.contrib.slim import layers\n\n\ndef init_state(inputs,\n               state_shape,\n               state_initializer=tf.zeros_initializer(),\n               dtype=tf.float32):\n  \"\"\"Helper function to create an initial state given inputs.\n\n  Args:\n    inputs: input Tensor, at least 2D, the first dimension being batch_size\n    state_shape: the shape of the state.\n    state_initializer: Initializer(shape, dtype) for state Tensor.\n    dtype: Optional dtype, needed when inputs is None.\n  Returns:\n     A tensors representing the initial state.\n  \"\"\"\n  if inputs is not None:\n    # Handle both the dynamic shape as well as the inferred shape.\n    inferred_batch_size = inputs.get_shape().with_rank_at_least(1)[0]\n    dtype = inputs.dtype\n  else:\n    inferred_batch_size = 0\n  initial_state = state_initializer(\n      [inferred_batch_size] + state_shape, dtype=dtype)\n  return initial_state\n\n\n@add_arg_scope\ndef basic_conv_lstm_cell(inputs,\n                         state,\n                         num_channels,\n                         filter_size=5,\n                         forget_bias=1.0,\n                         scope=None,\n                         reuse=None):\n  \"\"\"Basic LSTM recurrent network cell, with 2D convolution connctions.\n\n  We add forget_bias (default: 1) to the biases of the forget gate in order to\n  reduce the scale of forgetting in the beginning of the training.\n\n  It does not allow cell clipping, a projection layer, and does not\n  use peep-hole connections: it is the basic baseline.\n\n  Args:\n    inputs: input Tensor, 4D, batch x height x width x channels.\n    state: state Tensor, 4D, batch x height x width x channels.\n    num_channels: the number of output channels in the layer.\n    filter_size: the shape of the each convolution filter.\n    forget_bias: the initial value of the forget biases.\n    scope: Optional scope for variable_scope.\n    reuse: whether or not the layer and the variables should be reused.\n\n  Returns:\n     a tuple of tensors representing output and the new state.\n  \"\"\"\n  spatial_size = inputs.get_shape()[1:3]\n  if state is None:\n    state = init_state(inputs, list(spatial_size) + [2 * num_channels])\n  with tf.variable_scope(scope,\n                         'BasicConvLstmCell',\n                         [inputs, state],\n                         reuse=reuse):\n    inputs.get_shape().assert_has_rank(4)\n    state.get_shape().assert_has_rank(4)\n    c, h = tf.split(axis=3, num_or_size_splits=2, value=state)\n    inputs_h = tf.concat(axis=3, values=[inputs, h])\n    # Parameters of gates are concatenated into one conv for efficiency.\n    i_j_f_o = layers.conv2d(inputs_h,\n                            4 * num_channels, [filter_size, filter_size],\n                            stride=1,\n                            activation_fn=None,\n                            scope='Gates')\n\n    # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n    i, j, f, o = tf.split(axis=3, num_or_size_splits=4, value=i_j_f_o)\n\n    new_c = c * tf.sigmoid(f + forget_bias) + tf.sigmoid(i) * tf.tanh(j)\n    new_h = tf.tanh(new_c) * tf.sigmoid(o)\n\n    return new_h, tf.concat(axis=3, values=[new_c, new_h])\n\n\n\n", "description": "Models and examples built with TensorFlow", "file_name": "lstm_ops.py", "id": "c8f75802f2aeccb9d929fc9b6ec4d317", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tensorflow-models/tensorflow-models-7e4c66b/research/video_prediction/lstm_ops.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:59:36Z", "url": "https://github.com/tensorflow/models", "wiki": true}