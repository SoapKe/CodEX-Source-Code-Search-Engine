{"author": "aws", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\"). You\n may not use this file except in compliance with the License. A copy of\n the License is located at\n\n     http://aws.amazon.com/apache2.0/\n\n or in the \"license\" file accompanying this file. This file is\n distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n ANY KIND, either express or implied. See the License for the specific\n language governing permissions and limitations under the License.\nimport time\nimport signal\nimport os\nimport tempfile\nimport random\nimport shutil\n\nimport botocore.session\nfrom awscli.testutils import unittest, aws, BaseS3CLICommand\nfrom awscli.testutils import temporary_file\nfrom awscli.testutils import skip_if_windows\nfrom awscli.clidriver import create_clidriver\n\n\nclass TestBasicCommandFunctionality(unittest.TestCase):\n    \n\n    def put_object(self, bucket, key, content, extra_args=None):\n        session = botocore.session.get_session()\n        client = session.create_client('s3', 'us-east-1')\n        client.create_bucket(Bucket=bucket)\n        time.sleep(5)\n        self.addCleanup(client.delete_bucket, Bucket=bucket)\n        call_args = {\n            'Bucket': bucket,\n            'Key': key, 'Body': content\n        }\n        if extra_args is not None:\n            call_args.update(extra_args)\n        client.put_object(**call_args)\n        self.addCleanup(client.delete_object, Bucket=bucket, Key=key)\n\n    def test_ec2_describe_instances(self):\n         Verify we can make a call and get output.\n        p = aws('ec2 describe-instances')\n        self.assertEqual(p.rc, 0)\n         We don't know what instances a user might have, but we know\n         there should at least be a Reservations key.\n        self.assertIn('Reservations', p.json)\n\n    def test_help_output(self):\n        p = aws('help')\n        self.assertEqual(p.rc, 0)\n        self.assertIn('AWS', p.stdout)\n        self.assertRegexpMatches(\n            p.stdout, 'The\\s+AWS\\s+Command\\s+Line\\s+Interface')\n\n    def test_service_help_output(self):\n        p = aws('ec2 help')\n        self.assertEqual(p.rc, 0)\n        self.assertIn('Amazon EC2', p.stdout)\n\n    def test_operation_help_output(self):\n        p = aws('ec2 describe-instances help')\n        self.assertEqual(p.rc, 0)\n         XXX: This is a rendering bug that needs to be fixed in bcdoc.  In\n         the RST version there are multiple spaces between certain words.\n         For now we're making the test less strict about formatting, but\n         we eventually should update this test to check exactly for\n         'The describe-instances operation'.\n        self.assertRegexpMatches(p.stdout,\n                                 '\\s+Describes\\s+one\\s+or\\s+more')\n\n    def test_topic_list_help_output(self):\n        p = aws('help topics')\n        self.assertEqual(p.rc, 0)\n        self.assertRegexpMatches(p.stdout, '\\s+AWS\\s+CLI\\s+Topic\\s+Guide')\n        self.assertRegexpMatches(\n            p.stdout,\n            '\\s+This\\s+is\\s+the\\s+AWS\\s+CLI\\s+Topic\\s+Guide'\n        )\n\n    def test_topic_help_output(self):\n        p = aws('help return-codes')\n        self.assertEqual(p.rc, 0)\n        self.assertRegexpMatches(p.stdout, '\\s+AWS\\s+CLI\\s+Return\\s+Codes')\n        self.assertRegexpMatches(\n            p.stdout,\n            'These\\s+are\\s+the\\s+following\\s+return\\s+codes'\n        )\n\n    def test_operation_help_with_required_arg(self):\n        p = aws('s3api get-object help')\n        self.assertEqual(p.rc, 0, p.stderr)\n        self.assertIn('get-object', p.stdout)\n\n    def test_service_help_with_required_option(self):\n         In cloudsearchdomain, the --endpoint-url is required.\n         We want to make sure if you're just getting help tex\n         that we don't trigger that validation.\n        p = aws('cloudsearchdomain help')\n        self.assertEqual(p.rc, 0, p.stderr)\n        self.assertIn('cloudsearchdomain', p.stdout)\n         And nothing on stderr about missing options.\n        self.assertEqual(p.stderr, '')\n\n    def test_operation_help_with_required_option(self):\n        p = aws('cloudsearchdomain search help')\n        self.assertEqual(p.rc, 0, p.stderr)\n        self.assertIn('search', p.stdout)\n         And nothing on stderr about missing options.\n        self.assertEqual(p.stderr, '')\n\n    def test_help_with_warning_blocks(self):\n        p = aws('elastictranscoder create-pipeline help')\n        self.assertEqual(p.rc, 0, p.stderr)\n         Check text that appears in the warning block to ensure\n         the block was actually rendered.\n        self.assertRegexpMatches(p.stdout, 'To\\s+receive\\s+notifications')\n\n    def test_param_shorthand(self):\n        p = aws(\n            'ec2 describe-instances --filters Name=instance-id,Values=i-123')\n        self.assertEqual(p.rc, 0)\n        self.assertIn('Reservations', p.json)\n\n    def test_param_json(self):\n        p = aws(\n            'ec2 describe-instances --filters '\n            '\\'{\"Name\": \"instance-id\", \"Values\": [\"i-123\"]}\\'')\n        self.assertEqual(p.rc, 0, p.stdout + p.stderr)\n        self.assertIn('Reservations', p.json)\n\n    def test_param_with_bad_json(self):\n        p = aws(\n            'ec2 describe-instances --filters '\n            '\\'{\"Name\": \"bad-filter\", \"Values\": [\"i-123\"]}\\'')\n        self.assertEqual(p.rc, 255)\n        self.assertIn(\"The filter 'bad-filter' is invalid\", p.stderr,\n                      \"stdout: %s, stderr: %s\" % (p.stdout, p.stderr))\n\n    def test_param_with_file(self):\n        d = tempfile.mkdtemp()\n        self.addCleanup(os.rmdir, d)\n        param_file = os.path.abspath(os.path.join(d, 'params.json'))\n        with open(param_file, 'w') as f:\n            f.write('[{\"Name\": \"instance-id\", \"Values\": [\"i-123\"]}]')\n        self.addCleanup(os.remove, param_file)\n        p = aws('ec2 describe-instances --filters file://%s' % param_file)\n        self.assertEqual(p.rc, 0)\n        self.assertIn('Reservations', p.json)\n\n    def test_streaming_output_operation(self):\n        d = tempfile.mkdtemp()\n        self.addCleanup(shutil.rmtree, d)\n        bucket_name = 'clistream' + str(\n            int(time.time())) + str(random.randint(1, 100))\n\n        self.put_object(bucket=bucket_name, key='foobar',\n                        content='foobar contents')\n        p = aws('s3api get-object --bucket %s --key foobar %s' % (\n            bucket_name, os.path.join(d, 'foobar')))\n        self.assertEqual(p.rc, 0)\n        with open(os.path.join(d, 'foobar')) as f:\n            contents = f.read()\n        self.assertEqual(contents, 'foobar contents')\n\n    def test_no_sign_request(self):\n        d = tempfile.mkdtemp()\n        self.addCleanup(shutil.rmtree, d)\n\n        env_vars = os.environ.copy()\n        env_vars['AWS_ACCESS_KEY_ID'] = 'foo'\n        env_vars['AWS_SECRET_ACCESS_KEY'] = 'bar'\n\n        bucket_name = 'nosign' + str(\n            int(time.time())) + str(random.randint(1, 100))\n        self.put_object(bucket_name, 'foo', content='bar',\n                        extra_args={'ACL': 'public-read-write'})\n\n        p = aws('s3api get-object --bucket %s --key foo %s' % (\n            bucket_name, os.path.join(d, 'foo')), env_vars=env_vars)\n         Should have credential issues.\n        self.assertEqual(p.rc, 255)\n\n        p = aws('s3api get-object --bucket %s --key foo '\n                '%s --no-sign-request' % (bucket_name, os.path.join(d, 'foo')),\n                env_vars=env_vars)\n\n         Should be able to download the file when not signing.\n        self.assertEqual(p.rc, 0)\n\n        with open(os.path.join(d, 'foo')) as f:\n            contents = f.read()\n        self.assertEqual(contents, 'bar')\n\n    def test_no_paginate_arg(self):\n        d = tempfile.mkdtemp()\n        self.addCleanup(shutil.rmtree, d)\n        bucket_name = 'nopaginate' + str(\n            int(time.time())) + str(random.randint(1, 100))\n\n        self.put_object(bucket=bucket_name, key='foobar',\n                        content='foobar contents')\n        p = aws('s3api list-objects --bucket %s --no-paginate' % bucket_name)\n        self.assertEqual(p.rc, 0, p.stdout + p.stderr)\n\n        p = aws('s3api list-objects --bucket %s' % bucket_name)\n        self.assertEqual(p.rc, 0, p.stdout + p.stderr)\n\n    def test_top_level_options_debug(self):\n        p = aws('ec2 describe-instances --debug')\n        self.assertEqual(p.rc, 0)\n        self.assertIn('DEBUG', p.stderr)\n\n    def test_make_requests_to_other_region(self):\n        p = aws('ec2 describe-instances --region us-west-2')\n        self.assertEqual(p.rc, 0)\n        self.assertIn('Reservations', p.json)\n\n    def test_help_usage_top_level(self):\n        p = aws('')\n        self.assertIn('usage: aws [options] <command> '\n                      '<subcommand> [<subcommand> ...] [parameters]', p.stderr)\n        self.assertIn('aws: error', p.stderr)\n\n    def test_help_usage_service_level(self):\n        p = aws('ec2')\n        self.assertIn('usage: aws [options] <command> '\n                      '<subcommand> [<subcommand> ...] [parameters]', p.stderr)\n         python3: aws: error: the following arguments are required: operation\n         python2: aws: error: too few arguments\n         We don't care too much about the specific error message, as long\n         as it says we have a parse error.\n        self.assertIn('aws: error', p.stderr)\n\n    def test_help_usage_operation_level(self):\n        p = aws('ec2 start-instances')\n        self.assertIn('usage: aws [options] <command> '\n                      '<subcommand> [<subcommand> ...] [parameters]', p.stderr)\n\n    def test_unknown_argument(self):\n        p = aws('ec2 describe-instances --filterss')\n        self.assertEqual(p.rc, 255)\n        self.assertIn('Unknown options: --filterss', p.stderr)\n\n    def test_table_output(self):\n        p = aws('ec2 describe-instances --output table --color off')\n         We're not testing the specifics of table output, we just want\n         to make sure the output looks like a table using some heuristics.\n         If this prints JSON instead of a table, for example, this test\n         should fail.\n        self.assertEqual(p.rc, 0, p.stderr)\n        self.assertIn('-----', p.stdout)\n        self.assertIn('+-', p.stdout)\n        self.assertIn('DescribeInstances', p.stdout)\n\n    def test_version(self):\n        p = aws('--version')\n        self.assertEqual(p.rc, 0)\n         The version is wrote to standard out for Python 3.4 and\n         standard error for other Python versions.\n        version_output = p.stderr.startswith('aws-cli') or \\\n            p.stdout.startswith('aws-cli')\n        self.assertTrue(version_output, p.stderr)\n\n    def test_traceback_printed_when_debug_on(self):\n        p = aws('ec2 describe-instances --filters BADKEY=foo --debug')\n        self.assertIn('Traceback (most recent call last):', p.stderr, p.stderr)\n         Also should see DEBUG statements:\n        self.assertIn('DEBUG', p.stderr, p.stderr)\n\n    def test_leftover_args_in_operation(self):\n        p = aws('ec2 describe-instances BADKEY=foo')\n        self.assertEqual(p.rc, 255)\n        self.assertIn(\"Unknown option\", p.stderr, p.stderr)\n\n    def test_json_param_parsing(self):\n         This is convered by unit tests in botocore, but this is a sanity\n         check that we get a json response from a json service.\n        p = aws('swf list-domains --registration-status REGISTERED')\n        self.assertEqual(p.rc, 0)\n        self.assertIsInstance(p.json, dict)\n\n        p = aws('dynamodb list-tables')\n        self.assertEqual(p.rc, 0)\n        self.assertIsInstance(p.json, dict)\n\n    def test_pagination_with_text_output(self):\n        p = aws('iam list-users --output text')\n        self.assertEqual(p.rc, 0)\n\n    def test_bad_lc_ctype_env_var_is_handled(self):\n         Test for bad LC_CTYPE on Mac OS X.\n        base_env_vars = os.environ.copy()\n        base_env_vars['LC_CTYPE'] = 'UTF-8'\n        p = aws('iam list-users', env_vars=base_env_vars)\n        self.assertEqual(p.rc, 0)\n\n    def test_error_msg_with_no_region_configured(self):\n        environ = os.environ.copy()\n        try:\n            del environ['AWS_DEFAULT_REGION']\n        except KeyError:\n            pass\n        environ['AWS_CONFIG_FILE'] = 'nowhere-foo'\n        p = aws('ec2 describe-instances', env_vars=environ)\n        self.assertIn('must specify a region', p.stderr)\n\n    @skip_if_windows('Ctrl-C not supported on windows.')\n    def test_ctrl_c_does_not_print_traceback(self):\n         Relying on the fact that this generally takes\n         more than 1 second to complete.\n        process = aws('ec2 describe-images', wait_for_finish=False)\n        time.sleep(1)\n        process.send_signal(signal.SIGINT)\n        stdout, stderr = process.communicate()\n        self.assertNotIn(b'Traceback', stdout)\n        self.assertNotIn(b'Traceback', stderr)\n\n\nclass TestCommandLineage(unittest.TestCase):\n    def setUp(self):\n        self.driver = create_clidriver()\n        self.top_help = self.driver.create_help_command()\n\n    def assert_lineage_names(self, ref_lineage_names):\n        command_table = self.top_help.command_table\n        for i, cmd_name in enumerate(ref_lineage_names):\n            command = command_table[cmd_name]\n            help_command = command.create_help_command()\n            command_table = help_command.command_table\n\n        actual_lineage_names = []\n        for cmd in command.lineage:\n            actual_lineage_names.append(cmd.name)\n\n         Assert the actual names of each command in a lineage is as expected.\n        self.assertEqual(actual_lineage_names, ref_lineage_names)\n\n         Assert that ``lineage_names`` for each command is in sync with what\n         is actually in the command's ``lineage``.\n        self.assertEqual(command.lineage_names, actual_lineage_names)\n\n    def test_service_level_commands(self):\n         Check a normal unchanged service command\n        self.assert_lineage_names(['ec2'])\n\n         Check a service that had its name changed.\n        self.assert_lineage_names(['s3api'])\n\n         Check a couple custom service level commands.\n        self.assert_lineage_names(['s3'])\n        self.assert_lineage_names(['configure'])\n\n    def test_operation_level_commands(self):\n         Check a normal unchanged service and operation command\n        self.assert_lineage_names(['dynamodb', 'create-table'])\n\n         Check an operation commands with a service that had its name changed.\n        self.assert_lineage_names(['s3api', 'list-objects'])\n\n         Check a custom operation level command with no\n         custom service command.\n        self.assert_lineage_names(['emr', 'create-cluster'])\n\n         Check a couple of operation level commands that\n         are based off a custom service command\n        self.assert_lineage_names(['configure', 'set'])\n        self.assert_lineage_names(['s3', 'cp'])\n\n    def test_wait_commands(self):\n        self.assert_lineage_names(['ec2', 'wait'])\n        self.assert_lineage_names(['ec2', 'wait', 'instance-running'])\n\n\n We're using BaseS3CLICommand because we need a service to use\n for testing the global arguments.  We're picking S3 here because\n the BaseS3CLICommand has a lot of utility functions that help\n with this.\nclass TestGlobalArgs(BaseS3CLICommand):\n\n    def test_endpoint_url(self):\n        p = aws('s3api list-objects --bucket dnscompat '\n                '--endpoint-url http://localhost:51515 '\n                '--debug')\n        debug_logs = p.stderr\n        original_hostname = 'dnscompat.s3.amazonaws.com'\n        expected = 'localhost'\n        self.assertNotIn(original_hostname, debug_logs,\n                         '--endpoint-url is being ignored.')\n        self.assertIn(expected, debug_logs)\n\n    def test_no_pagination(self):\n        bucket_name = self.create_bucket()\n        self.put_object(bucket_name, 'foo.txt', contents=b'bar')\n        self.put_object(bucket_name, 'foo2.txt', contents=b'bar')\n        self.put_object(bucket_name, 'foo3.txt', contents=b'bar')\n        p = aws('s3api list-objects --bucket %s '\n                '--no-paginate --output json' % bucket_name)\n         A really simple way to check that --no-paginate was\n         honored is to see if we have all the mirrored input\n         arguments in the response json.  These normally aren't\n         present when the response is paginated.\n        self.assert_no_errors(p)\n        response_json = p.json\n        self.assertIn('IsTruncated', response_json)\n        self.assertIn('Name', response_json)\n\n    def test_no_paginate_and_original_args(self):\n        bucket_name = self.create_bucket()\n        self.put_object(bucket_name, 'foo.txt', contents=b'bar')\n        self.put_object(bucket_name, 'foo2.txt', contents=b'bar')\n        self.put_object(bucket_name, 'foo3.txt', contents=b'bar')\n        p = aws('s3api list-objects --bucket %s '\n                '--max-keys 1 --no-paginate --output json' % bucket_name)\n        self.assert_no_errors(p)\n        response_json = p.json\n        self.assertEqual(len(response_json['Contents']), 1)\n\n    def test_max_items(self):\n        bucket_name = self.create_bucket()\n        self.put_object(bucket_name, 'foo.txt', contents=b'bar')\n        self.put_object(bucket_name, 'foo2.txt', contents=b'bar')\n        self.put_object(bucket_name, 'foo3.txt', contents=b'bar')\n        p = aws('s3api list-objects --bucket %s '\n                '--max-items 1 --output json' % bucket_name)\n        self.assert_no_errors(p)\n        response_json = p.json\n        self.assertEqual(len(response_json['Contents']), 1)\n\n    def test_query(self):\n        bucket_name = self.create_bucket()\n        self.put_object(bucket_name, 'foo.txt', contents=b'bar')\n        p = aws('s3api list-objects --bucket %s '\n                '--query Contents[].Key --output json' % bucket_name)\n        self.assert_no_errors(p)\n        response_json = p.json\n        self.assertEqual(response_json, ['foo.txt'])\n\n    def test_no_sign_requests(self):\n        bucket_name = self.create_bucket()\n        self.put_object(bucket_name, 'public', contents=b'bar',\n                        extra_args={'ACL': 'public-read'})\n        self.put_object(bucket_name, 'private', contents=b'bar')\n        env = os.environ.copy()\n         Set the env vars to bad values so if we do actually\n         try to sign the request, we'll get an auth error.\n        env['AWS_ACCESS_KEY_ID'] = 'foo'\n        env['AWS_SECRET_ACCESS_KEY'] = 'bar'\n        p = aws('s3api head-object --bucket %s --key public --no-sign-request'\n                % bucket_name, env_vars=env)\n        self.assert_no_errors(p)\n        self.assertIn('ETag', p.json)\n\n         Should fail because we're not signing the request but the object is\n         private.\n        p = aws('s3api head-object --bucket %s --key private --no-sign-request'\n                % bucket_name, env_vars=env)\n        self.assertEqual(p.rc, 255)\n\n    def test_profile_arg_has_precedence_over_env_vars(self):\n         At a high level, we're going to set access_key/secret_key\n         via env vars, but ensure that a --profile <foo> results\n         in creds being retrieved from the shared creds file\n         and not from env vars.\n        env_vars = os.environ.copy()\n        with temporary_file('w') as f:\n            env_vars.pop('AWS_PROFILE', None)\n            env_vars.pop('AWS_DEFAULT_PROFILE', None)\n             'aws configure list' only shows 4 values\n             from the credentials so we'll show\n             4 char values.\n            env_vars['AWS_ACCESS_KEY_ID'] = 'enva'\n            env_vars['AWS_SECRET_ACCESS_KEY'] = 'envb'\n            env_vars['AWS_SHARED_CREDENTIALS_FILE'] = f.name\n            env_vars['AWS_CONFIG_FILE'] = 'does-not-exist-foo'\n            f.write(\n                '[from_argument]\\n'\n                'aws_access_key_id=proa\\n'\n                'aws_secret_access_key=prob\\n'\n            )\n            f.flush()\n            p = aws('configure list --profile from_argument',\n                    env_vars=env_vars)\n             1. We should see the profile name being set.\n            self.assertIn('from_argument', p.stdout)\n             2. The creds should be proa/prob, which come\n                from the \"from_argument\" profile.\n            self.assertIn('proa', p.stdout)\n            self.assertIn('prob', p.stdout)\n            self.assertIn('shared-credentials-file', p.stdout)\n\n    def test_profile_arg_wins_over_profile_env_var(self):\n        env_vars = os.environ.copy()\n        with temporary_file('w') as f:\n             Remove existing profile related env vars.\n            env_vars.pop('AWS_PROFILE', None)\n            env_vars.pop('AWS_DEFAULT_PROFILE', None)\n            env_vars['AWS_SHARED_CREDENTIALS_FILE'] = f.name\n            env_vars['AWS_CONFIG_FILE'] = 'does-not-exist-foo'\n            f.write(\n                '[from_env_var]\\n'\n                'aws_access_key_id=enva\\n'\n                'aws_secret_access_key=envb\\n'\n                '\\n'\n                '[from_argument]\\n'\n                'aws_access_key_id=proa\\n'\n                'aws_secret_access_key=prob\\n'\n            )\n            f.flush()\n             Now we set the current profile via env var:\n            env_vars['AWS_PROFILE'] = 'from_env_var'\n             If we specify the --profile argument, that\n             value should win over the AWS_PROFILE env var.\n            p = aws('configure list --profile from_argument',\n                    env_vars=env_vars)\n             1. We should see the profile name being set.\n            self.assertIn('from_argument', p.stdout)\n             2. The creds should be profa/profb, which come\n                from the \"from_argument\" profile.\n            self.assertIn('proa', p.stdout)\n            self.assertIn('prob', p.stdout)\n\n\nif __name__ == '__main__':\n    unittest.main()\n", "comments": "        these set tests assert high level features     cli   they anything exhaustive meant smoke     test verify basic cli functionality entirely broken             copyright 2013 amazon com  inc  affiliates  all rights reserved        licensed apache license  version 2 0 (the  license )  you    may use file except compliance license  a copy    license located           http   aws amazon com apache2 0         license  file accompanying file  this file    distributed  as is  basis  without warranties or conditions of    any kind  either express implied  see license specific    language governing permissions limitations license     verify make call get output     we know instances user might  know    least reservations key     xxx  this rendering bug needs fixed bcdoc   in    rst version multiple spaces certain words     for making test less strict formatting     eventually update test check exactly     the describe instances operation      in cloudsearchdomain    endpoint url required     we want make sure getting help tex    trigger validation     and nothing stderr missing options     and nothing stderr missing options     check text appears warning block ensure    block actually rendered     should credential issues     should able download file signing     python3  aws  error  following arguments required  operation    python2  aws  error  arguments    we care much specific error message  long    says parse error     we testing specifics table output  want    make sure output looks like table using heuristics     if prints json instead table  example  test    fail     the version wrote standard python 3 4    standard error python versions     also see debug statements     this convered unit tests botocore  sanity    check get json response json service     test bad lc ctype mac os x     relying fact generally takes    1 second complete     assert actual names command lineage expected     assert   lineage names   command sync    actually command   lineage       check normal unchanged service command    check service name changed     check couple custom service level commands     check normal unchanged service operation command    check operation commands service name changed     check custom operation level command    custom service command     check couple operation level commands    based custom service command    we using bases3clicommand need service use    testing global arguments   we picking s3    bases3clicommand lot utility functions help        a really simple way check   paginate    honored see mirrored input    arguments response json   these normally    present response paginated     set env vars bad values actually    try sign request  get auth error     should fail signing request object    private     at high level  going set access key secret key    via env vars  ensure   profile  foo  results    creds retrieved shared creds file    env vars      aws configure list  shows 4 values    credentials show    4 char values     1  we see profile name set     2  the creds proa prob  come        argument  profile     remove existing profile related env vars     now set current profile via env var     if specify   profile argument     value win aws profile env var     1  we see profile name set     2  the creds profa profb  come        argument  profile  ", "content": "# Copyright 2013 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport time\nimport signal\nimport os\nimport tempfile\nimport random\nimport shutil\n\nimport botocore.session\nfrom awscli.testutils import unittest, aws, BaseS3CLICommand\nfrom awscli.testutils import temporary_file\nfrom awscli.testutils import skip_if_windows\nfrom awscli.clidriver import create_clidriver\n\n\nclass TestBasicCommandFunctionality(unittest.TestCase):\n    \"\"\"\n    These are a set of tests that assert high level features of\n    the CLI.  They don't anything exhaustive and is meant as a smoke\n    test to verify basic CLI functionality isn't entirely broken.\n    \"\"\"\n\n    def put_object(self, bucket, key, content, extra_args=None):\n        session = botocore.session.get_session()\n        client = session.create_client('s3', 'us-east-1')\n        client.create_bucket(Bucket=bucket)\n        time.sleep(5)\n        self.addCleanup(client.delete_bucket, Bucket=bucket)\n        call_args = {\n            'Bucket': bucket,\n            'Key': key, 'Body': content\n        }\n        if extra_args is not None:\n            call_args.update(extra_args)\n        client.put_object(**call_args)\n        self.addCleanup(client.delete_object, Bucket=bucket, Key=key)\n\n    def test_ec2_describe_instances(self):\n        # Verify we can make a call and get output.\n        p = aws('ec2 describe-instances')\n        self.assertEqual(p.rc, 0)\n        # We don't know what instances a user might have, but we know\n        # there should at least be a Reservations key.\n        self.assertIn('Reservations', p.json)\n\n    def test_help_output(self):\n        p = aws('help')\n        self.assertEqual(p.rc, 0)\n        self.assertIn('AWS', p.stdout)\n        self.assertRegexpMatches(\n            p.stdout, 'The\\s+AWS\\s+Command\\s+Line\\s+Interface')\n\n    def test_service_help_output(self):\n        p = aws('ec2 help')\n        self.assertEqual(p.rc, 0)\n        self.assertIn('Amazon EC2', p.stdout)\n\n    def test_operation_help_output(self):\n        p = aws('ec2 describe-instances help')\n        self.assertEqual(p.rc, 0)\n        # XXX: This is a rendering bug that needs to be fixed in bcdoc.  In\n        # the RST version there are multiple spaces between certain words.\n        # For now we're making the test less strict about formatting, but\n        # we eventually should update this test to check exactly for\n        # 'The describe-instances operation'.\n        self.assertRegexpMatches(p.stdout,\n                                 '\\s+Describes\\s+one\\s+or\\s+more')\n\n    def test_topic_list_help_output(self):\n        p = aws('help topics')\n        self.assertEqual(p.rc, 0)\n        self.assertRegexpMatches(p.stdout, '\\s+AWS\\s+CLI\\s+Topic\\s+Guide')\n        self.assertRegexpMatches(\n            p.stdout,\n            '\\s+This\\s+is\\s+the\\s+AWS\\s+CLI\\s+Topic\\s+Guide'\n        )\n\n    def test_topic_help_output(self):\n        p = aws('help return-codes')\n        self.assertEqual(p.rc, 0)\n        self.assertRegexpMatches(p.stdout, '\\s+AWS\\s+CLI\\s+Return\\s+Codes')\n        self.assertRegexpMatches(\n            p.stdout,\n            'These\\s+are\\s+the\\s+following\\s+return\\s+codes'\n        )\n\n    def test_operation_help_with_required_arg(self):\n        p = aws('s3api get-object help')\n        self.assertEqual(p.rc, 0, p.stderr)\n        self.assertIn('get-object', p.stdout)\n\n    def test_service_help_with_required_option(self):\n        # In cloudsearchdomain, the --endpoint-url is required.\n        # We want to make sure if you're just getting help tex\n        # that we don't trigger that validation.\n        p = aws('cloudsearchdomain help')\n        self.assertEqual(p.rc, 0, p.stderr)\n        self.assertIn('cloudsearchdomain', p.stdout)\n        # And nothing on stderr about missing options.\n        self.assertEqual(p.stderr, '')\n\n    def test_operation_help_with_required_option(self):\n        p = aws('cloudsearchdomain search help')\n        self.assertEqual(p.rc, 0, p.stderr)\n        self.assertIn('search', p.stdout)\n        # And nothing on stderr about missing options.\n        self.assertEqual(p.stderr, '')\n\n    def test_help_with_warning_blocks(self):\n        p = aws('elastictranscoder create-pipeline help')\n        self.assertEqual(p.rc, 0, p.stderr)\n        # Check text that appears in the warning block to ensure\n        # the block was actually rendered.\n        self.assertRegexpMatches(p.stdout, 'To\\s+receive\\s+notifications')\n\n    def test_param_shorthand(self):\n        p = aws(\n            'ec2 describe-instances --filters Name=instance-id,Values=i-123')\n        self.assertEqual(p.rc, 0)\n        self.assertIn('Reservations', p.json)\n\n    def test_param_json(self):\n        p = aws(\n            'ec2 describe-instances --filters '\n            '\\'{\"Name\": \"instance-id\", \"Values\": [\"i-123\"]}\\'')\n        self.assertEqual(p.rc, 0, p.stdout + p.stderr)\n        self.assertIn('Reservations', p.json)\n\n    def test_param_with_bad_json(self):\n        p = aws(\n            'ec2 describe-instances --filters '\n            '\\'{\"Name\": \"bad-filter\", \"Values\": [\"i-123\"]}\\'')\n        self.assertEqual(p.rc, 255)\n        self.assertIn(\"The filter 'bad-filter' is invalid\", p.stderr,\n                      \"stdout: %s, stderr: %s\" % (p.stdout, p.stderr))\n\n    def test_param_with_file(self):\n        d = tempfile.mkdtemp()\n        self.addCleanup(os.rmdir, d)\n        param_file = os.path.abspath(os.path.join(d, 'params.json'))\n        with open(param_file, 'w') as f:\n            f.write('[{\"Name\": \"instance-id\", \"Values\": [\"i-123\"]}]')\n        self.addCleanup(os.remove, param_file)\n        p = aws('ec2 describe-instances --filters file://%s' % param_file)\n        self.assertEqual(p.rc, 0)\n        self.assertIn('Reservations', p.json)\n\n    def test_streaming_output_operation(self):\n        d = tempfile.mkdtemp()\n        self.addCleanup(shutil.rmtree, d)\n        bucket_name = 'clistream' + str(\n            int(time.time())) + str(random.randint(1, 100))\n\n        self.put_object(bucket=bucket_name, key='foobar',\n                        content='foobar contents')\n        p = aws('s3api get-object --bucket %s --key foobar %s' % (\n            bucket_name, os.path.join(d, 'foobar')))\n        self.assertEqual(p.rc, 0)\n        with open(os.path.join(d, 'foobar')) as f:\n            contents = f.read()\n        self.assertEqual(contents, 'foobar contents')\n\n    def test_no_sign_request(self):\n        d = tempfile.mkdtemp()\n        self.addCleanup(shutil.rmtree, d)\n\n        env_vars = os.environ.copy()\n        env_vars['AWS_ACCESS_KEY_ID'] = 'foo'\n        env_vars['AWS_SECRET_ACCESS_KEY'] = 'bar'\n\n        bucket_name = 'nosign' + str(\n            int(time.time())) + str(random.randint(1, 100))\n        self.put_object(bucket_name, 'foo', content='bar',\n                        extra_args={'ACL': 'public-read-write'})\n\n        p = aws('s3api get-object --bucket %s --key foo %s' % (\n            bucket_name, os.path.join(d, 'foo')), env_vars=env_vars)\n        # Should have credential issues.\n        self.assertEqual(p.rc, 255)\n\n        p = aws('s3api get-object --bucket %s --key foo '\n                '%s --no-sign-request' % (bucket_name, os.path.join(d, 'foo')),\n                env_vars=env_vars)\n\n        # Should be able to download the file when not signing.\n        self.assertEqual(p.rc, 0)\n\n        with open(os.path.join(d, 'foo')) as f:\n            contents = f.read()\n        self.assertEqual(contents, 'bar')\n\n    def test_no_paginate_arg(self):\n        d = tempfile.mkdtemp()\n        self.addCleanup(shutil.rmtree, d)\n        bucket_name = 'nopaginate' + str(\n            int(time.time())) + str(random.randint(1, 100))\n\n        self.put_object(bucket=bucket_name, key='foobar',\n                        content='foobar contents')\n        p = aws('s3api list-objects --bucket %s --no-paginate' % bucket_name)\n        self.assertEqual(p.rc, 0, p.stdout + p.stderr)\n\n        p = aws('s3api list-objects --bucket %s' % bucket_name)\n        self.assertEqual(p.rc, 0, p.stdout + p.stderr)\n\n    def test_top_level_options_debug(self):\n        p = aws('ec2 describe-instances --debug')\n        self.assertEqual(p.rc, 0)\n        self.assertIn('DEBUG', p.stderr)\n\n    def test_make_requests_to_other_region(self):\n        p = aws('ec2 describe-instances --region us-west-2')\n        self.assertEqual(p.rc, 0)\n        self.assertIn('Reservations', p.json)\n\n    def test_help_usage_top_level(self):\n        p = aws('')\n        self.assertIn('usage: aws [options] <command> '\n                      '<subcommand> [<subcommand> ...] [parameters]', p.stderr)\n        self.assertIn('aws: error', p.stderr)\n\n    def test_help_usage_service_level(self):\n        p = aws('ec2')\n        self.assertIn('usage: aws [options] <command> '\n                      '<subcommand> [<subcommand> ...] [parameters]', p.stderr)\n        # python3: aws: error: the following arguments are required: operation\n        # python2: aws: error: too few arguments\n        # We don't care too much about the specific error message, as long\n        # as it says we have a parse error.\n        self.assertIn('aws: error', p.stderr)\n\n    def test_help_usage_operation_level(self):\n        p = aws('ec2 start-instances')\n        self.assertIn('usage: aws [options] <command> '\n                      '<subcommand> [<subcommand> ...] [parameters]', p.stderr)\n\n    def test_unknown_argument(self):\n        p = aws('ec2 describe-instances --filterss')\n        self.assertEqual(p.rc, 255)\n        self.assertIn('Unknown options: --filterss', p.stderr)\n\n    def test_table_output(self):\n        p = aws('ec2 describe-instances --output table --color off')\n        # We're not testing the specifics of table output, we just want\n        # to make sure the output looks like a table using some heuristics.\n        # If this prints JSON instead of a table, for example, this test\n        # should fail.\n        self.assertEqual(p.rc, 0, p.stderr)\n        self.assertIn('-----', p.stdout)\n        self.assertIn('+-', p.stdout)\n        self.assertIn('DescribeInstances', p.stdout)\n\n    def test_version(self):\n        p = aws('--version')\n        self.assertEqual(p.rc, 0)\n        # The version is wrote to standard out for Python 3.4 and\n        # standard error for other Python versions.\n        version_output = p.stderr.startswith('aws-cli') or \\\n            p.stdout.startswith('aws-cli')\n        self.assertTrue(version_output, p.stderr)\n\n    def test_traceback_printed_when_debug_on(self):\n        p = aws('ec2 describe-instances --filters BADKEY=foo --debug')\n        self.assertIn('Traceback (most recent call last):', p.stderr, p.stderr)\n        # Also should see DEBUG statements:\n        self.assertIn('DEBUG', p.stderr, p.stderr)\n\n    def test_leftover_args_in_operation(self):\n        p = aws('ec2 describe-instances BADKEY=foo')\n        self.assertEqual(p.rc, 255)\n        self.assertIn(\"Unknown option\", p.stderr, p.stderr)\n\n    def test_json_param_parsing(self):\n        # This is convered by unit tests in botocore, but this is a sanity\n        # check that we get a json response from a json service.\n        p = aws('swf list-domains --registration-status REGISTERED')\n        self.assertEqual(p.rc, 0)\n        self.assertIsInstance(p.json, dict)\n\n        p = aws('dynamodb list-tables')\n        self.assertEqual(p.rc, 0)\n        self.assertIsInstance(p.json, dict)\n\n    def test_pagination_with_text_output(self):\n        p = aws('iam list-users --output text')\n        self.assertEqual(p.rc, 0)\n\n    def test_bad_lc_ctype_env_var_is_handled(self):\n        # Test for bad LC_CTYPE on Mac OS X.\n        base_env_vars = os.environ.copy()\n        base_env_vars['LC_CTYPE'] = 'UTF-8'\n        p = aws('iam list-users', env_vars=base_env_vars)\n        self.assertEqual(p.rc, 0)\n\n    def test_error_msg_with_no_region_configured(self):\n        environ = os.environ.copy()\n        try:\n            del environ['AWS_DEFAULT_REGION']\n        except KeyError:\n            pass\n        environ['AWS_CONFIG_FILE'] = 'nowhere-foo'\n        p = aws('ec2 describe-instances', env_vars=environ)\n        self.assertIn('must specify a region', p.stderr)\n\n    @skip_if_windows('Ctrl-C not supported on windows.')\n    def test_ctrl_c_does_not_print_traceback(self):\n        # Relying on the fact that this generally takes\n        # more than 1 second to complete.\n        process = aws('ec2 describe-images', wait_for_finish=False)\n        time.sleep(1)\n        process.send_signal(signal.SIGINT)\n        stdout, stderr = process.communicate()\n        self.assertNotIn(b'Traceback', stdout)\n        self.assertNotIn(b'Traceback', stderr)\n\n\nclass TestCommandLineage(unittest.TestCase):\n    def setUp(self):\n        self.driver = create_clidriver()\n        self.top_help = self.driver.create_help_command()\n\n    def assert_lineage_names(self, ref_lineage_names):\n        command_table = self.top_help.command_table\n        for i, cmd_name in enumerate(ref_lineage_names):\n            command = command_table[cmd_name]\n            help_command = command.create_help_command()\n            command_table = help_command.command_table\n\n        actual_lineage_names = []\n        for cmd in command.lineage:\n            actual_lineage_names.append(cmd.name)\n\n        # Assert the actual names of each command in a lineage is as expected.\n        self.assertEqual(actual_lineage_names, ref_lineage_names)\n\n        # Assert that ``lineage_names`` for each command is in sync with what\n        # is actually in the command's ``lineage``.\n        self.assertEqual(command.lineage_names, actual_lineage_names)\n\n    def test_service_level_commands(self):\n        # Check a normal unchanged service command\n        self.assert_lineage_names(['ec2'])\n\n        # Check a service that had its name changed.\n        self.assert_lineage_names(['s3api'])\n\n        # Check a couple custom service level commands.\n        self.assert_lineage_names(['s3'])\n        self.assert_lineage_names(['configure'])\n\n    def test_operation_level_commands(self):\n        # Check a normal unchanged service and operation command\n        self.assert_lineage_names(['dynamodb', 'create-table'])\n\n        # Check an operation commands with a service that had its name changed.\n        self.assert_lineage_names(['s3api', 'list-objects'])\n\n        # Check a custom operation level command with no\n        # custom service command.\n        self.assert_lineage_names(['emr', 'create-cluster'])\n\n        # Check a couple of operation level commands that\n        # are based off a custom service command\n        self.assert_lineage_names(['configure', 'set'])\n        self.assert_lineage_names(['s3', 'cp'])\n\n    def test_wait_commands(self):\n        self.assert_lineage_names(['ec2', 'wait'])\n        self.assert_lineage_names(['ec2', 'wait', 'instance-running'])\n\n\n# We're using BaseS3CLICommand because we need a service to use\n# for testing the global arguments.  We're picking S3 here because\n# the BaseS3CLICommand has a lot of utility functions that help\n# with this.\nclass TestGlobalArgs(BaseS3CLICommand):\n\n    def test_endpoint_url(self):\n        p = aws('s3api list-objects --bucket dnscompat '\n                '--endpoint-url http://localhost:51515 '\n                '--debug')\n        debug_logs = p.stderr\n        original_hostname = 'dnscompat.s3.amazonaws.com'\n        expected = 'localhost'\n        self.assertNotIn(original_hostname, debug_logs,\n                         '--endpoint-url is being ignored.')\n        self.assertIn(expected, debug_logs)\n\n    def test_no_pagination(self):\n        bucket_name = self.create_bucket()\n        self.put_object(bucket_name, 'foo.txt', contents=b'bar')\n        self.put_object(bucket_name, 'foo2.txt', contents=b'bar')\n        self.put_object(bucket_name, 'foo3.txt', contents=b'bar')\n        p = aws('s3api list-objects --bucket %s '\n                '--no-paginate --output json' % bucket_name)\n        # A really simple way to check that --no-paginate was\n        # honored is to see if we have all the mirrored input\n        # arguments in the response json.  These normally aren't\n        # present when the response is paginated.\n        self.assert_no_errors(p)\n        response_json = p.json\n        self.assertIn('IsTruncated', response_json)\n        self.assertIn('Name', response_json)\n\n    def test_no_paginate_and_original_args(self):\n        bucket_name = self.create_bucket()\n        self.put_object(bucket_name, 'foo.txt', contents=b'bar')\n        self.put_object(bucket_name, 'foo2.txt', contents=b'bar')\n        self.put_object(bucket_name, 'foo3.txt', contents=b'bar')\n        p = aws('s3api list-objects --bucket %s '\n                '--max-keys 1 --no-paginate --output json' % bucket_name)\n        self.assert_no_errors(p)\n        response_json = p.json\n        self.assertEqual(len(response_json['Contents']), 1)\n\n    def test_max_items(self):\n        bucket_name = self.create_bucket()\n        self.put_object(bucket_name, 'foo.txt', contents=b'bar')\n        self.put_object(bucket_name, 'foo2.txt', contents=b'bar')\n        self.put_object(bucket_name, 'foo3.txt', contents=b'bar')\n        p = aws('s3api list-objects --bucket %s '\n                '--max-items 1 --output json' % bucket_name)\n        self.assert_no_errors(p)\n        response_json = p.json\n        self.assertEqual(len(response_json['Contents']), 1)\n\n    def test_query(self):\n        bucket_name = self.create_bucket()\n        self.put_object(bucket_name, 'foo.txt', contents=b'bar')\n        p = aws('s3api list-objects --bucket %s '\n                '--query Contents[].Key --output json' % bucket_name)\n        self.assert_no_errors(p)\n        response_json = p.json\n        self.assertEqual(response_json, ['foo.txt'])\n\n    def test_no_sign_requests(self):\n        bucket_name = self.create_bucket()\n        self.put_object(bucket_name, 'public', contents=b'bar',\n                        extra_args={'ACL': 'public-read'})\n        self.put_object(bucket_name, 'private', contents=b'bar')\n        env = os.environ.copy()\n        # Set the env vars to bad values so if we do actually\n        # try to sign the request, we'll get an auth error.\n        env['AWS_ACCESS_KEY_ID'] = 'foo'\n        env['AWS_SECRET_ACCESS_KEY'] = 'bar'\n        p = aws('s3api head-object --bucket %s --key public --no-sign-request'\n                % bucket_name, env_vars=env)\n        self.assert_no_errors(p)\n        self.assertIn('ETag', p.json)\n\n        # Should fail because we're not signing the request but the object is\n        # private.\n        p = aws('s3api head-object --bucket %s --key private --no-sign-request'\n                % bucket_name, env_vars=env)\n        self.assertEqual(p.rc, 255)\n\n    def test_profile_arg_has_precedence_over_env_vars(self):\n        # At a high level, we're going to set access_key/secret_key\n        # via env vars, but ensure that a --profile <foo> results\n        # in creds being retrieved from the shared creds file\n        # and not from env vars.\n        env_vars = os.environ.copy()\n        with temporary_file('w') as f:\n            env_vars.pop('AWS_PROFILE', None)\n            env_vars.pop('AWS_DEFAULT_PROFILE', None)\n            # 'aws configure list' only shows 4 values\n            # from the credentials so we'll show\n            # 4 char values.\n            env_vars['AWS_ACCESS_KEY_ID'] = 'enva'\n            env_vars['AWS_SECRET_ACCESS_KEY'] = 'envb'\n            env_vars['AWS_SHARED_CREDENTIALS_FILE'] = f.name\n            env_vars['AWS_CONFIG_FILE'] = 'does-not-exist-foo'\n            f.write(\n                '[from_argument]\\n'\n                'aws_access_key_id=proa\\n'\n                'aws_secret_access_key=prob\\n'\n            )\n            f.flush()\n            p = aws('configure list --profile from_argument',\n                    env_vars=env_vars)\n            # 1. We should see the profile name being set.\n            self.assertIn('from_argument', p.stdout)\n            # 2. The creds should be proa/prob, which come\n            #    from the \"from_argument\" profile.\n            self.assertIn('proa', p.stdout)\n            self.assertIn('prob', p.stdout)\n            self.assertIn('shared-credentials-file', p.stdout)\n\n    def test_profile_arg_wins_over_profile_env_var(self):\n        env_vars = os.environ.copy()\n        with temporary_file('w') as f:\n            # Remove existing profile related env vars.\n            env_vars.pop('AWS_PROFILE', None)\n            env_vars.pop('AWS_DEFAULT_PROFILE', None)\n            env_vars['AWS_SHARED_CREDENTIALS_FILE'] = f.name\n            env_vars['AWS_CONFIG_FILE'] = 'does-not-exist-foo'\n            f.write(\n                '[from_env_var]\\n'\n                'aws_access_key_id=enva\\n'\n                'aws_secret_access_key=envb\\n'\n                '\\n'\n                '[from_argument]\\n'\n                'aws_access_key_id=proa\\n'\n                'aws_secret_access_key=prob\\n'\n            )\n            f.flush()\n            # Now we set the current profile via env var:\n            env_vars['AWS_PROFILE'] = 'from_env_var'\n            # If we specify the --profile argument, that\n            # value should win over the AWS_PROFILE env var.\n            p = aws('configure list --profile from_argument',\n                    env_vars=env_vars)\n            # 1. We should see the profile name being set.\n            self.assertIn('from_argument', p.stdout)\n            # 2. The creds should be profa/profb, which come\n            #    from the \"from_argument\" profile.\n            self.assertIn('proa', p.stdout)\n            self.assertIn('prob', p.stdout)\n\n\nif __name__ == '__main__':\n    unittest.main()\n", "description": "Universal Command Line Interface for Amazon Web Services", "file_name": "test_cli.py", "id": "aaa5cc94da1437173eb1827ead258209", "language": "Python", "project_name": "aws-cli", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/aws-aws-cli/aws-aws-cli-d705c60/tests/integration/test_cli.py", "save_time": "", "source": "", "update_at": "2018-03-18T15:33:26Z", "url": "https://github.com/aws/aws-cli", "wiki": false}