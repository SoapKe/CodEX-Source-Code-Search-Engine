{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\n\nimport os\nimport sys\n\n internal imports\nimport numpy as np\nimport tensorflow as tf\n\nfrom magenta.models.nsynth import utils\nfrom magenta.models.nsynth.wavenet.fastgen import encode\n\nFLAGS = tf.app.flags.FLAGS\n\ntf.app.flags.DEFINE_string(\"source_path\", \"\",\n                           \"The directory of WAVs to yield embeddings from.\")\ntf.app.flags.DEFINE_string(\"save_path\", \"\", \"The directory to save \"\n                           \"the embeddings.\")\ntf.app.flags.DEFINE_string(\"checkpoint_path\", \"\",\n                           \"A path to the checkpoint. If not given, the latest \"\n                           \"checkpoint in `expdir` will be used.\")\ntf.app.flags.DEFINE_string(\"expdir\", \"\",\n                           \"The log directory for this experiment. Required if \"\n                           \"`checkpoint_path` is not given.\")\ntf.app.flags.DEFINE_integer(\"sample_length\", 64000, \"Sample length.\")\ntf.app.flags.DEFINE_integer(\"batch_size\", 16, \"Sample length.\")\ntf.app.flags.DEFINE_string(\"log\", \"INFO\",\n                           \"The threshold for what messages will be logged.\"\n                           \"DEBUG, INFO, WARN, ERROR, or FATAL.\")\n\n\ndef main(unused_argv=None):\n  tf.logging.set_verbosity(FLAGS.log)\n\n  if FLAGS.checkpoint_path:\n    checkpoint_path = utils.shell_path(FLAGS.checkpoint_path)\n  else:\n    expdir = utils.shell_path(FLAGS.expdir)\n    tf.logging.info(\"Will load latest checkpoint from %s.\", expdir)\n    while not tf.gfile.Exists(expdir):\n      tf.logging.fatal(\"\\tExperiment save dir '%s' does not exist!\", expdir)\n      sys.exit(1)\n\n    try:\n      checkpoint_path = tf.train.latest_checkpoint(expdir)\n    except tf.errors.NotFoundError:\n      tf.logging.fatal(\"There was a problem determining the latest checkpoint.\")\n      sys.exit(1)\n\n  if not tf.train.checkpoint_exists(checkpoint_path):\n    tf.logging.fatal(\"Invalid checkpoint path: %s\", checkpoint_path)\n    sys.exit(1)\n\n  tf.logging.info(\"Will restore from checkpoint: %s\", checkpoint_path)\n\n  source_path = utils.shell_path(FLAGS.source_path)\n  tf.logging.info(\"Will load Wavs from %s.\" % source_path)\n\n  save_path = utils.shell_path(FLAGS.save_path)\n  tf.logging.info(\"Will save embeddings to %s.\" % save_path)\n  if not tf.gfile.Exists(save_path):\n    tf.logging.info(\"Creating save directory...\")\n    tf.gfile.MakeDirs(save_path)\n\n  sample_length = FLAGS.sample_length\n  batch_size = FLAGS.batch_size\n\n  def is_wav(f):\n    return f.lower().endswith(\".wav\")\n\n  wavfiles = sorted([\n      os.path.join(source_path, fname)\n      for fname in tf.gfile.ListDirectory(source_path) if is_wav(fname)\n  ])\n\n  for start_file in xrange(0, len(wavfiles), batch_size):\n    batch_number = (start_file / batch_size) + 1\n    tf.logging.info(\"On file number %s (batch %d).\", start_file, batch_number)\n    end_file = start_file + batch_size\n    wavefiles_batch = wavfiles[start_file:end_file]\n\n     Ensure that files has batch_size elements.\n    batch_filler = batch_size - len(wavefiles_batch)\n    wavefiles_batch.extend(batch_filler * [wavefiles_batch[-1]])\n    wav_data = np.array(\n        [utils.load_audio(f, sample_length) for f in wavefiles_batch])\n    try:\n      tf.reset_default_graph()\n       Load up the model for encoding and find the encoding\n      encoding = encode(wav_data, checkpoint_path, sample_length=sample_length)\n      if encoding.ndim == 2:\n        encoding = np.expand_dims(encoding, 0)\n\n      tf.logging.info(\"Encoding:\")\n      tf.logging.info(encoding.shape)\n      tf.logging.info(\"Sample length: %d\" % sample_length)\n\n      for num, (wavfile, enc) in enumerate(zip(wavefiles_batch, encoding)):\n        filename = \"%s_embeddings.npy\" % wavfile.split(\"/\")[-1].strip(\".wav\")\n        with tf.gfile.Open(os.path.join(save_path, filename), \"w\") as f:\n          np.save(f, enc)\n\n        if num + batch_filler + 1 == batch_size:\n          break\n    except Exception as e:\n      tf.logging.info(\"Unexpected error happened: %s.\", e)\n      raise\n\n\ndef console_entry_point():\n  tf.app.run(main)\n\n\nif __name__ == \"__main__\":\n  console_entry_point()\n", "comments": "   with trained model  compute embeddings directory wav files        copyright 2017 google inc  all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license          http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license     internal imports    ensure files batch size elements     load model encoding find encoding ", "content": "# Copyright 2017 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"With a trained model, compute the embeddings on a directory of WAV files.\"\"\"\n\nimport os\nimport sys\n\n# internal imports\nimport numpy as np\nimport tensorflow as tf\n\nfrom magenta.models.nsynth import utils\nfrom magenta.models.nsynth.wavenet.fastgen import encode\n\nFLAGS = tf.app.flags.FLAGS\n\ntf.app.flags.DEFINE_string(\"source_path\", \"\",\n                           \"The directory of WAVs to yield embeddings from.\")\ntf.app.flags.DEFINE_string(\"save_path\", \"\", \"The directory to save \"\n                           \"the embeddings.\")\ntf.app.flags.DEFINE_string(\"checkpoint_path\", \"\",\n                           \"A path to the checkpoint. If not given, the latest \"\n                           \"checkpoint in `expdir` will be used.\")\ntf.app.flags.DEFINE_string(\"expdir\", \"\",\n                           \"The log directory for this experiment. Required if \"\n                           \"`checkpoint_path` is not given.\")\ntf.app.flags.DEFINE_integer(\"sample_length\", 64000, \"Sample length.\")\ntf.app.flags.DEFINE_integer(\"batch_size\", 16, \"Sample length.\")\ntf.app.flags.DEFINE_string(\"log\", \"INFO\",\n                           \"The threshold for what messages will be logged.\"\n                           \"DEBUG, INFO, WARN, ERROR, or FATAL.\")\n\n\ndef main(unused_argv=None):\n  tf.logging.set_verbosity(FLAGS.log)\n\n  if FLAGS.checkpoint_path:\n    checkpoint_path = utils.shell_path(FLAGS.checkpoint_path)\n  else:\n    expdir = utils.shell_path(FLAGS.expdir)\n    tf.logging.info(\"Will load latest checkpoint from %s.\", expdir)\n    while not tf.gfile.Exists(expdir):\n      tf.logging.fatal(\"\\tExperiment save dir '%s' does not exist!\", expdir)\n      sys.exit(1)\n\n    try:\n      checkpoint_path = tf.train.latest_checkpoint(expdir)\n    except tf.errors.NotFoundError:\n      tf.logging.fatal(\"There was a problem determining the latest checkpoint.\")\n      sys.exit(1)\n\n  if not tf.train.checkpoint_exists(checkpoint_path):\n    tf.logging.fatal(\"Invalid checkpoint path: %s\", checkpoint_path)\n    sys.exit(1)\n\n  tf.logging.info(\"Will restore from checkpoint: %s\", checkpoint_path)\n\n  source_path = utils.shell_path(FLAGS.source_path)\n  tf.logging.info(\"Will load Wavs from %s.\" % source_path)\n\n  save_path = utils.shell_path(FLAGS.save_path)\n  tf.logging.info(\"Will save embeddings to %s.\" % save_path)\n  if not tf.gfile.Exists(save_path):\n    tf.logging.info(\"Creating save directory...\")\n    tf.gfile.MakeDirs(save_path)\n\n  sample_length = FLAGS.sample_length\n  batch_size = FLAGS.batch_size\n\n  def is_wav(f):\n    return f.lower().endswith(\".wav\")\n\n  wavfiles = sorted([\n      os.path.join(source_path, fname)\n      for fname in tf.gfile.ListDirectory(source_path) if is_wav(fname)\n  ])\n\n  for start_file in xrange(0, len(wavfiles), batch_size):\n    batch_number = (start_file / batch_size) + 1\n    tf.logging.info(\"On file number %s (batch %d).\", start_file, batch_number)\n    end_file = start_file + batch_size\n    wavefiles_batch = wavfiles[start_file:end_file]\n\n    # Ensure that files has batch_size elements.\n    batch_filler = batch_size - len(wavefiles_batch)\n    wavefiles_batch.extend(batch_filler * [wavefiles_batch[-1]])\n    wav_data = np.array(\n        [utils.load_audio(f, sample_length) for f in wavefiles_batch])\n    try:\n      tf.reset_default_graph()\n      # Load up the model for encoding and find the encoding\n      encoding = encode(wav_data, checkpoint_path, sample_length=sample_length)\n      if encoding.ndim == 2:\n        encoding = np.expand_dims(encoding, 0)\n\n      tf.logging.info(\"Encoding:\")\n      tf.logging.info(encoding.shape)\n      tf.logging.info(\"Sample length: %d\" % sample_length)\n\n      for num, (wavfile, enc) in enumerate(zip(wavefiles_batch, encoding)):\n        filename = \"%s_embeddings.npy\" % wavfile.split(\"/\")[-1].strip(\".wav\")\n        with tf.gfile.Open(os.path.join(save_path, filename), \"w\") as f:\n          np.save(f, enc)\n\n        if num + batch_filler + 1 == batch_size:\n          break\n    except Exception as e:\n      tf.logging.info(\"Unexpected error happened: %s.\", e)\n      raise\n\n\ndef console_entry_point():\n  tf.app.run(main)\n\n\nif __name__ == \"__main__\":\n  console_entry_point()\n", "description": "Magenta: Music and Art Generation with Machine Intelligence", "file_name": "nsynth_save_embeddings.py", "id": "ce8ca8406c2c4ab0d49985de3a571ad4", "language": "Python", "project_name": "magenta", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-magenta/tensorflow-magenta-c3eda3d/magenta/models/nsynth/wavenet/nsynth_save_embeddings.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:52:33Z", "url": "https://github.com/tensorflow/magenta", "wiki": false}