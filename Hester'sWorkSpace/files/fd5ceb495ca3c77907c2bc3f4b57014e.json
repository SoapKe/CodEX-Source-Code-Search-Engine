{"author": "rg3", "code": "\n\nfrom __future__ import unicode_literals\n\n\nimport itertools\nimport json\nimport os.path\nimport random\nimport re\nimport time\nimport traceback\n\nfrom .common import InfoExtractor, SearchInfoExtractor\nfrom ..jsinterp import JSInterpreter\nfrom ..swfinterp import SWFInterpreter\nfrom ..compat import (\n    compat_chr,\n    compat_kwargs,\n    compat_parse_qs,\n    compat_urllib_parse_unquote,\n    compat_urllib_parse_unquote_plus,\n    compat_urllib_parse_urlencode,\n    compat_urllib_parse_urlparse,\n    compat_urlparse,\n    compat_str,\n)\nfrom ..utils import (\n    clean_html,\n    error_to_compat_str,\n    ExtractorError,\n    float_or_none,\n    get_element_by_attribute,\n    get_element_by_id,\n    int_or_none,\n    mimetype2ext,\n    orderedSet,\n    parse_codecs,\n    parse_duration,\n    remove_quotes,\n    remove_start,\n    smuggle_url,\n    str_to_int,\n    try_get,\n    unescapeHTML,\n    unified_strdate,\n    unsmuggle_url,\n    uppercase_escape,\n    urlencode_postdata,\n)\n\n\nclass YoutubeBaseInfoExtractor(InfoExtractor):\n    \n    _LOGIN_REQUIRED = True\n\n    @property\n    def IE_NAME(self):\n        return 'youtube:%s' % self._FEED_NAME\n\n    def _real_initialize(self):\n        self._login()\n\n    def _real_extract(self, url):\n        page = self._download_webpage(\n            'https://www.youtube.com/feed/%s' % self._FEED_NAME, self._PLAYLIST_TITLE)\n\n        \n        \n        ids = []\n        more_widget_html = content_html = page\n        for page_num in itertools.count(1):\n            matches = re.findall(r'href=\"\\s*/watch\\?v=([0-9A-Za-z_-]{11})', content_html)\n\n            \n            \n            \n            new_ids = filter(lambda video_id: video_id not in ids, orderedSet(matches))\n            if not new_ids:\n                break\n\n            ids.extend(new_ids)\n\n            mobj = re.search(r'data-uix-load-more-href=\"/?(?P<more>[^\"]+)\"', more_widget_html)\n            if not mobj:\n                break\n\n            more = self._download_json(\n                'https://youtube.com/%s' % mobj.group('more'), self._PLAYLIST_TITLE,\n                'Downloading page \n                transform_source=uppercase_escape)\n            content_html = more['content_html']\n            more_widget_html = more['load_more_widget_html']\n\n        return self.playlist_result(\n            self._ids_to_results(ids), playlist_title=self._PLAYLIST_TITLE)\n\n\nclass YoutubeWatchLaterIE(YoutubePlaylistIE):\n    IE_NAME = 'youtube:watchlater'\n    IE_DESC = 'Youtube watch later list, \":ytwatchlater\" for short (requires authentication)'\n    _VALID_URL = r'https?://(?:www\\.)?youtube\\.com/(?:feed/watch_later|(?:playlist|watch)\\?(?:.+&)?list=WL)|:ytwatchlater'\n\n    _TESTS = [{\n        'url': 'https://www.youtube.com/playlist?list=WL',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/watch?v=bCNU9TrbiRk&index=1&list=WL',\n        'only_matching': True,\n    }]\n\n    def _real_extract(self, url):\n        _, video = self._check_download_just_video(url, 'WL')\n        if video:\n            return video\n        _, playlist = self._extract_playlist('WL')\n        return playlist\n\n\nclass YoutubeFavouritesIE(YoutubeBaseInfoExtractor):\n    IE_NAME = 'youtube:favorites'\n    IE_DESC = 'YouTube.com favourite videos, \":ytfav\" for short (requires authentication)'\n    _VALID_URL = r'https?://(?:www\\.)?youtube\\.com/my_favorites|:ytfav(?:ou?rites)?'\n    _LOGIN_REQUIRED = True\n\n    def _real_extract(self, url):\n        webpage = self._download_webpage('https://www.youtube.com/my_favorites', 'Youtube Favourites videos')\n        playlist_id = self._search_regex(r'list=(.+?)[\"&]', webpage, 'favourites playlist id')\n        return self.url_result(playlist_id, 'YoutubePlaylist')\n\n\nclass YoutubeRecommendedIE(YoutubeFeedsInfoExtractor):\n    IE_DESC = 'YouTube.com recommended videos, \":ytrec\" for short (requires authentication)'\n    _VALID_URL = r'https?://(?:www\\.)?youtube\\.com/feed/recommended|:ytrec(?:ommended)?'\n    _FEED_NAME = 'recommended'\n    _PLAYLIST_TITLE = 'Youtube Recommended videos'\n\n\nclass YoutubeSubscriptionsIE(YoutubeFeedsInfoExtractor):\n    IE_DESC = 'YouTube.com subscriptions feed, \"ytsubs\" keyword (requires authentication)'\n    _VALID_URL = r'https?://(?:www\\.)?youtube\\.com/feed/subscriptions|:ytsubs(?:criptions)?'\n    _FEED_NAME = 'subscriptions'\n    _PLAYLIST_TITLE = 'Youtube Subscriptions'\n\n\nclass YoutubeHistoryIE(YoutubeFeedsInfoExtractor):\n    IE_DESC = 'Youtube watch history, \":ythistory\" for short (requires authentication)'\n    _VALID_URL = r'https?://(?:www\\.)?youtube\\.com/feed/history|:ythistory'\n    _FEED_NAME = 'history'\n    _PLAYLIST_TITLE = 'Youtube History'\n\n\nclass YoutubeTruncatedURLIE(InfoExtractor):\n    IE_NAME = 'youtube:truncated_url'\n    IE_DESC = False  \n    _VALID_URL = r\n\n    _TESTS = [{\n        'url': 'https://www.youtube.com/watch?annotation_id=annotation_3951667041',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/watch?',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/watch?x-yt-cl=84503534',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/watch?feature=foo',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/watch?hl=en-GB',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/watch?t=2372',\n        'only_matching': True,\n    }]\n\n    def _real_extract(self, url):\n        raise ExtractorError(\n            'Did you forget to quote the URL? Remember that & is a meta '\n            'character in most shells, so you want to put the URL in quotes, '\n            'like  youtube-dl '\n            '\"https://www.youtube.com/watch?feature=foo&v=BaW_jenozKc\" '\n            ' or simply  youtube-dl BaW_jenozKc  .',\n            expected=True)\n\n\nclass YoutubeTruncatedIDIE(InfoExtractor):\n    IE_NAME = 'youtube:truncated_id'\n    IE_DESC = False  \n    _VALID_URL = r'https?://(?:www\\.)?youtube\\.com/watch\\?v=(?P<id>[0-9A-Za-z_-]{1,10})$'\n\n    _TESTS = [{\n        'url': 'https://www.youtube.com/watch?v=N_708QY7Ob',\n        'only_matching': True,\n    }]\n\n    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        raise ExtractorError(\n            'Incomplete YouTube ID %s. URL %s looks truncated.' % (video_id, url),\n            expected=True)\n", "comments": "Provide base functions for Youtube extractors\"\"\"\n    _LOGIN_URL = 'https://accounts.google.com/ServiceLogin'\n    _TWOFACTOR_URL = 'https://accounts.google.com/signin/challenge'\n\n    _LOOKUP_URL = 'https://accounts.google.com/_/signin/sl/lookup'\n    _CHALLENGE_URL = 'https://accounts.google.com/_/signin/sl/challenge'\n    _TFA_URL = 'https://accounts.google.com/_/signin/challenge?hl=en&TL={0}'\n\n    _NETRC_MACHINE = 'youtube'\n    # If True it will raise an error if no login info is provided\n    _LOGIN_REQUIRED = False\n\n    _PLAYLIST_ID_RE = r'(?:PL|LL|EC|UU|FL|RD|UL|TL)[0-9A-Za-z-_]{10,}'\n\n    def _set_language(self):\n        self._set_cookie(\n            '.youtube.com', 'PREF', 'f1=50000000&hl=en',\n            # YouTube sets the expire time to about two months\n            expire_time=time.time() + 2 * 30 * 24 * 3600)\n\n    def _ids_to_results(self, ids):\n        return [\n            self.url_result(vid_id, 'Youtube', video_id=vid_id)\n            for vid_id in ids]\n\n    def _login(self):\n        \"\"\"\n        Attempt to log in to YouTube.\n        True is returned if successful or skipped.\n        False is returned if login failed.\n\n        If _LOGIN_REQUIRED is set and no authentication was provided, an error is raised.\n        \"\"\"\n        (username, password) = self._get_login_info()\n        # No authentication to be performed\n        if username is None:\n            if self._LOGIN_REQUIRED:\n                raise ExtractorError('No login info available, needed for using %s.' % self.IE_NAME, expected=True)\n            return True\n\n        login_page = self._download_webpage(\n            self._LOGIN_URL, None,\n            note='Downloading login page',\n            errnote='unable to fetch login page', fatal=False)\n        if login_page is False:\n            return\n\n        login_form = self._hidden_inputs(login_page)\n\n        def req(url, f_req, note, errnote):\n            data = login_form.copy()\n            data.update({\n                'pstMsg': 1,\n                'checkConnection': 'youtube',\n                'checkedDomains': 'youtube',\n                'hl': 'en',\n                'deviceinfo': '[null,null,null,[],null,\"US\",null,null,[],\"GlifWebSignIn\",null,[null,null,[]]]',\n                'f.req': json.dumps(f_req),\n                'flowName': 'GlifWebSignIn',\n                'flowEntry': 'ServiceLogin',\n            })\n            return self._download_json(\n                url, None, note=note, errnote=errnote,\n                transform_source=lambda s: re.sub(r'^[^[]*', '', s),\n                fatal=False,\n                data=urlencode_postdata(data), headers={\n                    'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8',\n                    'Google-Accounts-XSRF': 1,\n                })\n\n        def warn(message):\n            self._downloader.report_warning(message)\n\n        lookup_req = [\n            username,\n            None, [], None, 'US', None, None, 2, False, True,\n            [\n                None, None,\n                [2, 1, None, 1,\n                 'https://accounts.google.com/ServiceLogin?passive=true&continue=https%3A%2F%2Fwww.youtube.com%2Fsignin%3Fnext%3D%252F%26action_handle_signin%3Dtrue%26hl%3Den%26app%3Ddesktop%26feature%3Dsign_in_button&hl=en&service=youtube&uilel=3&requestPath=%2FServiceLogin&Page=PasswordSeparationSignIn',\n                 None, [], 4],\n                1, [None, None, []], None, None, None, True\n            ],\n            username,\n        ]\n\n        lookup_results = req(\n            self._LOOKUP_URL, lookup_req,\n            'Looking up account info', 'Unable to look up account info')\n\n        if lookup_results is False:\n            return False\n\n        user_hash = try_get(lookup_results, lambda x: x[0][2], compat_str)\n        if not user_hash:\n            warn('Unable to extract user hash')\n            return False\n\n        challenge_req = [\n            user_hash,\n            None, 1, None, [1, None, None, None, [password, None, True]],\n            [\n                None, None, [2, 1, None, 1, 'https://accounts.google.com/ServiceLogin?passive=true&continue=https%3A%2F%2Fwww.youtube.com%2Fsignin%3Fnext%3D%252F%26action_handle_signin%3Dtrue%26hl%3Den%26app%3Ddesktop%26feature%3Dsign_in_button&hl=en&service=youtube&uilel=3&requestPath=%2FServiceLogin&Page=PasswordSeparationSignIn', None, [], 4],\n                1, [None, None, []], None, None, None, True\n            ]]\n\n        challenge_results = req(\n            self._CHALLENGE_URL, challenge_req,\n            'Logging in', 'Unable to log in')\n\n        if challenge_results is False:\n            return\n\n        login_res = try_get(challenge_results, lambda x: x[0][5], list)\n        if login_res:\n            login_msg = try_get(login_res, lambda x: x[5], compat_str)\n            warn(\n                'Unable to login: %s' % 'Invalid password'\n                if login_msg == 'INCORRECT_ANSWER_ENTERED' else login_msg)\n            return False\n\n        res = try_get(challenge_results, lambda x: x[0][-1], list)\n        if not res:\n            warn('Unable to extract result entry')\n            return False\n\n        tfa = try_get(res, lambda x: x[0][0], list)\n        if tfa:\n            tfa_str = try_get(tfa, lambda x: x[2], compat_str)\n            if tfa_str == 'TWO_STEP_VERIFICATION':\n                # SEND_SUCCESS - TFA code has been successfully sent to phone\n                # QUOTA_EXCEEDED - reached the limit of TFA codes\n                status = try_get(tfa, lambda x: x[5], compat_str)\n                if status == 'QUOTA_EXCEEDED':\n                    warn('Exceeded the limit of TFA codes, try later')\n                    return False\n\n                tl = try_get(challenge_results, lambda x: x[1][2], compat_str)\n                if not tl:\n                    warn('Unable to extract TL')\n                    return False\n\n                tfa_code = self._get_tfa_info('2-step verification code')\n\n                if not tfa_code:\n                    warn(\n                        'Two-factor authentication required. Provide it either interactively or with --twofactor <code>'\n                        '(Note that only TOTP (Google Authenticator App) codes work at this time.)')\n                    return False\n\n                tfa_code = remove_start(tfa_code, 'G-')\n\n                tfa_req = [\n                    user_hash, None, 2, None,\n                    [\n                        9, None, None, None, None, None, None, None,\n                        [None, tfa_code, True, 2]\n                    ]]\n\n                tfa_results = req(\n                    self._TFA_URL.format(tl), tfa_req,\n                    'Submitting TFA code', 'Unable to submit TFA code')\n\n                if tfa_results is False:\n                    return False\n\n                tfa_res = try_get(tfa_results, lambda x: x[0][5], list)\n                if tfa_res:\n                    tfa_msg = try_get(tfa_res, lambda x: x[5], compat_str)\n                    warn(\n                        'Unable to finish TFA: %s' % 'Invalid TFA code'\n                        if tfa_msg == 'INCORRECT_ANSWER_ENTERED' else tfa_msg)\n                    return False\n\n                check_cookie_url = try_get(\n                    tfa_results, lambda x: x[0][-1][2], compat_str)\n        else:\n            check_cookie_url = try_get(res, lambda x: x[2], compat_str)\n\n        if not check_cookie_url:\n            warn('Unable to extract CheckCookie URL')\n            return False\n\n        check_cookie_results = self._download_webpage(\n            check_cookie_url, None, 'Checking cookie', fatal=False)\n\n        if check_cookie_results is False:\n            return False\n\n        if 'https://myaccount.google.com/' not in check_cookie_results:\n            warn('Unable to log in')\n            return False\n\n        return True\n\n    def _download_webpage(self, *args, **kwargs):\n        kwargs.setdefault('query', {})['disable_polymer'] = 'true'\n        return super(YoutubeBaseInfoExtractor, self)._download_webpage(\n            *args, **compat_kwargs(kwargs))\n\n    def _real_initialize(self):\n        if self._downloader is None:\n            return\n        self._set_language()\n        if not self._login():\n            return\n\n\nclass YoutubeEntryListBaseInfoExtractor(YoutubeBaseInfoExtractor):\n    # Extract entries from page with \"Load more\" button\n    def _entries(self, page, playlist_id):\n        more_widget_html = content_html = page\n        for page_num in itertools.count(1):\n            for entry in self._process_page(content_html):\n                yield entry\n\n            mobj = re.search(r'data-uix-load-more-href=\"/?(?P<more>[^\"]+)\"', more_widget_html)\n            if not mobj:\n                break\n\n            more = self._download_json(\n                'https://youtube.com/%s' % mobj.group('more'), playlist_id,\n                'Downloading page #%s' % page_num,\n                transform_source=uppercase_escape)\n            content_html = more['content_html']\n            if not content_html.strip():\n                # Some webpages show a \"Load more\" button but they don't\n                # have more videos\n                break\n            more_widget_html = more['load_more_widget_html']\n\n\nclass YoutubePlaylistBaseInfoExtractor(YoutubeEntryListBaseInfoExtractor):\n    def _process_page(self, content):\n        for video_id, video_title in self.extract_videos_from_page(content):\n            yield self.url_result(video_id, 'Youtube', video_id, video_title)\n\n    def extract_videos_from_page(self, page):\n        ids_in_page = []\n        titles_in_page = []\n        for mobj in re.finditer(self._VIDEO_RE, page):\n            # The link with index 0 is not the first video of the playlist (not sure if still actual)\n            if 'index' in mobj.groupdict() and mobj.group('id') == '0':\n                continue\n            video_id = mobj.group('id')\n            video_title = unescapeHTML(mobj.group('title'))\n            if video_title:\n                video_title = video_title.strip()\n            try:\n                idx = ids_in_page.index(video_id)\n                if video_title and not titles_in_page[idx]:\n                    titles_in_page[idx] = video_title\n            except ValueError:\n                ids_in_page.append(video_id)\n                titles_in_page.append(video_title)\n        return zip(ids_in_page, titles_in_page)\n\n\nclass YoutubePlaylistsBaseInfoExtractor(YoutubeEntryListBaseInfoExtractor):\n    def _process_page(self, content):\n        for playlist_id in orderedSet(re.findall(\n                r'<h3[^>]+class=\"[^\"]*yt-lockup-title[^\"]*\"[^>]*><a[^>]+href=\"/?playlist\\?list=([0-9A-Za-z-_]{10,})\"',\n                content)):\n            yield self.url_result(\n                'https://www.youtube.com/playlist?list=%s' % playlist_id, 'YoutubePlaylist')\n\n    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        webpage = self._download_webpage(url, playlist_id)\n        title = self._og_search_title(webpage, fatal=False)\n        return self.playlist_result(self._entries(webpage, playlist_id), playlist_id, title)\n\n\nclass YoutubeIE(YoutubeBaseInfoExtractor):\n    IE_DESC = 'YouTube.com'\n    _VALID_URL = r\"\"\"(?x)^\n                     (\n                         (?:https?://|//)                                    # http(s):// or protocol-independent URL\n                         (?:(?:(?:(?:\\w+\\.)?[yY][oO][uU][tT][uU][bB][eE](?:-nocookie)?\\.com/|\n                            (?:www\\.)?deturl\\.com/www\\.youtube\\.com/|\n                            (?:www\\.)?pwnyoutube\\.com/|\n                            (?:www\\.)?hooktube\\.com/|\n                            (?:www\\.)?yourepeat\\.com/|\n                            tube\\.majestyc\\.net/|\n                            youtube\\.googleapis\\.com/)                        # the various hostnames, with wildcard subdomains\n                         (?:.*?\\#/)?                                          # handle anchor (#/) redirect urls\n                         (?:                                                  # the various things that can precede the ID:\n                             (?:(?:v|embed|e)/(?!videoseries))                # v/ or embed/ or e/\n                             |(?:                                             # or the v= param in all its forms\n                                 (?:(?:watch|movie)(?:_popup)?(?:\\.php)?/?)?  # preceding watch(_popup|.php) or nothing (like /?v=xxxx)\n                                 (?:\\?|\\#!?)                                  # the params delimiter ? or # or #!\n                                 (?:.*?[&;])??                                # any other preceding param (like /?s=tuff&v=xxxx or ?s=tuff&amp;v=V36LpHqtcDY)\n                                 v=\n                             )\n                         ))\n                         |(?:\n                            youtu\\.be|                                        # just youtu.be/xxxx\n                            vid\\.plus|                                        # or vid.plus/xxxx\n                            zwearz\\.com/watch|                                # or zwearz.com/watch/xxxx\n                         )/\n                         |(?:www\\.)?cleanvideosearch\\.com/media/action/yt/watch\\?videoId=\n                         )\n                     )?                                                       # all until now is optional -> you can pass the naked ID\n                     ([0-9A-Za-z_-]{11})                                      # here is it! the YouTube video ID\n                     (?!.*?\\blist=\n                        (?:\n                            %(playlist_id)s|                                  # combined list/video URLs are handled by the playlist IE\n                            WL                                                # WL are handled by the watch later IE\n                        )\n                     )\n                     (?(1).+)?                                                # if we found the ID, everything can follow\n                     $\"\"\" % {'playlist_id': YoutubeBaseInfoExtractor._PLAYLIST_ID_RE}\n    _NEXT_URL_RE = r'[\\?&]next_url=([^&]+)'\n    _formats = {\n        '5': {'ext': 'flv', 'width': 400, 'height': 240, 'acodec': 'mp3', 'abr': 64, 'vcodec': 'h263'},\n        '6': {'ext': 'flv', 'width': 450, 'height': 270, 'acodec': 'mp3', 'abr': 64, 'vcodec': 'h263'},\n        '13': {'ext': '3gp', 'acodec': 'aac', 'vcodec': 'mp4v'},\n        '17': {'ext': '3gp', 'width': 176, 'height': 144, 'acodec': 'aac', 'abr': 24, 'vcodec': 'mp4v'},\n        '18': {'ext': 'mp4', 'width': 640, 'height': 360, 'acodec': 'aac', 'abr': 96, 'vcodec': 'h264'},\n        '22': {'ext': 'mp4', 'width': 1280, 'height': 720, 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264'},\n        '34': {'ext': 'flv', 'width': 640, 'height': 360, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},\n        '35': {'ext': 'flv', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},\n        # itag 36 videos are either 320x180 (BaW_jenozKc) or 320x240 (__2ABJjxzNo), abr varies as well\n        '36': {'ext': '3gp', 'width': 320, 'acodec': 'aac', 'vcodec': 'mp4v'},\n        '37': {'ext': 'mp4', 'width': 1920, 'height': 1080, 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264'},\n        '38': {'ext': 'mp4', 'width': 4096, 'height': 3072, 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264'},\n        '43': {'ext': 'webm', 'width': 640, 'height': 360, 'acodec': 'vorbis', 'abr': 128, 'vcodec': 'vp8'},\n        '44': {'ext': 'webm', 'width': 854, 'height': 480, 'acodec': 'vorbis', 'abr': 128, 'vcodec': 'vp8'},\n        '45': {'ext': 'webm', 'width': 1280, 'height': 720, 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8'},\n        '46': {'ext': 'webm', 'width': 1920, 'height': 1080, 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8'},\n        '59': {'ext': 'mp4', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},\n        '78': {'ext': 'mp4', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},\n\n\n        # 3D videos\n        '82': {'ext': 'mp4', 'height': 360, 'format_note': '3D', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -20},\n        '83': {'ext': 'mp4', 'height': 480, 'format_note': '3D', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -20},\n        '84': {'ext': 'mp4', 'height': 720, 'format_note': '3D', 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264', 'preference': -20},\n        '85': {'ext': 'mp4', 'height': 1080, 'format_note': '3D', 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264', 'preference': -20},\n        '100': {'ext': 'webm', 'height': 360, 'format_note': '3D', 'acodec': 'vorbis', 'abr': 128, 'vcodec': 'vp8', 'preference': -20},\n        '101': {'ext': 'webm', 'height': 480, 'format_note': '3D', 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8', 'preference': -20},\n        '102': {'ext': 'webm', 'height': 720, 'format_note': '3D', 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8', 'preference': -20},\n\n        # Apple HTTP Live Streaming\n        '91': {'ext': 'mp4', 'height': 144, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 48, 'vcodec': 'h264', 'preference': -10},\n        '92': {'ext': 'mp4', 'height': 240, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 48, 'vcodec': 'h264', 'preference': -10},\n        '93': {'ext': 'mp4', 'height': 360, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -10},\n        '94': {'ext': 'mp4', 'height': 480, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -10},\n        '95': {'ext': 'mp4', 'height': 720, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 256, 'vcodec': 'h264', 'preference': -10},\n        '96': {'ext': 'mp4', 'height': 1080, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 256, 'vcodec': 'h264', 'preference': -10},\n        '132': {'ext': 'mp4', 'height': 240, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 48, 'vcodec': 'h264', 'preference': -10},\n        '151': {'ext': 'mp4', 'height': 72, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 24, 'vcodec': 'h264', 'preference': -10},\n\n        # DASH mp4 video\n        '133': {'ext': 'mp4', 'height': 240, 'format_note': 'DASH video', 'vcodec': 'h264'},\n        '134': {'ext': 'mp4', 'height': 360, 'format_note': 'DASH video', 'vcodec': 'h264'},\n        '135': {'ext': 'mp4', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'h264'},\n        '136': {'ext': 'mp4', 'height': 720, 'format_note': 'DASH video', 'vcodec': 'h264'},\n        '137': {'ext': 'mp4', 'height': 1080, 'format_note': 'DASH video', 'vcodec': 'h264'},\n        '138': {'ext': 'mp4', 'format_note': 'DASH video', 'vcodec': 'h264'},  # Height can vary (https://github.com/rg3/youtube-dl/issues/4559)\n        '160': {'ext': 'mp4', 'height': 144, 'format_note': 'DASH video', 'vcodec': 'h264'},\n        '212': {'ext': 'mp4', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'h264'},\n        '264': {'ext': 'mp4', 'height': 1440, 'format_note': 'DASH video', 'vcodec': 'h264'},\n        '298': {'ext': 'mp4', 'height': 720, 'format_note': 'DASH video', 'vcodec': 'h264', 'fps': 60},\n        '299': {'ext': 'mp4', 'height': 1080, 'format_note': 'DASH video', 'vcodec': 'h264', 'fps': 60},\n        '266': {'ext': 'mp4', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'h264'},\n\n        # Dash mp4 audio\n        '139': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 48, 'container': 'm4a_dash'},\n        '140': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 128, 'container': 'm4a_dash'},\n        '141': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 256, 'container': 'm4a_dash'},\n        '256': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'container': 'm4a_dash'},\n        '258': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'container': 'm4a_dash'},\n        '325': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'dtse', 'container': 'm4a_dash'},\n        '328': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'ec-3', 'container': 'm4a_dash'},\n\n        # Dash webm\n        '167': {'ext': 'webm', 'height': 360, 'width': 640, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},\n        '168': {'ext': 'webm', 'height': 480, 'width': 854, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},\n        '169': {'ext': 'webm', 'height': 720, 'width': 1280, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},\n        '170': {'ext': 'webm', 'height': 1080, 'width': 1920, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},\n        '218': {'ext': 'webm', 'height': 480, 'width': 854, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},\n        '219': {'ext': 'webm', 'height': 480, 'width': 854, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},\n        '278': {'ext': 'webm', 'height': 144, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp9'},\n        '242': {'ext': 'webm', 'height': 240, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '243': {'ext': 'webm', 'height': 360, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '244': {'ext': 'webm', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '245': {'ext': 'webm', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '246': {'ext': 'webm', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '247': {'ext': 'webm', 'height': 720, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '248': {'ext': 'webm', 'height': 1080, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '271': {'ext': 'webm', 'height': 1440, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        # itag 272 videos are either 3840x2160 (e.g. RtoitU2A-3E) or 7680x4320 (sLprVF6d7Ug)\n        '272': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '302': {'ext': 'webm', 'height': 720, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60},\n        '303': {'ext': 'webm', 'height': 1080, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60},\n        '308': {'ext': 'webm', 'height': 1440, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60},\n        '313': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '315': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60},\n\n        # Dash webm audio\n        '171': {'ext': 'webm', 'acodec': 'vorbis', 'format_note': 'DASH audio', 'abr': 128},\n        '172': {'ext': 'webm', 'acodec': 'vorbis', 'format_note': 'DASH audio', 'abr': 256},\n\n        # Dash webm audio with opus inside\n        '249': {'ext': 'webm', 'format_note': 'DASH audio', 'acodec': 'opus', 'abr': 50},\n        '250': {'ext': 'webm', 'format_note': 'DASH audio', 'acodec': 'opus', 'abr': 70},\n        '251': {'ext': 'webm', 'format_note': 'DASH audio', 'acodec': 'opus', 'abr': 160},\n\n        # RTMP (unnamed)\n        '_rtmp': {'protocol': 'rtmp'},\n    }\n    _SUBTITLE_FORMATS = ('ttml', 'vtt')\n\n    _GEO_BYPASS = False\n\n    IE_NAME = 'youtube'\n    _TESTS = [\n        {\n            'url': 'https://www.youtube.com/watch?v=BaW_jenozKc&t=1s&end=9',\n            'info_dict': {\n                'id': 'BaW_jenozKc',\n                'ext': 'mp4',\n                'title': 'youtube-dl test video \"\\'/\\\\\u00e4\u21ad\ud835\udd50',\n                'uploader': 'Philipp Hagemeister',\n                'uploader_id': 'phihag',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/phihag',\n                'upload_date': '20121002',\n                'license': 'Standard YouTube License',\n                'description': 'test chars:  \"\\'/\\\\\u00e4\u21ad\ud835\udd50\\ntest URL: https://github.com/rg3/youtube-dl/issues/1892\\n\\nThis is a test video for youtube-dl.\\n\\nFor more information, contact phihag@phihag.de .',\n                'categories': ['Science & Technology'],\n                'tags': ['youtube-dl'],\n                'duration': 10,\n                'like_count': int,\n                'dislike_count': int,\n                'start_time': 1,\n                'end_time': 9,\n            }\n        },\n        {\n            'url': 'https://www.youtube.com/watch?v=UxxajLWwzqY',\n            'note': 'Test generic use_cipher_signature video (#897)',\n            'info_dict': {\n                'id': 'UxxajLWwzqY',\n                'ext': 'mp4',\n                'upload_date': '20120506',\n                'title': 'Icona Pop - I Love It (feat. Charli XCX) [OFFICIAL VIDEO]',\n                'alt_title': 'I Love It (feat. Charli XCX)',\n                'description': 'md5:f3ceb5ef83a08d95b9d146f973157cc8',\n                'tags': ['Icona Pop i love it', 'sweden', 'pop music', 'big beat records', 'big beat', 'charli',\n                         'xcx', 'charli xcx', 'girls', 'hbo', 'i love it', \"i don't care\", 'icona', 'pop',\n                         'iconic ep', 'iconic', 'love', 'it'],\n                'duration': 180,\n                'uploader': 'Icona Pop',\n                'uploader_id': 'IconaPop',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/IconaPop',\n                'license': 'Standard YouTube License',\n                'creator': 'Icona Pop',\n            }\n        },\n        {\n            'url': 'https://www.youtube.com/watch?v=07FYdnEawAQ',\n            'note': 'Test VEVO video with age protection (#956)',\n            'info_dict': {\n                'id': '07FYdnEawAQ',\n                'ext': 'mp4',\n                'upload_date': '20130703',\n                'title': 'Justin Timberlake - Tunnel Vision (Explicit)',\n                'alt_title': 'Tunnel Vision',\n                'description': 'md5:64249768eec3bc4276236606ea996373',\n                'duration': 419,\n                'uploader': 'justintimberlakeVEVO',\n                'uploader_id': 'justintimberlakeVEVO',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/justintimberlakeVEVO',\n                'license': 'Standard YouTube License',\n                'creator': 'Justin Timberlake',\n                'age_limit': 18,\n            }\n        },\n        {\n            'url': '//www.YouTube.com/watch?v=yZIXLfi8CZQ',\n            'note': 'Embed-only video (#1746)',\n            'info_dict': {\n                'id': 'yZIXLfi8CZQ',\n                'ext': 'mp4',\n                'upload_date': '20120608',\n                'title': 'Principal Sexually Assaults A Teacher - Episode 117 - 8th June 2012',\n                'description': 'md5:09b78bd971f1e3e289601dfba15ca4f7',\n                'uploader': 'SET India',\n                'uploader_id': 'setindia',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/setindia',\n                'license': 'Standard YouTube License',\n                'age_limit': 18,\n            }\n        },\n        {\n            'url': 'https://www.youtube.com/watch?v=BaW_jenozKc&v=UxxajLWwzqY',\n            'note': 'Use the first video ID in the URL',\n            'info_dict': {\n                'id': 'BaW_jenozKc',\n                'ext': 'mp4',\n                'title': 'youtube-dl test video \"\\'/\\\\\u00e4\u21ad\ud835\udd50',\n                'uploader': 'Philipp Hagemeister',\n                'uploader_id': 'phihag',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/phihag',\n                'upload_date': '20121002',\n                'license': 'Standard YouTube License',\n                'description': 'test chars:  \"\\'/\\\\\u00e4\u21ad\ud835\udd50\\ntest URL: https://github.com/rg3/youtube-dl/issues/1892\\n\\nThis is a test video for youtube-dl.\\n\\nFor more information, contact phihag@phihag.de .',\n                'categories': ['Science & Technology'],\n                'tags': ['youtube-dl'],\n                'duration': 10,\n                'like_count': int,\n                'dislike_count': int,\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            'url': 'https://www.youtube.com/watch?v=a9LDPn-MO4I',\n            'note': '256k DASH audio (format 141) via DASH manifest',\n            'info_dict': {\n                'id': 'a9LDPn-MO4I',\n                'ext': 'm4a',\n                'upload_date': '20121002',\n                'uploader_id': '8KVIDEO',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/8KVIDEO',\n                'description': '',\n                'uploader': '8KVIDEO',\n                'license': 'Standard YouTube License',\n                'title': 'UHDTV TEST 8K VIDEO.mp4'\n            },\n            'params': {\n                'youtube_include_dash_manifest': True,\n                'format': '141',\n            },\n            'skip': 'format 141 not served anymore',\n        },\n        # DASH manifest with encrypted signature\n        {\n            'url': 'https://www.youtube.com/watch?v=IB3lcPjvWLA',\n            'info_dict': {\n                'id': 'IB3lcPjvWLA',\n                'ext': 'm4a',\n                'title': 'Afrojack, Spree Wilson - The Spark ft. Spree Wilson',\n                'description': 'md5:12e7067fa6735a77bdcbb58cb1187d2d',\n                'duration': 244,\n                'uploader': 'AfrojackVEVO',\n                'uploader_id': 'AfrojackVEVO',\n                'upload_date': '20131011',\n                'license': 'Standard YouTube License',\n            },\n            'params': {\n                'youtube_include_dash_manifest': True,\n                'format': '141/bestaudio[ext=m4a]',\n            },\n        },\n        # JS player signature function name containing $\n        {\n            'url': 'https://www.youtube.com/watch?v=nfWlot6h_JM',\n            'info_dict': {\n                'id': 'nfWlot6h_JM',\n                'ext': 'm4a',\n                'title': 'Taylor Swift - Shake It Off',\n                'alt_title': 'Shake It Off',\n                'description': 'md5:95f66187cd7c8b2c13eb78e1223b63c3',\n                'duration': 242,\n                'uploader': 'TaylorSwiftVEVO',\n                'uploader_id': 'TaylorSwiftVEVO',\n                'upload_date': '20140818',\n                'license': 'Standard YouTube License',\n                'creator': 'Taylor Swift',\n            },\n            'params': {\n                'youtube_include_dash_manifest': True,\n                'format': '141/bestaudio[ext=m4a]',\n            },\n        },\n        # Controversy video\n        {\n            'url': 'https://www.youtube.com/watch?v=T4XJQO3qol8',\n            'info_dict': {\n                'id': 'T4XJQO3qol8',\n                'ext': 'mp4',\n                'duration': 219,\n                'upload_date': '20100909',\n                'uploader': 'The Amazing Atheist',\n                'uploader_id': 'TheAmazingAtheist',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/TheAmazingAtheist',\n                'license': 'Standard YouTube License',\n                'title': 'Burning Everyone\\'s Koran',\n                'description': 'SUBSCRIBE: http://www.youtube.com/saturninefilms\\n\\nEven Obama has taken a stand against freedom on this issue: http://www.huffingtonpost.com/2010/09/09/obama-gma-interview-quran_n_710282.html',\n            }\n        },\n        # Normal age-gate video (No vevo, embed allowed)\n        {\n            'url': 'https://youtube.com/watch?v=HtVdAasjOgU',\n            'info_dict': {\n                'id': 'HtVdAasjOgU',\n                'ext': 'mp4',\n                'title': 'The Witcher 3: Wild Hunt - The Sword Of Destiny Trailer',\n                'description': r're:(?s).{100,}About the Game\\n.*?The Witcher 3: Wild Hunt.{100,}',\n                'duration': 142,\n                'uploader': 'The Witcher',\n                'uploader_id': 'WitcherGame',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/WitcherGame',\n                'upload_date': '20140605',\n                'license': 'Standard YouTube License',\n                'age_limit': 18,\n            },\n        },\n        # Age-gate video with encrypted signature\n        {\n            'url': 'https://www.youtube.com/watch?v=6kLq3WMV1nU',\n            'info_dict': {\n                'id': '6kLq3WMV1nU',\n                'ext': 'mp4',\n                'title': 'Dedication To My Ex (Miss That) (Lyric Video)',\n                'description': 'md5:33765bb339e1b47e7e72b5490139bb41',\n                'duration': 247,\n                'uploader': 'LloydVEVO',\n                'uploader_id': 'LloydVEVO',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/LloydVEVO',\n                'upload_date': '20110629',\n                'license': 'Standard YouTube License',\n                'age_limit': 18,\n            },\n        },\n        # video_info is None (https://github.com/rg3/youtube-dl/issues/4421)\n        # YouTube Red ad is not captured for creator\n        {\n            'url': '__2ABJjxzNo',\n            'info_dict': {\n                'id': '__2ABJjxzNo',\n                'ext': 'mp4',\n                'duration': 266,\n                'upload_date': '20100430',\n                'uploader_id': 'deadmau5',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/deadmau5',\n                'creator': 'deadmau5',\n                'description': 'md5:12c56784b8032162bb936a5f76d55360',\n                'uploader': 'deadmau5',\n                'license': 'Standard YouTube License',\n                'title': 'Deadmau5 - Some Chords (HD)',\n                'alt_title': 'Some Chords',\n            },\n            'expected_warnings': [\n                'DASH manifest missing',\n            ]\n        },\n        # Olympics (https://github.com/rg3/youtube-dl/issues/4431)\n        {\n            'url': 'lqQg6PlCWgI',\n            'info_dict': {\n                'id': 'lqQg6PlCWgI',\n                'ext': 'mp4',\n                'duration': 6085,\n                'upload_date': '20150827',\n                'uploader_id': 'olympic',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/olympic',\n                'license': 'Standard YouTube License',\n                'description': 'HO09  - Women -  GER-AUS - Hockey - 31 July 2012 - London 2012 Olympic Games',\n                'uploader': 'Olympic',\n                'title': 'Hockey - Women -  GER-AUS - London 2012 Olympic Games',\n            },\n            'params': {\n                'skip_download': 'requires avconv',\n            }\n        },\n        # Non-square pixels\n        {\n            'url': 'https://www.youtube.com/watch?v=_b-2C3KPAM0',\n            'info_dict': {\n                'id': '_b-2C3KPAM0',\n                'ext': 'mp4',\n                'stretched_ratio': 16 / 9.,\n                'duration': 85,\n                'upload_date': '20110310',\n                'uploader_id': 'AllenMeow',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/AllenMeow',\n                'description': 'made by Wacom from Korea | \u5b57\u5e55&\u52a0\u6cb9\u6dfb\u918b by TY\\'s Allen | \u611f\u8b1dheylisa00cavey1001\u540c\u5b78\u71b1\u60c5\u63d0\u4f9b\u6897\u53ca\u7ffb\u8b6f',\n                'uploader': '\u5b6b\u827e\u502b',\n                'license': 'Standard YouTube License',\n                'title': '[A-made] \u8b8a\u614b\u598d\u5b57\u5e55\u7248 \u592a\u598d \u6211\u5c31\u662f\u9019\u6a23\u7684\u4eba',\n            },\n        },\n        # url_encoded_fmt_stream_map is empty string\n        {\n            'url': 'qEJwOuvDf7I',\n            'info_dict': {\n                'id': 'qEJwOuvDf7I',\n                'ext': 'webm',\n                'title': '\u041e\u0431\u0441\u0443\u0436\u0434\u0435\u043d\u0438\u0435 \u0441\u0443\u0434\u0435\u0431\u043d\u043e\u0439 \u043f\u0440\u0430\u043a\u0442\u0438\u043a\u0438 \u043f\u043e \u0432\u044b\u0431\u043e\u0440\u0430\u043c 14 \u0441\u0435\u043d\u0442\u044f\u0431\u0440\u044f 2014 \u0433\u043e\u0434\u0430 \u0432 \u0421\u0430\u043d\u043a\u0442-\u041f\u0435\u0442\u0435\u0440\u0431\u0443\u0440\u0433\u0435',\n                'description': '',\n                'upload_date': '20150404',\n                'uploader_id': 'spbelect',\n                'uploader': '\u041d\u0430\u0431\u043b\u044e\u0434\u0430\u0442\u0435\u043b\u0438 \u041f\u0435\u0442\u0435\u0440\u0431\u0443\u0440\u0433\u0430',\n            },\n            'params': {\n                'skip_download': 'requires avconv',\n            },\n            'skip': 'This live event has ended.',\n        },\n        # Extraction from multiple DASH manifests (https://github.com/rg3/youtube-dl/pull/6097)\n        {\n            'url': 'https://www.youtube.com/watch?v=FIl7x6_3R5Y',\n            'info_dict': {\n                'id': 'FIl7x6_3R5Y',\n                'ext': 'mp4',\n                'title': 'md5:7b81415841e02ecd4313668cde88737a',\n                'description': 'md5:116377fd2963b81ec4ce64b542173306',\n                'duration': 220,\n                'upload_date': '20150625',\n                'uploader_id': 'dorappi2000',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/dorappi2000',\n                'uploader': 'dorappi2000',\n                'license': 'Standard YouTube License',\n                'formats': 'mincount:32',\n            },\n        },\n        # DASH manifest with segment_list\n        {\n            'url': 'https://www.youtube.com/embed/CsmdDsKjzN8',\n            'md5': '8ce563a1d667b599d21064e982ab9e31',\n            'info_dict': {\n                'id': 'CsmdDsKjzN8',\n                'ext': 'mp4',\n                'upload_date': '20150501',  # According to '<meta itemprop=\"datePublished\"', but in other places it's 20150510\n                'uploader': 'Airtek',\n                'description': 'Retransmisi\u00f3n en directo de la XVIII media marat\u00f3n de Zaragoza.',\n                'uploader_id': 'UCzTzUmjXxxacNnL8I3m4LnQ',\n                'license': 'Standard YouTube License',\n                'title': 'Retransmisi\u00f3n XVIII Media marat\u00f3n Zaragoza 2015',\n            },\n            'params': {\n                'youtube_include_dash_manifest': True,\n                'format': '135',  # bestvideo\n            },\n            'skip': 'This live event has ended.',\n        },\n        {\n            # Multifeed videos (multiple cameras), URL is for Main Camera\n            'url': 'https://www.youtube.com/watch?v=jqWvoWXjCVs',\n            'info_dict': {\n                'id': 'jqWvoWXjCVs',\n                'title': 'teamPGP: Rocket League Noob Stream',\n                'description': 'md5:dc7872fb300e143831327f1bae3af010',\n            },\n            'playlist': [{\n                'info_dict': {\n                    'id': 'jqWvoWXjCVs',\n                    'ext': 'mp4',\n                    'title': 'teamPGP: Rocket League Noob Stream (Main Camera)',\n                    'description': 'md5:dc7872fb300e143831327f1bae3af010',\n                    'duration': 7335,\n                    'upload_date': '20150721',\n                    'uploader': 'Beer Games Beer',\n                    'uploader_id': 'beergamesbeer',\n                    'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/beergamesbeer',\n                    'license': 'Standard YouTube License',\n                },\n            }, {\n                'info_dict': {\n                    'id': '6h8e8xoXJzg',\n                    'ext': 'mp4',\n                    'title': 'teamPGP: Rocket League Noob Stream (kreestuh)',\n                    'description': 'md5:dc7872fb300e143831327f1bae3af010',\n                    'duration': 7337,\n                    'upload_date': '20150721',\n                    'uploader': 'Beer Games Beer',\n                    'uploader_id': 'beergamesbeer',\n                    'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/beergamesbeer',\n                    'license': 'Standard YouTube License',\n                },\n            }, {\n                'info_dict': {\n                    'id': 'PUOgX5z9xZw',\n                    'ext': 'mp4',\n                    'title': 'teamPGP: Rocket League Noob Stream (grizzle)',\n                    'description': 'md5:dc7872fb300e143831327f1bae3af010',\n                    'duration': 7337,\n                    'upload_date': '20150721',\n                    'uploader': 'Beer Games Beer',\n                    'uploader_id': 'beergamesbeer',\n                    'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/beergamesbeer',\n                    'license': 'Standard YouTube License',\n                },\n            }, {\n                'info_dict': {\n                    'id': 'teuwxikvS5k',\n                    'ext': 'mp4',\n                    'title': 'teamPGP: Rocket League Noob Stream (zim)',\n                    'description': 'md5:dc7872fb300e143831327f1bae3af010',\n                    'duration': 7334,\n                    'upload_date': '20150721',\n                    'uploader': 'Beer Games Beer',\n                    'uploader_id': 'beergamesbeer',\n                    'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/beergamesbeer',\n                    'license': 'Standard YouTube License',\n                },\n            }],\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # Multifeed video with comma in title (see https://github.com/rg3/youtube-dl/issues/8536)\n            'url': 'https://www.youtube.com/watch?v=gVfLd0zydlo',\n            'info_dict': {\n                'id': 'gVfLd0zydlo',\n                'title': 'DevConf.cz 2016 Day 2 Workshops 1 14:00 - 15:30',\n            },\n            'playlist_count': 2,\n            'skip': 'Not multifeed anymore',\n        },\n        {\n            'url': 'https://vid.plus/FlRa-iH7PGw',\n            'only_matching': True,\n        },\n        {\n            'url': 'https://zwearz.com/watch/9lWxNJF-ufM/electra-woman-dyna-girl-official-trailer-grace-helbig.html',\n            'only_matching': True,\n        },\n        {\n            # Title with JS-like syntax \"};\" (see https://github.com/rg3/youtube-dl/issues/7468)\n            # Also tests cut-off URL expansion in video description (see\n            # https://github.com/rg3/youtube-dl/issues/1892,\n            # https://github.com/rg3/youtube-dl/issues/8164)\n            'url': 'https://www.youtube.com/watch?v=lsguqyKfVQg',\n            'info_dict': {\n                'id': 'lsguqyKfVQg',\n                'ext': 'mp4',\n                'title': '{dark walk}; Loki/AC/Dishonored; collab w/Elflover21',\n                'alt_title': 'Dark Walk',\n                'description': 'md5:8085699c11dc3f597ce0410b0dcbb34a',\n                'duration': 133,\n                'upload_date': '20151119',\n                'uploader_id': 'IronSoulElf',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/IronSoulElf',\n                'uploader': 'IronSoulElf',\n                'license': 'Standard YouTube License',\n                'creator': 'Todd Haberman, Daniel Law Heath & Aaron Kaplan',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # Tags with '};' (see https://github.com/rg3/youtube-dl/issues/7468)\n            'url': 'https://www.youtube.com/watch?v=Ms7iBXnlUO8',\n            'only_matching': True,\n        },\n        {\n            # Video with yt:stretch=17:0\n            'url': 'https://www.youtube.com/watch?v=Q39EVAstoRM',\n            'info_dict': {\n                'id': 'Q39EVAstoRM',\n                'ext': 'mp4',\n                'title': 'Clash Of Clans#14 Dicas De Ataque Para CV 4',\n                'description': 'md5:ee18a25c350637c8faff806845bddee9',\n                'upload_date': '20151107',\n                'uploader_id': 'UCCr7TALkRbo3EtFzETQF1LA',\n                'uploader': 'CH GAMER DROID',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'skip': 'This video does not exist.',\n        },\n        {\n            # Video licensed under Creative Commons\n            'url': 'https://www.youtube.com/watch?v=M4gD1WSo5mA',\n            'info_dict': {\n                'id': 'M4gD1WSo5mA',\n                'ext': 'mp4',\n                'title': 'md5:e41008789470fc2533a3252216f1c1d1',\n                'description': 'md5:a677553cf0840649b731a3024aeff4cc',\n                'duration': 721,\n                'upload_date': '20150127',\n                'uploader_id': 'BerkmanCenter',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/BerkmanCenter',\n                'uploader': 'The Berkman Klein Center for Internet & Society',\n                'license': 'Creative Commons Attribution license (reuse allowed)',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # Channel-like uploader_url\n            'url': 'https://www.youtube.com/watch?v=eQcmzGIKrzg',\n            'info_dict': {\n                'id': 'eQcmzGIKrzg',\n                'ext': 'mp4',\n                'title': 'Democratic Socialism and Foreign Policy | Bernie Sanders',\n                'description': 'md5:dda0d780d5a6e120758d1711d062a867',\n                'duration': 4060,\n                'upload_date': '20151119',\n                'uploader': 'Bernie 2016',\n                'uploader_id': 'UCH1dpzjCEiGAt8CXkryhkZg',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/channel/UCH1dpzjCEiGAt8CXkryhkZg',\n                'license': 'Creative Commons Attribution license (reuse allowed)',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            'url': 'https://www.youtube.com/watch?feature=player_embedded&amp;amp;v=V36LpHqtcDY',\n            'only_matching': True,\n        },\n        {\n            # YouTube Red paid video (https://github.com/rg3/youtube-dl/issues/10059)\n            'url': 'https://www.youtube.com/watch?v=i1Ko8UG-Tdo',\n            'only_matching': True,\n        },\n        {\n            # Rental video preview\n            'url': 'https://www.youtube.com/watch?v=yYr8q0y5Jfg',\n            'info_dict': {\n                'id': 'uGpuVWrhIzE',\n                'ext': 'mp4',\n                'title': 'Piku - Trailer',\n                'description': 'md5:c36bd60c3fd6f1954086c083c72092eb',\n                'upload_date': '20150811',\n                'uploader': 'FlixMatrix',\n                'uploader_id': 'FlixMatrixKaravan',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/FlixMatrixKaravan',\n                'license': 'Standard YouTube License',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # YouTube Red video with episode data\n            'url': 'https://www.youtube.com/watch?v=iqKdEhx-dD4',\n            'info_dict': {\n                'id': 'iqKdEhx-dD4',\n                'ext': 'mp4',\n                'title': 'Isolation - Mind Field (Ep 1)',\n                'description': 'md5:8013b7ddea787342608f63a13ddc9492',\n                'duration': 2085,\n                'upload_date': '20170118',\n                'uploader': 'Vsauce',\n                'uploader_id': 'Vsauce',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/Vsauce',\n                'license': 'Standard YouTube License',\n                'series': 'Mind Field',\n                'season_number': 1,\n                'episode_number': 1,\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'expected_warnings': [\n                'Skipping DASH manifest',\n            ],\n        },\n        {\n            # The following content has been identified by the YouTube community\n            # as inappropriate or offensive to some audiences.\n            'url': 'https://www.youtube.com/watch?v=6SJNVb0GnPI',\n            'info_dict': {\n                'id': '6SJNVb0GnPI',\n                'ext': 'mp4',\n                'title': 'Race Differences in Intelligence',\n                'description': 'md5:5d161533167390427a1f8ee89a1fc6f1',\n                'duration': 965,\n                'upload_date': '20140124',\n                'uploader': 'New Century Foundation',\n                'uploader_id': 'UCEJYpZGqgUob0zVVEaLhvVg',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/channel/UCEJYpZGqgUob0zVVEaLhvVg',\n                'license': 'Standard YouTube License',\n                'view_count': int,\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # itag 212\n            'url': '1t24XAntNCY',\n            'only_matching': True,\n        },\n        {\n            # geo restricted to JP\n            'url': 'sJL6WA-aGkQ',\n            'only_matching': True,\n        },\n        {\n            'url': 'https://www.youtube.com/watch?v=MuAGGZNfUkU&list=RDMM',\n            'only_matching': True,\n        },\n    ]\n\n    def __init__(self, *args, **kwargs):\n        super(YoutubeIE, self).__init__(*args, **kwargs)\n        self._player_cache = {}\n\n    def report_video_info_webpage_download(self, video_id):\n        \"\"\"Report attempt to download video info webpage.\"\"\"\n        self.to_screen('%s: Downloading video info webpage' % video_id)\n\n    def report_information_extraction(self, video_id):\n        \"\"\"Report attempt to extract video information.\"\"\"\n        self.to_screen('%s: Extracting video information' % video_id)\n\n    def report_unavailable_format(self, video_id, format):\n        \"\"\"Report extracted video URL.\"\"\"\n        self.to_screen('%s: Format %s not available' % (video_id, format))\n\n    def report_rtmp_download(self):\n        \"\"\"Indicate the download will use the RTMP protocol.\"\"\"\n        self.to_screen('RTMP download detected')\n\n    def _signature_cache_id(self, example_sig):\n        \"\"\" Return a string representation of a signature \"\"\"\n        return '.'.join(compat_str(len(part)) for part in example_sig.split('.'))\n\n    def _extract_signature_function(self, video_id, player_url, example_sig):\n        id_m = re.match(\n            r'.*?-(?P<id>[a-zA-Z0-9_-]+)(?:/watch_as3|/html5player(?:-new)?|(?:/[a-z]{2}_[A-Z]{2})?/base)?\\.(?P<ext>[a-z]+)$',\n            player_url)\n        if not id_m:\n            raise ExtractorError('Cannot identify player %r' % player_url)\n        player_type = id_m.group('ext')\n        player_id = id_m.group('id')\n\n        # Read from filesystem cache\n        func_id = '%s_%s_%s' % (\n            player_type, player_id, self._signature_cache_id(example_sig))\n        assert os.path.basename(func_id) == func_id\n\n        cache_spec = self._downloader.cache.load('youtube-sigfuncs', func_id)\n        if cache_spec is not None:\n            return lambda s: ''.join(s[i] for i in cache_spec)\n\n        download_note = (\n            'Downloading player %s' % player_url\n            if self._downloader.params.get('verbose') else\n            'Downloading %s player %s' % (player_type, player_id)\n        )\n        if player_type == 'js':\n            code = self._download_webpage(\n                player_url, video_id,\n                note=download_note,\n                errnote='Download of %s failed' % player_url)\n            res = self._parse_sig_js(code)\n        elif player_type == 'swf':\n            urlh = self._request_webpage(\n                player_url, video_id,\n                note=download_note,\n                errnote='Download of %s failed' % player_url)\n            code = urlh.read()\n            res = self._parse_sig_swf(code)\n        else:\n            assert False, 'Invalid player type %r' % player_type\n\n        test_string = ''.join(map(compat_chr, range(len(example_sig))))\n        cache_res = res(test_string)\n        cache_spec = [ord(c) for c in cache_res]\n\n        self._downloader.cache.store('youtube-sigfuncs', func_id, cache_spec)\n        return res\n\n    def _print_sig_code(self, func, example_sig):\n        def gen_sig_code(idxs):\n            def _genslice(start, end, step):\n                starts = '' if start == 0 else str(start)\n                ends = (':%d' % (end + step)) if end + step >= 0 else ':'\n                steps = '' if step == 1 else (':%d' % step)\n                return 's[%s%s%s]' % (starts, ends, steps)\n\n            step = None\n            # Quelch pyflakes warnings - start will be set when step is set\n            start = '(Never used)'\n            for i, prev in zip(idxs[1:], idxs[:-1]):\n                if step is not None:\n                    if i - prev == step:\n                        continue\n                    yield _genslice(start, prev, step)\n                    step = None\n                    continue\n                if i - prev in [-1, 1]:\n                    step = i - prev\n                    start = prev\n                    continue\n                else:\n                    yield 's[%d]' % prev\n            if step is None:\n                yield 's[%d]' % i\n            else:\n                yield _genslice(start, i, step)\n\n        test_string = ''.join(map(compat_chr, range(len(example_sig))))\n        cache_res = func(test_string)\n        cache_spec = [ord(c) for c in cache_res]\n        expr_code = ' + '.join(gen_sig_code(cache_spec))\n        signature_id_tuple = '(%s)' % (\n            ', '.join(compat_str(len(p)) for p in example_sig.split('.')))\n        code = ('if tuple(len(p) for p in s.split(\\'.\\')) == %s:\\n'\n                '    return %s\\n') % (signature_id_tuple, expr_code)\n        self.to_screen('Extracted signature function:\\n' + code)\n\n    def _parse_sig_js(self, jscode):\n        funcname = self._search_regex(\n            (r'([\"\\'])signature\\1\\s*,\\s*(?P<sig>[a-zA-Z0-9$]+)\\(',\n             r'\\.sig\\|\\|(?P<sig>[a-zA-Z0-9$]+)\\('),\n            jscode, 'Initial JS player signature function name', group='sig')\n\n        jsi = JSInterpreter(jscode)\n        initial_function = jsi.extract_function(funcname)\n        return lambda s: initial_function([s])\n\n    def _parse_sig_swf(self, file_contents):\n        swfi = SWFInterpreter(file_contents)\n        TARGET_CLASSNAME = 'SignatureDecipher'\n        searched_class = swfi.extract_class(TARGET_CLASSNAME)\n        initial_function = swfi.extract_function(searched_class, 'decipher')\n        return lambda s: initial_function([s])\n\n    def _decrypt_signature(self, s, video_id, player_url, age_gate=False):\n        \"\"\"Turn the encrypted s field into a working signature\"\"\"\n\n        if player_url is None:\n            raise ExtractorError('Cannot decrypt signature without player_url')\n\n        if player_url.startswith('//'):\n            player_url = 'https:' + player_url\n        elif not re.match(r'https?://', player_url):\n            player_url = compat_urlparse.urljoin(\n                'https://www.youtube.com', player_url)\n        try:\n            player_id = (player_url, self._signature_cache_id(s))\n            if player_id not in self._player_cache:\n                func = self._extract_signature_function(\n                    video_id, player_url, s\n                )\n                self._player_cache[player_id] = func\n            func = self._player_cache[player_id]\n            if self._downloader.params.get('youtube_print_sig_code'):\n                self._print_sig_code(func, s)\n            return func(s)\n        except Exception as e:\n            tb = traceback.format_exc()\n            raise ExtractorError(\n                'Signature extraction failed: ' + tb, cause=e)\n\n    def _get_subtitles(self, video_id, webpage):\n        try:\n            subs_doc = self._download_xml(\n                'https://video.google.com/timedtext?hl=en&type=list&v=%s' % video_id,\n                video_id, note=False)\n        except ExtractorError as err:\n            self._downloader.report_warning('unable to download video subtitles: %s' % error_to_compat_str(err))\n            return {}\n\n        sub_lang_list = {}\n        for track in subs_doc.findall('track'):\n            lang = track.attrib['lang_code']\n            if lang in sub_lang_list:\n                continue\n            sub_formats = []\n            for ext in self._SUBTITLE_FORMATS:\n                params = compat_urllib_parse_urlencode({\n                    'lang': lang,\n                    'v': video_id,\n                    'fmt': ext,\n                    'name': track.attrib['name'].encode('utf-8'),\n                })\n                sub_formats.append({\n                    'url': 'https://www.youtube.com/api/timedtext?' + params,\n                    'ext': ext,\n                })\n            sub_lang_list[lang] = sub_formats\n        if not sub_lang_list:\n            self._downloader.report_warning('video doesn\\'t have subtitles')\n            return {}\n        return sub_lang_list\n\n    def _get_ytplayer_config(self, video_id, webpage):\n        patterns = (\n            # User data may contain arbitrary character sequences that may affect\n            # JSON extraction with regex, e.g. when '};' is contained the second\n            # regex won't capture the whole JSON. Yet working around by trying more\n            # concrete regex first keeping in mind proper quoted string handling\n            # to be implemented in future that will replace this workaround (see\n            # https://github.com/rg3/youtube-dl/issues/7468,\n            # https://github.com/rg3/youtube-dl/pull/7599)\n            r';ytplayer\\.config\\s*=\\s*({.+?});ytplayer',\n            r';ytplayer\\.config\\s*=\\s*({.+?});',\n        )\n        config = self._search_regex(\n            patterns, webpage, 'ytplayer.config', default=None)\n        if config:\n            return self._parse_json(\n                uppercase_escape(config), video_id, fatal=False)\n\n    def _get_automatic_captions(self, video_id, webpage):\n        \"\"\"We need the webpage for getting the captions url, pass it as an\n           argument to speed up the process.\"\"\"\n        self.to_screen('%s: Looking for automatic captions' % video_id)\n        player_config = self._get_ytplayer_config(video_id, webpage)\n        err_msg = 'Couldn\\'t find automatic captions for %s' % video_id\n        if not player_config:\n            self._downloader.report_warning(err_msg)\n            return {}\n        try:\n            args = player_config['args']\n            caption_url = args.get('ttsurl')\n            if caption_url:\n                timestamp = args['timestamp']\n                # We get the available subtitles\n                list_params = compat_urllib_parse_urlencode({\n                    'type': 'list',\n                    'tlangs': 1,\n                    'asrs': 1,\n                })\n                list_url = caption_url + '&' + list_params\n                caption_list = self._download_xml(list_url, video_id)\n                original_lang_node = caption_list.find('track')\n                if original_lang_node is None:\n                    self._downloader.report_warning('Video doesn\\'t have automatic captions')\n                    return {}\n                original_lang = original_lang_node.attrib['lang_code']\n                caption_kind = original_lang_node.attrib.get('kind', '')\n\n                sub_lang_list = {}\n                for lang_node in caption_list.findall('target'):\n                    sub_lang = lang_node.attrib['lang_code']\n                    sub_formats = []\n                    for ext in self._SUBTITLE_FORMATS:\n                        params = compat_urllib_parse_urlencode({\n                            'lang': original_lang,\n                            'tlang': sub_lang,\n                            'fmt': ext,\n                            'ts': timestamp,\n                            'kind': caption_kind,\n                        })\n                        sub_formats.append({\n                            'url': caption_url + '&' + params,\n                            'ext': ext,\n                        })\n                    sub_lang_list[sub_lang] = sub_formats\n                return sub_lang_list\n\n            def make_captions(sub_url, sub_langs):\n                parsed_sub_url = compat_urllib_parse_urlparse(sub_url)\n                caption_qs = compat_parse_qs(parsed_sub_url.query)\n                captions = {}\n                for sub_lang in sub_langs:\n                    sub_formats = []\n                    for ext in self._SUBTITLE_FORMATS:\n                        caption_qs.update({\n                            'tlang': [sub_lang],\n                            'fmt': [ext],\n                        })\n                        sub_url = compat_urlparse.urlunparse(parsed_sub_url._replace(\n                            query=compat_urllib_parse_urlencode(caption_qs, True)))\n                        sub_formats.append({\n                            'url': sub_url,\n                            'ext': ext,\n                        })\n                    captions[sub_lang] = sub_formats\n                return captions\n\n            # New captions format as of 22.06.2017\n            player_response = args.get('player_response')\n            if player_response and isinstance(player_response, compat_str):\n                player_response = self._parse_json(\n                    player_response, video_id, fatal=False)\n                if player_response:\n                    renderer = player_response['captions']['playerCaptionsTracklistRenderer']\n                    base_url = renderer['captionTracks'][0]['baseUrl']\n                    sub_lang_list = []\n                    for lang in renderer['translationLanguages']:\n                        lang_code = lang.get('languageCode')\n                        if lang_code:\n                            sub_lang_list.append(lang_code)\n                    return make_captions(base_url, sub_lang_list)\n\n            # Some videos don't provide ttsurl but rather caption_tracks and\n            # caption_translation_languages (e.g. 20LmZk1hakA)\n            # Does not used anymore as of 22.06.2017\n            caption_tracks = args['caption_tracks']\n            caption_translation_languages = args['caption_translation_languages']\n            caption_url = compat_parse_qs(caption_tracks.split(',')[0])['u'][0]\n            sub_lang_list = []\n            for lang in caption_translation_languages.split(','):\n                lang_qs = compat_parse_qs(compat_urllib_parse_unquote_plus(lang))\n                sub_lang = lang_qs.get('lc', [None])[0]\n                if sub_lang:\n                    sub_lang_list.append(sub_lang)\n            return make_captions(caption_url, sub_lang_list)\n        # An extractor error can be raise by the download process if there are\n        # no automatic captions but there are subtitles\n        except (KeyError, IndexError, ExtractorError):\n            self._downloader.report_warning(err_msg)\n            return {}\n\n    def _mark_watched(self, video_id, video_info):\n        playback_url = video_info.get('videostats_playback_base_url', [None])[0]\n        if not playback_url:\n            return\n        parsed_playback_url = compat_urlparse.urlparse(playback_url)\n        qs = compat_urlparse.parse_qs(parsed_playback_url.query)\n\n        # cpn generation algorithm is reverse engineered from base.js.\n        # In fact it works even with dummy cpn.\n        CPN_ALPHABET = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_'\n        cpn = ''.join((CPN_ALPHABET[random.randint(0, 256) & 63] for _ in range(0, 16)))\n\n        qs.update({\n            'ver': ['2'],\n            'cpn': [cpn],\n        })\n        playback_url = compat_urlparse.urlunparse(\n            parsed_playback_url._replace(query=compat_urllib_parse_urlencode(qs, True)))\n\n        self._download_webpage(\n            playback_url, video_id, 'Marking watched',\n            'Unable to mark watched', fatal=False)\n\n    @staticmethod\n    def _extract_urls(webpage):\n        # Embedded YouTube player\n        entries = [\n            unescapeHTML(mobj.group('url'))\n            for mobj in re.finditer(r'''(?x)\n            (?:\n                <iframe[^>]+?src=|\n                data-video-url=|\n                <embed[^>]+?src=|\n                embedSWF\\(?:\\s*|\n                <object[^>]+data=|\n                new\\s+SWFObject\\(\n            )\n            ([\"\\'])\n                (?P<url>(?:https?:)?//(?:www\\.)?youtube(?:-nocookie)?\\.com/\n                (?:embed|v|p)/[0-9A-Za-z_-]{11}.*?)\n            \\1''', webpage)]\n\n        # lazyYT YouTube embed\n        entries.extend(list(map(\n            unescapeHTML,\n            re.findall(r'class=\"lazyYT\" data-youtube-id=\"([^\"]+)\"', webpage))))\n\n        # Wordpress \"YouTube Video Importer\" plugin\n        matches = re.findall(r'''(?x)<div[^>]+\n            class=(?P<q1>[\\'\"])[^\\'\"]*\\byvii_single_video_player\\b[^\\'\"]*(?P=q1)[^>]+\n            data-video_id=(?P<q2>[\\'\"])([^\\'\"]+)(?P=q2)''', webpage)\n        entries.extend(m[-1] for m in matches)\n\n        return entries\n\n    @staticmethod\n    def _extract_url(webpage):\n        urls = YoutubeIE._extract_urls(webpage)\n        return urls[0] if urls else None\n\n    @classmethod\n    def extract_id(cls, url):\n        mobj = re.match(cls._VALID_URL, url, re.VERBOSE)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n        video_id = mobj.group(2)\n        return video_id\n\n    def _extract_annotations(self, video_id):\n        url = 'https://www.youtube.com/annotations_invideo?features=1&legacy=1&video_id=%s' % video_id\n        return self._download_webpage(url, video_id, note='Searching for annotations.', errnote='Unable to download video annotations.')\n\n    @staticmethod\n    def _extract_chapters(description, duration):\n        if not description:\n            return None\n        chapter_lines = re.findall(\n            r'(?:^|<br\\s*/>)([^<]*<a[^>]+onclick=[\"\\']yt\\.www\\.watch\\.player\\.seekTo[^>]+>(\\d{1,2}:\\d{1,2}(?::\\d{1,2})?)</a>[^>]*)(?=$|<br\\s*/>)',\n            description)\n        if not chapter_lines:\n            return None\n        chapters = []\n        for next_num, (chapter_line, time_point) in enumerate(\n                chapter_lines, start=1):\n            start_time = parse_duration(time_point)\n            if start_time is None:\n                continue\n            if start_time > duration:\n                break\n            end_time = (duration if next_num == len(chapter_lines)\n                        else parse_duration(chapter_lines[next_num][1]))\n            if end_time is None:\n                continue\n            if end_time > duration:\n                end_time = duration\n            if start_time > end_time:\n                break\n            chapter_title = re.sub(\n                r'<a[^>]+>[^<]+</a>', '', chapter_line).strip(' \\t-')\n            chapter_title = re.sub(r'\\s+', ' ', chapter_title)\n            chapters.append({\n                'start_time': start_time,\n                'end_time': end_time,\n                'title': chapter_title,\n            })\n        return chapters\n\n    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        proto = (\n            'http' if self._downloader.params.get('prefer_insecure', False)\n            else 'https')\n\n        start_time = None\n        end_time = None\n        parsed_url = compat_urllib_parse_urlparse(url)\n        for component in [parsed_url.fragment, parsed_url.query]:\n            query = compat_parse_qs(component)\n            if start_time is None and 't' in query:\n                start_time = parse_duration(query['t'][0])\n            if start_time is None and 'start' in query:\n                start_time = parse_duration(query['start'][0])\n            if end_time is None and 'end' in query:\n                end_time = parse_duration(query['end'][0])\n\n        # Extract original video URL from URL with redirection, like age verification, using next_url parameter\n        mobj = re.search(self._NEXT_URL_RE, url)\n        if mobj:\n            url = proto + '://www.youtube.com/' + compat_urllib_parse_unquote(mobj.group(1)).lstrip('/')\n        video_id = self.extract_id(url)\n\n        # Get video webpage\n        url = proto + '://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1&bpctr=9999999999' % video_id\n        video_webpage = self._download_webpage(url, video_id)\n\n        # Attempt to extract SWF player URL\n        mobj = re.search(r'swfConfig.*?\"(https?:\\\\/\\\\/.*?watch.*?-.*?\\.swf)\"', video_webpage)\n        if mobj is not None:\n            player_url = re.sub(r'\\\\(.)', r'\\1', mobj.group(1))\n        else:\n            player_url = None\n\n        dash_mpds = []\n\n        def add_dash_mpd(video_info):\n            dash_mpd = video_info.get('dashmpd')\n            if dash_mpd and dash_mpd[0] not in dash_mpds:\n                dash_mpds.append(dash_mpd[0])\n\n        is_live = None\n        view_count = None\n\n        def extract_view_count(v_info):\n            return int_or_none(try_get(v_info, lambda x: x['view_count'][0]))\n\n        # Get video info\n        embed_webpage = None\n        if re.search(r'player-age-gate-content\">', video_webpage) is not None:\n            age_gate = True\n            # We simulate the access to the video from www.youtube.com/v/{video_id}\n            # this can be viewed without login into Youtube\n            url = proto + '://www.youtube.com/embed/%s' % video_id\n            embed_webpage = self._download_webpage(url, video_id, 'Downloading embed webpage')\n            data = compat_urllib_parse_urlencode({\n                'video_id': video_id,\n                'eurl': 'https://youtube.googleapis.com/v/' + video_id,\n                'sts': self._search_regex(\n                    r'\"sts\"\\s*:\\s*(\\d+)', embed_webpage, 'sts', default=''),\n            })\n            video_info_url = proto + '://www.youtube.com/get_video_info?' + data\n            video_info_webpage = self._download_webpage(\n                video_info_url, video_id,\n                note='Refetching age-gated info webpage',\n                errnote='unable to download video info webpage')\n            video_info = compat_parse_qs(video_info_webpage)\n            add_dash_mpd(video_info)\n        else:\n            age_gate = False\n            video_info = None\n            sts = None\n            # Try looking directly into the video webpage\n            ytplayer_config = self._get_ytplayer_config(video_id, video_webpage)\n            if ytplayer_config:\n                args = ytplayer_config['args']\n                if args.get('url_encoded_fmt_stream_map'):\n                    # Convert to the same format returned by compat_parse_qs\n                    video_info = dict((k, [v]) for k, v in args.items())\n                    add_dash_mpd(video_info)\n                # Rental video is not rented but preview is available (e.g.\n                # https://www.youtube.com/watch?v=yYr8q0y5Jfg,\n                # https://github.com/rg3/youtube-dl/issues/10532)\n                if not video_info and args.get('ypc_vid'):\n                    return self.url_result(\n                        args['ypc_vid'], YoutubeIE.ie_key(), video_id=args['ypc_vid'])\n                if args.get('livestream') == '1' or args.get('live_playback') == 1:\n                    is_live = True\n                sts = ytplayer_config.get('sts')\n            if not video_info or self._downloader.params.get('youtube_include_dash_manifest', True):\n                # We also try looking in get_video_info since it may contain different dashmpd\n                # URL that points to a DASH manifest with possibly different itag set (some itags\n                # are missing from DASH manifest pointed by webpage's dashmpd, some - from DASH\n                # manifest pointed by get_video_info's dashmpd).\n                # The general idea is to take a union of itags of both DASH manifests (for example\n                # video with such 'manifest behavior' see https://github.com/rg3/youtube-dl/issues/6093)\n                self.report_video_info_webpage_download(video_id)\n                for el in ('info', 'embedded', 'detailpage', 'vevo', ''):\n                    query = {\n                        'video_id': video_id,\n                        'ps': 'default',\n                        'eurl': '',\n                        'gl': 'US',\n                        'hl': 'en',\n                    }\n                    if el:\n                        query['el'] = el\n                    if sts:\n                        query['sts'] = sts\n                    video_info_webpage = self._download_webpage(\n                        '%s://www.youtube.com/get_video_info' % proto,\n                        video_id, note=False,\n                        errnote='unable to download video info webpage',\n                        fatal=False, query=query)\n                    if not video_info_webpage:\n                        continue\n                    get_video_info = compat_parse_qs(video_info_webpage)\n                    add_dash_mpd(get_video_info)\n                    if view_count is None:\n                        view_count = extract_view_count(get_video_info)\n                    if not video_info:\n                        video_info = get_video_info\n                    if 'token' in get_video_info:\n                        # Different get_video_info requests may report different results, e.g.\n                        # some may report video unavailability, but some may serve it without\n                        # any complaint (see https://github.com/rg3/youtube-dl/issues/7362,\n                        # the original webpage as well as el=info and el=embedded get_video_info\n                        # requests report video unavailability due to geo restriction while\n                        # el=detailpage succeeds and returns valid data). This is probably\n                        # due to YouTube measures against IP ranges of hosting providers.\n                        # Working around by preferring the first succeeded video_info containing\n                        # the token if no such video_info yet was found.\n                        if 'token' not in video_info:\n                            video_info = get_video_info\n                        break\n\n        def extract_unavailable_message():\n            return self._html_search_regex(\n                r'(?s)<h1[^>]+id=\"unavailable-message\"[^>]*>(.+?)</h1>',\n                video_webpage, 'unavailable message', default=None)\n\n        if 'token' not in video_info:\n            if 'reason' in video_info:\n                if 'The uploader has not made this video available in your country.' in video_info['reason']:\n                    regions_allowed = self._html_search_meta(\n                        'regionsAllowed', video_webpage, default=None)\n                    countries = regions_allowed.split(',') if regions_allowed else None\n                    self.raise_geo_restricted(\n                        msg=video_info['reason'][0], countries=countries)\n                reason = video_info['reason'][0]\n                if 'Invalid parameters' in reason:\n                    unavailable_message = extract_unavailable_message()\n                    if unavailable_message:\n                        reason = unavailable_message\n                raise ExtractorError(\n                    'YouTube said: %s' % reason,\n                    expected=True, video_id=video_id)\n            else:\n                raise ExtractorError(\n                    '\"token\" parameter not in video info for unknown reason',\n                    video_id=video_id)\n\n        # title\n        if 'title' in video_info:\n            video_title = video_info['title'][0]\n        else:\n            self._downloader.report_warning('Unable to extract video title')\n            video_title = '_'\n\n        # description\n        description_original = video_description = get_element_by_id(\"eow-description\", video_webpage)\n        if video_description:\n\n            def replace_url(m):\n                redir_url = compat_urlparse.urljoin(url, m.group(1))\n                parsed_redir_url = compat_urllib_parse_urlparse(redir_url)\n                if re.search(r'^(?:www\\.)?(?:youtube(?:-nocookie)?\\.com|youtu\\.be)$', parsed_redir_url.netloc) and parsed_redir_url.path == '/redirect':\n                    qs = compat_parse_qs(parsed_redir_url.query)\n                    q = qs.get('q')\n                    if q and q[0]:\n                        return q[0]\n                return redir_url\n\n            description_original = video_description = re.sub(r'''(?x)\n                <a\\s+\n                    (?:[a-zA-Z-]+=\"[^\"]*\"\\s+)*?\n                    (?:title|href)=\"([^\"]+)\"\\s+\n                    (?:[a-zA-Z-]+=\"[^\"]*\"\\s+)*?\n                    class=\"[^\"]*\"[^>]*>\n                [^<]+\\.{3}\\s*\n                </a>\n            ''', replace_url, video_description)\n            video_description = clean_html(video_description)\n        else:\n            fd_mobj = re.search(r'<meta name=\"description\" content=\"([^\"]+)\"', video_webpage)\n            if fd_mobj:\n                video_description = unescapeHTML(fd_mobj.group(1))\n            else:\n                video_description = ''\n\n        if 'multifeed_metadata_list' in video_info and not smuggled_data.get('force_singlefeed', False):\n            if not self._downloader.params.get('noplaylist'):\n                entries = []\n                feed_ids = []\n                multifeed_metadata_list = video_info['multifeed_metadata_list'][0]\n                for feed in multifeed_metadata_list.split(','):\n                    # Unquote should take place before split on comma (,) since textual\n                    # fields may contain comma as well (see\n                    # https://github.com/rg3/youtube-dl/issues/8536)\n                    feed_data = compat_parse_qs(compat_urllib_parse_unquote_plus(feed))\n                    entries.append({\n                        '_type': 'url_transparent',\n                        'ie_key': 'Youtube',\n                        'url': smuggle_url(\n                            '%s://www.youtube.com/watch?v=%s' % (proto, feed_data['id'][0]),\n                            {'force_singlefeed': True}),\n                        'title': '%s (%s)' % (video_title, feed_data['title'][0]),\n                    })\n                    feed_ids.append(feed_data['id'][0])\n                self.to_screen(\n                    'Downloading multifeed video (%s) - add --no-playlist to just download video %s'\n                    % (', '.join(feed_ids), video_id))\n                return self.playlist_result(entries, video_id, video_title, video_description)\n            self.to_screen('Downloading just video %s because of --no-playlist' % video_id)\n\n        if view_count is None:\n            view_count = extract_view_count(video_info)\n\n        # Check for \"rental\" videos\n        if 'ypc_video_rental_bar_text' in video_info and 'author' not in video_info:\n            raise ExtractorError('\"rental\" videos not supported. See https://github.com/rg3/youtube-dl/issues/359 for more information.', expected=True)\n\n        # Start extracting information\n        self.report_information_extraction(video_id)\n\n        # uploader\n        if 'author' not in video_info:\n            raise ExtractorError('Unable to extract uploader name')\n        video_uploader = compat_urllib_parse_unquote_plus(video_info['author'][0])\n\n        # uploader_id\n        video_uploader_id = None\n        video_uploader_url = None\n        mobj = re.search(\n            r'<link itemprop=\"url\" href=\"(?P<uploader_url>https?://www\\.youtube\\.com/(?:user|channel)/(?P<uploader_id>[^\"]+))\">',\n            video_webpage)\n        if mobj is not None:\n            video_uploader_id = mobj.group('uploader_id')\n            video_uploader_url = mobj.group('uploader_url')\n        else:\n            self._downloader.report_warning('unable to extract uploader nickname')\n\n        # thumbnail image\n        # We try first to get a high quality image:\n        m_thumb = re.search(r'<span itemprop=\"thumbnail\".*?href=\"(.*?)\">',\n                            video_webpage, re.DOTALL)\n        if m_thumb is not None:\n            video_thumbnail = m_thumb.group(1)\n        elif 'thumbnail_url' not in video_info:\n            self._downloader.report_warning('unable to extract video thumbnail')\n            video_thumbnail = None\n        else:   # don't panic if we can't find it\n            video_thumbnail = compat_urllib_parse_unquote_plus(video_info['thumbnail_url'][0])\n\n        # upload date\n        upload_date = self._html_search_meta(\n            'datePublished', video_webpage, 'upload date', default=None)\n        if not upload_date:\n            upload_date = self._search_regex(\n                [r'(?s)id=\"eow-date.*?>(.*?)</span>',\n                 r'(?:id=\"watch-uploader-info\".*?>.*?|[\"\\']simpleText[\"\\']\\s*:\\s*[\"\\'])(?:Published|Uploaded|Streamed live|Started) on (.+?)[<\"\\']'],\n                video_webpage, 'upload date', default=None)\n        upload_date = unified_strdate(upload_date)\n\n        video_license = self._html_search_regex(\n            r'<h4[^>]+class=\"title\"[^>]*>\\s*License\\s*</h4>\\s*<ul[^>]*>\\s*<li>(.+?)</li',\n            video_webpage, 'license', default=None)\n\n        m_music = re.search(\n            r'''(?x)\n                <h4[^>]+class=\"title\"[^>]*>\\s*Music\\s*</h4>\\s*\n                <ul[^>]*>\\s*\n                <li>(?P<title>.+?)\n                by (?P<creator>.+?)\n                (?:\n                    \\(.+?\\)|\n                    <a[^>]*\n                        (?:\n                            \\bhref=[\"\\']/red[^>]*>|             # drop possible\n                            >\\s*Listen ad-free with YouTube Red # YouTube Red ad\n                        )\n                    .*?\n                )?</li\n            ''',\n            video_webpage)\n        if m_music:\n            video_alt_title = remove_quotes(unescapeHTML(m_music.group('title')))\n            video_creator = clean_html(m_music.group('creator'))\n        else:\n            video_alt_title = video_creator = None\n\n        m_episode = re.search(\n            r'<div[^>]+id=\"watch7-headline\"[^>]*>\\s*<span[^>]*>.*?>(?P<series>[^<]+)</a></b>\\s*S(?P<season>\\d+)\\s*\u2022\\s*E(?P<episode>\\d+)</span>',\n            video_webpage)\n        if m_episode:\n            series = m_episode.group('series')\n            season_number = int(m_episode.group('season'))\n            episode_number = int(m_episode.group('episode'))\n        else:\n            series = season_number = episode_number = None\n\n        m_cat_container = self._search_regex(\n            r'(?s)<h4[^>]*>\\s*Category\\s*</h4>\\s*<ul[^>]*>(.*?)</ul>',\n            video_webpage, 'categories', default=None)\n        if m_cat_container:\n            category = self._html_search_regex(\n                r'(?s)<a[^<]+>(.*?)</a>', m_cat_container, 'category',\n                default=None)\n            video_categories = None if category is None else [category]\n        else:\n            video_categories = None\n\n        video_tags = [\n            unescapeHTML(m.group('content'))\n            for m in re.finditer(self._meta_regex('og:video:tag'), video_webpage)]\n\n        def _extract_count(count_name):\n            return str_to_int(self._search_regex(\n                r'-%s-button[^>]+><span[^>]+class=\"yt-uix-button-content\"[^>]*>([\\d,]+)</span>'\n                % re.escape(count_name),\n                video_webpage, count_name, default=None))\n\n        like_count = _extract_count('like')\n        dislike_count = _extract_count('dislike')\n\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, video_webpage)\n        automatic_captions = self.extract_automatic_captions(video_id, video_webpage)\n\n        video_duration = try_get(\n            video_info, lambda x: int_or_none(x['length_seconds'][0]))\n        if not video_duration:\n            video_duration = parse_duration(self._html_search_meta(\n                'duration', video_webpage, 'video duration'))\n\n        # annotations\n        video_annotations = None\n        if self._downloader.params.get('writeannotations', False):\n            video_annotations = self._extract_annotations(video_id)\n\n        chapters = self._extract_chapters(description_original, video_duration)\n\n        if 'conn' in video_info and video_info['conn'][0].startswith('rtmp'):\n            self.report_rtmp_download()\n            formats = [{\n                'format_id': '_rtmp',\n                'protocol': 'rtmp',\n                'url': video_info['conn'][0],\n                'player_url': player_url,\n            }]\n        elif not is_live and (len(video_info.get('url_encoded_fmt_stream_map', [''])[0]) >= 1 or len(video_info.get('adaptive_fmts', [''])[0]) >= 1):\n            encoded_url_map = video_info.get('url_encoded_fmt_stream_map', [''])[0] + ',' + video_info.get('adaptive_fmts', [''])[0]\n            if 'rtmpe%3Dyes' in encoded_url_map:\n                raise ExtractorError('rtmpe downloads are not supported, see https://github.com/rg3/youtube-dl/issues/343 for more information.', expected=True)\n            formats_spec = {}\n            fmt_list = video_info.get('fmt_list', [''])[0]\n            if fmt_list:\n                for fmt in fmt_list.split(','):\n                    spec = fmt.split('/')\n                    if len(spec) > 1:\n                        width_height = spec[1].split('x')\n                        if len(width_height) == 2:\n                            formats_spec[spec[0]] = {\n                                'resolution': spec[1],\n                                'width': int_or_none(width_height[0]),\n                                'height': int_or_none(width_height[1]),\n                            }\n            formats = []\n            for url_data_str in encoded_url_map.split(','):\n                url_data = compat_parse_qs(url_data_str)\n                if 'itag' not in url_data or 'url' not in url_data:\n                    continue\n                format_id = url_data['itag'][0]\n                url = url_data['url'][0]\n\n                if 's' in url_data or self._downloader.params.get('youtube_include_dash_manifest', True):\n                    ASSETS_RE = r'\"assets\":.+?\"js\":\\s*(\"[^\"]+\")'\n                    jsplayer_url_json = self._search_regex(\n                        ASSETS_RE,\n                        embed_webpage if age_gate else video_webpage,\n                        'JS player URL (1)', default=None)\n                    if not jsplayer_url_json and not age_gate:\n                        # We need the embed website after all\n                        if embed_webpage is None:\n                            embed_url = proto + '://www.youtube.com/embed/%s' % video_id\n                            embed_webpage = self._download_webpage(\n                                embed_url, video_id, 'Downloading embed webpage')\n                        jsplayer_url_json = self._search_regex(\n                            ASSETS_RE, embed_webpage, 'JS player URL')\n\n                    player_url = json.loads(jsplayer_url_json)\n                    if player_url is None:\n                        player_url_json = self._search_regex(\n                            r'ytplayer\\.config.*?\"url\"\\s*:\\s*(\"[^\"]+\")',\n                            video_webpage, 'age gate player URL')\n                        player_url = json.loads(player_url_json)\n\n                if 'sig' in url_data:\n                    url += '&signature=' + url_data['sig'][0]\n                elif 's' in url_data:\n                    encrypted_sig = url_data['s'][0]\n\n                    if self._downloader.params.get('verbose'):\n                        if player_url is None:\n                            player_version = 'unknown'\n                            player_desc = 'unknown'\n                        else:\n                            if player_url.endswith('swf'):\n                                player_version = self._search_regex(\n                                    r'-(.+?)(?:/watch_as3)?\\.swf$', player_url,\n                                    'flash player', fatal=False)\n                                player_desc = 'flash player %s' % player_version\n                            else:\n                                player_version = self._search_regex(\n                                    [r'html5player-([^/]+?)(?:/html5player(?:-new)?)?\\.js',\n                                     r'(?:www|player)-([^/]+)(?:/[a-z]{2}_[A-Z]{2})?/base\\.js'],\n                                    player_url,\n                                    'html5 player', fatal=False)\n                                player_desc = 'html5 player %s' % player_version\n\n                        parts_sizes = self._signature_cache_id(encrypted_sig)\n                        self.to_screen('{%s} signature length %s, %s' %\n                                       (format_id, parts_sizes, player_desc))\n\n                    signature = self._decrypt_signature(\n                        encrypted_sig, video_id, player_url, age_gate)\n                    url += '&signature=' + signature\n                if 'ratebypass' not in url:\n                    url += '&ratebypass=yes'\n\n                dct = {\n                    'format_id': format_id,\n                    'url': url,\n                    'player_url': player_url,\n                }\n                if format_id in self._formats:\n                    dct.update(self._formats[format_id])\n                if format_id in formats_spec:\n                    dct.update(formats_spec[format_id])\n\n                # Some itags are not included in DASH manifest thus corresponding formats will\n                # lack metadata (see https://github.com/rg3/youtube-dl/pull/5993).\n                # Trying to extract metadata from url_encoded_fmt_stream_map entry.\n                mobj = re.search(r'^(?P<width>\\d+)[xX](?P<height>\\d+)$', url_data.get('size', [''])[0])\n                width, height = (int(mobj.group('width')), int(mobj.group('height'))) if mobj else (None, None)\n\n                more_fields = {\n                    'filesize': int_or_none(url_data.get('clen', [None])[0]),\n                    'tbr': float_or_none(url_data.get('bitrate', [None])[0], 1000),\n                    'width': width,\n                    'height': height,\n                    'fps': int_or_none(url_data.get('fps', [None])[0]),\n                    'format_note': url_data.get('quality_label', [None])[0] or url_data.get('quality', [None])[0],\n                }\n                for key, value in more_fields.items():\n                    if value:\n                        dct[key] = value\n                type_ = url_data.get('type', [None])[0]\n                if type_:\n                    type_split = type_.split(';')\n                    kind_ext = type_split[0].split('/')\n                    if len(kind_ext) == 2:\n                        kind, _ = kind_ext\n                        dct['ext'] = mimetype2ext(type_split[0])\n                        if kind in ('audio', 'video'):\n                            codecs = None\n                            for mobj in re.finditer(\n                                    r'(?P<key>[a-zA-Z_-]+)=(?P<quote>[\"\\']?)(?P<val>.+?)(?P=quote)(?:;|$)', type_):\n                                if mobj.group('key') == 'codecs':\n                                    codecs = mobj.group('val')\n                                    break\n                            if codecs:\n                                dct.update(parse_codecs(codecs))\n                if dct.get('acodec') == 'none' or dct.get('vcodec') == 'none':\n                    dct['downloader_options'] = {\n                        # Youtube throttles chunks >~10M\n                        'http_chunk_size': 10485760,\n                    }\n                formats.append(dct)\n        elif video_info.get('hlsvp'):\n            manifest_url = video_info['hlsvp'][0]\n            formats = []\n            m3u8_formats = self._extract_m3u8_formats(\n                manifest_url, video_id, 'mp4', fatal=False)\n            for a_format in m3u8_formats:\n                itag = self._search_regex(\n                    r'/itag/(\\d+)/', a_format['url'], 'itag', default=None)\n                if itag:\n                    a_format['format_id'] = itag\n                    if itag in self._formats:\n                        dct = self._formats[itag].copy()\n                        dct.update(a_format)\n                        a_format = dct\n                a_format['player_url'] = player_url\n                # Accept-Encoding header causes failures in live streams on Youtube and Youtube Gaming\n                a_format.setdefault('http_headers', {})['Youtubedl-no-compression'] = 'True'\n                formats.append(a_format)\n        else:\n            unavailable_message = extract_unavailable_message()\n            if unavailable_message:\n                raise ExtractorError(unavailable_message, expected=True)\n            raise ExtractorError('no conn, hlsvp or url_encoded_fmt_stream_map information found in video info')\n\n        # Look for the DASH manifest\n        if self._downloader.params.get('youtube_include_dash_manifest', True):\n            dash_mpd_fatal = True\n            for mpd_url in dash_mpds:\n                dash_formats = {}\n                try:\n                    def decrypt_sig(mobj):\n                        s = mobj.group(1)\n                        dec_s = self._decrypt_signature(s, video_id, player_url, age_gate)\n                        return '/signature/%s' % dec_s\n\n                    mpd_url = re.sub(r'/s/([a-fA-F0-9\\.]+)', decrypt_sig, mpd_url)\n\n                    for df in self._extract_mpd_formats(\n                            mpd_url, video_id, fatal=dash_mpd_fatal,\n                            formats_dict=self._formats):\n                        # Do not overwrite DASH format found in some previous DASH manifest\n                        if df['format_id'] not in dash_formats:\n                            dash_formats[df['format_id']] = df\n                        # Additional DASH manifests may end up in HTTP Error 403 therefore\n                        # allow them to fail without bug report message if we already have\n                        # some DASH manifest succeeded. This is temporary workaround to reduce\n                        # burst of bug reports until we figure out the reason and whether it\n                        # can be fixed at all.\n                        dash_mpd_fatal = False\n                except (ExtractorError, KeyError) as e:\n                    self.report_warning(\n                        'Skipping DASH manifest: %r' % e, video_id)\n                if dash_formats:\n                    # Remove the formats we found through non-DASH, they\n                    # contain less info and it can be wrong, because we use\n                    # fixed values (for example the resolution). See\n                    # https://github.com/rg3/youtube-dl/issues/5774 for an\n                    # example.\n                    formats = [f for f in formats if f['format_id'] not in dash_formats.keys()]\n                    formats.extend(dash_formats.values())\n\n        # Check for malformed aspect ratio\n        stretched_m = re.search(\n            r'<meta\\s+property=\"og:video:tag\".*?content=\"yt:stretch=(?P<w>[0-9]+):(?P<h>[0-9]+)\">',\n            video_webpage)\n        if stretched_m:\n            w = float(stretched_m.group('w'))\n            h = float(stretched_m.group('h'))\n            # yt:stretch may hold invalid ratio data (e.g. for Q39EVAstoRM ratio is 17:0).\n            # We will only process correct ratios.\n            if w > 0 and h > 0:\n                ratio = w / h\n                for f in formats:\n                    if f.get('vcodec') != 'none':\n                        f['stretched_ratio'] = ratio\n\n        self._sort_formats(formats)\n\n        self.mark_watched(video_id, video_info)\n\n        return {\n            'id': video_id,\n            'uploader': video_uploader,\n            'uploader_id': video_uploader_id,\n            'uploader_url': video_uploader_url,\n            'upload_date': upload_date,\n            'license': video_license,\n            'creator': video_creator,\n            'title': video_title,\n            'alt_title': video_alt_title,\n            'thumbnail': video_thumbnail,\n            'description': video_description,\n            'categories': video_categories,\n            'tags': video_tags,\n            'subtitles': video_subtitles,\n            'automatic_captions': automatic_captions,\n            'duration': video_duration,\n            'age_limit': 18 if age_gate else 0,\n            'annotations': video_annotations,\n            'chapters': chapters,\n            'webpage_url': proto + '://www.youtube.com/watch?v=%s' % video_id,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'average_rating': float_or_none(video_info.get('avg_rating', [None])[0]),\n            'formats': formats,\n            'is_live': is_live,\n            'start_time': start_time,\n            'end_time': end_time,\n            'series': series,\n            'season_number': season_number,\n            'episode_number': episode_number,\n        }\n\n\nclass YoutubePlaylistIE(YoutubePlaylistBaseInfoExtractor):\n    IE_DESC = 'YouTube.com playlists'\n    _VALID_URL = r\"\"\"(?x)(?:\n                        (?:https?://)?\n                        (?:\\w+\\.)?\n                        (?:\n                            youtube\\.com/\n                            (?:\n                               (?:course|view_play_list|my_playlists|artist|playlist|watch|embed/(?:videoseries|[0-9A-Za-z_-]{11}))\n                               \\? (?:.*?[&;])*? (?:p|a|list)=\n                            |  p/\n                            )|\n                            youtu\\.be/[0-9A-Za-z_-]{11}\\?.*?\\blist=\n                        )\n                        (\n                            (?:PL|LL|EC|UU|FL|RD|UL|TL)?[0-9A-Za-z-_]{10,}\n                            # Top tracks, they can also include dots\n                            |(?:MC)[\\w\\.]*\n                        )\n                        .*\n                     |\n                        (%(playlist_id)s)\n                     )\"\"\" % {'playlist_id': YoutubeBaseInfoExtractor._PLAYLIST_ID_RE}\n    _TEMPLATE_URL = 'https://www.youtube.com/playlist?list=%s'\n    _VIDEO_RE = r'href=\"\\s*/watch\\?v=(?P<id>[0-9A-Za-z_-]{11})&amp;[^\"]*?index=(?P<index>\\d+)(?:[^>]+>(?P<title>[^<]+))?'\n    IE_NAME = 'youtube:playlist'\n    _TESTS = [{\n        'url': 'https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re',\n        'info_dict': {\n            'title': 'ytdl test PL',\n            'id': 'PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re',\n        },\n        'playlist_count': 3,\n    }, {\n        'url': 'https://www.youtube.com/playlist?list=PLtPgu7CB4gbZDA7i_euNxn75ISqxwZPYx',\n        'info_dict': {\n            'id': 'PLtPgu7CB4gbZDA7i_euNxn75ISqxwZPYx',\n            'title': 'YDL_Empty_List',\n        },\n        'playlist_count': 0,\n        'skip': 'This playlist is private',\n    }, {\n        'note': 'Playlist with deleted videos (#651). As a bonus, the video #51 is also twice in this list.',\n        'url': 'https://www.youtube.com/playlist?list=PLwP_SiAcdui0KVebT0mU9Apz359a4ubsC',\n        'info_dict': {\n            'title': '29C3: Not my department',\n            'id': 'PLwP_SiAcdui0KVebT0mU9Apz359a4ubsC',\n        },\n        'playlist_count': 95,\n    }, {\n        'note': 'issue #673',\n        'url': 'PLBB231211A4F62143',\n        'info_dict': {\n            'title': '[OLD]Team Fortress 2 (Class-based LP)',\n            'id': 'PLBB231211A4F62143',\n        },\n        'playlist_mincount': 26,\n    }, {\n        'note': 'Large playlist',\n        'url': 'https://www.youtube.com/playlist?list=UUBABnxM4Ar9ten8Mdjj1j0Q',\n        'info_dict': {\n            'title': 'Uploads from Cauchemar',\n            'id': 'UUBABnxM4Ar9ten8Mdjj1j0Q',\n        },\n        'playlist_mincount': 799,\n    }, {\n        'url': 'PLtPgu7CB4gbY9oDN3drwC3cMbJggS7dKl',\n        'info_dict': {\n            'title': 'YDL_safe_search',\n            'id': 'PLtPgu7CB4gbY9oDN3drwC3cMbJggS7dKl',\n        },\n        'playlist_count': 2,\n        'skip': 'This playlist is private',\n    }, {\n        'note': 'embedded',\n        'url': 'https://www.youtube.com/embed/videoseries?list=PL6IaIsEjSbf96XFRuNccS_RuEXwNdsoEu',\n        'playlist_count': 4,\n        'info_dict': {\n            'title': 'JODA15',\n            'id': 'PL6IaIsEjSbf96XFRuNccS_RuEXwNdsoEu',\n        }\n    }, {\n        'url': 'http://www.youtube.com/embed/_xDOZElKyNU?list=PLsyOSbh5bs16vubvKePAQ1x3PhKavfBIl',\n        'playlist_mincount': 485,\n        'info_dict': {\n            'title': '2017 \u83ef\u8a9e\u6700\u65b0\u55ae\u66f2 (2/24\u66f4\u65b0)',\n            'id': 'PLsyOSbh5bs16vubvKePAQ1x3PhKavfBIl',\n        }\n    }, {\n        'note': 'Embedded SWF player',\n        'url': 'https://www.youtube.com/p/YN5VISEtHet5D4NEvfTd0zcgFk84NqFZ?hl=en_US&fs=1&rel=0',\n        'playlist_count': 4,\n        'info_dict': {\n            'title': 'JODA7',\n            'id': 'YN5VISEtHet5D4NEvfTd0zcgFk84NqFZ',\n        }\n    }, {\n        'note': 'Buggy playlist: the webpage has a \"Load more\" button but it doesn\\'t have more videos',\n        'url': 'https://www.youtube.com/playlist?list=UUXw-G3eDE9trcvY2sBMM_aA',\n        'info_dict': {\n            'title': 'Uploads from Interstellar Movie',\n            'id': 'UUXw-G3eDE9trcvY2sBMM_aA',\n        },\n        'playlist_mincount': 21,\n    }, {\n        # Playlist URL that does not actually serve a playlist\n        'url': 'https://www.youtube.com/watch?v=FqZTN594JQw&list=PLMYEtVRpaqY00V9W81Cwmzp6N6vZqfUKD4',\n        'info_dict': {\n            'id': 'FqZTN594JQw',\n            'ext': 'webm',\n            'title': \"Smiley's People 01 detective, Adventure Series, Action\",\n            'uploader': 'STREEM',\n            'uploader_id': 'UCyPhqAZgwYWZfxElWVbVJng',\n            'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/channel/UCyPhqAZgwYWZfxElWVbVJng',\n            'upload_date': '20150526',\n            'license': 'Standard YouTube License',\n            'description': 'md5:507cdcb5a49ac0da37a920ece610be80',\n            'categories': ['People & Blogs'],\n            'tags': list,\n            'like_count': int,\n            'dislike_count': int,\n        },\n        'params': {\n            'skip_download': True,\n        },\n        'add_ie': [YoutubeIE.ie_key()],\n    }, {\n        'url': 'https://youtu.be/yeWKywCrFtk?list=PL2qgrgXsNUG5ig9cat4ohreBjYLAPC0J5',\n        'info_dict': {\n            'id': 'yeWKywCrFtk',\n            'ext': 'mp4',\n            'title': 'Small Scale Baler and Braiding Rugs',\n            'uploader': 'Backus-Page House Museum',\n            'uploader_id': 'backuspagemuseum',\n            'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/backuspagemuseum',\n            'upload_date': '20161008',\n            'license': 'Standard YouTube License',\n            'description': 'md5:800c0c78d5eb128500bffd4f0b4f2e8a',\n            'categories': ['Nonprofits & Activism'],\n            'tags': list,\n            'like_count': int,\n            'dislike_count': int,\n        },\n        'params': {\n            'noplaylist': True,\n            'skip_download': True,\n        },\n    }, {\n        'url': 'https://youtu.be/uWyaPkt-VOI?list=PL9D9FC436B881BA21',\n        'only_matching': True,\n    }, {\n        'url': 'TLGGrESM50VT6acwMjAyMjAxNw',\n        'only_matching': True,\n    }]\n\n    def _real_initialize(self):\n        self._login()\n\n    def _extract_mix(self, playlist_id):\n        # The mixes are generated from a single video\n        # the id of the playlist is just 'RD' + video_id\n        ids = []\n        last_id = playlist_id[-11:]\n        for n in itertools.count(1):\n            url = 'https://youtube.com/watch?v=%s&list=%s' % (last_id, playlist_id)\n            webpage = self._download_webpage(\n                url, playlist_id, 'Downloading page {0} of Youtube mix'.format(n))\n            new_ids = orderedSet(re.findall(\n                r'''(?xs)data-video-username=\".*?\".*?\n                           href=\"/watch\\?v=([0-9A-Za-z_-]{11})&amp;[^\"]*?list=%s''' % re.escape(playlist_id),\n                webpage))\n            # Fetch new pages until all the videos are repeated, it seems that\n            # there are always 51 unique videos.\n            new_ids = [_id for _id in new_ids if _id not in ids]\n            if not new_ids:\n                break\n            ids.extend(new_ids)\n            last_id = ids[-1]\n\n        url_results = self._ids_to_results(ids)\n\n        search_title = lambda class_name: get_element_by_attribute('class', class_name, webpage)\n        title_span = (\n            search_title('playlist-title') or\n            search_title('title long-title') or\n            search_title('title'))\n        title = clean_html(title_span)\n\n        return self.playlist_result(url_results, playlist_id, title)\n\n    def _extract_playlist(self, playlist_id):\n        url = self._TEMPLATE_URL % playlist_id\n        page = self._download_webpage(url, playlist_id)\n\n        # the yt-alert-message now has tabindex attribute (see https://github.com/rg3/youtube-dl/issues/11604)\n        for match in re.findall(r'<div class=\"yt-alert-message\"[^>]*>([^<]+)</div>', page):\n            match = match.strip()\n            # Check if the playlist exists or is private\n            mobj = re.match(r'[^<]*(?:The|This) playlist (?P<reason>does not exist|is private)[^<]*', match)\n            if mobj:\n                reason = mobj.group('reason')\n                message = 'This playlist %s' % reason\n                if 'private' in reason:\n                    message += ', use --username or --netrc to access it'\n                message += '.'\n                raise ExtractorError(message, expected=True)\n            elif re.match(r'[^<]*Invalid parameters[^<]*', match):\n                raise ExtractorError(\n                    'Invalid parameters. Maybe URL is incorrect.',\n                    expected=True)\n            elif re.match(r'[^<]*Choose your language[^<]*', match):\n                continue\n            else:\n                self.report_warning('Youtube gives an alert message: ' + match)\n\n        playlist_title = self._html_search_regex(\n            r'(?s)<h1 class=\"pl-header-title[^\"]*\"[^>]*>\\s*(.*?)\\s*</h1>',\n            page, 'title', default=None)\n\n        _UPLOADER_BASE = r'class=[\"\\']pl-header-details[^>]+>\\s*<li>\\s*<a[^>]+\\bhref='\n        uploader = self._search_regex(\n            r'%s[\"\\']/(?:user|channel)/[^>]+>([^<]+)' % _UPLOADER_BASE,\n            page, 'uploader', default=None)\n        mobj = re.search(\n            r'%s([\"\\'])(?P<path>/(?:user|channel)/(?P<uploader_id>.+?))\\1' % _UPLOADER_BASE,\n            page)\n        if mobj:\n            uploader_id = mobj.group('uploader_id')\n            uploader_url = compat_urlparse.urljoin(url, mobj.group('path'))\n        else:\n            uploader_id = uploader_url = None\n\n        has_videos = True\n\n        if not playlist_title:\n            try:\n                # Some playlist URLs don't actually serve a playlist (e.g.\n                # https://www.youtube.com/watch?v=FqZTN594JQw&list=PLMYEtVRpaqY00V9W81Cwmzp6N6vZqfUKD4)\n                next(self._entries(page, playlist_id))\n            except StopIteration:\n                has_videos = False\n\n        playlist = self.playlist_result(\n            self._entries(page, playlist_id), playlist_id, playlist_title)\n        playlist.update({\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'uploader_url': uploader_url,\n        })\n\n        return has_videos, playlist\n\n    def _check_download_just_video(self, url, playlist_id):\n        # Check if it's a video-specific URL\n        query_dict = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n        video_id = query_dict.get('v', [None])[0] or self._search_regex(\n            r'(?:(?:^|//)youtu\\.be/|youtube\\.com/embed/(?!videoseries))([0-9A-Za-z_-]{11})', url,\n            'video id', default=None)\n        if video_id:\n            if self._downloader.params.get('noplaylist'):\n                self.to_screen('Downloading just video %s because of --no-playlist' % video_id)\n                return video_id, self.url_result(video_id, 'Youtube', video_id=video_id)\n            else:\n                self.to_screen('Downloading playlist %s - add --no-playlist to just download video %s' % (playlist_id, video_id))\n                return video_id, None\n        return None, None\n\n    def _real_extract(self, url):\n        # Extract playlist id\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n        playlist_id = mobj.group(1) or mobj.group(2)\n\n        video_id, video = self._check_download_just_video(url, playlist_id)\n        if video:\n            return video\n\n        if playlist_id.startswith(('RD', 'UL', 'PU')):\n            # Mixes require a custom extraction process\n            return self._extract_mix(playlist_id)\n\n        has_videos, playlist = self._extract_playlist(playlist_id)\n        if has_videos or not video_id:\n            return playlist\n\n        # Some playlist URLs don't actually serve a playlist (see\n        # https://github.com/rg3/youtube-dl/issues/10537).\n        # Fallback to plain video extraction if there is a video id\n        # along with playlist id.\n        return self.url_result(video_id, 'Youtube', video_id=video_id)\n\n\nclass YoutubeChannelIE(YoutubePlaylistBaseInfoExtractor):\n    IE_DESC = 'YouTube.com channels'\n    _VALID_URL = r'https?://(?:youtu\\.be|(?:\\w+\\.)?youtube(?:-nocookie)?\\.com)/channel/(?P<id>[0-9A-Za-z_-]+)'\n    _TEMPLATE_URL = 'https://www.youtube.com/channel/%s/videos'\n    _VIDEO_RE = r'(?:title=\"(?P<title>[^\"]+)\"[^>]+)?href=\"/watch\\?v=(?P<id>[0-9A-Za-z_-]+)&?'\n    IE_NAME = 'youtube:channel'\n    _TESTS = [{\n        'note': 'paginated channel',\n        'url': 'https://www.youtube.com/channel/UCKfVa3S1e4PHvxWcwyMMg8w',\n        'playlist_mincount': 91,\n        'info_dict': {\n            'id': 'UUKfVa3S1e4PHvxWcwyMMg8w',\n            'title': 'Uploads from lex will',\n        }\n    }, {\n        'note': 'Age restricted channel',\n        # from https://www.youtube.com/user/DeusExOfficial\n        'url': 'https://www.youtube.com/channel/UCs0ifCMCm1icqRbqhUINa0w',\n        'playlist_mincount': 64,\n        'info_dict': {\n            'id': 'UUs0ifCMCm1icqRbqhUINa0w',\n            'title': 'Uploads from Deus Ex',\n        },\n    }]\n\n    @classmethod\n    def suitable(cls, url):\n        return (False if YoutubePlaylistsIE.suitable(url) or YoutubeLiveIE.suitable(url)\n                else super(YoutubeChannelIE, cls).suitable(url))\n\n    def _build_template_url(self, url, channel_id):\n        return self._TEMPLATE_URL % channel_id\n\n    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n\n        url = self._build_template_url(url, channel_id)\n\n        # Channel by page listing is restricted to 35 pages of 30 items, i.e. 1050 videos total (see #5778)\n        # Workaround by extracting as a playlist if managed to obtain channel playlist URL\n        # otherwise fallback on channel by page extraction\n        channel_page = self._download_webpage(\n            url + '?view=57', channel_id,\n            'Downloading channel page', fatal=False)\n        if channel_page is False:\n            channel_playlist_id = False\n        else:\n            channel_playlist_id = self._html_search_meta(\n                'channelId', channel_page, 'channel id', default=None)\n            if not channel_playlist_id:\n                channel_url = self._html_search_meta(\n                    ('al:ios:url', 'twitter:app:url:iphone', 'twitter:app:url:ipad'),\n                    channel_page, 'channel url', default=None)\n                if channel_url:\n                    channel_playlist_id = self._search_regex(\n                        r'vnd\\.youtube://user/([0-9A-Za-z_-]+)',\n                        channel_url, 'channel id', default=None)\n        if channel_playlist_id and channel_playlist_id.startswith('UC'):\n            playlist_id = 'UU' + channel_playlist_id[2:]\n            return self.url_result(\n                compat_urlparse.urljoin(url, '/playlist?list=%s' % playlist_id), 'YoutubePlaylist')\n\n        channel_page = self._download_webpage(url, channel_id, 'Downloading page #1')\n        autogenerated = re.search(r'''(?x)\n                class=\"[^\"]*?(?:\n                    channel-header-autogenerated-label|\n                    yt-channel-title-autogenerated\n                )[^\"]*\"''', channel_page) is not None\n\n        if autogenerated:\n            # The videos are contained in a single page\n            # the ajax pages can't be used, they are empty\n            entries = [\n                self.url_result(\n                    video_id, 'Youtube', video_id=video_id,\n                    video_title=video_title)\n                for video_id, video_title in self.extract_videos_from_page(channel_page)]\n            return self.playlist_result(entries, channel_id)\n\n        try:\n            next(self._entries(channel_page, channel_id))\n        except StopIteration:\n            alert_message = self._html_search_regex(\n                r'(?s)<div[^>]+class=([\"\\']).*?\\byt-alert-message\\b.*?\\1[^>]*>(?P<alert>[^<]+)</div>',\n                channel_page, 'alert', default=None, group='alert')\n            if alert_message:\n                raise ExtractorError('Youtube said: %s' % alert_message, expected=True)\n\n        return self.playlist_result(self._entries(channel_page, channel_id), channel_id)\n\n\nclass YoutubeUserIE(YoutubeChannelIE):\n    IE_DESC = 'YouTube.com user videos (URL or \"ytuser\" keyword)'\n    _VALID_URL = r'(?:(?:https?://(?:\\w+\\.)?youtube\\.com/(?:(?P<user>user|c)/)?(?!(?:attribution_link|watch|results|shared)(?:$|[^a-z_A-Z0-9-])))|ytuser:)(?!feed/)(?P<id>[A-Za-z0-9_-]+)'\n    _TEMPLATE_URL = 'https://www.youtube.com/%s/%s/videos'\n    IE_NAME = 'youtube:user'\n\n    _TESTS = [{\n        'url': 'https://www.youtube.com/user/TheLinuxFoundation',\n        'playlist_mincount': 320,\n        'info_dict': {\n            'id': 'UUfX55Sx5hEFjoC3cNs6mCUQ',\n            'title': 'Uploads from The Linux Foundation',\n        }\n    }, {\n        # Only available via https://www.youtube.com/c/12minuteathlete/videos\n        # but not https://www.youtube.com/user/12minuteathlete/videos\n        'url': 'https://www.youtube.com/c/12minuteathlete/videos',\n        'playlist_mincount': 249,\n        'info_dict': {\n            'id': 'UUVjM-zV6_opMDx7WYxnjZiQ',\n            'title': 'Uploads from 12 Minute Athlete',\n        }\n    }, {\n        'url': 'ytuser:phihag',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/c/gametrailers',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/gametrailers',\n        'only_matching': True,\n    }, {\n        # This channel is not available, geo restricted to JP\n        'url': 'https://www.youtube.com/user/kananishinoSMEJ/videos',\n        'only_matching': True,\n    }]\n\n    @classmethod\n    def suitable(cls, url):\n        # Don't return True if the url can be extracted with other youtube\n        # extractor, the regex would is too permissive and it would match.\n        other_yt_ies = iter(klass for (name, klass) in globals().items() if name.startswith('Youtube') and name.endswith('IE') and klass is not cls)\n        if any(ie.suitable(url) for ie in other_yt_ies):\n            return False\n        else:\n            return super(YoutubeUserIE, cls).suitable(url)\n\n    def _build_template_url(self, url, channel_id):\n        mobj = re.match(self._VALID_URL, url)\n        return self._TEMPLATE_URL % (mobj.group('user') or 'user', mobj.group('id'))\n\n\nclass YoutubeLiveIE(YoutubeBaseInfoExtractor):\n    IE_DESC = 'YouTube.com live streams'\n    _VALID_URL = r'(?P<base_url>https?://(?:\\w+\\.)?youtube\\.com/(?:(?:user|channel|c)/)?(?P<id>[^/]+))/live'\n    IE_NAME = 'youtube:live'\n\n    _TESTS = [{\n        'url': 'https://www.youtube.com/user/TheYoungTurks/live',\n        'info_dict': {\n            'id': 'a48o2S1cPoo',\n            'ext': 'mp4',\n            'title': 'The Young Turks - Live Main Show',\n            'uploader': 'The Young Turks',\n            'uploader_id': 'TheYoungTurks',\n            'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/TheYoungTurks',\n            'upload_date': '20150715',\n            'license': 'Standard YouTube License',\n            'description': 'md5:438179573adcdff3c97ebb1ee632b891',\n            'categories': ['News & Politics'],\n            'tags': ['Cenk Uygur (TV Program Creator)', 'The Young Turks (Award-Winning Work)', 'Talk Show (TV Genre)'],\n            'like_count': int,\n            'dislike_count': int,\n        },\n        'params': {\n            'skip_download': True,\n        },\n    }, {\n        'url': 'https://www.youtube.com/channel/UC1yBKRuGpC1tSM73A0ZjYjQ/live',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/c/CommanderVideoHq/live',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/TheYoungTurks/live',\n        'only_matching': True,\n    }]\n\n    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        channel_id = mobj.group('id')\n        base_url = mobj.group('base_url')\n        webpage = self._download_webpage(url, channel_id, fatal=False)\n        if webpage:\n            page_type = self._og_search_property(\n                'type', webpage, 'page type', default='')\n            video_id = self._html_search_meta(\n                'videoId', webpage, 'video id', default=None)\n            if page_type.startswith('video') and video_id and re.match(\n                    r'^[0-9A-Za-z_-]{11}$', video_id):\n                return self.url_result(video_id, YoutubeIE.ie_key())\n        return self.url_result(base_url)\n\n\nclass YoutubePlaylistsIE(YoutubePlaylistsBaseInfoExtractor):\n    IE_DESC = 'YouTube.com user/channel playlists'\n    _VALID_URL = r'https?://(?:\\w+\\.)?youtube\\.com/(?:user|channel)/(?P<id>[^/]+)/playlists'\n    IE_NAME = 'youtube:playlists'\n\n    _TESTS = [{\n        'url': 'https://www.youtube.com/user/ThirstForScience/playlists',\n        'playlist_mincount': 4,\n        'info_dict': {\n            'id': 'ThirstForScience',\n            'title': 'Thirst for Science',\n        },\n    }, {\n        # with \"Load more\" button\n        'url': 'https://www.youtube.com/user/igorkle1/playlists?view=1&sort=dd',\n        'playlist_mincount': 70,\n        'info_dict': {\n            'id': 'igorkle1',\n            'title': '\u0418\u0433\u043e\u0440\u044c \u041a\u043b\u0435\u0439\u043d\u0435\u0440',\n        },\n    }, {\n        'url': 'https://www.youtube.com/channel/UCiU1dHvZObB2iP6xkJ__Icw/playlists',\n        'playlist_mincount': 17,\n        'info_dict': {\n            'id': 'UCiU1dHvZObB2iP6xkJ__Icw',\n            'title': 'Chem Player',\n        },\n    }]\n\n\nclass YoutubeSearchBaseInfoExtractor(YoutubePlaylistBaseInfoExtractor):\n    _VIDEO_RE = r'href=\"\\s*/watch\\?v=(?P<id>[0-9A-Za-z_-]{11})(?:[^\"]*\"[^>]+\\btitle=\"(?P<title>[^\"]+))?'\n\n\nclass YoutubeSearchIE(SearchInfoExtractor, YoutubeSearchBaseInfoExtractor):\n    IE_DESC = 'YouTube.com searches'\n    # there doesn't appear to be a real limit, for example if you search for\n    # 'python' you get more than 8.000.000 results\n    _MAX_RESULTS = float('inf')\n    IE_NAME = 'youtube:search'\n    _SEARCH_KEY = 'ytsearch'\n    _EXTRA_QUERY_ARGS = {}\n    _TESTS = []\n\n    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n\n        videos = []\n        limit = n\n\n        url_query = {\n            'search_query': query.encode('utf-8'),\n        }\n        url_query.update(self._EXTRA_QUERY_ARGS)\n        result_url = 'https://www.youtube.com/results?' + compat_urllib_parse_urlencode(url_query)\n\n        for pagenum in itertools.count(1):\n            data = self._download_json(\n                result_url, video_id='query \"%s\"' % query,\n                note='Downloading page %s' % pagenum,\n                errnote='Unable to download API page',\n                query={'spf': 'navigate'})\n            html_content = data[1]['body']['content']\n\n            if 'class=\"search-message' in html_content:\n                raise ExtractorError(\n                    '[youtube] No video results', expected=True)\n\n            new_videos = list(self._process_page(html_content))\n            videos += new_videos\n            if not new_videos or len(videos) > limit:\n                break\n            next_link = self._html_search_regex(\n                r'href=\"(/results\\?[^\"]*\\bsp=[^\"]+)\"[^>]*>\\s*<span[^>]+class=\"[^\"]*\\byt-uix-button-content\\b[^\"]*\"[^>]*>Next',\n                html_content, 'next link', default=None)\n            if next_link is None:\n                break\n            result_url = compat_urlparse.urljoin('https://www.youtube.com/', next_link)\n\n        if len(videos) > n:\n            videos = videos[:n]\n        return self.playlist_result(videos, query)\n\n\nclass YoutubeSearchDateIE(YoutubeSearchIE):\n    IE_NAME = YoutubeSearchIE.IE_NAME + ':date'\n    _SEARCH_KEY = 'ytsearchdate'\n    IE_DESC = 'YouTube.com searches, newest videos first'\n    _EXTRA_QUERY_ARGS = {'search_sort': 'video_date_uploaded'}\n\n\nclass YoutubeSearchURLIE(YoutubeSearchBaseInfoExtractor):\n    IE_DESC = 'YouTube.com search URLs'\n    IE_NAME = 'youtube:search_url'\n    _VALID_URL = r'https?://(?:www\\.)?youtube\\.com/results\\?(.*?&)?(?:search_query|q)=(?P<query>[^&]+)(?:[&]|$)'\n    _TESTS = [{\n        'url': 'https://www.youtube.com/results?baz=bar&search_query=youtube-dl+test+video&filters=video&lclk=video',\n        'playlist_mincount': 5,\n        'info_dict': {\n            'title': 'youtube-dl test video',\n        }\n    }, {\n        'url': 'https://www.youtube.com/results?q=test&sp=EgQIBBgB',\n        'only_matching': True,\n    }]\n\n    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        query = compat_urllib_parse_unquote_plus(mobj.group('query'))\n        webpage = self._download_webpage(url, query)\n        return self.playlist_result(self._process_page(webpage), playlist_title=query)\n\n\nclass YoutubeShowIE(YoutubePlaylistsBaseInfoExtractor):\n    IE_DESC = 'YouTube.com (multi-season) shows'\n    _VALID_URL = r'https?://(?:www\\.)?youtube\\.com/show/(?P<id>[^?#]*)'\n    IE_NAME = 'youtube:show'\n    _TESTS = [{\n        'url': 'https://www.youtube.com/show/airdisasters',\n        'playlist_mincount': 5,\n        'info_dict': {\n            'id': 'airdisasters',\n            'title': 'Air Disasters',\n        }\n    }]\n\n    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        return super(YoutubeShowIE, self)._real_extract(\n            'https://www.youtube.com/show/%s/playlists' % playlist_id)\n\n\nclass YoutubeFeedsInfoExtractor(YoutubeBaseInfoExtractor):\n    \"\"\"\n    Base class for feed extractors\n    Subclasses must define the _FEED_NAME and _PLAYLIST_TITLE properties.\n    \n \n(?x)\n        (?:https?://)?\n        (?:\\w+\\.)?[yY][oO][uU][tT][uU][bB][eE](?:-nocookie)?\\.com/\n        (?:watch\\?(?:\n            feature=[a-z_]+|\n            annotation_id=annotation_[^&]+|\n            x-yt-cl=[0-9]+|\n            hl=[^&]*|\n            t=[0-9]+\n        )?\n        |\n            attribution_link\\?a=[^&]+\n        )\n        $\n    \n \n# coding: utf-8\n# The extraction process is the same as for playlists, but the regex\n# for the video ids doesn't contain an index\n# 'recommended' feed has infinite 'load more' and each new portion spins\n# the same videos in (sometimes) slightly different order, so we'll check\n# for unicity and break when portion has no new videos\n#%s' % page_num,\n# Do not list\n# Do not list\n", "content": "# coding: utf-8\n\nfrom __future__ import unicode_literals\n\n\nimport itertools\nimport json\nimport os.path\nimport random\nimport re\nimport time\nimport traceback\n\nfrom .common import InfoExtractor, SearchInfoExtractor\nfrom ..jsinterp import JSInterpreter\nfrom ..swfinterp import SWFInterpreter\nfrom ..compat import (\n    compat_chr,\n    compat_kwargs,\n    compat_parse_qs,\n    compat_urllib_parse_unquote,\n    compat_urllib_parse_unquote_plus,\n    compat_urllib_parse_urlencode,\n    compat_urllib_parse_urlparse,\n    compat_urlparse,\n    compat_str,\n)\nfrom ..utils import (\n    clean_html,\n    error_to_compat_str,\n    ExtractorError,\n    float_or_none,\n    get_element_by_attribute,\n    get_element_by_id,\n    int_or_none,\n    mimetype2ext,\n    orderedSet,\n    parse_codecs,\n    parse_duration,\n    remove_quotes,\n    remove_start,\n    smuggle_url,\n    str_to_int,\n    try_get,\n    unescapeHTML,\n    unified_strdate,\n    unsmuggle_url,\n    uppercase_escape,\n    urlencode_postdata,\n)\n\n\nclass YoutubeBaseInfoExtractor(InfoExtractor):\n    \"\"\"Provide base functions for Youtube extractors\"\"\"\n    _LOGIN_URL = 'https://accounts.google.com/ServiceLogin'\n    _TWOFACTOR_URL = 'https://accounts.google.com/signin/challenge'\n\n    _LOOKUP_URL = 'https://accounts.google.com/_/signin/sl/lookup'\n    _CHALLENGE_URL = 'https://accounts.google.com/_/signin/sl/challenge'\n    _TFA_URL = 'https://accounts.google.com/_/signin/challenge?hl=en&TL={0}'\n\n    _NETRC_MACHINE = 'youtube'\n    # If True it will raise an error if no login info is provided\n    _LOGIN_REQUIRED = False\n\n    _PLAYLIST_ID_RE = r'(?:PL|LL|EC|UU|FL|RD|UL|TL)[0-9A-Za-z-_]{10,}'\n\n    def _set_language(self):\n        self._set_cookie(\n            '.youtube.com', 'PREF', 'f1=50000000&hl=en',\n            # YouTube sets the expire time to about two months\n            expire_time=time.time() + 2 * 30 * 24 * 3600)\n\n    def _ids_to_results(self, ids):\n        return [\n            self.url_result(vid_id, 'Youtube', video_id=vid_id)\n            for vid_id in ids]\n\n    def _login(self):\n        \"\"\"\n        Attempt to log in to YouTube.\n        True is returned if successful or skipped.\n        False is returned if login failed.\n\n        If _LOGIN_REQUIRED is set and no authentication was provided, an error is raised.\n        \"\"\"\n        (username, password) = self._get_login_info()\n        # No authentication to be performed\n        if username is None:\n            if self._LOGIN_REQUIRED:\n                raise ExtractorError('No login info available, needed for using %s.' % self.IE_NAME, expected=True)\n            return True\n\n        login_page = self._download_webpage(\n            self._LOGIN_URL, None,\n            note='Downloading login page',\n            errnote='unable to fetch login page', fatal=False)\n        if login_page is False:\n            return\n\n        login_form = self._hidden_inputs(login_page)\n\n        def req(url, f_req, note, errnote):\n            data = login_form.copy()\n            data.update({\n                'pstMsg': 1,\n                'checkConnection': 'youtube',\n                'checkedDomains': 'youtube',\n                'hl': 'en',\n                'deviceinfo': '[null,null,null,[],null,\"US\",null,null,[],\"GlifWebSignIn\",null,[null,null,[]]]',\n                'f.req': json.dumps(f_req),\n                'flowName': 'GlifWebSignIn',\n                'flowEntry': 'ServiceLogin',\n            })\n            return self._download_json(\n                url, None, note=note, errnote=errnote,\n                transform_source=lambda s: re.sub(r'^[^[]*', '', s),\n                fatal=False,\n                data=urlencode_postdata(data), headers={\n                    'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8',\n                    'Google-Accounts-XSRF': 1,\n                })\n\n        def warn(message):\n            self._downloader.report_warning(message)\n\n        lookup_req = [\n            username,\n            None, [], None, 'US', None, None, 2, False, True,\n            [\n                None, None,\n                [2, 1, None, 1,\n                 'https://accounts.google.com/ServiceLogin?passive=true&continue=https%3A%2F%2Fwww.youtube.com%2Fsignin%3Fnext%3D%252F%26action_handle_signin%3Dtrue%26hl%3Den%26app%3Ddesktop%26feature%3Dsign_in_button&hl=en&service=youtube&uilel=3&requestPath=%2FServiceLogin&Page=PasswordSeparationSignIn',\n                 None, [], 4],\n                1, [None, None, []], None, None, None, True\n            ],\n            username,\n        ]\n\n        lookup_results = req(\n            self._LOOKUP_URL, lookup_req,\n            'Looking up account info', 'Unable to look up account info')\n\n        if lookup_results is False:\n            return False\n\n        user_hash = try_get(lookup_results, lambda x: x[0][2], compat_str)\n        if not user_hash:\n            warn('Unable to extract user hash')\n            return False\n\n        challenge_req = [\n            user_hash,\n            None, 1, None, [1, None, None, None, [password, None, True]],\n            [\n                None, None, [2, 1, None, 1, 'https://accounts.google.com/ServiceLogin?passive=true&continue=https%3A%2F%2Fwww.youtube.com%2Fsignin%3Fnext%3D%252F%26action_handle_signin%3Dtrue%26hl%3Den%26app%3Ddesktop%26feature%3Dsign_in_button&hl=en&service=youtube&uilel=3&requestPath=%2FServiceLogin&Page=PasswordSeparationSignIn', None, [], 4],\n                1, [None, None, []], None, None, None, True\n            ]]\n\n        challenge_results = req(\n            self._CHALLENGE_URL, challenge_req,\n            'Logging in', 'Unable to log in')\n\n        if challenge_results is False:\n            return\n\n        login_res = try_get(challenge_results, lambda x: x[0][5], list)\n        if login_res:\n            login_msg = try_get(login_res, lambda x: x[5], compat_str)\n            warn(\n                'Unable to login: %s' % 'Invalid password'\n                if login_msg == 'INCORRECT_ANSWER_ENTERED' else login_msg)\n            return False\n\n        res = try_get(challenge_results, lambda x: x[0][-1], list)\n        if not res:\n            warn('Unable to extract result entry')\n            return False\n\n        tfa = try_get(res, lambda x: x[0][0], list)\n        if tfa:\n            tfa_str = try_get(tfa, lambda x: x[2], compat_str)\n            if tfa_str == 'TWO_STEP_VERIFICATION':\n                # SEND_SUCCESS - TFA code has been successfully sent to phone\n                # QUOTA_EXCEEDED - reached the limit of TFA codes\n                status = try_get(tfa, lambda x: x[5], compat_str)\n                if status == 'QUOTA_EXCEEDED':\n                    warn('Exceeded the limit of TFA codes, try later')\n                    return False\n\n                tl = try_get(challenge_results, lambda x: x[1][2], compat_str)\n                if not tl:\n                    warn('Unable to extract TL')\n                    return False\n\n                tfa_code = self._get_tfa_info('2-step verification code')\n\n                if not tfa_code:\n                    warn(\n                        'Two-factor authentication required. Provide it either interactively or with --twofactor <code>'\n                        '(Note that only TOTP (Google Authenticator App) codes work at this time.)')\n                    return False\n\n                tfa_code = remove_start(tfa_code, 'G-')\n\n                tfa_req = [\n                    user_hash, None, 2, None,\n                    [\n                        9, None, None, None, None, None, None, None,\n                        [None, tfa_code, True, 2]\n                    ]]\n\n                tfa_results = req(\n                    self._TFA_URL.format(tl), tfa_req,\n                    'Submitting TFA code', 'Unable to submit TFA code')\n\n                if tfa_results is False:\n                    return False\n\n                tfa_res = try_get(tfa_results, lambda x: x[0][5], list)\n                if tfa_res:\n                    tfa_msg = try_get(tfa_res, lambda x: x[5], compat_str)\n                    warn(\n                        'Unable to finish TFA: %s' % 'Invalid TFA code'\n                        if tfa_msg == 'INCORRECT_ANSWER_ENTERED' else tfa_msg)\n                    return False\n\n                check_cookie_url = try_get(\n                    tfa_results, lambda x: x[0][-1][2], compat_str)\n        else:\n            check_cookie_url = try_get(res, lambda x: x[2], compat_str)\n\n        if not check_cookie_url:\n            warn('Unable to extract CheckCookie URL')\n            return False\n\n        check_cookie_results = self._download_webpage(\n            check_cookie_url, None, 'Checking cookie', fatal=False)\n\n        if check_cookie_results is False:\n            return False\n\n        if 'https://myaccount.google.com/' not in check_cookie_results:\n            warn('Unable to log in')\n            return False\n\n        return True\n\n    def _download_webpage(self, *args, **kwargs):\n        kwargs.setdefault('query', {})['disable_polymer'] = 'true'\n        return super(YoutubeBaseInfoExtractor, self)._download_webpage(\n            *args, **compat_kwargs(kwargs))\n\n    def _real_initialize(self):\n        if self._downloader is None:\n            return\n        self._set_language()\n        if not self._login():\n            return\n\n\nclass YoutubeEntryListBaseInfoExtractor(YoutubeBaseInfoExtractor):\n    # Extract entries from page with \"Load more\" button\n    def _entries(self, page, playlist_id):\n        more_widget_html = content_html = page\n        for page_num in itertools.count(1):\n            for entry in self._process_page(content_html):\n                yield entry\n\n            mobj = re.search(r'data-uix-load-more-href=\"/?(?P<more>[^\"]+)\"', more_widget_html)\n            if not mobj:\n                break\n\n            more = self._download_json(\n                'https://youtube.com/%s' % mobj.group('more'), playlist_id,\n                'Downloading page #%s' % page_num,\n                transform_source=uppercase_escape)\n            content_html = more['content_html']\n            if not content_html.strip():\n                # Some webpages show a \"Load more\" button but they don't\n                # have more videos\n                break\n            more_widget_html = more['load_more_widget_html']\n\n\nclass YoutubePlaylistBaseInfoExtractor(YoutubeEntryListBaseInfoExtractor):\n    def _process_page(self, content):\n        for video_id, video_title in self.extract_videos_from_page(content):\n            yield self.url_result(video_id, 'Youtube', video_id, video_title)\n\n    def extract_videos_from_page(self, page):\n        ids_in_page = []\n        titles_in_page = []\n        for mobj in re.finditer(self._VIDEO_RE, page):\n            # The link with index 0 is not the first video of the playlist (not sure if still actual)\n            if 'index' in mobj.groupdict() and mobj.group('id') == '0':\n                continue\n            video_id = mobj.group('id')\n            video_title = unescapeHTML(mobj.group('title'))\n            if video_title:\n                video_title = video_title.strip()\n            try:\n                idx = ids_in_page.index(video_id)\n                if video_title and not titles_in_page[idx]:\n                    titles_in_page[idx] = video_title\n            except ValueError:\n                ids_in_page.append(video_id)\n                titles_in_page.append(video_title)\n        return zip(ids_in_page, titles_in_page)\n\n\nclass YoutubePlaylistsBaseInfoExtractor(YoutubeEntryListBaseInfoExtractor):\n    def _process_page(self, content):\n        for playlist_id in orderedSet(re.findall(\n                r'<h3[^>]+class=\"[^\"]*yt-lockup-title[^\"]*\"[^>]*><a[^>]+href=\"/?playlist\\?list=([0-9A-Za-z-_]{10,})\"',\n                content)):\n            yield self.url_result(\n                'https://www.youtube.com/playlist?list=%s' % playlist_id, 'YoutubePlaylist')\n\n    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        webpage = self._download_webpage(url, playlist_id)\n        title = self._og_search_title(webpage, fatal=False)\n        return self.playlist_result(self._entries(webpage, playlist_id), playlist_id, title)\n\n\nclass YoutubeIE(YoutubeBaseInfoExtractor):\n    IE_DESC = 'YouTube.com'\n    _VALID_URL = r\"\"\"(?x)^\n                     (\n                         (?:https?://|//)                                    # http(s):// or protocol-independent URL\n                         (?:(?:(?:(?:\\w+\\.)?[yY][oO][uU][tT][uU][bB][eE](?:-nocookie)?\\.com/|\n                            (?:www\\.)?deturl\\.com/www\\.youtube\\.com/|\n                            (?:www\\.)?pwnyoutube\\.com/|\n                            (?:www\\.)?hooktube\\.com/|\n                            (?:www\\.)?yourepeat\\.com/|\n                            tube\\.majestyc\\.net/|\n                            youtube\\.googleapis\\.com/)                        # the various hostnames, with wildcard subdomains\n                         (?:.*?\\#/)?                                          # handle anchor (#/) redirect urls\n                         (?:                                                  # the various things that can precede the ID:\n                             (?:(?:v|embed|e)/(?!videoseries))                # v/ or embed/ or e/\n                             |(?:                                             # or the v= param in all its forms\n                                 (?:(?:watch|movie)(?:_popup)?(?:\\.php)?/?)?  # preceding watch(_popup|.php) or nothing (like /?v=xxxx)\n                                 (?:\\?|\\#!?)                                  # the params delimiter ? or # or #!\n                                 (?:.*?[&;])??                                # any other preceding param (like /?s=tuff&v=xxxx or ?s=tuff&amp;v=V36LpHqtcDY)\n                                 v=\n                             )\n                         ))\n                         |(?:\n                            youtu\\.be|                                        # just youtu.be/xxxx\n                            vid\\.plus|                                        # or vid.plus/xxxx\n                            zwearz\\.com/watch|                                # or zwearz.com/watch/xxxx\n                         )/\n                         |(?:www\\.)?cleanvideosearch\\.com/media/action/yt/watch\\?videoId=\n                         )\n                     )?                                                       # all until now is optional -> you can pass the naked ID\n                     ([0-9A-Za-z_-]{11})                                      # here is it! the YouTube video ID\n                     (?!.*?\\blist=\n                        (?:\n                            %(playlist_id)s|                                  # combined list/video URLs are handled by the playlist IE\n                            WL                                                # WL are handled by the watch later IE\n                        )\n                     )\n                     (?(1).+)?                                                # if we found the ID, everything can follow\n                     $\"\"\" % {'playlist_id': YoutubeBaseInfoExtractor._PLAYLIST_ID_RE}\n    _NEXT_URL_RE = r'[\\?&]next_url=([^&]+)'\n    _formats = {\n        '5': {'ext': 'flv', 'width': 400, 'height': 240, 'acodec': 'mp3', 'abr': 64, 'vcodec': 'h263'},\n        '6': {'ext': 'flv', 'width': 450, 'height': 270, 'acodec': 'mp3', 'abr': 64, 'vcodec': 'h263'},\n        '13': {'ext': '3gp', 'acodec': 'aac', 'vcodec': 'mp4v'},\n        '17': {'ext': '3gp', 'width': 176, 'height': 144, 'acodec': 'aac', 'abr': 24, 'vcodec': 'mp4v'},\n        '18': {'ext': 'mp4', 'width': 640, 'height': 360, 'acodec': 'aac', 'abr': 96, 'vcodec': 'h264'},\n        '22': {'ext': 'mp4', 'width': 1280, 'height': 720, 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264'},\n        '34': {'ext': 'flv', 'width': 640, 'height': 360, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},\n        '35': {'ext': 'flv', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},\n        # itag 36 videos are either 320x180 (BaW_jenozKc) or 320x240 (__2ABJjxzNo), abr varies as well\n        '36': {'ext': '3gp', 'width': 320, 'acodec': 'aac', 'vcodec': 'mp4v'},\n        '37': {'ext': 'mp4', 'width': 1920, 'height': 1080, 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264'},\n        '38': {'ext': 'mp4', 'width': 4096, 'height': 3072, 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264'},\n        '43': {'ext': 'webm', 'width': 640, 'height': 360, 'acodec': 'vorbis', 'abr': 128, 'vcodec': 'vp8'},\n        '44': {'ext': 'webm', 'width': 854, 'height': 480, 'acodec': 'vorbis', 'abr': 128, 'vcodec': 'vp8'},\n        '45': {'ext': 'webm', 'width': 1280, 'height': 720, 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8'},\n        '46': {'ext': 'webm', 'width': 1920, 'height': 1080, 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8'},\n        '59': {'ext': 'mp4', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},\n        '78': {'ext': 'mp4', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},\n\n\n        # 3D videos\n        '82': {'ext': 'mp4', 'height': 360, 'format_note': '3D', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -20},\n        '83': {'ext': 'mp4', 'height': 480, 'format_note': '3D', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -20},\n        '84': {'ext': 'mp4', 'height': 720, 'format_note': '3D', 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264', 'preference': -20},\n        '85': {'ext': 'mp4', 'height': 1080, 'format_note': '3D', 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264', 'preference': -20},\n        '100': {'ext': 'webm', 'height': 360, 'format_note': '3D', 'acodec': 'vorbis', 'abr': 128, 'vcodec': 'vp8', 'preference': -20},\n        '101': {'ext': 'webm', 'height': 480, 'format_note': '3D', 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8', 'preference': -20},\n        '102': {'ext': 'webm', 'height': 720, 'format_note': '3D', 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8', 'preference': -20},\n\n        # Apple HTTP Live Streaming\n        '91': {'ext': 'mp4', 'height': 144, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 48, 'vcodec': 'h264', 'preference': -10},\n        '92': {'ext': 'mp4', 'height': 240, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 48, 'vcodec': 'h264', 'preference': -10},\n        '93': {'ext': 'mp4', 'height': 360, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -10},\n        '94': {'ext': 'mp4', 'height': 480, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -10},\n        '95': {'ext': 'mp4', 'height': 720, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 256, 'vcodec': 'h264', 'preference': -10},\n        '96': {'ext': 'mp4', 'height': 1080, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 256, 'vcodec': 'h264', 'preference': -10},\n        '132': {'ext': 'mp4', 'height': 240, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 48, 'vcodec': 'h264', 'preference': -10},\n        '151': {'ext': 'mp4', 'height': 72, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 24, 'vcodec': 'h264', 'preference': -10},\n\n        # DASH mp4 video\n        '133': {'ext': 'mp4', 'height': 240, 'format_note': 'DASH video', 'vcodec': 'h264'},\n        '134': {'ext': 'mp4', 'height': 360, 'format_note': 'DASH video', 'vcodec': 'h264'},\n        '135': {'ext': 'mp4', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'h264'},\n        '136': {'ext': 'mp4', 'height': 720, 'format_note': 'DASH video', 'vcodec': 'h264'},\n        '137': {'ext': 'mp4', 'height': 1080, 'format_note': 'DASH video', 'vcodec': 'h264'},\n        '138': {'ext': 'mp4', 'format_note': 'DASH video', 'vcodec': 'h264'},  # Height can vary (https://github.com/rg3/youtube-dl/issues/4559)\n        '160': {'ext': 'mp4', 'height': 144, 'format_note': 'DASH video', 'vcodec': 'h264'},\n        '212': {'ext': 'mp4', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'h264'},\n        '264': {'ext': 'mp4', 'height': 1440, 'format_note': 'DASH video', 'vcodec': 'h264'},\n        '298': {'ext': 'mp4', 'height': 720, 'format_note': 'DASH video', 'vcodec': 'h264', 'fps': 60},\n        '299': {'ext': 'mp4', 'height': 1080, 'format_note': 'DASH video', 'vcodec': 'h264', 'fps': 60},\n        '266': {'ext': 'mp4', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'h264'},\n\n        # Dash mp4 audio\n        '139': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 48, 'container': 'm4a_dash'},\n        '140': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 128, 'container': 'm4a_dash'},\n        '141': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 256, 'container': 'm4a_dash'},\n        '256': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'container': 'm4a_dash'},\n        '258': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'container': 'm4a_dash'},\n        '325': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'dtse', 'container': 'm4a_dash'},\n        '328': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'ec-3', 'container': 'm4a_dash'},\n\n        # Dash webm\n        '167': {'ext': 'webm', 'height': 360, 'width': 640, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},\n        '168': {'ext': 'webm', 'height': 480, 'width': 854, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},\n        '169': {'ext': 'webm', 'height': 720, 'width': 1280, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},\n        '170': {'ext': 'webm', 'height': 1080, 'width': 1920, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},\n        '218': {'ext': 'webm', 'height': 480, 'width': 854, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},\n        '219': {'ext': 'webm', 'height': 480, 'width': 854, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},\n        '278': {'ext': 'webm', 'height': 144, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp9'},\n        '242': {'ext': 'webm', 'height': 240, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '243': {'ext': 'webm', 'height': 360, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '244': {'ext': 'webm', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '245': {'ext': 'webm', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '246': {'ext': 'webm', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '247': {'ext': 'webm', 'height': 720, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '248': {'ext': 'webm', 'height': 1080, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '271': {'ext': 'webm', 'height': 1440, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        # itag 272 videos are either 3840x2160 (e.g. RtoitU2A-3E) or 7680x4320 (sLprVF6d7Ug)\n        '272': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '302': {'ext': 'webm', 'height': 720, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60},\n        '303': {'ext': 'webm', 'height': 1080, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60},\n        '308': {'ext': 'webm', 'height': 1440, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60},\n        '313': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'vp9'},\n        '315': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60},\n\n        # Dash webm audio\n        '171': {'ext': 'webm', 'acodec': 'vorbis', 'format_note': 'DASH audio', 'abr': 128},\n        '172': {'ext': 'webm', 'acodec': 'vorbis', 'format_note': 'DASH audio', 'abr': 256},\n\n        # Dash webm audio with opus inside\n        '249': {'ext': 'webm', 'format_note': 'DASH audio', 'acodec': 'opus', 'abr': 50},\n        '250': {'ext': 'webm', 'format_note': 'DASH audio', 'acodec': 'opus', 'abr': 70},\n        '251': {'ext': 'webm', 'format_note': 'DASH audio', 'acodec': 'opus', 'abr': 160},\n\n        # RTMP (unnamed)\n        '_rtmp': {'protocol': 'rtmp'},\n    }\n    _SUBTITLE_FORMATS = ('ttml', 'vtt')\n\n    _GEO_BYPASS = False\n\n    IE_NAME = 'youtube'\n    _TESTS = [\n        {\n            'url': 'https://www.youtube.com/watch?v=BaW_jenozKc&t=1s&end=9',\n            'info_dict': {\n                'id': 'BaW_jenozKc',\n                'ext': 'mp4',\n                'title': 'youtube-dl test video \"\\'/\\\\\u00e4\u21ad\ud835\udd50',\n                'uploader': 'Philipp Hagemeister',\n                'uploader_id': 'phihag',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/phihag',\n                'upload_date': '20121002',\n                'license': 'Standard YouTube License',\n                'description': 'test chars:  \"\\'/\\\\\u00e4\u21ad\ud835\udd50\\ntest URL: https://github.com/rg3/youtube-dl/issues/1892\\n\\nThis is a test video for youtube-dl.\\n\\nFor more information, contact phihag@phihag.de .',\n                'categories': ['Science & Technology'],\n                'tags': ['youtube-dl'],\n                'duration': 10,\n                'like_count': int,\n                'dislike_count': int,\n                'start_time': 1,\n                'end_time': 9,\n            }\n        },\n        {\n            'url': 'https://www.youtube.com/watch?v=UxxajLWwzqY',\n            'note': 'Test generic use_cipher_signature video (#897)',\n            'info_dict': {\n                'id': 'UxxajLWwzqY',\n                'ext': 'mp4',\n                'upload_date': '20120506',\n                'title': 'Icona Pop - I Love It (feat. Charli XCX) [OFFICIAL VIDEO]',\n                'alt_title': 'I Love It (feat. Charli XCX)',\n                'description': 'md5:f3ceb5ef83a08d95b9d146f973157cc8',\n                'tags': ['Icona Pop i love it', 'sweden', 'pop music', 'big beat records', 'big beat', 'charli',\n                         'xcx', 'charli xcx', 'girls', 'hbo', 'i love it', \"i don't care\", 'icona', 'pop',\n                         'iconic ep', 'iconic', 'love', 'it'],\n                'duration': 180,\n                'uploader': 'Icona Pop',\n                'uploader_id': 'IconaPop',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/IconaPop',\n                'license': 'Standard YouTube License',\n                'creator': 'Icona Pop',\n            }\n        },\n        {\n            'url': 'https://www.youtube.com/watch?v=07FYdnEawAQ',\n            'note': 'Test VEVO video with age protection (#956)',\n            'info_dict': {\n                'id': '07FYdnEawAQ',\n                'ext': 'mp4',\n                'upload_date': '20130703',\n                'title': 'Justin Timberlake - Tunnel Vision (Explicit)',\n                'alt_title': 'Tunnel Vision',\n                'description': 'md5:64249768eec3bc4276236606ea996373',\n                'duration': 419,\n                'uploader': 'justintimberlakeVEVO',\n                'uploader_id': 'justintimberlakeVEVO',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/justintimberlakeVEVO',\n                'license': 'Standard YouTube License',\n                'creator': 'Justin Timberlake',\n                'age_limit': 18,\n            }\n        },\n        {\n            'url': '//www.YouTube.com/watch?v=yZIXLfi8CZQ',\n            'note': 'Embed-only video (#1746)',\n            'info_dict': {\n                'id': 'yZIXLfi8CZQ',\n                'ext': 'mp4',\n                'upload_date': '20120608',\n                'title': 'Principal Sexually Assaults A Teacher - Episode 117 - 8th June 2012',\n                'description': 'md5:09b78bd971f1e3e289601dfba15ca4f7',\n                'uploader': 'SET India',\n                'uploader_id': 'setindia',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/setindia',\n                'license': 'Standard YouTube License',\n                'age_limit': 18,\n            }\n        },\n        {\n            'url': 'https://www.youtube.com/watch?v=BaW_jenozKc&v=UxxajLWwzqY',\n            'note': 'Use the first video ID in the URL',\n            'info_dict': {\n                'id': 'BaW_jenozKc',\n                'ext': 'mp4',\n                'title': 'youtube-dl test video \"\\'/\\\\\u00e4\u21ad\ud835\udd50',\n                'uploader': 'Philipp Hagemeister',\n                'uploader_id': 'phihag',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/phihag',\n                'upload_date': '20121002',\n                'license': 'Standard YouTube License',\n                'description': 'test chars:  \"\\'/\\\\\u00e4\u21ad\ud835\udd50\\ntest URL: https://github.com/rg3/youtube-dl/issues/1892\\n\\nThis is a test video for youtube-dl.\\n\\nFor more information, contact phihag@phihag.de .',\n                'categories': ['Science & Technology'],\n                'tags': ['youtube-dl'],\n                'duration': 10,\n                'like_count': int,\n                'dislike_count': int,\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            'url': 'https://www.youtube.com/watch?v=a9LDPn-MO4I',\n            'note': '256k DASH audio (format 141) via DASH manifest',\n            'info_dict': {\n                'id': 'a9LDPn-MO4I',\n                'ext': 'm4a',\n                'upload_date': '20121002',\n                'uploader_id': '8KVIDEO',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/8KVIDEO',\n                'description': '',\n                'uploader': '8KVIDEO',\n                'license': 'Standard YouTube License',\n                'title': 'UHDTV TEST 8K VIDEO.mp4'\n            },\n            'params': {\n                'youtube_include_dash_manifest': True,\n                'format': '141',\n            },\n            'skip': 'format 141 not served anymore',\n        },\n        # DASH manifest with encrypted signature\n        {\n            'url': 'https://www.youtube.com/watch?v=IB3lcPjvWLA',\n            'info_dict': {\n                'id': 'IB3lcPjvWLA',\n                'ext': 'm4a',\n                'title': 'Afrojack, Spree Wilson - The Spark ft. Spree Wilson',\n                'description': 'md5:12e7067fa6735a77bdcbb58cb1187d2d',\n                'duration': 244,\n                'uploader': 'AfrojackVEVO',\n                'uploader_id': 'AfrojackVEVO',\n                'upload_date': '20131011',\n                'license': 'Standard YouTube License',\n            },\n            'params': {\n                'youtube_include_dash_manifest': True,\n                'format': '141/bestaudio[ext=m4a]',\n            },\n        },\n        # JS player signature function name containing $\n        {\n            'url': 'https://www.youtube.com/watch?v=nfWlot6h_JM',\n            'info_dict': {\n                'id': 'nfWlot6h_JM',\n                'ext': 'm4a',\n                'title': 'Taylor Swift - Shake It Off',\n                'alt_title': 'Shake It Off',\n                'description': 'md5:95f66187cd7c8b2c13eb78e1223b63c3',\n                'duration': 242,\n                'uploader': 'TaylorSwiftVEVO',\n                'uploader_id': 'TaylorSwiftVEVO',\n                'upload_date': '20140818',\n                'license': 'Standard YouTube License',\n                'creator': 'Taylor Swift',\n            },\n            'params': {\n                'youtube_include_dash_manifest': True,\n                'format': '141/bestaudio[ext=m4a]',\n            },\n        },\n        # Controversy video\n        {\n            'url': 'https://www.youtube.com/watch?v=T4XJQO3qol8',\n            'info_dict': {\n                'id': 'T4XJQO3qol8',\n                'ext': 'mp4',\n                'duration': 219,\n                'upload_date': '20100909',\n                'uploader': 'The Amazing Atheist',\n                'uploader_id': 'TheAmazingAtheist',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/TheAmazingAtheist',\n                'license': 'Standard YouTube License',\n                'title': 'Burning Everyone\\'s Koran',\n                'description': 'SUBSCRIBE: http://www.youtube.com/saturninefilms\\n\\nEven Obama has taken a stand against freedom on this issue: http://www.huffingtonpost.com/2010/09/09/obama-gma-interview-quran_n_710282.html',\n            }\n        },\n        # Normal age-gate video (No vevo, embed allowed)\n        {\n            'url': 'https://youtube.com/watch?v=HtVdAasjOgU',\n            'info_dict': {\n                'id': 'HtVdAasjOgU',\n                'ext': 'mp4',\n                'title': 'The Witcher 3: Wild Hunt - The Sword Of Destiny Trailer',\n                'description': r're:(?s).{100,}About the Game\\n.*?The Witcher 3: Wild Hunt.{100,}',\n                'duration': 142,\n                'uploader': 'The Witcher',\n                'uploader_id': 'WitcherGame',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/WitcherGame',\n                'upload_date': '20140605',\n                'license': 'Standard YouTube License',\n                'age_limit': 18,\n            },\n        },\n        # Age-gate video with encrypted signature\n        {\n            'url': 'https://www.youtube.com/watch?v=6kLq3WMV1nU',\n            'info_dict': {\n                'id': '6kLq3WMV1nU',\n                'ext': 'mp4',\n                'title': 'Dedication To My Ex (Miss That) (Lyric Video)',\n                'description': 'md5:33765bb339e1b47e7e72b5490139bb41',\n                'duration': 247,\n                'uploader': 'LloydVEVO',\n                'uploader_id': 'LloydVEVO',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/LloydVEVO',\n                'upload_date': '20110629',\n                'license': 'Standard YouTube License',\n                'age_limit': 18,\n            },\n        },\n        # video_info is None (https://github.com/rg3/youtube-dl/issues/4421)\n        # YouTube Red ad is not captured for creator\n        {\n            'url': '__2ABJjxzNo',\n            'info_dict': {\n                'id': '__2ABJjxzNo',\n                'ext': 'mp4',\n                'duration': 266,\n                'upload_date': '20100430',\n                'uploader_id': 'deadmau5',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/deadmau5',\n                'creator': 'deadmau5',\n                'description': 'md5:12c56784b8032162bb936a5f76d55360',\n                'uploader': 'deadmau5',\n                'license': 'Standard YouTube License',\n                'title': 'Deadmau5 - Some Chords (HD)',\n                'alt_title': 'Some Chords',\n            },\n            'expected_warnings': [\n                'DASH manifest missing',\n            ]\n        },\n        # Olympics (https://github.com/rg3/youtube-dl/issues/4431)\n        {\n            'url': 'lqQg6PlCWgI',\n            'info_dict': {\n                'id': 'lqQg6PlCWgI',\n                'ext': 'mp4',\n                'duration': 6085,\n                'upload_date': '20150827',\n                'uploader_id': 'olympic',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/olympic',\n                'license': 'Standard YouTube License',\n                'description': 'HO09  - Women -  GER-AUS - Hockey - 31 July 2012 - London 2012 Olympic Games',\n                'uploader': 'Olympic',\n                'title': 'Hockey - Women -  GER-AUS - London 2012 Olympic Games',\n            },\n            'params': {\n                'skip_download': 'requires avconv',\n            }\n        },\n        # Non-square pixels\n        {\n            'url': 'https://www.youtube.com/watch?v=_b-2C3KPAM0',\n            'info_dict': {\n                'id': '_b-2C3KPAM0',\n                'ext': 'mp4',\n                'stretched_ratio': 16 / 9.,\n                'duration': 85,\n                'upload_date': '20110310',\n                'uploader_id': 'AllenMeow',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/AllenMeow',\n                'description': 'made by Wacom from Korea | \u5b57\u5e55&\u52a0\u6cb9\u6dfb\u918b by TY\\'s Allen | \u611f\u8b1dheylisa00cavey1001\u540c\u5b78\u71b1\u60c5\u63d0\u4f9b\u6897\u53ca\u7ffb\u8b6f',\n                'uploader': '\u5b6b\u827e\u502b',\n                'license': 'Standard YouTube License',\n                'title': '[A-made] \u8b8a\u614b\u598d\u5b57\u5e55\u7248 \u592a\u598d \u6211\u5c31\u662f\u9019\u6a23\u7684\u4eba',\n            },\n        },\n        # url_encoded_fmt_stream_map is empty string\n        {\n            'url': 'qEJwOuvDf7I',\n            'info_dict': {\n                'id': 'qEJwOuvDf7I',\n                'ext': 'webm',\n                'title': '\u041e\u0431\u0441\u0443\u0436\u0434\u0435\u043d\u0438\u0435 \u0441\u0443\u0434\u0435\u0431\u043d\u043e\u0439 \u043f\u0440\u0430\u043a\u0442\u0438\u043a\u0438 \u043f\u043e \u0432\u044b\u0431\u043e\u0440\u0430\u043c 14 \u0441\u0435\u043d\u0442\u044f\u0431\u0440\u044f 2014 \u0433\u043e\u0434\u0430 \u0432 \u0421\u0430\u043d\u043a\u0442-\u041f\u0435\u0442\u0435\u0440\u0431\u0443\u0440\u0433\u0435',\n                'description': '',\n                'upload_date': '20150404',\n                'uploader_id': 'spbelect',\n                'uploader': '\u041d\u0430\u0431\u043b\u044e\u0434\u0430\u0442\u0435\u043b\u0438 \u041f\u0435\u0442\u0435\u0440\u0431\u0443\u0440\u0433\u0430',\n            },\n            'params': {\n                'skip_download': 'requires avconv',\n            },\n            'skip': 'This live event has ended.',\n        },\n        # Extraction from multiple DASH manifests (https://github.com/rg3/youtube-dl/pull/6097)\n        {\n            'url': 'https://www.youtube.com/watch?v=FIl7x6_3R5Y',\n            'info_dict': {\n                'id': 'FIl7x6_3R5Y',\n                'ext': 'mp4',\n                'title': 'md5:7b81415841e02ecd4313668cde88737a',\n                'description': 'md5:116377fd2963b81ec4ce64b542173306',\n                'duration': 220,\n                'upload_date': '20150625',\n                'uploader_id': 'dorappi2000',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/dorappi2000',\n                'uploader': 'dorappi2000',\n                'license': 'Standard YouTube License',\n                'formats': 'mincount:32',\n            },\n        },\n        # DASH manifest with segment_list\n        {\n            'url': 'https://www.youtube.com/embed/CsmdDsKjzN8',\n            'md5': '8ce563a1d667b599d21064e982ab9e31',\n            'info_dict': {\n                'id': 'CsmdDsKjzN8',\n                'ext': 'mp4',\n                'upload_date': '20150501',  # According to '<meta itemprop=\"datePublished\"', but in other places it's 20150510\n                'uploader': 'Airtek',\n                'description': 'Retransmisi\u00f3n en directo de la XVIII media marat\u00f3n de Zaragoza.',\n                'uploader_id': 'UCzTzUmjXxxacNnL8I3m4LnQ',\n                'license': 'Standard YouTube License',\n                'title': 'Retransmisi\u00f3n XVIII Media marat\u00f3n Zaragoza 2015',\n            },\n            'params': {\n                'youtube_include_dash_manifest': True,\n                'format': '135',  # bestvideo\n            },\n            'skip': 'This live event has ended.',\n        },\n        {\n            # Multifeed videos (multiple cameras), URL is for Main Camera\n            'url': 'https://www.youtube.com/watch?v=jqWvoWXjCVs',\n            'info_dict': {\n                'id': 'jqWvoWXjCVs',\n                'title': 'teamPGP: Rocket League Noob Stream',\n                'description': 'md5:dc7872fb300e143831327f1bae3af010',\n            },\n            'playlist': [{\n                'info_dict': {\n                    'id': 'jqWvoWXjCVs',\n                    'ext': 'mp4',\n                    'title': 'teamPGP: Rocket League Noob Stream (Main Camera)',\n                    'description': 'md5:dc7872fb300e143831327f1bae3af010',\n                    'duration': 7335,\n                    'upload_date': '20150721',\n                    'uploader': 'Beer Games Beer',\n                    'uploader_id': 'beergamesbeer',\n                    'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/beergamesbeer',\n                    'license': 'Standard YouTube License',\n                },\n            }, {\n                'info_dict': {\n                    'id': '6h8e8xoXJzg',\n                    'ext': 'mp4',\n                    'title': 'teamPGP: Rocket League Noob Stream (kreestuh)',\n                    'description': 'md5:dc7872fb300e143831327f1bae3af010',\n                    'duration': 7337,\n                    'upload_date': '20150721',\n                    'uploader': 'Beer Games Beer',\n                    'uploader_id': 'beergamesbeer',\n                    'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/beergamesbeer',\n                    'license': 'Standard YouTube License',\n                },\n            }, {\n                'info_dict': {\n                    'id': 'PUOgX5z9xZw',\n                    'ext': 'mp4',\n                    'title': 'teamPGP: Rocket League Noob Stream (grizzle)',\n                    'description': 'md5:dc7872fb300e143831327f1bae3af010',\n                    'duration': 7337,\n                    'upload_date': '20150721',\n                    'uploader': 'Beer Games Beer',\n                    'uploader_id': 'beergamesbeer',\n                    'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/beergamesbeer',\n                    'license': 'Standard YouTube License',\n                },\n            }, {\n                'info_dict': {\n                    'id': 'teuwxikvS5k',\n                    'ext': 'mp4',\n                    'title': 'teamPGP: Rocket League Noob Stream (zim)',\n                    'description': 'md5:dc7872fb300e143831327f1bae3af010',\n                    'duration': 7334,\n                    'upload_date': '20150721',\n                    'uploader': 'Beer Games Beer',\n                    'uploader_id': 'beergamesbeer',\n                    'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/beergamesbeer',\n                    'license': 'Standard YouTube License',\n                },\n            }],\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # Multifeed video with comma in title (see https://github.com/rg3/youtube-dl/issues/8536)\n            'url': 'https://www.youtube.com/watch?v=gVfLd0zydlo',\n            'info_dict': {\n                'id': 'gVfLd0zydlo',\n                'title': 'DevConf.cz 2016 Day 2 Workshops 1 14:00 - 15:30',\n            },\n            'playlist_count': 2,\n            'skip': 'Not multifeed anymore',\n        },\n        {\n            'url': 'https://vid.plus/FlRa-iH7PGw',\n            'only_matching': True,\n        },\n        {\n            'url': 'https://zwearz.com/watch/9lWxNJF-ufM/electra-woman-dyna-girl-official-trailer-grace-helbig.html',\n            'only_matching': True,\n        },\n        {\n            # Title with JS-like syntax \"};\" (see https://github.com/rg3/youtube-dl/issues/7468)\n            # Also tests cut-off URL expansion in video description (see\n            # https://github.com/rg3/youtube-dl/issues/1892,\n            # https://github.com/rg3/youtube-dl/issues/8164)\n            'url': 'https://www.youtube.com/watch?v=lsguqyKfVQg',\n            'info_dict': {\n                'id': 'lsguqyKfVQg',\n                'ext': 'mp4',\n                'title': '{dark walk}; Loki/AC/Dishonored; collab w/Elflover21',\n                'alt_title': 'Dark Walk',\n                'description': 'md5:8085699c11dc3f597ce0410b0dcbb34a',\n                'duration': 133,\n                'upload_date': '20151119',\n                'uploader_id': 'IronSoulElf',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/IronSoulElf',\n                'uploader': 'IronSoulElf',\n                'license': 'Standard YouTube License',\n                'creator': 'Todd Haberman, Daniel Law Heath & Aaron Kaplan',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # Tags with '};' (see https://github.com/rg3/youtube-dl/issues/7468)\n            'url': 'https://www.youtube.com/watch?v=Ms7iBXnlUO8',\n            'only_matching': True,\n        },\n        {\n            # Video with yt:stretch=17:0\n            'url': 'https://www.youtube.com/watch?v=Q39EVAstoRM',\n            'info_dict': {\n                'id': 'Q39EVAstoRM',\n                'ext': 'mp4',\n                'title': 'Clash Of Clans#14 Dicas De Ataque Para CV 4',\n                'description': 'md5:ee18a25c350637c8faff806845bddee9',\n                'upload_date': '20151107',\n                'uploader_id': 'UCCr7TALkRbo3EtFzETQF1LA',\n                'uploader': 'CH GAMER DROID',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'skip': 'This video does not exist.',\n        },\n        {\n            # Video licensed under Creative Commons\n            'url': 'https://www.youtube.com/watch?v=M4gD1WSo5mA',\n            'info_dict': {\n                'id': 'M4gD1WSo5mA',\n                'ext': 'mp4',\n                'title': 'md5:e41008789470fc2533a3252216f1c1d1',\n                'description': 'md5:a677553cf0840649b731a3024aeff4cc',\n                'duration': 721,\n                'upload_date': '20150127',\n                'uploader_id': 'BerkmanCenter',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/BerkmanCenter',\n                'uploader': 'The Berkman Klein Center for Internet & Society',\n                'license': 'Creative Commons Attribution license (reuse allowed)',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # Channel-like uploader_url\n            'url': 'https://www.youtube.com/watch?v=eQcmzGIKrzg',\n            'info_dict': {\n                'id': 'eQcmzGIKrzg',\n                'ext': 'mp4',\n                'title': 'Democratic Socialism and Foreign Policy | Bernie Sanders',\n                'description': 'md5:dda0d780d5a6e120758d1711d062a867',\n                'duration': 4060,\n                'upload_date': '20151119',\n                'uploader': 'Bernie 2016',\n                'uploader_id': 'UCH1dpzjCEiGAt8CXkryhkZg',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/channel/UCH1dpzjCEiGAt8CXkryhkZg',\n                'license': 'Creative Commons Attribution license (reuse allowed)',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            'url': 'https://www.youtube.com/watch?feature=player_embedded&amp;amp;v=V36LpHqtcDY',\n            'only_matching': True,\n        },\n        {\n            # YouTube Red paid video (https://github.com/rg3/youtube-dl/issues/10059)\n            'url': 'https://www.youtube.com/watch?v=i1Ko8UG-Tdo',\n            'only_matching': True,\n        },\n        {\n            # Rental video preview\n            'url': 'https://www.youtube.com/watch?v=yYr8q0y5Jfg',\n            'info_dict': {\n                'id': 'uGpuVWrhIzE',\n                'ext': 'mp4',\n                'title': 'Piku - Trailer',\n                'description': 'md5:c36bd60c3fd6f1954086c083c72092eb',\n                'upload_date': '20150811',\n                'uploader': 'FlixMatrix',\n                'uploader_id': 'FlixMatrixKaravan',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/FlixMatrixKaravan',\n                'license': 'Standard YouTube License',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # YouTube Red video with episode data\n            'url': 'https://www.youtube.com/watch?v=iqKdEhx-dD4',\n            'info_dict': {\n                'id': 'iqKdEhx-dD4',\n                'ext': 'mp4',\n                'title': 'Isolation - Mind Field (Ep 1)',\n                'description': 'md5:8013b7ddea787342608f63a13ddc9492',\n                'duration': 2085,\n                'upload_date': '20170118',\n                'uploader': 'Vsauce',\n                'uploader_id': 'Vsauce',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/Vsauce',\n                'license': 'Standard YouTube License',\n                'series': 'Mind Field',\n                'season_number': 1,\n                'episode_number': 1,\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'expected_warnings': [\n                'Skipping DASH manifest',\n            ],\n        },\n        {\n            # The following content has been identified by the YouTube community\n            # as inappropriate or offensive to some audiences.\n            'url': 'https://www.youtube.com/watch?v=6SJNVb0GnPI',\n            'info_dict': {\n                'id': '6SJNVb0GnPI',\n                'ext': 'mp4',\n                'title': 'Race Differences in Intelligence',\n                'description': 'md5:5d161533167390427a1f8ee89a1fc6f1',\n                'duration': 965,\n                'upload_date': '20140124',\n                'uploader': 'New Century Foundation',\n                'uploader_id': 'UCEJYpZGqgUob0zVVEaLhvVg',\n                'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/channel/UCEJYpZGqgUob0zVVEaLhvVg',\n                'license': 'Standard YouTube License',\n                'view_count': int,\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # itag 212\n            'url': '1t24XAntNCY',\n            'only_matching': True,\n        },\n        {\n            # geo restricted to JP\n            'url': 'sJL6WA-aGkQ',\n            'only_matching': True,\n        },\n        {\n            'url': 'https://www.youtube.com/watch?v=MuAGGZNfUkU&list=RDMM',\n            'only_matching': True,\n        },\n    ]\n\n    def __init__(self, *args, **kwargs):\n        super(YoutubeIE, self).__init__(*args, **kwargs)\n        self._player_cache = {}\n\n    def report_video_info_webpage_download(self, video_id):\n        \"\"\"Report attempt to download video info webpage.\"\"\"\n        self.to_screen('%s: Downloading video info webpage' % video_id)\n\n    def report_information_extraction(self, video_id):\n        \"\"\"Report attempt to extract video information.\"\"\"\n        self.to_screen('%s: Extracting video information' % video_id)\n\n    def report_unavailable_format(self, video_id, format):\n        \"\"\"Report extracted video URL.\"\"\"\n        self.to_screen('%s: Format %s not available' % (video_id, format))\n\n    def report_rtmp_download(self):\n        \"\"\"Indicate the download will use the RTMP protocol.\"\"\"\n        self.to_screen('RTMP download detected')\n\n    def _signature_cache_id(self, example_sig):\n        \"\"\" Return a string representation of a signature \"\"\"\n        return '.'.join(compat_str(len(part)) for part in example_sig.split('.'))\n\n    def _extract_signature_function(self, video_id, player_url, example_sig):\n        id_m = re.match(\n            r'.*?-(?P<id>[a-zA-Z0-9_-]+)(?:/watch_as3|/html5player(?:-new)?|(?:/[a-z]{2}_[A-Z]{2})?/base)?\\.(?P<ext>[a-z]+)$',\n            player_url)\n        if not id_m:\n            raise ExtractorError('Cannot identify player %r' % player_url)\n        player_type = id_m.group('ext')\n        player_id = id_m.group('id')\n\n        # Read from filesystem cache\n        func_id = '%s_%s_%s' % (\n            player_type, player_id, self._signature_cache_id(example_sig))\n        assert os.path.basename(func_id) == func_id\n\n        cache_spec = self._downloader.cache.load('youtube-sigfuncs', func_id)\n        if cache_spec is not None:\n            return lambda s: ''.join(s[i] for i in cache_spec)\n\n        download_note = (\n            'Downloading player %s' % player_url\n            if self._downloader.params.get('verbose') else\n            'Downloading %s player %s' % (player_type, player_id)\n        )\n        if player_type == 'js':\n            code = self._download_webpage(\n                player_url, video_id,\n                note=download_note,\n                errnote='Download of %s failed' % player_url)\n            res = self._parse_sig_js(code)\n        elif player_type == 'swf':\n            urlh = self._request_webpage(\n                player_url, video_id,\n                note=download_note,\n                errnote='Download of %s failed' % player_url)\n            code = urlh.read()\n            res = self._parse_sig_swf(code)\n        else:\n            assert False, 'Invalid player type %r' % player_type\n\n        test_string = ''.join(map(compat_chr, range(len(example_sig))))\n        cache_res = res(test_string)\n        cache_spec = [ord(c) for c in cache_res]\n\n        self._downloader.cache.store('youtube-sigfuncs', func_id, cache_spec)\n        return res\n\n    def _print_sig_code(self, func, example_sig):\n        def gen_sig_code(idxs):\n            def _genslice(start, end, step):\n                starts = '' if start == 0 else str(start)\n                ends = (':%d' % (end + step)) if end + step >= 0 else ':'\n                steps = '' if step == 1 else (':%d' % step)\n                return 's[%s%s%s]' % (starts, ends, steps)\n\n            step = None\n            # Quelch pyflakes warnings - start will be set when step is set\n            start = '(Never used)'\n            for i, prev in zip(idxs[1:], idxs[:-1]):\n                if step is not None:\n                    if i - prev == step:\n                        continue\n                    yield _genslice(start, prev, step)\n                    step = None\n                    continue\n                if i - prev in [-1, 1]:\n                    step = i - prev\n                    start = prev\n                    continue\n                else:\n                    yield 's[%d]' % prev\n            if step is None:\n                yield 's[%d]' % i\n            else:\n                yield _genslice(start, i, step)\n\n        test_string = ''.join(map(compat_chr, range(len(example_sig))))\n        cache_res = func(test_string)\n        cache_spec = [ord(c) for c in cache_res]\n        expr_code = ' + '.join(gen_sig_code(cache_spec))\n        signature_id_tuple = '(%s)' % (\n            ', '.join(compat_str(len(p)) for p in example_sig.split('.')))\n        code = ('if tuple(len(p) for p in s.split(\\'.\\')) == %s:\\n'\n                '    return %s\\n') % (signature_id_tuple, expr_code)\n        self.to_screen('Extracted signature function:\\n' + code)\n\n    def _parse_sig_js(self, jscode):\n        funcname = self._search_regex(\n            (r'([\"\\'])signature\\1\\s*,\\s*(?P<sig>[a-zA-Z0-9$]+)\\(',\n             r'\\.sig\\|\\|(?P<sig>[a-zA-Z0-9$]+)\\('),\n            jscode, 'Initial JS player signature function name', group='sig')\n\n        jsi = JSInterpreter(jscode)\n        initial_function = jsi.extract_function(funcname)\n        return lambda s: initial_function([s])\n\n    def _parse_sig_swf(self, file_contents):\n        swfi = SWFInterpreter(file_contents)\n        TARGET_CLASSNAME = 'SignatureDecipher'\n        searched_class = swfi.extract_class(TARGET_CLASSNAME)\n        initial_function = swfi.extract_function(searched_class, 'decipher')\n        return lambda s: initial_function([s])\n\n    def _decrypt_signature(self, s, video_id, player_url, age_gate=False):\n        \"\"\"Turn the encrypted s field into a working signature\"\"\"\n\n        if player_url is None:\n            raise ExtractorError('Cannot decrypt signature without player_url')\n\n        if player_url.startswith('//'):\n            player_url = 'https:' + player_url\n        elif not re.match(r'https?://', player_url):\n            player_url = compat_urlparse.urljoin(\n                'https://www.youtube.com', player_url)\n        try:\n            player_id = (player_url, self._signature_cache_id(s))\n            if player_id not in self._player_cache:\n                func = self._extract_signature_function(\n                    video_id, player_url, s\n                )\n                self._player_cache[player_id] = func\n            func = self._player_cache[player_id]\n            if self._downloader.params.get('youtube_print_sig_code'):\n                self._print_sig_code(func, s)\n            return func(s)\n        except Exception as e:\n            tb = traceback.format_exc()\n            raise ExtractorError(\n                'Signature extraction failed: ' + tb, cause=e)\n\n    def _get_subtitles(self, video_id, webpage):\n        try:\n            subs_doc = self._download_xml(\n                'https://video.google.com/timedtext?hl=en&type=list&v=%s' % video_id,\n                video_id, note=False)\n        except ExtractorError as err:\n            self._downloader.report_warning('unable to download video subtitles: %s' % error_to_compat_str(err))\n            return {}\n\n        sub_lang_list = {}\n        for track in subs_doc.findall('track'):\n            lang = track.attrib['lang_code']\n            if lang in sub_lang_list:\n                continue\n            sub_formats = []\n            for ext in self._SUBTITLE_FORMATS:\n                params = compat_urllib_parse_urlencode({\n                    'lang': lang,\n                    'v': video_id,\n                    'fmt': ext,\n                    'name': track.attrib['name'].encode('utf-8'),\n                })\n                sub_formats.append({\n                    'url': 'https://www.youtube.com/api/timedtext?' + params,\n                    'ext': ext,\n                })\n            sub_lang_list[lang] = sub_formats\n        if not sub_lang_list:\n            self._downloader.report_warning('video doesn\\'t have subtitles')\n            return {}\n        return sub_lang_list\n\n    def _get_ytplayer_config(self, video_id, webpage):\n        patterns = (\n            # User data may contain arbitrary character sequences that may affect\n            # JSON extraction with regex, e.g. when '};' is contained the second\n            # regex won't capture the whole JSON. Yet working around by trying more\n            # concrete regex first keeping in mind proper quoted string handling\n            # to be implemented in future that will replace this workaround (see\n            # https://github.com/rg3/youtube-dl/issues/7468,\n            # https://github.com/rg3/youtube-dl/pull/7599)\n            r';ytplayer\\.config\\s*=\\s*({.+?});ytplayer',\n            r';ytplayer\\.config\\s*=\\s*({.+?});',\n        )\n        config = self._search_regex(\n            patterns, webpage, 'ytplayer.config', default=None)\n        if config:\n            return self._parse_json(\n                uppercase_escape(config), video_id, fatal=False)\n\n    def _get_automatic_captions(self, video_id, webpage):\n        \"\"\"We need the webpage for getting the captions url, pass it as an\n           argument to speed up the process.\"\"\"\n        self.to_screen('%s: Looking for automatic captions' % video_id)\n        player_config = self._get_ytplayer_config(video_id, webpage)\n        err_msg = 'Couldn\\'t find automatic captions for %s' % video_id\n        if not player_config:\n            self._downloader.report_warning(err_msg)\n            return {}\n        try:\n            args = player_config['args']\n            caption_url = args.get('ttsurl')\n            if caption_url:\n                timestamp = args['timestamp']\n                # We get the available subtitles\n                list_params = compat_urllib_parse_urlencode({\n                    'type': 'list',\n                    'tlangs': 1,\n                    'asrs': 1,\n                })\n                list_url = caption_url + '&' + list_params\n                caption_list = self._download_xml(list_url, video_id)\n                original_lang_node = caption_list.find('track')\n                if original_lang_node is None:\n                    self._downloader.report_warning('Video doesn\\'t have automatic captions')\n                    return {}\n                original_lang = original_lang_node.attrib['lang_code']\n                caption_kind = original_lang_node.attrib.get('kind', '')\n\n                sub_lang_list = {}\n                for lang_node in caption_list.findall('target'):\n                    sub_lang = lang_node.attrib['lang_code']\n                    sub_formats = []\n                    for ext in self._SUBTITLE_FORMATS:\n                        params = compat_urllib_parse_urlencode({\n                            'lang': original_lang,\n                            'tlang': sub_lang,\n                            'fmt': ext,\n                            'ts': timestamp,\n                            'kind': caption_kind,\n                        })\n                        sub_formats.append({\n                            'url': caption_url + '&' + params,\n                            'ext': ext,\n                        })\n                    sub_lang_list[sub_lang] = sub_formats\n                return sub_lang_list\n\n            def make_captions(sub_url, sub_langs):\n                parsed_sub_url = compat_urllib_parse_urlparse(sub_url)\n                caption_qs = compat_parse_qs(parsed_sub_url.query)\n                captions = {}\n                for sub_lang in sub_langs:\n                    sub_formats = []\n                    for ext in self._SUBTITLE_FORMATS:\n                        caption_qs.update({\n                            'tlang': [sub_lang],\n                            'fmt': [ext],\n                        })\n                        sub_url = compat_urlparse.urlunparse(parsed_sub_url._replace(\n                            query=compat_urllib_parse_urlencode(caption_qs, True)))\n                        sub_formats.append({\n                            'url': sub_url,\n                            'ext': ext,\n                        })\n                    captions[sub_lang] = sub_formats\n                return captions\n\n            # New captions format as of 22.06.2017\n            player_response = args.get('player_response')\n            if player_response and isinstance(player_response, compat_str):\n                player_response = self._parse_json(\n                    player_response, video_id, fatal=False)\n                if player_response:\n                    renderer = player_response['captions']['playerCaptionsTracklistRenderer']\n                    base_url = renderer['captionTracks'][0]['baseUrl']\n                    sub_lang_list = []\n                    for lang in renderer['translationLanguages']:\n                        lang_code = lang.get('languageCode')\n                        if lang_code:\n                            sub_lang_list.append(lang_code)\n                    return make_captions(base_url, sub_lang_list)\n\n            # Some videos don't provide ttsurl but rather caption_tracks and\n            # caption_translation_languages (e.g. 20LmZk1hakA)\n            # Does not used anymore as of 22.06.2017\n            caption_tracks = args['caption_tracks']\n            caption_translation_languages = args['caption_translation_languages']\n            caption_url = compat_parse_qs(caption_tracks.split(',')[0])['u'][0]\n            sub_lang_list = []\n            for lang in caption_translation_languages.split(','):\n                lang_qs = compat_parse_qs(compat_urllib_parse_unquote_plus(lang))\n                sub_lang = lang_qs.get('lc', [None])[0]\n                if sub_lang:\n                    sub_lang_list.append(sub_lang)\n            return make_captions(caption_url, sub_lang_list)\n        # An extractor error can be raise by the download process if there are\n        # no automatic captions but there are subtitles\n        except (KeyError, IndexError, ExtractorError):\n            self._downloader.report_warning(err_msg)\n            return {}\n\n    def _mark_watched(self, video_id, video_info):\n        playback_url = video_info.get('videostats_playback_base_url', [None])[0]\n        if not playback_url:\n            return\n        parsed_playback_url = compat_urlparse.urlparse(playback_url)\n        qs = compat_urlparse.parse_qs(parsed_playback_url.query)\n\n        # cpn generation algorithm is reverse engineered from base.js.\n        # In fact it works even with dummy cpn.\n        CPN_ALPHABET = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_'\n        cpn = ''.join((CPN_ALPHABET[random.randint(0, 256) & 63] for _ in range(0, 16)))\n\n        qs.update({\n            'ver': ['2'],\n            'cpn': [cpn],\n        })\n        playback_url = compat_urlparse.urlunparse(\n            parsed_playback_url._replace(query=compat_urllib_parse_urlencode(qs, True)))\n\n        self._download_webpage(\n            playback_url, video_id, 'Marking watched',\n            'Unable to mark watched', fatal=False)\n\n    @staticmethod\n    def _extract_urls(webpage):\n        # Embedded YouTube player\n        entries = [\n            unescapeHTML(mobj.group('url'))\n            for mobj in re.finditer(r'''(?x)\n            (?:\n                <iframe[^>]+?src=|\n                data-video-url=|\n                <embed[^>]+?src=|\n                embedSWF\\(?:\\s*|\n                <object[^>]+data=|\n                new\\s+SWFObject\\(\n            )\n            ([\"\\'])\n                (?P<url>(?:https?:)?//(?:www\\.)?youtube(?:-nocookie)?\\.com/\n                (?:embed|v|p)/[0-9A-Za-z_-]{11}.*?)\n            \\1''', webpage)]\n\n        # lazyYT YouTube embed\n        entries.extend(list(map(\n            unescapeHTML,\n            re.findall(r'class=\"lazyYT\" data-youtube-id=\"([^\"]+)\"', webpage))))\n\n        # Wordpress \"YouTube Video Importer\" plugin\n        matches = re.findall(r'''(?x)<div[^>]+\n            class=(?P<q1>[\\'\"])[^\\'\"]*\\byvii_single_video_player\\b[^\\'\"]*(?P=q1)[^>]+\n            data-video_id=(?P<q2>[\\'\"])([^\\'\"]+)(?P=q2)''', webpage)\n        entries.extend(m[-1] for m in matches)\n\n        return entries\n\n    @staticmethod\n    def _extract_url(webpage):\n        urls = YoutubeIE._extract_urls(webpage)\n        return urls[0] if urls else None\n\n    @classmethod\n    def extract_id(cls, url):\n        mobj = re.match(cls._VALID_URL, url, re.VERBOSE)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n        video_id = mobj.group(2)\n        return video_id\n\n    def _extract_annotations(self, video_id):\n        url = 'https://www.youtube.com/annotations_invideo?features=1&legacy=1&video_id=%s' % video_id\n        return self._download_webpage(url, video_id, note='Searching for annotations.', errnote='Unable to download video annotations.')\n\n    @staticmethod\n    def _extract_chapters(description, duration):\n        if not description:\n            return None\n        chapter_lines = re.findall(\n            r'(?:^|<br\\s*/>)([^<]*<a[^>]+onclick=[\"\\']yt\\.www\\.watch\\.player\\.seekTo[^>]+>(\\d{1,2}:\\d{1,2}(?::\\d{1,2})?)</a>[^>]*)(?=$|<br\\s*/>)',\n            description)\n        if not chapter_lines:\n            return None\n        chapters = []\n        for next_num, (chapter_line, time_point) in enumerate(\n                chapter_lines, start=1):\n            start_time = parse_duration(time_point)\n            if start_time is None:\n                continue\n            if start_time > duration:\n                break\n            end_time = (duration if next_num == len(chapter_lines)\n                        else parse_duration(chapter_lines[next_num][1]))\n            if end_time is None:\n                continue\n            if end_time > duration:\n                end_time = duration\n            if start_time > end_time:\n                break\n            chapter_title = re.sub(\n                r'<a[^>]+>[^<]+</a>', '', chapter_line).strip(' \\t-')\n            chapter_title = re.sub(r'\\s+', ' ', chapter_title)\n            chapters.append({\n                'start_time': start_time,\n                'end_time': end_time,\n                'title': chapter_title,\n            })\n        return chapters\n\n    def _real_extract(self, url):\n        url, smuggled_data = unsmuggle_url(url, {})\n\n        proto = (\n            'http' if self._downloader.params.get('prefer_insecure', False)\n            else 'https')\n\n        start_time = None\n        end_time = None\n        parsed_url = compat_urllib_parse_urlparse(url)\n        for component in [parsed_url.fragment, parsed_url.query]:\n            query = compat_parse_qs(component)\n            if start_time is None and 't' in query:\n                start_time = parse_duration(query['t'][0])\n            if start_time is None and 'start' in query:\n                start_time = parse_duration(query['start'][0])\n            if end_time is None and 'end' in query:\n                end_time = parse_duration(query['end'][0])\n\n        # Extract original video URL from URL with redirection, like age verification, using next_url parameter\n        mobj = re.search(self._NEXT_URL_RE, url)\n        if mobj:\n            url = proto + '://www.youtube.com/' + compat_urllib_parse_unquote(mobj.group(1)).lstrip('/')\n        video_id = self.extract_id(url)\n\n        # Get video webpage\n        url = proto + '://www.youtube.com/watch?v=%s&gl=US&hl=en&has_verified=1&bpctr=9999999999' % video_id\n        video_webpage = self._download_webpage(url, video_id)\n\n        # Attempt to extract SWF player URL\n        mobj = re.search(r'swfConfig.*?\"(https?:\\\\/\\\\/.*?watch.*?-.*?\\.swf)\"', video_webpage)\n        if mobj is not None:\n            player_url = re.sub(r'\\\\(.)', r'\\1', mobj.group(1))\n        else:\n            player_url = None\n\n        dash_mpds = []\n\n        def add_dash_mpd(video_info):\n            dash_mpd = video_info.get('dashmpd')\n            if dash_mpd and dash_mpd[0] not in dash_mpds:\n                dash_mpds.append(dash_mpd[0])\n\n        is_live = None\n        view_count = None\n\n        def extract_view_count(v_info):\n            return int_or_none(try_get(v_info, lambda x: x['view_count'][0]))\n\n        # Get video info\n        embed_webpage = None\n        if re.search(r'player-age-gate-content\">', video_webpage) is not None:\n            age_gate = True\n            # We simulate the access to the video from www.youtube.com/v/{video_id}\n            # this can be viewed without login into Youtube\n            url = proto + '://www.youtube.com/embed/%s' % video_id\n            embed_webpage = self._download_webpage(url, video_id, 'Downloading embed webpage')\n            data = compat_urllib_parse_urlencode({\n                'video_id': video_id,\n                'eurl': 'https://youtube.googleapis.com/v/' + video_id,\n                'sts': self._search_regex(\n                    r'\"sts\"\\s*:\\s*(\\d+)', embed_webpage, 'sts', default=''),\n            })\n            video_info_url = proto + '://www.youtube.com/get_video_info?' + data\n            video_info_webpage = self._download_webpage(\n                video_info_url, video_id,\n                note='Refetching age-gated info webpage',\n                errnote='unable to download video info webpage')\n            video_info = compat_parse_qs(video_info_webpage)\n            add_dash_mpd(video_info)\n        else:\n            age_gate = False\n            video_info = None\n            sts = None\n            # Try looking directly into the video webpage\n            ytplayer_config = self._get_ytplayer_config(video_id, video_webpage)\n            if ytplayer_config:\n                args = ytplayer_config['args']\n                if args.get('url_encoded_fmt_stream_map'):\n                    # Convert to the same format returned by compat_parse_qs\n                    video_info = dict((k, [v]) for k, v in args.items())\n                    add_dash_mpd(video_info)\n                # Rental video is not rented but preview is available (e.g.\n                # https://www.youtube.com/watch?v=yYr8q0y5Jfg,\n                # https://github.com/rg3/youtube-dl/issues/10532)\n                if not video_info and args.get('ypc_vid'):\n                    return self.url_result(\n                        args['ypc_vid'], YoutubeIE.ie_key(), video_id=args['ypc_vid'])\n                if args.get('livestream') == '1' or args.get('live_playback') == 1:\n                    is_live = True\n                sts = ytplayer_config.get('sts')\n            if not video_info or self._downloader.params.get('youtube_include_dash_manifest', True):\n                # We also try looking in get_video_info since it may contain different dashmpd\n                # URL that points to a DASH manifest with possibly different itag set (some itags\n                # are missing from DASH manifest pointed by webpage's dashmpd, some - from DASH\n                # manifest pointed by get_video_info's dashmpd).\n                # The general idea is to take a union of itags of both DASH manifests (for example\n                # video with such 'manifest behavior' see https://github.com/rg3/youtube-dl/issues/6093)\n                self.report_video_info_webpage_download(video_id)\n                for el in ('info', 'embedded', 'detailpage', 'vevo', ''):\n                    query = {\n                        'video_id': video_id,\n                        'ps': 'default',\n                        'eurl': '',\n                        'gl': 'US',\n                        'hl': 'en',\n                    }\n                    if el:\n                        query['el'] = el\n                    if sts:\n                        query['sts'] = sts\n                    video_info_webpage = self._download_webpage(\n                        '%s://www.youtube.com/get_video_info' % proto,\n                        video_id, note=False,\n                        errnote='unable to download video info webpage',\n                        fatal=False, query=query)\n                    if not video_info_webpage:\n                        continue\n                    get_video_info = compat_parse_qs(video_info_webpage)\n                    add_dash_mpd(get_video_info)\n                    if view_count is None:\n                        view_count = extract_view_count(get_video_info)\n                    if not video_info:\n                        video_info = get_video_info\n                    if 'token' in get_video_info:\n                        # Different get_video_info requests may report different results, e.g.\n                        # some may report video unavailability, but some may serve it without\n                        # any complaint (see https://github.com/rg3/youtube-dl/issues/7362,\n                        # the original webpage as well as el=info and el=embedded get_video_info\n                        # requests report video unavailability due to geo restriction while\n                        # el=detailpage succeeds and returns valid data). This is probably\n                        # due to YouTube measures against IP ranges of hosting providers.\n                        # Working around by preferring the first succeeded video_info containing\n                        # the token if no such video_info yet was found.\n                        if 'token' not in video_info:\n                            video_info = get_video_info\n                        break\n\n        def extract_unavailable_message():\n            return self._html_search_regex(\n                r'(?s)<h1[^>]+id=\"unavailable-message\"[^>]*>(.+?)</h1>',\n                video_webpage, 'unavailable message', default=None)\n\n        if 'token' not in video_info:\n            if 'reason' in video_info:\n                if 'The uploader has not made this video available in your country.' in video_info['reason']:\n                    regions_allowed = self._html_search_meta(\n                        'regionsAllowed', video_webpage, default=None)\n                    countries = regions_allowed.split(',') if regions_allowed else None\n                    self.raise_geo_restricted(\n                        msg=video_info['reason'][0], countries=countries)\n                reason = video_info['reason'][0]\n                if 'Invalid parameters' in reason:\n                    unavailable_message = extract_unavailable_message()\n                    if unavailable_message:\n                        reason = unavailable_message\n                raise ExtractorError(\n                    'YouTube said: %s' % reason,\n                    expected=True, video_id=video_id)\n            else:\n                raise ExtractorError(\n                    '\"token\" parameter not in video info for unknown reason',\n                    video_id=video_id)\n\n        # title\n        if 'title' in video_info:\n            video_title = video_info['title'][0]\n        else:\n            self._downloader.report_warning('Unable to extract video title')\n            video_title = '_'\n\n        # description\n        description_original = video_description = get_element_by_id(\"eow-description\", video_webpage)\n        if video_description:\n\n            def replace_url(m):\n                redir_url = compat_urlparse.urljoin(url, m.group(1))\n                parsed_redir_url = compat_urllib_parse_urlparse(redir_url)\n                if re.search(r'^(?:www\\.)?(?:youtube(?:-nocookie)?\\.com|youtu\\.be)$', parsed_redir_url.netloc) and parsed_redir_url.path == '/redirect':\n                    qs = compat_parse_qs(parsed_redir_url.query)\n                    q = qs.get('q')\n                    if q and q[0]:\n                        return q[0]\n                return redir_url\n\n            description_original = video_description = re.sub(r'''(?x)\n                <a\\s+\n                    (?:[a-zA-Z-]+=\"[^\"]*\"\\s+)*?\n                    (?:title|href)=\"([^\"]+)\"\\s+\n                    (?:[a-zA-Z-]+=\"[^\"]*\"\\s+)*?\n                    class=\"[^\"]*\"[^>]*>\n                [^<]+\\.{3}\\s*\n                </a>\n            ''', replace_url, video_description)\n            video_description = clean_html(video_description)\n        else:\n            fd_mobj = re.search(r'<meta name=\"description\" content=\"([^\"]+)\"', video_webpage)\n            if fd_mobj:\n                video_description = unescapeHTML(fd_mobj.group(1))\n            else:\n                video_description = ''\n\n        if 'multifeed_metadata_list' in video_info and not smuggled_data.get('force_singlefeed', False):\n            if not self._downloader.params.get('noplaylist'):\n                entries = []\n                feed_ids = []\n                multifeed_metadata_list = video_info['multifeed_metadata_list'][0]\n                for feed in multifeed_metadata_list.split(','):\n                    # Unquote should take place before split on comma (,) since textual\n                    # fields may contain comma as well (see\n                    # https://github.com/rg3/youtube-dl/issues/8536)\n                    feed_data = compat_parse_qs(compat_urllib_parse_unquote_plus(feed))\n                    entries.append({\n                        '_type': 'url_transparent',\n                        'ie_key': 'Youtube',\n                        'url': smuggle_url(\n                            '%s://www.youtube.com/watch?v=%s' % (proto, feed_data['id'][0]),\n                            {'force_singlefeed': True}),\n                        'title': '%s (%s)' % (video_title, feed_data['title'][0]),\n                    })\n                    feed_ids.append(feed_data['id'][0])\n                self.to_screen(\n                    'Downloading multifeed video (%s) - add --no-playlist to just download video %s'\n                    % (', '.join(feed_ids), video_id))\n                return self.playlist_result(entries, video_id, video_title, video_description)\n            self.to_screen('Downloading just video %s because of --no-playlist' % video_id)\n\n        if view_count is None:\n            view_count = extract_view_count(video_info)\n\n        # Check for \"rental\" videos\n        if 'ypc_video_rental_bar_text' in video_info and 'author' not in video_info:\n            raise ExtractorError('\"rental\" videos not supported. See https://github.com/rg3/youtube-dl/issues/359 for more information.', expected=True)\n\n        # Start extracting information\n        self.report_information_extraction(video_id)\n\n        # uploader\n        if 'author' not in video_info:\n            raise ExtractorError('Unable to extract uploader name')\n        video_uploader = compat_urllib_parse_unquote_plus(video_info['author'][0])\n\n        # uploader_id\n        video_uploader_id = None\n        video_uploader_url = None\n        mobj = re.search(\n            r'<link itemprop=\"url\" href=\"(?P<uploader_url>https?://www\\.youtube\\.com/(?:user|channel)/(?P<uploader_id>[^\"]+))\">',\n            video_webpage)\n        if mobj is not None:\n            video_uploader_id = mobj.group('uploader_id')\n            video_uploader_url = mobj.group('uploader_url')\n        else:\n            self._downloader.report_warning('unable to extract uploader nickname')\n\n        # thumbnail image\n        # We try first to get a high quality image:\n        m_thumb = re.search(r'<span itemprop=\"thumbnail\".*?href=\"(.*?)\">',\n                            video_webpage, re.DOTALL)\n        if m_thumb is not None:\n            video_thumbnail = m_thumb.group(1)\n        elif 'thumbnail_url' not in video_info:\n            self._downloader.report_warning('unable to extract video thumbnail')\n            video_thumbnail = None\n        else:   # don't panic if we can't find it\n            video_thumbnail = compat_urllib_parse_unquote_plus(video_info['thumbnail_url'][0])\n\n        # upload date\n        upload_date = self._html_search_meta(\n            'datePublished', video_webpage, 'upload date', default=None)\n        if not upload_date:\n            upload_date = self._search_regex(\n                [r'(?s)id=\"eow-date.*?>(.*?)</span>',\n                 r'(?:id=\"watch-uploader-info\".*?>.*?|[\"\\']simpleText[\"\\']\\s*:\\s*[\"\\'])(?:Published|Uploaded|Streamed live|Started) on (.+?)[<\"\\']'],\n                video_webpage, 'upload date', default=None)\n        upload_date = unified_strdate(upload_date)\n\n        video_license = self._html_search_regex(\n            r'<h4[^>]+class=\"title\"[^>]*>\\s*License\\s*</h4>\\s*<ul[^>]*>\\s*<li>(.+?)</li',\n            video_webpage, 'license', default=None)\n\n        m_music = re.search(\n            r'''(?x)\n                <h4[^>]+class=\"title\"[^>]*>\\s*Music\\s*</h4>\\s*\n                <ul[^>]*>\\s*\n                <li>(?P<title>.+?)\n                by (?P<creator>.+?)\n                (?:\n                    \\(.+?\\)|\n                    <a[^>]*\n                        (?:\n                            \\bhref=[\"\\']/red[^>]*>|             # drop possible\n                            >\\s*Listen ad-free with YouTube Red # YouTube Red ad\n                        )\n                    .*?\n                )?</li\n            ''',\n            video_webpage)\n        if m_music:\n            video_alt_title = remove_quotes(unescapeHTML(m_music.group('title')))\n            video_creator = clean_html(m_music.group('creator'))\n        else:\n            video_alt_title = video_creator = None\n\n        m_episode = re.search(\n            r'<div[^>]+id=\"watch7-headline\"[^>]*>\\s*<span[^>]*>.*?>(?P<series>[^<]+)</a></b>\\s*S(?P<season>\\d+)\\s*\u2022\\s*E(?P<episode>\\d+)</span>',\n            video_webpage)\n        if m_episode:\n            series = m_episode.group('series')\n            season_number = int(m_episode.group('season'))\n            episode_number = int(m_episode.group('episode'))\n        else:\n            series = season_number = episode_number = None\n\n        m_cat_container = self._search_regex(\n            r'(?s)<h4[^>]*>\\s*Category\\s*</h4>\\s*<ul[^>]*>(.*?)</ul>',\n            video_webpage, 'categories', default=None)\n        if m_cat_container:\n            category = self._html_search_regex(\n                r'(?s)<a[^<]+>(.*?)</a>', m_cat_container, 'category',\n                default=None)\n            video_categories = None if category is None else [category]\n        else:\n            video_categories = None\n\n        video_tags = [\n            unescapeHTML(m.group('content'))\n            for m in re.finditer(self._meta_regex('og:video:tag'), video_webpage)]\n\n        def _extract_count(count_name):\n            return str_to_int(self._search_regex(\n                r'-%s-button[^>]+><span[^>]+class=\"yt-uix-button-content\"[^>]*>([\\d,]+)</span>'\n                % re.escape(count_name),\n                video_webpage, count_name, default=None))\n\n        like_count = _extract_count('like')\n        dislike_count = _extract_count('dislike')\n\n        # subtitles\n        video_subtitles = self.extract_subtitles(video_id, video_webpage)\n        automatic_captions = self.extract_automatic_captions(video_id, video_webpage)\n\n        video_duration = try_get(\n            video_info, lambda x: int_or_none(x['length_seconds'][0]))\n        if not video_duration:\n            video_duration = parse_duration(self._html_search_meta(\n                'duration', video_webpage, 'video duration'))\n\n        # annotations\n        video_annotations = None\n        if self._downloader.params.get('writeannotations', False):\n            video_annotations = self._extract_annotations(video_id)\n\n        chapters = self._extract_chapters(description_original, video_duration)\n\n        if 'conn' in video_info and video_info['conn'][0].startswith('rtmp'):\n            self.report_rtmp_download()\n            formats = [{\n                'format_id': '_rtmp',\n                'protocol': 'rtmp',\n                'url': video_info['conn'][0],\n                'player_url': player_url,\n            }]\n        elif not is_live and (len(video_info.get('url_encoded_fmt_stream_map', [''])[0]) >= 1 or len(video_info.get('adaptive_fmts', [''])[0]) >= 1):\n            encoded_url_map = video_info.get('url_encoded_fmt_stream_map', [''])[0] + ',' + video_info.get('adaptive_fmts', [''])[0]\n            if 'rtmpe%3Dyes' in encoded_url_map:\n                raise ExtractorError('rtmpe downloads are not supported, see https://github.com/rg3/youtube-dl/issues/343 for more information.', expected=True)\n            formats_spec = {}\n            fmt_list = video_info.get('fmt_list', [''])[0]\n            if fmt_list:\n                for fmt in fmt_list.split(','):\n                    spec = fmt.split('/')\n                    if len(spec) > 1:\n                        width_height = spec[1].split('x')\n                        if len(width_height) == 2:\n                            formats_spec[spec[0]] = {\n                                'resolution': spec[1],\n                                'width': int_or_none(width_height[0]),\n                                'height': int_or_none(width_height[1]),\n                            }\n            formats = []\n            for url_data_str in encoded_url_map.split(','):\n                url_data = compat_parse_qs(url_data_str)\n                if 'itag' not in url_data or 'url' not in url_data:\n                    continue\n                format_id = url_data['itag'][0]\n                url = url_data['url'][0]\n\n                if 's' in url_data or self._downloader.params.get('youtube_include_dash_manifest', True):\n                    ASSETS_RE = r'\"assets\":.+?\"js\":\\s*(\"[^\"]+\")'\n                    jsplayer_url_json = self._search_regex(\n                        ASSETS_RE,\n                        embed_webpage if age_gate else video_webpage,\n                        'JS player URL (1)', default=None)\n                    if not jsplayer_url_json and not age_gate:\n                        # We need the embed website after all\n                        if embed_webpage is None:\n                            embed_url = proto + '://www.youtube.com/embed/%s' % video_id\n                            embed_webpage = self._download_webpage(\n                                embed_url, video_id, 'Downloading embed webpage')\n                        jsplayer_url_json = self._search_regex(\n                            ASSETS_RE, embed_webpage, 'JS player URL')\n\n                    player_url = json.loads(jsplayer_url_json)\n                    if player_url is None:\n                        player_url_json = self._search_regex(\n                            r'ytplayer\\.config.*?\"url\"\\s*:\\s*(\"[^\"]+\")',\n                            video_webpage, 'age gate player URL')\n                        player_url = json.loads(player_url_json)\n\n                if 'sig' in url_data:\n                    url += '&signature=' + url_data['sig'][0]\n                elif 's' in url_data:\n                    encrypted_sig = url_data['s'][0]\n\n                    if self._downloader.params.get('verbose'):\n                        if player_url is None:\n                            player_version = 'unknown'\n                            player_desc = 'unknown'\n                        else:\n                            if player_url.endswith('swf'):\n                                player_version = self._search_regex(\n                                    r'-(.+?)(?:/watch_as3)?\\.swf$', player_url,\n                                    'flash player', fatal=False)\n                                player_desc = 'flash player %s' % player_version\n                            else:\n                                player_version = self._search_regex(\n                                    [r'html5player-([^/]+?)(?:/html5player(?:-new)?)?\\.js',\n                                     r'(?:www|player)-([^/]+)(?:/[a-z]{2}_[A-Z]{2})?/base\\.js'],\n                                    player_url,\n                                    'html5 player', fatal=False)\n                                player_desc = 'html5 player %s' % player_version\n\n                        parts_sizes = self._signature_cache_id(encrypted_sig)\n                        self.to_screen('{%s} signature length %s, %s' %\n                                       (format_id, parts_sizes, player_desc))\n\n                    signature = self._decrypt_signature(\n                        encrypted_sig, video_id, player_url, age_gate)\n                    url += '&signature=' + signature\n                if 'ratebypass' not in url:\n                    url += '&ratebypass=yes'\n\n                dct = {\n                    'format_id': format_id,\n                    'url': url,\n                    'player_url': player_url,\n                }\n                if format_id in self._formats:\n                    dct.update(self._formats[format_id])\n                if format_id in formats_spec:\n                    dct.update(formats_spec[format_id])\n\n                # Some itags are not included in DASH manifest thus corresponding formats will\n                # lack metadata (see https://github.com/rg3/youtube-dl/pull/5993).\n                # Trying to extract metadata from url_encoded_fmt_stream_map entry.\n                mobj = re.search(r'^(?P<width>\\d+)[xX](?P<height>\\d+)$', url_data.get('size', [''])[0])\n                width, height = (int(mobj.group('width')), int(mobj.group('height'))) if mobj else (None, None)\n\n                more_fields = {\n                    'filesize': int_or_none(url_data.get('clen', [None])[0]),\n                    'tbr': float_or_none(url_data.get('bitrate', [None])[0], 1000),\n                    'width': width,\n                    'height': height,\n                    'fps': int_or_none(url_data.get('fps', [None])[0]),\n                    'format_note': url_data.get('quality_label', [None])[0] or url_data.get('quality', [None])[0],\n                }\n                for key, value in more_fields.items():\n                    if value:\n                        dct[key] = value\n                type_ = url_data.get('type', [None])[0]\n                if type_:\n                    type_split = type_.split(';')\n                    kind_ext = type_split[0].split('/')\n                    if len(kind_ext) == 2:\n                        kind, _ = kind_ext\n                        dct['ext'] = mimetype2ext(type_split[0])\n                        if kind in ('audio', 'video'):\n                            codecs = None\n                            for mobj in re.finditer(\n                                    r'(?P<key>[a-zA-Z_-]+)=(?P<quote>[\"\\']?)(?P<val>.+?)(?P=quote)(?:;|$)', type_):\n                                if mobj.group('key') == 'codecs':\n                                    codecs = mobj.group('val')\n                                    break\n                            if codecs:\n                                dct.update(parse_codecs(codecs))\n                if dct.get('acodec') == 'none' or dct.get('vcodec') == 'none':\n                    dct['downloader_options'] = {\n                        # Youtube throttles chunks >~10M\n                        'http_chunk_size': 10485760,\n                    }\n                formats.append(dct)\n        elif video_info.get('hlsvp'):\n            manifest_url = video_info['hlsvp'][0]\n            formats = []\n            m3u8_formats = self._extract_m3u8_formats(\n                manifest_url, video_id, 'mp4', fatal=False)\n            for a_format in m3u8_formats:\n                itag = self._search_regex(\n                    r'/itag/(\\d+)/', a_format['url'], 'itag', default=None)\n                if itag:\n                    a_format['format_id'] = itag\n                    if itag in self._formats:\n                        dct = self._formats[itag].copy()\n                        dct.update(a_format)\n                        a_format = dct\n                a_format['player_url'] = player_url\n                # Accept-Encoding header causes failures in live streams on Youtube and Youtube Gaming\n                a_format.setdefault('http_headers', {})['Youtubedl-no-compression'] = 'True'\n                formats.append(a_format)\n        else:\n            unavailable_message = extract_unavailable_message()\n            if unavailable_message:\n                raise ExtractorError(unavailable_message, expected=True)\n            raise ExtractorError('no conn, hlsvp or url_encoded_fmt_stream_map information found in video info')\n\n        # Look for the DASH manifest\n        if self._downloader.params.get('youtube_include_dash_manifest', True):\n            dash_mpd_fatal = True\n            for mpd_url in dash_mpds:\n                dash_formats = {}\n                try:\n                    def decrypt_sig(mobj):\n                        s = mobj.group(1)\n                        dec_s = self._decrypt_signature(s, video_id, player_url, age_gate)\n                        return '/signature/%s' % dec_s\n\n                    mpd_url = re.sub(r'/s/([a-fA-F0-9\\.]+)', decrypt_sig, mpd_url)\n\n                    for df in self._extract_mpd_formats(\n                            mpd_url, video_id, fatal=dash_mpd_fatal,\n                            formats_dict=self._formats):\n                        # Do not overwrite DASH format found in some previous DASH manifest\n                        if df['format_id'] not in dash_formats:\n                            dash_formats[df['format_id']] = df\n                        # Additional DASH manifests may end up in HTTP Error 403 therefore\n                        # allow them to fail without bug report message if we already have\n                        # some DASH manifest succeeded. This is temporary workaround to reduce\n                        # burst of bug reports until we figure out the reason and whether it\n                        # can be fixed at all.\n                        dash_mpd_fatal = False\n                except (ExtractorError, KeyError) as e:\n                    self.report_warning(\n                        'Skipping DASH manifest: %r' % e, video_id)\n                if dash_formats:\n                    # Remove the formats we found through non-DASH, they\n                    # contain less info and it can be wrong, because we use\n                    # fixed values (for example the resolution). See\n                    # https://github.com/rg3/youtube-dl/issues/5774 for an\n                    # example.\n                    formats = [f for f in formats if f['format_id'] not in dash_formats.keys()]\n                    formats.extend(dash_formats.values())\n\n        # Check for malformed aspect ratio\n        stretched_m = re.search(\n            r'<meta\\s+property=\"og:video:tag\".*?content=\"yt:stretch=(?P<w>[0-9]+):(?P<h>[0-9]+)\">',\n            video_webpage)\n        if stretched_m:\n            w = float(stretched_m.group('w'))\n            h = float(stretched_m.group('h'))\n            # yt:stretch may hold invalid ratio data (e.g. for Q39EVAstoRM ratio is 17:0).\n            # We will only process correct ratios.\n            if w > 0 and h > 0:\n                ratio = w / h\n                for f in formats:\n                    if f.get('vcodec') != 'none':\n                        f['stretched_ratio'] = ratio\n\n        self._sort_formats(formats)\n\n        self.mark_watched(video_id, video_info)\n\n        return {\n            'id': video_id,\n            'uploader': video_uploader,\n            'uploader_id': video_uploader_id,\n            'uploader_url': video_uploader_url,\n            'upload_date': upload_date,\n            'license': video_license,\n            'creator': video_creator,\n            'title': video_title,\n            'alt_title': video_alt_title,\n            'thumbnail': video_thumbnail,\n            'description': video_description,\n            'categories': video_categories,\n            'tags': video_tags,\n            'subtitles': video_subtitles,\n            'automatic_captions': automatic_captions,\n            'duration': video_duration,\n            'age_limit': 18 if age_gate else 0,\n            'annotations': video_annotations,\n            'chapters': chapters,\n            'webpage_url': proto + '://www.youtube.com/watch?v=%s' % video_id,\n            'view_count': view_count,\n            'like_count': like_count,\n            'dislike_count': dislike_count,\n            'average_rating': float_or_none(video_info.get('avg_rating', [None])[0]),\n            'formats': formats,\n            'is_live': is_live,\n            'start_time': start_time,\n            'end_time': end_time,\n            'series': series,\n            'season_number': season_number,\n            'episode_number': episode_number,\n        }\n\n\nclass YoutubePlaylistIE(YoutubePlaylistBaseInfoExtractor):\n    IE_DESC = 'YouTube.com playlists'\n    _VALID_URL = r\"\"\"(?x)(?:\n                        (?:https?://)?\n                        (?:\\w+\\.)?\n                        (?:\n                            youtube\\.com/\n                            (?:\n                               (?:course|view_play_list|my_playlists|artist|playlist|watch|embed/(?:videoseries|[0-9A-Za-z_-]{11}))\n                               \\? (?:.*?[&;])*? (?:p|a|list)=\n                            |  p/\n                            )|\n                            youtu\\.be/[0-9A-Za-z_-]{11}\\?.*?\\blist=\n                        )\n                        (\n                            (?:PL|LL|EC|UU|FL|RD|UL|TL)?[0-9A-Za-z-_]{10,}\n                            # Top tracks, they can also include dots\n                            |(?:MC)[\\w\\.]*\n                        )\n                        .*\n                     |\n                        (%(playlist_id)s)\n                     )\"\"\" % {'playlist_id': YoutubeBaseInfoExtractor._PLAYLIST_ID_RE}\n    _TEMPLATE_URL = 'https://www.youtube.com/playlist?list=%s'\n    _VIDEO_RE = r'href=\"\\s*/watch\\?v=(?P<id>[0-9A-Za-z_-]{11})&amp;[^\"]*?index=(?P<index>\\d+)(?:[^>]+>(?P<title>[^<]+))?'\n    IE_NAME = 'youtube:playlist'\n    _TESTS = [{\n        'url': 'https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re',\n        'info_dict': {\n            'title': 'ytdl test PL',\n            'id': 'PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re',\n        },\n        'playlist_count': 3,\n    }, {\n        'url': 'https://www.youtube.com/playlist?list=PLtPgu7CB4gbZDA7i_euNxn75ISqxwZPYx',\n        'info_dict': {\n            'id': 'PLtPgu7CB4gbZDA7i_euNxn75ISqxwZPYx',\n            'title': 'YDL_Empty_List',\n        },\n        'playlist_count': 0,\n        'skip': 'This playlist is private',\n    }, {\n        'note': 'Playlist with deleted videos (#651). As a bonus, the video #51 is also twice in this list.',\n        'url': 'https://www.youtube.com/playlist?list=PLwP_SiAcdui0KVebT0mU9Apz359a4ubsC',\n        'info_dict': {\n            'title': '29C3: Not my department',\n            'id': 'PLwP_SiAcdui0KVebT0mU9Apz359a4ubsC',\n        },\n        'playlist_count': 95,\n    }, {\n        'note': 'issue #673',\n        'url': 'PLBB231211A4F62143',\n        'info_dict': {\n            'title': '[OLD]Team Fortress 2 (Class-based LP)',\n            'id': 'PLBB231211A4F62143',\n        },\n        'playlist_mincount': 26,\n    }, {\n        'note': 'Large playlist',\n        'url': 'https://www.youtube.com/playlist?list=UUBABnxM4Ar9ten8Mdjj1j0Q',\n        'info_dict': {\n            'title': 'Uploads from Cauchemar',\n            'id': 'UUBABnxM4Ar9ten8Mdjj1j0Q',\n        },\n        'playlist_mincount': 799,\n    }, {\n        'url': 'PLtPgu7CB4gbY9oDN3drwC3cMbJggS7dKl',\n        'info_dict': {\n            'title': 'YDL_safe_search',\n            'id': 'PLtPgu7CB4gbY9oDN3drwC3cMbJggS7dKl',\n        },\n        'playlist_count': 2,\n        'skip': 'This playlist is private',\n    }, {\n        'note': 'embedded',\n        'url': 'https://www.youtube.com/embed/videoseries?list=PL6IaIsEjSbf96XFRuNccS_RuEXwNdsoEu',\n        'playlist_count': 4,\n        'info_dict': {\n            'title': 'JODA15',\n            'id': 'PL6IaIsEjSbf96XFRuNccS_RuEXwNdsoEu',\n        }\n    }, {\n        'url': 'http://www.youtube.com/embed/_xDOZElKyNU?list=PLsyOSbh5bs16vubvKePAQ1x3PhKavfBIl',\n        'playlist_mincount': 485,\n        'info_dict': {\n            'title': '2017 \u83ef\u8a9e\u6700\u65b0\u55ae\u66f2 (2/24\u66f4\u65b0)',\n            'id': 'PLsyOSbh5bs16vubvKePAQ1x3PhKavfBIl',\n        }\n    }, {\n        'note': 'Embedded SWF player',\n        'url': 'https://www.youtube.com/p/YN5VISEtHet5D4NEvfTd0zcgFk84NqFZ?hl=en_US&fs=1&rel=0',\n        'playlist_count': 4,\n        'info_dict': {\n            'title': 'JODA7',\n            'id': 'YN5VISEtHet5D4NEvfTd0zcgFk84NqFZ',\n        }\n    }, {\n        'note': 'Buggy playlist: the webpage has a \"Load more\" button but it doesn\\'t have more videos',\n        'url': 'https://www.youtube.com/playlist?list=UUXw-G3eDE9trcvY2sBMM_aA',\n        'info_dict': {\n            'title': 'Uploads from Interstellar Movie',\n            'id': 'UUXw-G3eDE9trcvY2sBMM_aA',\n        },\n        'playlist_mincount': 21,\n    }, {\n        # Playlist URL that does not actually serve a playlist\n        'url': 'https://www.youtube.com/watch?v=FqZTN594JQw&list=PLMYEtVRpaqY00V9W81Cwmzp6N6vZqfUKD4',\n        'info_dict': {\n            'id': 'FqZTN594JQw',\n            'ext': 'webm',\n            'title': \"Smiley's People 01 detective, Adventure Series, Action\",\n            'uploader': 'STREEM',\n            'uploader_id': 'UCyPhqAZgwYWZfxElWVbVJng',\n            'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/channel/UCyPhqAZgwYWZfxElWVbVJng',\n            'upload_date': '20150526',\n            'license': 'Standard YouTube License',\n            'description': 'md5:507cdcb5a49ac0da37a920ece610be80',\n            'categories': ['People & Blogs'],\n            'tags': list,\n            'like_count': int,\n            'dislike_count': int,\n        },\n        'params': {\n            'skip_download': True,\n        },\n        'add_ie': [YoutubeIE.ie_key()],\n    }, {\n        'url': 'https://youtu.be/yeWKywCrFtk?list=PL2qgrgXsNUG5ig9cat4ohreBjYLAPC0J5',\n        'info_dict': {\n            'id': 'yeWKywCrFtk',\n            'ext': 'mp4',\n            'title': 'Small Scale Baler and Braiding Rugs',\n            'uploader': 'Backus-Page House Museum',\n            'uploader_id': 'backuspagemuseum',\n            'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/backuspagemuseum',\n            'upload_date': '20161008',\n            'license': 'Standard YouTube License',\n            'description': 'md5:800c0c78d5eb128500bffd4f0b4f2e8a',\n            'categories': ['Nonprofits & Activism'],\n            'tags': list,\n            'like_count': int,\n            'dislike_count': int,\n        },\n        'params': {\n            'noplaylist': True,\n            'skip_download': True,\n        },\n    }, {\n        'url': 'https://youtu.be/uWyaPkt-VOI?list=PL9D9FC436B881BA21',\n        'only_matching': True,\n    }, {\n        'url': 'TLGGrESM50VT6acwMjAyMjAxNw',\n        'only_matching': True,\n    }]\n\n    def _real_initialize(self):\n        self._login()\n\n    def _extract_mix(self, playlist_id):\n        # The mixes are generated from a single video\n        # the id of the playlist is just 'RD' + video_id\n        ids = []\n        last_id = playlist_id[-11:]\n        for n in itertools.count(1):\n            url = 'https://youtube.com/watch?v=%s&list=%s' % (last_id, playlist_id)\n            webpage = self._download_webpage(\n                url, playlist_id, 'Downloading page {0} of Youtube mix'.format(n))\n            new_ids = orderedSet(re.findall(\n                r'''(?xs)data-video-username=\".*?\".*?\n                           href=\"/watch\\?v=([0-9A-Za-z_-]{11})&amp;[^\"]*?list=%s''' % re.escape(playlist_id),\n                webpage))\n            # Fetch new pages until all the videos are repeated, it seems that\n            # there are always 51 unique videos.\n            new_ids = [_id for _id in new_ids if _id not in ids]\n            if not new_ids:\n                break\n            ids.extend(new_ids)\n            last_id = ids[-1]\n\n        url_results = self._ids_to_results(ids)\n\n        search_title = lambda class_name: get_element_by_attribute('class', class_name, webpage)\n        title_span = (\n            search_title('playlist-title') or\n            search_title('title long-title') or\n            search_title('title'))\n        title = clean_html(title_span)\n\n        return self.playlist_result(url_results, playlist_id, title)\n\n    def _extract_playlist(self, playlist_id):\n        url = self._TEMPLATE_URL % playlist_id\n        page = self._download_webpage(url, playlist_id)\n\n        # the yt-alert-message now has tabindex attribute (see https://github.com/rg3/youtube-dl/issues/11604)\n        for match in re.findall(r'<div class=\"yt-alert-message\"[^>]*>([^<]+)</div>', page):\n            match = match.strip()\n            # Check if the playlist exists or is private\n            mobj = re.match(r'[^<]*(?:The|This) playlist (?P<reason>does not exist|is private)[^<]*', match)\n            if mobj:\n                reason = mobj.group('reason')\n                message = 'This playlist %s' % reason\n                if 'private' in reason:\n                    message += ', use --username or --netrc to access it'\n                message += '.'\n                raise ExtractorError(message, expected=True)\n            elif re.match(r'[^<]*Invalid parameters[^<]*', match):\n                raise ExtractorError(\n                    'Invalid parameters. Maybe URL is incorrect.',\n                    expected=True)\n            elif re.match(r'[^<]*Choose your language[^<]*', match):\n                continue\n            else:\n                self.report_warning('Youtube gives an alert message: ' + match)\n\n        playlist_title = self._html_search_regex(\n            r'(?s)<h1 class=\"pl-header-title[^\"]*\"[^>]*>\\s*(.*?)\\s*</h1>',\n            page, 'title', default=None)\n\n        _UPLOADER_BASE = r'class=[\"\\']pl-header-details[^>]+>\\s*<li>\\s*<a[^>]+\\bhref='\n        uploader = self._search_regex(\n            r'%s[\"\\']/(?:user|channel)/[^>]+>([^<]+)' % _UPLOADER_BASE,\n            page, 'uploader', default=None)\n        mobj = re.search(\n            r'%s([\"\\'])(?P<path>/(?:user|channel)/(?P<uploader_id>.+?))\\1' % _UPLOADER_BASE,\n            page)\n        if mobj:\n            uploader_id = mobj.group('uploader_id')\n            uploader_url = compat_urlparse.urljoin(url, mobj.group('path'))\n        else:\n            uploader_id = uploader_url = None\n\n        has_videos = True\n\n        if not playlist_title:\n            try:\n                # Some playlist URLs don't actually serve a playlist (e.g.\n                # https://www.youtube.com/watch?v=FqZTN594JQw&list=PLMYEtVRpaqY00V9W81Cwmzp6N6vZqfUKD4)\n                next(self._entries(page, playlist_id))\n            except StopIteration:\n                has_videos = False\n\n        playlist = self.playlist_result(\n            self._entries(page, playlist_id), playlist_id, playlist_title)\n        playlist.update({\n            'uploader': uploader,\n            'uploader_id': uploader_id,\n            'uploader_url': uploader_url,\n        })\n\n        return has_videos, playlist\n\n    def _check_download_just_video(self, url, playlist_id):\n        # Check if it's a video-specific URL\n        query_dict = compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)\n        video_id = query_dict.get('v', [None])[0] or self._search_regex(\n            r'(?:(?:^|//)youtu\\.be/|youtube\\.com/embed/(?!videoseries))([0-9A-Za-z_-]{11})', url,\n            'video id', default=None)\n        if video_id:\n            if self._downloader.params.get('noplaylist'):\n                self.to_screen('Downloading just video %s because of --no-playlist' % video_id)\n                return video_id, self.url_result(video_id, 'Youtube', video_id=video_id)\n            else:\n                self.to_screen('Downloading playlist %s - add --no-playlist to just download video %s' % (playlist_id, video_id))\n                return video_id, None\n        return None, None\n\n    def _real_extract(self, url):\n        # Extract playlist id\n        mobj = re.match(self._VALID_URL, url)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n        playlist_id = mobj.group(1) or mobj.group(2)\n\n        video_id, video = self._check_download_just_video(url, playlist_id)\n        if video:\n            return video\n\n        if playlist_id.startswith(('RD', 'UL', 'PU')):\n            # Mixes require a custom extraction process\n            return self._extract_mix(playlist_id)\n\n        has_videos, playlist = self._extract_playlist(playlist_id)\n        if has_videos or not video_id:\n            return playlist\n\n        # Some playlist URLs don't actually serve a playlist (see\n        # https://github.com/rg3/youtube-dl/issues/10537).\n        # Fallback to plain video extraction if there is a video id\n        # along with playlist id.\n        return self.url_result(video_id, 'Youtube', video_id=video_id)\n\n\nclass YoutubeChannelIE(YoutubePlaylistBaseInfoExtractor):\n    IE_DESC = 'YouTube.com channels'\n    _VALID_URL = r'https?://(?:youtu\\.be|(?:\\w+\\.)?youtube(?:-nocookie)?\\.com)/channel/(?P<id>[0-9A-Za-z_-]+)'\n    _TEMPLATE_URL = 'https://www.youtube.com/channel/%s/videos'\n    _VIDEO_RE = r'(?:title=\"(?P<title>[^\"]+)\"[^>]+)?href=\"/watch\\?v=(?P<id>[0-9A-Za-z_-]+)&?'\n    IE_NAME = 'youtube:channel'\n    _TESTS = [{\n        'note': 'paginated channel',\n        'url': 'https://www.youtube.com/channel/UCKfVa3S1e4PHvxWcwyMMg8w',\n        'playlist_mincount': 91,\n        'info_dict': {\n            'id': 'UUKfVa3S1e4PHvxWcwyMMg8w',\n            'title': 'Uploads from lex will',\n        }\n    }, {\n        'note': 'Age restricted channel',\n        # from https://www.youtube.com/user/DeusExOfficial\n        'url': 'https://www.youtube.com/channel/UCs0ifCMCm1icqRbqhUINa0w',\n        'playlist_mincount': 64,\n        'info_dict': {\n            'id': 'UUs0ifCMCm1icqRbqhUINa0w',\n            'title': 'Uploads from Deus Ex',\n        },\n    }]\n\n    @classmethod\n    def suitable(cls, url):\n        return (False if YoutubePlaylistsIE.suitable(url) or YoutubeLiveIE.suitable(url)\n                else super(YoutubeChannelIE, cls).suitable(url))\n\n    def _build_template_url(self, url, channel_id):\n        return self._TEMPLATE_URL % channel_id\n\n    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n\n        url = self._build_template_url(url, channel_id)\n\n        # Channel by page listing is restricted to 35 pages of 30 items, i.e. 1050 videos total (see #5778)\n        # Workaround by extracting as a playlist if managed to obtain channel playlist URL\n        # otherwise fallback on channel by page extraction\n        channel_page = self._download_webpage(\n            url + '?view=57', channel_id,\n            'Downloading channel page', fatal=False)\n        if channel_page is False:\n            channel_playlist_id = False\n        else:\n            channel_playlist_id = self._html_search_meta(\n                'channelId', channel_page, 'channel id', default=None)\n            if not channel_playlist_id:\n                channel_url = self._html_search_meta(\n                    ('al:ios:url', 'twitter:app:url:iphone', 'twitter:app:url:ipad'),\n                    channel_page, 'channel url', default=None)\n                if channel_url:\n                    channel_playlist_id = self._search_regex(\n                        r'vnd\\.youtube://user/([0-9A-Za-z_-]+)',\n                        channel_url, 'channel id', default=None)\n        if channel_playlist_id and channel_playlist_id.startswith('UC'):\n            playlist_id = 'UU' + channel_playlist_id[2:]\n            return self.url_result(\n                compat_urlparse.urljoin(url, '/playlist?list=%s' % playlist_id), 'YoutubePlaylist')\n\n        channel_page = self._download_webpage(url, channel_id, 'Downloading page #1')\n        autogenerated = re.search(r'''(?x)\n                class=\"[^\"]*?(?:\n                    channel-header-autogenerated-label|\n                    yt-channel-title-autogenerated\n                )[^\"]*\"''', channel_page) is not None\n\n        if autogenerated:\n            # The videos are contained in a single page\n            # the ajax pages can't be used, they are empty\n            entries = [\n                self.url_result(\n                    video_id, 'Youtube', video_id=video_id,\n                    video_title=video_title)\n                for video_id, video_title in self.extract_videos_from_page(channel_page)]\n            return self.playlist_result(entries, channel_id)\n\n        try:\n            next(self._entries(channel_page, channel_id))\n        except StopIteration:\n            alert_message = self._html_search_regex(\n                r'(?s)<div[^>]+class=([\"\\']).*?\\byt-alert-message\\b.*?\\1[^>]*>(?P<alert>[^<]+)</div>',\n                channel_page, 'alert', default=None, group='alert')\n            if alert_message:\n                raise ExtractorError('Youtube said: %s' % alert_message, expected=True)\n\n        return self.playlist_result(self._entries(channel_page, channel_id), channel_id)\n\n\nclass YoutubeUserIE(YoutubeChannelIE):\n    IE_DESC = 'YouTube.com user videos (URL or \"ytuser\" keyword)'\n    _VALID_URL = r'(?:(?:https?://(?:\\w+\\.)?youtube\\.com/(?:(?P<user>user|c)/)?(?!(?:attribution_link|watch|results|shared)(?:$|[^a-z_A-Z0-9-])))|ytuser:)(?!feed/)(?P<id>[A-Za-z0-9_-]+)'\n    _TEMPLATE_URL = 'https://www.youtube.com/%s/%s/videos'\n    IE_NAME = 'youtube:user'\n\n    _TESTS = [{\n        'url': 'https://www.youtube.com/user/TheLinuxFoundation',\n        'playlist_mincount': 320,\n        'info_dict': {\n            'id': 'UUfX55Sx5hEFjoC3cNs6mCUQ',\n            'title': 'Uploads from The Linux Foundation',\n        }\n    }, {\n        # Only available via https://www.youtube.com/c/12minuteathlete/videos\n        # but not https://www.youtube.com/user/12minuteathlete/videos\n        'url': 'https://www.youtube.com/c/12minuteathlete/videos',\n        'playlist_mincount': 249,\n        'info_dict': {\n            'id': 'UUVjM-zV6_opMDx7WYxnjZiQ',\n            'title': 'Uploads from 12 Minute Athlete',\n        }\n    }, {\n        'url': 'ytuser:phihag',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/c/gametrailers',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/gametrailers',\n        'only_matching': True,\n    }, {\n        # This channel is not available, geo restricted to JP\n        'url': 'https://www.youtube.com/user/kananishinoSMEJ/videos',\n        'only_matching': True,\n    }]\n\n    @classmethod\n    def suitable(cls, url):\n        # Don't return True if the url can be extracted with other youtube\n        # extractor, the regex would is too permissive and it would match.\n        other_yt_ies = iter(klass for (name, klass) in globals().items() if name.startswith('Youtube') and name.endswith('IE') and klass is not cls)\n        if any(ie.suitable(url) for ie in other_yt_ies):\n            return False\n        else:\n            return super(YoutubeUserIE, cls).suitable(url)\n\n    def _build_template_url(self, url, channel_id):\n        mobj = re.match(self._VALID_URL, url)\n        return self._TEMPLATE_URL % (mobj.group('user') or 'user', mobj.group('id'))\n\n\nclass YoutubeLiveIE(YoutubeBaseInfoExtractor):\n    IE_DESC = 'YouTube.com live streams'\n    _VALID_URL = r'(?P<base_url>https?://(?:\\w+\\.)?youtube\\.com/(?:(?:user|channel|c)/)?(?P<id>[^/]+))/live'\n    IE_NAME = 'youtube:live'\n\n    _TESTS = [{\n        'url': 'https://www.youtube.com/user/TheYoungTurks/live',\n        'info_dict': {\n            'id': 'a48o2S1cPoo',\n            'ext': 'mp4',\n            'title': 'The Young Turks - Live Main Show',\n            'uploader': 'The Young Turks',\n            'uploader_id': 'TheYoungTurks',\n            'uploader_url': r're:https?://(?:www\\.)?youtube\\.com/user/TheYoungTurks',\n            'upload_date': '20150715',\n            'license': 'Standard YouTube License',\n            'description': 'md5:438179573adcdff3c97ebb1ee632b891',\n            'categories': ['News & Politics'],\n            'tags': ['Cenk Uygur (TV Program Creator)', 'The Young Turks (Award-Winning Work)', 'Talk Show (TV Genre)'],\n            'like_count': int,\n            'dislike_count': int,\n        },\n        'params': {\n            'skip_download': True,\n        },\n    }, {\n        'url': 'https://www.youtube.com/channel/UC1yBKRuGpC1tSM73A0ZjYjQ/live',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/c/CommanderVideoHq/live',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/TheYoungTurks/live',\n        'only_matching': True,\n    }]\n\n    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        channel_id = mobj.group('id')\n        base_url = mobj.group('base_url')\n        webpage = self._download_webpage(url, channel_id, fatal=False)\n        if webpage:\n            page_type = self._og_search_property(\n                'type', webpage, 'page type', default='')\n            video_id = self._html_search_meta(\n                'videoId', webpage, 'video id', default=None)\n            if page_type.startswith('video') and video_id and re.match(\n                    r'^[0-9A-Za-z_-]{11}$', video_id):\n                return self.url_result(video_id, YoutubeIE.ie_key())\n        return self.url_result(base_url)\n\n\nclass YoutubePlaylistsIE(YoutubePlaylistsBaseInfoExtractor):\n    IE_DESC = 'YouTube.com user/channel playlists'\n    _VALID_URL = r'https?://(?:\\w+\\.)?youtube\\.com/(?:user|channel)/(?P<id>[^/]+)/playlists'\n    IE_NAME = 'youtube:playlists'\n\n    _TESTS = [{\n        'url': 'https://www.youtube.com/user/ThirstForScience/playlists',\n        'playlist_mincount': 4,\n        'info_dict': {\n            'id': 'ThirstForScience',\n            'title': 'Thirst for Science',\n        },\n    }, {\n        # with \"Load more\" button\n        'url': 'https://www.youtube.com/user/igorkle1/playlists?view=1&sort=dd',\n        'playlist_mincount': 70,\n        'info_dict': {\n            'id': 'igorkle1',\n            'title': '\u0418\u0433\u043e\u0440\u044c \u041a\u043b\u0435\u0439\u043d\u0435\u0440',\n        },\n    }, {\n        'url': 'https://www.youtube.com/channel/UCiU1dHvZObB2iP6xkJ__Icw/playlists',\n        'playlist_mincount': 17,\n        'info_dict': {\n            'id': 'UCiU1dHvZObB2iP6xkJ__Icw',\n            'title': 'Chem Player',\n        },\n    }]\n\n\nclass YoutubeSearchBaseInfoExtractor(YoutubePlaylistBaseInfoExtractor):\n    _VIDEO_RE = r'href=\"\\s*/watch\\?v=(?P<id>[0-9A-Za-z_-]{11})(?:[^\"]*\"[^>]+\\btitle=\"(?P<title>[^\"]+))?'\n\n\nclass YoutubeSearchIE(SearchInfoExtractor, YoutubeSearchBaseInfoExtractor):\n    IE_DESC = 'YouTube.com searches'\n    # there doesn't appear to be a real limit, for example if you search for\n    # 'python' you get more than 8.000.000 results\n    _MAX_RESULTS = float('inf')\n    IE_NAME = 'youtube:search'\n    _SEARCH_KEY = 'ytsearch'\n    _EXTRA_QUERY_ARGS = {}\n    _TESTS = []\n\n    def _get_n_results(self, query, n):\n        \"\"\"Get a specified number of results for a query\"\"\"\n\n        videos = []\n        limit = n\n\n        url_query = {\n            'search_query': query.encode('utf-8'),\n        }\n        url_query.update(self._EXTRA_QUERY_ARGS)\n        result_url = 'https://www.youtube.com/results?' + compat_urllib_parse_urlencode(url_query)\n\n        for pagenum in itertools.count(1):\n            data = self._download_json(\n                result_url, video_id='query \"%s\"' % query,\n                note='Downloading page %s' % pagenum,\n                errnote='Unable to download API page',\n                query={'spf': 'navigate'})\n            html_content = data[1]['body']['content']\n\n            if 'class=\"search-message' in html_content:\n                raise ExtractorError(\n                    '[youtube] No video results', expected=True)\n\n            new_videos = list(self._process_page(html_content))\n            videos += new_videos\n            if not new_videos or len(videos) > limit:\n                break\n            next_link = self._html_search_regex(\n                r'href=\"(/results\\?[^\"]*\\bsp=[^\"]+)\"[^>]*>\\s*<span[^>]+class=\"[^\"]*\\byt-uix-button-content\\b[^\"]*\"[^>]*>Next',\n                html_content, 'next link', default=None)\n            if next_link is None:\n                break\n            result_url = compat_urlparse.urljoin('https://www.youtube.com/', next_link)\n\n        if len(videos) > n:\n            videos = videos[:n]\n        return self.playlist_result(videos, query)\n\n\nclass YoutubeSearchDateIE(YoutubeSearchIE):\n    IE_NAME = YoutubeSearchIE.IE_NAME + ':date'\n    _SEARCH_KEY = 'ytsearchdate'\n    IE_DESC = 'YouTube.com searches, newest videos first'\n    _EXTRA_QUERY_ARGS = {'search_sort': 'video_date_uploaded'}\n\n\nclass YoutubeSearchURLIE(YoutubeSearchBaseInfoExtractor):\n    IE_DESC = 'YouTube.com search URLs'\n    IE_NAME = 'youtube:search_url'\n    _VALID_URL = r'https?://(?:www\\.)?youtube\\.com/results\\?(.*?&)?(?:search_query|q)=(?P<query>[^&]+)(?:[&]|$)'\n    _TESTS = [{\n        'url': 'https://www.youtube.com/results?baz=bar&search_query=youtube-dl+test+video&filters=video&lclk=video',\n        'playlist_mincount': 5,\n        'info_dict': {\n            'title': 'youtube-dl test video',\n        }\n    }, {\n        'url': 'https://www.youtube.com/results?q=test&sp=EgQIBBgB',\n        'only_matching': True,\n    }]\n\n    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        query = compat_urllib_parse_unquote_plus(mobj.group('query'))\n        webpage = self._download_webpage(url, query)\n        return self.playlist_result(self._process_page(webpage), playlist_title=query)\n\n\nclass YoutubeShowIE(YoutubePlaylistsBaseInfoExtractor):\n    IE_DESC = 'YouTube.com (multi-season) shows'\n    _VALID_URL = r'https?://(?:www\\.)?youtube\\.com/show/(?P<id>[^?#]*)'\n    IE_NAME = 'youtube:show'\n    _TESTS = [{\n        'url': 'https://www.youtube.com/show/airdisasters',\n        'playlist_mincount': 5,\n        'info_dict': {\n            'id': 'airdisasters',\n            'title': 'Air Disasters',\n        }\n    }]\n\n    def _real_extract(self, url):\n        playlist_id = self._match_id(url)\n        return super(YoutubeShowIE, self)._real_extract(\n            'https://www.youtube.com/show/%s/playlists' % playlist_id)\n\n\nclass YoutubeFeedsInfoExtractor(YoutubeBaseInfoExtractor):\n    \"\"\"\n    Base class for feed extractors\n    Subclasses must define the _FEED_NAME and _PLAYLIST_TITLE properties.\n    \"\"\"\n    _LOGIN_REQUIRED = True\n\n    @property\n    def IE_NAME(self):\n        return 'youtube:%s' % self._FEED_NAME\n\n    def _real_initialize(self):\n        self._login()\n\n    def _real_extract(self, url):\n        page = self._download_webpage(\n            'https://www.youtube.com/feed/%s' % self._FEED_NAME, self._PLAYLIST_TITLE)\n\n        # The extraction process is the same as for playlists, but the regex\n        # for the video ids doesn't contain an index\n        ids = []\n        more_widget_html = content_html = page\n        for page_num in itertools.count(1):\n            matches = re.findall(r'href=\"\\s*/watch\\?v=([0-9A-Za-z_-]{11})', content_html)\n\n            # 'recommended' feed has infinite 'load more' and each new portion spins\n            # the same videos in (sometimes) slightly different order, so we'll check\n            # for unicity and break when portion has no new videos\n            new_ids = filter(lambda video_id: video_id not in ids, orderedSet(matches))\n            if not new_ids:\n                break\n\n            ids.extend(new_ids)\n\n            mobj = re.search(r'data-uix-load-more-href=\"/?(?P<more>[^\"]+)\"', more_widget_html)\n            if not mobj:\n                break\n\n            more = self._download_json(\n                'https://youtube.com/%s' % mobj.group('more'), self._PLAYLIST_TITLE,\n                'Downloading page #%s' % page_num,\n                transform_source=uppercase_escape)\n            content_html = more['content_html']\n            more_widget_html = more['load_more_widget_html']\n\n        return self.playlist_result(\n            self._ids_to_results(ids), playlist_title=self._PLAYLIST_TITLE)\n\n\nclass YoutubeWatchLaterIE(YoutubePlaylistIE):\n    IE_NAME = 'youtube:watchlater'\n    IE_DESC = 'Youtube watch later list, \":ytwatchlater\" for short (requires authentication)'\n    _VALID_URL = r'https?://(?:www\\.)?youtube\\.com/(?:feed/watch_later|(?:playlist|watch)\\?(?:.+&)?list=WL)|:ytwatchlater'\n\n    _TESTS = [{\n        'url': 'https://www.youtube.com/playlist?list=WL',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/watch?v=bCNU9TrbiRk&index=1&list=WL',\n        'only_matching': True,\n    }]\n\n    def _real_extract(self, url):\n        _, video = self._check_download_just_video(url, 'WL')\n        if video:\n            return video\n        _, playlist = self._extract_playlist('WL')\n        return playlist\n\n\nclass YoutubeFavouritesIE(YoutubeBaseInfoExtractor):\n    IE_NAME = 'youtube:favorites'\n    IE_DESC = 'YouTube.com favourite videos, \":ytfav\" for short (requires authentication)'\n    _VALID_URL = r'https?://(?:www\\.)?youtube\\.com/my_favorites|:ytfav(?:ou?rites)?'\n    _LOGIN_REQUIRED = True\n\n    def _real_extract(self, url):\n        webpage = self._download_webpage('https://www.youtube.com/my_favorites', 'Youtube Favourites videos')\n        playlist_id = self._search_regex(r'list=(.+?)[\"&]', webpage, 'favourites playlist id')\n        return self.url_result(playlist_id, 'YoutubePlaylist')\n\n\nclass YoutubeRecommendedIE(YoutubeFeedsInfoExtractor):\n    IE_DESC = 'YouTube.com recommended videos, \":ytrec\" for short (requires authentication)'\n    _VALID_URL = r'https?://(?:www\\.)?youtube\\.com/feed/recommended|:ytrec(?:ommended)?'\n    _FEED_NAME = 'recommended'\n    _PLAYLIST_TITLE = 'Youtube Recommended videos'\n\n\nclass YoutubeSubscriptionsIE(YoutubeFeedsInfoExtractor):\n    IE_DESC = 'YouTube.com subscriptions feed, \"ytsubs\" keyword (requires authentication)'\n    _VALID_URL = r'https?://(?:www\\.)?youtube\\.com/feed/subscriptions|:ytsubs(?:criptions)?'\n    _FEED_NAME = 'subscriptions'\n    _PLAYLIST_TITLE = 'Youtube Subscriptions'\n\n\nclass YoutubeHistoryIE(YoutubeFeedsInfoExtractor):\n    IE_DESC = 'Youtube watch history, \":ythistory\" for short (requires authentication)'\n    _VALID_URL = r'https?://(?:www\\.)?youtube\\.com/feed/history|:ythistory'\n    _FEED_NAME = 'history'\n    _PLAYLIST_TITLE = 'Youtube History'\n\n\nclass YoutubeTruncatedURLIE(InfoExtractor):\n    IE_NAME = 'youtube:truncated_url'\n    IE_DESC = False  # Do not list\n    _VALID_URL = r'''(?x)\n        (?:https?://)?\n        (?:\\w+\\.)?[yY][oO][uU][tT][uU][bB][eE](?:-nocookie)?\\.com/\n        (?:watch\\?(?:\n            feature=[a-z_]+|\n            annotation_id=annotation_[^&]+|\n            x-yt-cl=[0-9]+|\n            hl=[^&]*|\n            t=[0-9]+\n        )?\n        |\n            attribution_link\\?a=[^&]+\n        )\n        $\n    '''\n\n    _TESTS = [{\n        'url': 'https://www.youtube.com/watch?annotation_id=annotation_3951667041',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/watch?',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/watch?x-yt-cl=84503534',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/watch?feature=foo',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/watch?hl=en-GB',\n        'only_matching': True,\n    }, {\n        'url': 'https://www.youtube.com/watch?t=2372',\n        'only_matching': True,\n    }]\n\n    def _real_extract(self, url):\n        raise ExtractorError(\n            'Did you forget to quote the URL? Remember that & is a meta '\n            'character in most shells, so you want to put the URL in quotes, '\n            'like  youtube-dl '\n            '\"https://www.youtube.com/watch?feature=foo&v=BaW_jenozKc\" '\n            ' or simply  youtube-dl BaW_jenozKc  .',\n            expected=True)\n\n\nclass YoutubeTruncatedIDIE(InfoExtractor):\n    IE_NAME = 'youtube:truncated_id'\n    IE_DESC = False  # Do not list\n    _VALID_URL = r'https?://(?:www\\.)?youtube\\.com/watch\\?v=(?P<id>[0-9A-Za-z_-]{1,10})$'\n\n    _TESTS = [{\n        'url': 'https://www.youtube.com/watch?v=N_708QY7Ob',\n        'only_matching': True,\n    }]\n\n    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        raise ExtractorError(\n            'Incomplete YouTube ID %s. URL %s looks truncated.' % (video_id, url),\n            expected=True)\n", "description": "Command-line program to download videos from YouTube.com and other video sites", "file_name": "youtube.py", "language": "Python", "project_name": "youtube-dl", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/rg3_youtube-dl/rg3-youtube-dl-6202f08/youtube_dl/extractor/youtube.py", "save_time": "", "source": "", "update_at": "2018-03-07T09:18:39Z", "url": "https://github.com/rg3/youtube-dl", "wiki": false}