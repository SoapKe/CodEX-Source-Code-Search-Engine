{"author": "donnemartin", "code": " \nimport pandas as pd\nimport numpy as np\nimport csv as csv\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n\ntrain_df = pd.read_csv('train.csv', header=0)        \n\n\n\n\n\ntrain_df['Gender'] = train_df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n\n\n\n\n\nif len(train_df.Embarked[ train_df.Embarked.isnull() ]) > 0:\n    train_df.Embarked[ train_df.Embarked.isnull() ] = train_df.Embarked.dropna().mode().values\n\nPorts = list(enumerate(np.unique(train_df['Embarked'])))    \nPorts_dict = { name : i for i, name in Ports }              \ntrain_df.Embarked = train_df.Embarked.map( lambda x: Ports_dict[x]).astype(int)     \n\n\nmedian_age = train_df['Age'].dropna().median()\nif len(train_df.Age[ train_df.Age.isnull() ]) > 0:\n    train_df.loc[ (train_df.Age.isnull()), 'Age'] = median_age\n\n# Remove the Name column, Cabin, Ticket, and Sex (since I copied and filled it to Gender)\ntrain_df = train_df.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'PassengerId'], axis=1) \n\n\n\ntest_df = pd.read_csv('test.csv', header=0)        \n\n\n\n\ntest_df['Gender'] = test_df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n\n\n\nif len(test_df.Embarked[ test_df.Embarked.isnull() ]) > 0:\n    test_df.Embarked[ test_df.Embarked.isnull() ] = test_df.Embarked.dropna().mode().values\n\ntest_df.Embarked = test_df.Embarked.map( lambda x: Ports_dict[x]).astype(int)\n\n\n\nmedian_age = test_df['Age'].dropna().median()\nif len(test_df.Age[ test_df.Age.isnull() ]) > 0:\n    test_df.loc[ (test_df.Age.isnull()), 'Age'] = median_age\n\n\nif len(test_df.Fare[ test_df.Fare.isnull() ]) > 0:\n    median_fare = np.zeros(3)\n    for f in range(0,3):                                              \n        median_fare[f] = test_df[ test_df.Pclass == f+1 ]['Fare'].dropna().median()\n    for f in range(0,3):                                              \n        test_df.loc[ (test_df.Fare.isnull()) & (test_df.Pclass == f+1 ), 'Fare'] = median_fare[f]\n\n\nids = test_df['PassengerId'].values\n# Remove the Name column, Cabin, Ticket, and Sex (since I copied and filled it to Gender)\ntest_df = test_df.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'PassengerId'], axis=1) \n\n\n\n\ntrain_data = train_df.values\ntest_data = test_df.values\n\n\nprint 'Training...'\nforest = RandomForestClassifier(n_estimators=100)\nforest = forest.fit( train_data[0::,1::], train_data[0::,0] )\n\nprint 'Predicting...'\noutput = forest.predict(test_data).astype(int)\n\n\npredictions_file = open(\"myfirstforest.csv\", \"wb\")\nopen_file_object = csv.writer(predictions_file)\nopen_file_object.writerow([\"PassengerId\",\"Survived\"])\nopen_file_object.writerows(zip(ids, output))\npredictions_file.close()\nprint 'Done.'\n", "comments": "    writing first randomforest code  author   astrodave date   23rd september 2012 revised  15 april 2014 please see packages python org milk randomforests html         data cleanup    train data    load train file dataframe    i need convert strings integer classifiers     i need fill missing values data make complete     female   0  male   1    embarked  c    q    s     note ideal  translating categories numbers  port  2  2 times greater port  1   etc     all missing embarked    make embark common place    determine values embarked     set dictionary form  ports   index    convert embark strings int    all ages data    make median ages    remove name column  cabin  ticket  sex (since i copied filled gender)    test data    load test file dataframe    i need test data  columns training data    i need convert strings integer classifiers     female   0  male   1    embarked  c    q    s     all missing embarked    make embark common place    again convert embarked strings int    all ages data    make median ages    all missing fares    assume median respective class    loop 0 2    loop 0 2    collect test data passengerids dropping    remove name column  cabin  ticket  sex (since i copied filled gender)    the data ready go  so lets fit train  predict test     convert back numpy array ", "content": "\"\"\" Writing my first randomforest code.\nAuthor : AstroDave\nDate : 23rd September 2012\nRevised: 15 April 2014\nplease see packages.python.org/milk/randomforests.html for more\n\n\"\"\" \nimport pandas as pd\nimport numpy as np\nimport csv as csv\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Data cleanup\n# TRAIN DATA\ntrain_df = pd.read_csv('train.csv', header=0)        # Load the train file into a dataframe\n\n# I need to convert all strings to integer classifiers.\n# I need to fill in the missing values of the data and make it complete.\n\n# female = 0, Male = 1\ntrain_df['Gender'] = train_df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n\n# Embarked from 'C', 'Q', 'S'\n# Note this is not ideal: in translating categories to numbers, Port \"2\" is not 2 times greater than Port \"1\", etc.\n\n# All missing Embarked -> just make them embark from most common place\nif len(train_df.Embarked[ train_df.Embarked.isnull() ]) > 0:\n    train_df.Embarked[ train_df.Embarked.isnull() ] = train_df.Embarked.dropna().mode().values\n\nPorts = list(enumerate(np.unique(train_df['Embarked'])))    # determine all values of Embarked,\nPorts_dict = { name : i for i, name in Ports }              # set up a dictionary in the form  Ports : index\ntrain_df.Embarked = train_df.Embarked.map( lambda x: Ports_dict[x]).astype(int)     # Convert all Embark strings to int\n\n# All the ages with no data -> make the median of all Ages\nmedian_age = train_df['Age'].dropna().median()\nif len(train_df.Age[ train_df.Age.isnull() ]) > 0:\n    train_df.loc[ (train_df.Age.isnull()), 'Age'] = median_age\n\n# Remove the Name column, Cabin, Ticket, and Sex (since I copied and filled it to Gender)\ntrain_df = train_df.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'PassengerId'], axis=1) \n\n\n# TEST DATA\ntest_df = pd.read_csv('test.csv', header=0)        # Load the test file into a dataframe\n\n# I need to do the same with the test data now, so that the columns are the same as the training data\n# I need to convert all strings to integer classifiers:\n# female = 0, Male = 1\ntest_df['Gender'] = test_df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n\n# Embarked from 'C', 'Q', 'S'\n# All missing Embarked -> just make them embark from most common place\nif len(test_df.Embarked[ test_df.Embarked.isnull() ]) > 0:\n    test_df.Embarked[ test_df.Embarked.isnull() ] = test_df.Embarked.dropna().mode().values\n# Again convert all Embarked strings to int\ntest_df.Embarked = test_df.Embarked.map( lambda x: Ports_dict[x]).astype(int)\n\n\n# All the ages with no data -> make the median of all Ages\nmedian_age = test_df['Age'].dropna().median()\nif len(test_df.Age[ test_df.Age.isnull() ]) > 0:\n    test_df.loc[ (test_df.Age.isnull()), 'Age'] = median_age\n\n# All the missing Fares -> assume median of their respective class\nif len(test_df.Fare[ test_df.Fare.isnull() ]) > 0:\n    median_fare = np.zeros(3)\n    for f in range(0,3):                                              # loop 0 to 2\n        median_fare[f] = test_df[ test_df.Pclass == f+1 ]['Fare'].dropna().median()\n    for f in range(0,3):                                              # loop 0 to 2\n        test_df.loc[ (test_df.Fare.isnull()) & (test_df.Pclass == f+1 ), 'Fare'] = median_fare[f]\n\n# Collect the test data's PassengerIds before dropping it\nids = test_df['PassengerId'].values\n# Remove the Name column, Cabin, Ticket, and Sex (since I copied and filled it to Gender)\ntest_df = test_df.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'PassengerId'], axis=1) \n\n\n# The data is now ready to go. So lets fit to the train, then predict to the test!\n# Convert back to a numpy array\ntrain_data = train_df.values\ntest_data = test_df.values\n\n\nprint 'Training...'\nforest = RandomForestClassifier(n_estimators=100)\nforest = forest.fit( train_data[0::,1::], train_data[0::,0] )\n\nprint 'Predicting...'\noutput = forest.predict(test_data).astype(int)\n\n\npredictions_file = open(\"myfirstforest.csv\", \"wb\")\nopen_file_object = csv.writer(predictions_file)\nopen_file_object.writerow([\"PassengerId\",\"Survived\"])\nopen_file_object.writerows(zip(ids, output))\npredictions_file.close()\nprint 'Done.'\n", "description": "Data science Python notebooks: Deep learning (TensorFlow, Theano, Caffe, Keras), scikit-learn, Kaggle, big data (Spark, Hadoop MapReduce, HDFS), matplotlib, pandas, NumPy, SciPy, Python essentials, AWS, and various command lines.", "file_name": "myfirstforest.py", "id": "149d178d0573c10398a45f0cd21a6fe7", "language": "Python", "project_name": "data-science-ipython-notebooks", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/donnemartin-data-science-ipython-notebooks/donnemartin-data-science-ipython-notebooks-a876e34/data/titanic/myfirstforest.py", "save_time": "", "source": "", "update_at": "2018-03-13T23:30:30Z", "url": "https://github.com/donnemartin/data-science-ipython-notebooks", "wiki": true}