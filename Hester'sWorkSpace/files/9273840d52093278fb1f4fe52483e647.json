{"author": "rg3", "code": "\nfrom __future__ import unicode_literals\n\nimport re\n\nfrom .adobepass import AdobePassIE\nfrom ..compat import compat_str\nfrom ..utils import (\n    xpath_text,\n    int_or_none,\n    determine_ext,\n    parse_duration,\n    xpath_attr,\n    update_url_query,\n    ExtractorError,\n    strip_or_none,\n)\n\n\nclass TurnerBaseIE(AdobePassIE):\n    _AKAMAI_SPE_TOKEN_CACHE = {}\n\n    def _extract_timestamp(self, video_data):\n        return int_or_none(xpath_attr(video_data, 'dateCreated', 'uts'))\n\n    def _add_akamai_spe_token(self, tokenizer_src, video_url, content_id, ap_data):\n        secure_path = self._search_regex(r'https?://[^/]+(.+/)', video_url, 'secure path') + '*'\n        token = self._AKAMAI_SPE_TOKEN_CACHE.get(secure_path)\n        if not token:\n            query = {\n                'path': secure_path,\n                'videoId': content_id,\n            }\n            if ap_data.get('auth_required'):\n                query['accessToken'] = self._extract_mvpd_auth(ap_data['url'], content_id, ap_data['site_name'], ap_data['site_name'])\n            auth = self._download_xml(\n                tokenizer_src, content_id, query=query)\n            error_msg = xpath_text(auth, 'error/msg')\n            if error_msg:\n                raise ExtractorError(error_msg, expected=True)\n            token = xpath_text(auth, 'token')\n            if not token:\n                return video_url\n            self._AKAMAI_SPE_TOKEN_CACHE[secure_path] = token\n        return video_url + '?hdnea=' + token\n\n    def _extract_cvp_info(self, data_src, video_id, path_data={}, ap_data={}):\n        video_data = self._download_xml(data_src, video_id)\n        video_id = video_data.attrib['id']\n        title = xpath_text(video_data, 'headline', fatal=True)\n        content_id = xpath_text(video_data, 'contentId') or video_id\n        \n        \n        \n        \n        \n        \n\n        urls = []\n        formats = []\n        rex = re.compile(\n            r'(?P<width>[0-9]+)x(?P<height>[0-9]+)(?:_(?P<bitrate>[0-9]+))?')\n        \n        \n        for video_file in video_data.findall('.//file'):\n            video_url = video_file.text.strip()\n            if not video_url:\n                continue\n            ext = determine_ext(video_url)\n            if video_url.startswith('/mp4:protected/'):\n                continue\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n            elif video_url.startswith('/secure/'):\n                secure_path_data = path_data.get('secure')\n                if not secure_path_data:\n                    continue\n                video_url = self._add_akamai_spe_token(\n                    secure_path_data['tokenizer_src'],\n                    secure_path_data['media_src'] + video_url,\n                    content_id, ap_data)\n            elif not re.match('https?://', video_url):\n                base_path_data = path_data.get(ext, path_data.get('default', {}))\n                media_src = base_path_data.get('media_src')\n                if not media_src:\n                    continue\n                video_url = media_src + video_url\n            if video_url in urls:\n                continue\n            urls.append(video_url)\n            format_id = video_file.get('bitrate')\n            if ext == 'smil':\n                formats.extend(self._extract_smil_formats(\n                    video_url, video_id, fatal=False))\n            elif ext == 'm3u8':\n                m3u8_formats = self._extract_m3u8_formats(\n                    video_url, video_id, 'mp4',\n                    m3u8_id=format_id or 'hls', fatal=False)\n                if '/secure/' in video_url and '?hdnea=' in video_url:\n                    for f in m3u8_formats:\n                        f['_seekable'] = False\n                formats.extend(m3u8_formats)\n            elif ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    update_url_query(video_url, {'hdcore': '3.7.0'}),\n                    video_id, f4m_id=format_id or 'hds', fatal=False))\n            else:\n                f = {\n                    'format_id': format_id,\n                    'url': video_url,\n                    'ext': ext,\n                }\n                mobj = rex.search(format_id + video_url)\n                if mobj:\n                    f.update({\n                        'width': int(mobj.group('width')),\n                        'height': int(mobj.group('height')),\n                        'tbr': int_or_none(mobj.group('bitrate')),\n                    })\n                elif isinstance(format_id, compat_str):\n                    if format_id.isdigit():\n                        f['tbr'] = int(format_id)\n                    else:\n                        mobj = re.match(r'ios_(audio|[0-9]+)$', format_id)\n                        if mobj:\n                            if mobj.group(1) == 'audio':\n                                f.update({\n                                    'vcodec': 'none',\n                                    'ext': 'm4a',\n                                })\n                            else:\n                                f['tbr'] = int(mobj.group(1))\n                formats.append(f)\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for source in video_data.findall('closedCaptions/source'):\n            for track in source.findall('track'):\n                track_url = track.get('url')\n                if not isinstance(track_url, compat_str) or track_url.endswith('/big'):\n                    continue\n                lang = track.get('lang') or track.get('label') or 'en'\n                subtitles.setdefault(lang, []).append({\n                    'url': track_url,\n                    'ext': {\n                        'scc': 'scc',\n                        'webvtt': 'vtt',\n                        'smptett': 'tt',\n                    }.get(source.get('format'))\n                })\n\n        thumbnails = [{\n            'id': image.get('cut'),\n            'url': image.text,\n            'width': int_or_none(image.get('width')),\n            'height': int_or_none(image.get('height')),\n        } for image in video_data.findall('images/image')]\n\n        is_live = xpath_text(video_data, 'isLive') == 'true'\n\n        return {\n            'id': video_id,\n            'title': self._live_title(title) if is_live else title,\n            'formats': formats,\n            'subtitles': subtitles,\n            'thumbnails': thumbnails,\n            'thumbnail': xpath_text(video_data, 'poster'),\n            'description': strip_or_none(xpath_text(video_data, 'description')),\n            'duration': parse_duration(xpath_text(video_data, 'length') or xpath_text(video_data, 'trt')),\n            'timestamp': self._extract_timestamp(video_data),\n            'upload_date': xpath_attr(video_data, 'metas', 'version'),\n            'series': xpath_text(video_data, 'showTitle'),\n            'season_number': int_or_none(xpath_text(video_data, 'seasonNumber')),\n            'episode_number': int_or_none(xpath_text(video_data, 'episodeNumber')),\n            'is_live': is_live,\n        }\n", "comments": "# coding: utf-8\n# rtmp_src = xpath_text(video_data, 'akamai/src')\n# if rtmp_src:\n#     splited_rtmp_src = rtmp_src.split(',')\n#     if len(splited_rtmp_src) == 2:\n#         rtmp_src = splited_rtmp_src[1]\n# aifp = xpath_text(video_data, 'akamai/aifp', default='')\n# Possible formats locations: files/file, files/groupFiles/files\n# and maybe others\n# TODO Correct extraction for these files\n# protected_path_data = path_data.get('protected')\n# if not protected_path_data or not rtmp_src:\n#     continue\n# protected_path = self._search_regex(\n#     r'/mp4:(.+)\\.[a-z0-9]', video_url, 'secure path')\n# auth = self._download_webpage(\n#     protected_path_data['tokenizer_src'], query={\n#         'path': protected_path,\n#         'videoId': content_id,\n#         'aifp': aifp,\n#     })\n# token = xpath_text(auth, 'token')\n# if not token:\n#     continue\n# video_url = rtmp_src + video_url + '?' + token\n", "content": "# coding: utf-8\nfrom __future__ import unicode_literals\n\nimport re\n\nfrom .adobepass import AdobePassIE\nfrom ..compat import compat_str\nfrom ..utils import (\n    xpath_text,\n    int_or_none,\n    determine_ext,\n    parse_duration,\n    xpath_attr,\n    update_url_query,\n    ExtractorError,\n    strip_or_none,\n)\n\n\nclass TurnerBaseIE(AdobePassIE):\n    _AKAMAI_SPE_TOKEN_CACHE = {}\n\n    def _extract_timestamp(self, video_data):\n        return int_or_none(xpath_attr(video_data, 'dateCreated', 'uts'))\n\n    def _add_akamai_spe_token(self, tokenizer_src, video_url, content_id, ap_data):\n        secure_path = self._search_regex(r'https?://[^/]+(.+/)', video_url, 'secure path') + '*'\n        token = self._AKAMAI_SPE_TOKEN_CACHE.get(secure_path)\n        if not token:\n            query = {\n                'path': secure_path,\n                'videoId': content_id,\n            }\n            if ap_data.get('auth_required'):\n                query['accessToken'] = self._extract_mvpd_auth(ap_data['url'], content_id, ap_data['site_name'], ap_data['site_name'])\n            auth = self._download_xml(\n                tokenizer_src, content_id, query=query)\n            error_msg = xpath_text(auth, 'error/msg')\n            if error_msg:\n                raise ExtractorError(error_msg, expected=True)\n            token = xpath_text(auth, 'token')\n            if not token:\n                return video_url\n            self._AKAMAI_SPE_TOKEN_CACHE[secure_path] = token\n        return video_url + '?hdnea=' + token\n\n    def _extract_cvp_info(self, data_src, video_id, path_data={}, ap_data={}):\n        video_data = self._download_xml(data_src, video_id)\n        video_id = video_data.attrib['id']\n        title = xpath_text(video_data, 'headline', fatal=True)\n        content_id = xpath_text(video_data, 'contentId') or video_id\n        # rtmp_src = xpath_text(video_data, 'akamai/src')\n        # if rtmp_src:\n        #     splited_rtmp_src = rtmp_src.split(',')\n        #     if len(splited_rtmp_src) == 2:\n        #         rtmp_src = splited_rtmp_src[1]\n        # aifp = xpath_text(video_data, 'akamai/aifp', default='')\n\n        urls = []\n        formats = []\n        rex = re.compile(\n            r'(?P<width>[0-9]+)x(?P<height>[0-9]+)(?:_(?P<bitrate>[0-9]+))?')\n        # Possible formats locations: files/file, files/groupFiles/files\n        # and maybe others\n        for video_file in video_data.findall('.//file'):\n            video_url = video_file.text.strip()\n            if not video_url:\n                continue\n            ext = determine_ext(video_url)\n            if video_url.startswith('/mp4:protected/'):\n                continue\n                # TODO Correct extraction for these files\n                # protected_path_data = path_data.get('protected')\n                # if not protected_path_data or not rtmp_src:\n                #     continue\n                # protected_path = self._search_regex(\n                #     r'/mp4:(.+)\\.[a-z0-9]', video_url, 'secure path')\n                # auth = self._download_webpage(\n                #     protected_path_data['tokenizer_src'], query={\n                #         'path': protected_path,\n                #         'videoId': content_id,\n                #         'aifp': aifp,\n                #     })\n                # token = xpath_text(auth, 'token')\n                # if not token:\n                #     continue\n                # video_url = rtmp_src + video_url + '?' + token\n            elif video_url.startswith('/secure/'):\n                secure_path_data = path_data.get('secure')\n                if not secure_path_data:\n                    continue\n                video_url = self._add_akamai_spe_token(\n                    secure_path_data['tokenizer_src'],\n                    secure_path_data['media_src'] + video_url,\n                    content_id, ap_data)\n            elif not re.match('https?://', video_url):\n                base_path_data = path_data.get(ext, path_data.get('default', {}))\n                media_src = base_path_data.get('media_src')\n                if not media_src:\n                    continue\n                video_url = media_src + video_url\n            if video_url in urls:\n                continue\n            urls.append(video_url)\n            format_id = video_file.get('bitrate')\n            if ext == 'smil':\n                formats.extend(self._extract_smil_formats(\n                    video_url, video_id, fatal=False))\n            elif ext == 'm3u8':\n                m3u8_formats = self._extract_m3u8_formats(\n                    video_url, video_id, 'mp4',\n                    m3u8_id=format_id or 'hls', fatal=False)\n                if '/secure/' in video_url and '?hdnea=' in video_url:\n                    for f in m3u8_formats:\n                        f['_seekable'] = False\n                formats.extend(m3u8_formats)\n            elif ext == 'f4m':\n                formats.extend(self._extract_f4m_formats(\n                    update_url_query(video_url, {'hdcore': '3.7.0'}),\n                    video_id, f4m_id=format_id or 'hds', fatal=False))\n            else:\n                f = {\n                    'format_id': format_id,\n                    'url': video_url,\n                    'ext': ext,\n                }\n                mobj = rex.search(format_id + video_url)\n                if mobj:\n                    f.update({\n                        'width': int(mobj.group('width')),\n                        'height': int(mobj.group('height')),\n                        'tbr': int_or_none(mobj.group('bitrate')),\n                    })\n                elif isinstance(format_id, compat_str):\n                    if format_id.isdigit():\n                        f['tbr'] = int(format_id)\n                    else:\n                        mobj = re.match(r'ios_(audio|[0-9]+)$', format_id)\n                        if mobj:\n                            if mobj.group(1) == 'audio':\n                                f.update({\n                                    'vcodec': 'none',\n                                    'ext': 'm4a',\n                                })\n                            else:\n                                f['tbr'] = int(mobj.group(1))\n                formats.append(f)\n        self._sort_formats(formats)\n\n        subtitles = {}\n        for source in video_data.findall('closedCaptions/source'):\n            for track in source.findall('track'):\n                track_url = track.get('url')\n                if not isinstance(track_url, compat_str) or track_url.endswith('/big'):\n                    continue\n                lang = track.get('lang') or track.get('label') or 'en'\n                subtitles.setdefault(lang, []).append({\n                    'url': track_url,\n                    'ext': {\n                        'scc': 'scc',\n                        'webvtt': 'vtt',\n                        'smptett': 'tt',\n                    }.get(source.get('format'))\n                })\n\n        thumbnails = [{\n            'id': image.get('cut'),\n            'url': image.text,\n            'width': int_or_none(image.get('width')),\n            'height': int_or_none(image.get('height')),\n        } for image in video_data.findall('images/image')]\n\n        is_live = xpath_text(video_data, 'isLive') == 'true'\n\n        return {\n            'id': video_id,\n            'title': self._live_title(title) if is_live else title,\n            'formats': formats,\n            'subtitles': subtitles,\n            'thumbnails': thumbnails,\n            'thumbnail': xpath_text(video_data, 'poster'),\n            'description': strip_or_none(xpath_text(video_data, 'description')),\n            'duration': parse_duration(xpath_text(video_data, 'length') or xpath_text(video_data, 'trt')),\n            'timestamp': self._extract_timestamp(video_data),\n            'upload_date': xpath_attr(video_data, 'metas', 'version'),\n            'series': xpath_text(video_data, 'showTitle'),\n            'season_number': int_or_none(xpath_text(video_data, 'seasonNumber')),\n            'episode_number': int_or_none(xpath_text(video_data, 'episodeNumber')),\n            'is_live': is_live,\n        }\n", "description": "Command-line program to download videos from YouTube.com and other video sites", "file_name": "turner.py", "language": "Python", "project_name": "youtube-dl", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/rg3_youtube-dl/rg3-youtube-dl-6202f08/youtube_dl/extractor/turner.py", "save_time": "", "source": "", "update_at": "2018-03-07T09:18:39Z", "url": "https://github.com/rg3/youtube-dl", "wiki": false}