{"author": "tornadoweb", "code": "\n Copyright 2009 Facebook\n\n Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n not use this file except in compliance with the License. You may obtain\n a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n License for the specific language governing permissions and limitations\n under the License.\n\n\"\"\"Implementation of an S3-like storage server based on local files.\n\nUseful to test features that will eventually run on S3, or if you want to\nrun something locally that was once running on S3.\n\nWe don't support all the features of S3, but it does work with the\nstandard S3 client for the most basic semantics. To use the standard\nS3 client with this module:\n\n    c = S3.AWSAuthConnection(\"\", \"\", server=\"localhost\", port=8888,\n                             is_secure=False)\n    c.create_bucket(\"mybucket\")\n    c.put(\"mybucket\", \"mykey\", \"a value\")\n    print c.get(\"mybucket\", \"mykey\").body\n\n\"\"\"\n\nimport bisect\nimport datetime\nimport hashlib\nimport os\nimport os.path\nimport urllib\n\nfrom tornado import escape\nfrom tornado import httpserver\nfrom tornado import ioloop\nfrom tornado import web\nfrom tornado.util import unicode_type\n\ntry:\n    long\nexcept NameError:\n    long = int\n\n\ndef start(port, root_directory=\"/tmp/s3\", bucket_depth=0):\n    \"\"\"Starts the mock S3 server on the given port at the given path.\"\"\"\n    application = S3Application(root_directory, bucket_depth)\n    http_server = httpserver.HTTPServer(application)\n    http_server.listen(port)\n    ioloop.IOLoop.current().start()\n\n\nclass S3Application(web.Application):\n    \"\"\"Implementation of an S3-like storage server based on local files.\n\n    If bucket depth is given, we break files up into multiple directories\n    to prevent hitting file system limits for number of files in each\n    directories. 1 means one level of directories, 2 means 2, etc.\n    \"\"\"\n    def __init__(self, root_directory, bucket_depth=0):\n        web.Application.__init__(self, [\n            (r\"/\", RootHandler),\n            (r\"/([^/]+)/(.+)\", ObjectHandler),\n            (r\"/([^/]+)/\", BucketHandler),\n        ])\n        self.directory = os.path.abspath(root_directory)\n        if not os.path.exists(self.directory):\n            os.makedirs(self.directory)\n        self.bucket_depth = bucket_depth\n\n\nclass BaseRequestHandler(web.RequestHandler):\n    SUPPORTED_METHODS = (\"PUT\", \"GET\", \"DELETE\")\n\n    def render_xml(self, value):\n        assert isinstance(value, dict) and len(value) == 1\n        self.set_header(\"Content-Type\", \"application/xml; charset=UTF-8\")\n        name = value.keys()[0]\n        parts = []\n        parts.append('<' + escape.utf8(name) +\n                     ' xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">')\n        self._render_parts(value.values()[0], parts)\n        parts.append('</' + escape.utf8(name) + '>')\n        self.finish('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n' +\n                    ''.join(parts))\n\n    def _render_parts(self, value, parts=[]):\n        if isinstance(value, (unicode_type, bytes)):\n            parts.append(escape.xhtml_escape(value))\n        elif isinstance(value, (int, long)):\n            parts.append(str(value))\n        elif isinstance(value, datetime.datetime):\n            parts.append(value.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\"))\n        elif isinstance(value, dict):\n            for name, subvalue in value.iteritems():\n                if not isinstance(subvalue, list):\n                    subvalue = [subvalue]\n                for subsubvalue in subvalue:\n                    parts.append('<' + escape.utf8(name) + '>')\n                    self._render_parts(subsubvalue, parts)\n                    parts.append('</' + escape.utf8(name) + '>')\n        else:\n            raise Exception(\"Unknown S3 value type %r\", value)\n\n    def _object_path(self, bucket, object_name):\n        if self.application.bucket_depth < 1:\n            return os.path.abspath(os.path.join(\n                self.application.directory, bucket, object_name))\n        hash = hashlib.md5(object_name).hexdigest()\n        path = os.path.abspath(os.path.join(\n            self.application.directory, bucket))\n        for i in range(self.application.bucket_depth):\n            path = os.path.join(path, hash[:2 * (i + 1)])\n        return os.path.join(path, object_name)\n\n\nclass RootHandler(BaseRequestHandler):\n    def get(self):\n        names = os.listdir(self.application.directory)\n        buckets = []\n        for name in names:\n            path = os.path.join(self.application.directory, name)\n            info = os.stat(path)\n            buckets.append({\n                \"Name\": name,\n                \"CreationDate\": datetime.datetime.utcfromtimestamp(\n                    info.st_ctime),\n            })\n        self.render_xml({\"ListAllMyBucketsResult\": {\n            \"Buckets\": {\"Bucket\": buckets},\n        }})\n\n\nclass BucketHandler(BaseRequestHandler):\n    def get(self, bucket_name):\n        prefix = self.get_argument(\"prefix\", u\"\")\n        marker = self.get_argument(\"marker\", u\"\")\n        max_keys = int(self.get_argument(\"max-keys\", 50000))\n        path = os.path.abspath(os.path.join(self.application.directory,\n                                            bucket_name))\n        terse = int(self.get_argument(\"terse\", 0))\n        if not path.startswith(self.application.directory) or \\\n           not os.path.isdir(path):\n            raise web.HTTPError(404)\n        object_names = []\n        for root, dirs, files in os.walk(path):\n            for file_name in files:\n                object_names.append(os.path.join(root, file_name))\n        skip = len(path) + 1\n        for i in range(self.application.bucket_depth):\n            skip += 2 * (i + 1) + 1\n        object_names = [n[skip:] for n in object_names]\n        object_names.sort()\n        contents = []\n\n        start_pos = 0\n        if marker:\n            start_pos = bisect.bisect_right(object_names, marker, start_pos)\n        if prefix:\n            start_pos = bisect.bisect_left(object_names, prefix, start_pos)\n\n        truncated = False\n        for object_name in object_names[start_pos:]:\n            if not object_name.startswith(prefix):\n                break\n            if len(contents) >= max_keys:\n                truncated = True\n                break\n            object_path = self._object_path(bucket_name, object_name)\n            c = {\"Key\": object_name}\n            if not terse:\n                info = os.stat(object_path)\n                c.update({\n                    \"LastModified\": datetime.datetime.utcfromtimestamp(\n                        info.st_mtime),\n                    \"Size\": info.st_size,\n                })\n            contents.append(c)\n            marker = object_name\n        self.render_xml({\"ListBucketResult\": {\n            \"Name\": bucket_name,\n            \"Prefix\": prefix,\n            \"Marker\": marker,\n            \"MaxKeys\": max_keys,\n            \"IsTruncated\": truncated,\n            \"Contents\": contents,\n        }})\n\n    def put(self, bucket_name):\n        path = os.path.abspath(os.path.join(\n            self.application.directory, bucket_name))\n        if not path.startswith(self.application.directory) or \\\n           os.path.exists(path):\n            raise web.HTTPError(403)\n        os.makedirs(path)\n        self.finish()\n\n    def delete(self, bucket_name):\n        path = os.path.abspath(os.path.join(\n            self.application.directory, bucket_name))\n        if not path.startswith(self.application.directory) or \\\n           not os.path.isdir(path):\n            raise web.HTTPError(404)\n        if len(os.listdir(path)) > 0:\n            raise web.HTTPError(403)\n        os.rmdir(path)\n        self.set_status(204)\n        self.finish()\n\n\nclass ObjectHandler(BaseRequestHandler):\n    def get(self, bucket, object_name):\n        object_name = urllib.unquote(object_name)\n        path = self._object_path(bucket, object_name)\n        if not path.startswith(self.application.directory) or \\\n           not os.path.isfile(path):\n            raise web.HTTPError(404)\n        info = os.stat(path)\n        self.set_header(\"Content-Type\", \"application/unknown\")\n        self.set_header(\"Last-Modified\", datetime.datetime.utcfromtimestamp(\n            info.st_mtime))\n        object_file = open(path, \"rb\")\n        try:\n            self.finish(object_file.read())\n        finally:\n            object_file.close()\n\n    def put(self, bucket, object_name):\n        object_name = urllib.unquote(object_name)\n        bucket_dir = os.path.abspath(os.path.join(\n            self.application.directory, bucket))\n        if not bucket_dir.startswith(self.application.directory) or \\\n           not os.path.isdir(bucket_dir):\n            raise web.HTTPError(404)\n        path = self._object_path(bucket, object_name)\n        if not path.startswith(bucket_dir) or os.path.isdir(path):\n            raise web.HTTPError(403)\n        directory = os.path.dirname(path)\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n        object_file = open(path, \"w\")\n        object_file.write(self.request.body)\n        object_file.close()\n        self.finish()\n\n    def delete(self, bucket, object_name):\n        object_name = urllib.unquote(object_name)\n        path = self._object_path(bucket, object_name)\n        if not path.startswith(self.application.directory) or \\\n           not os.path.isfile(path):\n            raise web.HTTPError(404)\n        os.unlink(path)\n        self.set_status(204)\n        self.finish()\n", "comments": "   implementation s3 like storage server based local files   useful test features eventually run s3  want run something locally running s3   we support features s3  work standard s3 client basic semantics  to use standard s3 client module       c   s3 awsauthconnection(        server  localhost   port 8888                               secure false)     c create bucket( mybucket )     c put( mybucket    mykey    value )     print c get( mybucket    mykey ) body       import bisect import datetime import hashlib import os import os path import urllib  tornado import escape tornado import httpserver tornado import ioloop tornado import web tornado util import unicode type  try      long except nameerror      long   int   def start(port  root directory   tmp s3   bucket depth 0)         starts mock s3 server given port given path         application   s3application(root directory  bucket depth)     http server   httpserver httpserver(application)     http server listen(port)     ioloop ioloop current() start()   class s3application(web application)         implementation s3 like storage server based local files       if bucket depth given  break files multiple directories     prevent hitting file system limits number files     directories  1 means one level directories  2 means 2  etc                copyright 2009 facebook       licensed apache license  version 2 0 (the  license )  may    use file except compliance license  you may obtain    copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis  without    warranties or conditions of any kind  either express implied  see    license specific language governing permissions limitations    license  ", "content": "#\n# Copyright 2009 Facebook\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\n\"\"\"Implementation of an S3-like storage server based on local files.\n\nUseful to test features that will eventually run on S3, or if you want to\nrun something locally that was once running on S3.\n\nWe don't support all the features of S3, but it does work with the\nstandard S3 client for the most basic semantics. To use the standard\nS3 client with this module:\n\n    c = S3.AWSAuthConnection(\"\", \"\", server=\"localhost\", port=8888,\n                             is_secure=False)\n    c.create_bucket(\"mybucket\")\n    c.put(\"mybucket\", \"mykey\", \"a value\")\n    print c.get(\"mybucket\", \"mykey\").body\n\n\"\"\"\n\nimport bisect\nimport datetime\nimport hashlib\nimport os\nimport os.path\nimport urllib\n\nfrom tornado import escape\nfrom tornado import httpserver\nfrom tornado import ioloop\nfrom tornado import web\nfrom tornado.util import unicode_type\n\ntry:\n    long\nexcept NameError:\n    long = int\n\n\ndef start(port, root_directory=\"/tmp/s3\", bucket_depth=0):\n    \"\"\"Starts the mock S3 server on the given port at the given path.\"\"\"\n    application = S3Application(root_directory, bucket_depth)\n    http_server = httpserver.HTTPServer(application)\n    http_server.listen(port)\n    ioloop.IOLoop.current().start()\n\n\nclass S3Application(web.Application):\n    \"\"\"Implementation of an S3-like storage server based on local files.\n\n    If bucket depth is given, we break files up into multiple directories\n    to prevent hitting file system limits for number of files in each\n    directories. 1 means one level of directories, 2 means 2, etc.\n    \"\"\"\n    def __init__(self, root_directory, bucket_depth=0):\n        web.Application.__init__(self, [\n            (r\"/\", RootHandler),\n            (r\"/([^/]+)/(.+)\", ObjectHandler),\n            (r\"/([^/]+)/\", BucketHandler),\n        ])\n        self.directory = os.path.abspath(root_directory)\n        if not os.path.exists(self.directory):\n            os.makedirs(self.directory)\n        self.bucket_depth = bucket_depth\n\n\nclass BaseRequestHandler(web.RequestHandler):\n    SUPPORTED_METHODS = (\"PUT\", \"GET\", \"DELETE\")\n\n    def render_xml(self, value):\n        assert isinstance(value, dict) and len(value) == 1\n        self.set_header(\"Content-Type\", \"application/xml; charset=UTF-8\")\n        name = value.keys()[0]\n        parts = []\n        parts.append('<' + escape.utf8(name) +\n                     ' xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">')\n        self._render_parts(value.values()[0], parts)\n        parts.append('</' + escape.utf8(name) + '>')\n        self.finish('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n' +\n                    ''.join(parts))\n\n    def _render_parts(self, value, parts=[]):\n        if isinstance(value, (unicode_type, bytes)):\n            parts.append(escape.xhtml_escape(value))\n        elif isinstance(value, (int, long)):\n            parts.append(str(value))\n        elif isinstance(value, datetime.datetime):\n            parts.append(value.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\"))\n        elif isinstance(value, dict):\n            for name, subvalue in value.iteritems():\n                if not isinstance(subvalue, list):\n                    subvalue = [subvalue]\n                for subsubvalue in subvalue:\n                    parts.append('<' + escape.utf8(name) + '>')\n                    self._render_parts(subsubvalue, parts)\n                    parts.append('</' + escape.utf8(name) + '>')\n        else:\n            raise Exception(\"Unknown S3 value type %r\", value)\n\n    def _object_path(self, bucket, object_name):\n        if self.application.bucket_depth < 1:\n            return os.path.abspath(os.path.join(\n                self.application.directory, bucket, object_name))\n        hash = hashlib.md5(object_name).hexdigest()\n        path = os.path.abspath(os.path.join(\n            self.application.directory, bucket))\n        for i in range(self.application.bucket_depth):\n            path = os.path.join(path, hash[:2 * (i + 1)])\n        return os.path.join(path, object_name)\n\n\nclass RootHandler(BaseRequestHandler):\n    def get(self):\n        names = os.listdir(self.application.directory)\n        buckets = []\n        for name in names:\n            path = os.path.join(self.application.directory, name)\n            info = os.stat(path)\n            buckets.append({\n                \"Name\": name,\n                \"CreationDate\": datetime.datetime.utcfromtimestamp(\n                    info.st_ctime),\n            })\n        self.render_xml({\"ListAllMyBucketsResult\": {\n            \"Buckets\": {\"Bucket\": buckets},\n        }})\n\n\nclass BucketHandler(BaseRequestHandler):\n    def get(self, bucket_name):\n        prefix = self.get_argument(\"prefix\", u\"\")\n        marker = self.get_argument(\"marker\", u\"\")\n        max_keys = int(self.get_argument(\"max-keys\", 50000))\n        path = os.path.abspath(os.path.join(self.application.directory,\n                                            bucket_name))\n        terse = int(self.get_argument(\"terse\", 0))\n        if not path.startswith(self.application.directory) or \\\n           not os.path.isdir(path):\n            raise web.HTTPError(404)\n        object_names = []\n        for root, dirs, files in os.walk(path):\n            for file_name in files:\n                object_names.append(os.path.join(root, file_name))\n        skip = len(path) + 1\n        for i in range(self.application.bucket_depth):\n            skip += 2 * (i + 1) + 1\n        object_names = [n[skip:] for n in object_names]\n        object_names.sort()\n        contents = []\n\n        start_pos = 0\n        if marker:\n            start_pos = bisect.bisect_right(object_names, marker, start_pos)\n        if prefix:\n            start_pos = bisect.bisect_left(object_names, prefix, start_pos)\n\n        truncated = False\n        for object_name in object_names[start_pos:]:\n            if not object_name.startswith(prefix):\n                break\n            if len(contents) >= max_keys:\n                truncated = True\n                break\n            object_path = self._object_path(bucket_name, object_name)\n            c = {\"Key\": object_name}\n            if not terse:\n                info = os.stat(object_path)\n                c.update({\n                    \"LastModified\": datetime.datetime.utcfromtimestamp(\n                        info.st_mtime),\n                    \"Size\": info.st_size,\n                })\n            contents.append(c)\n            marker = object_name\n        self.render_xml({\"ListBucketResult\": {\n            \"Name\": bucket_name,\n            \"Prefix\": prefix,\n            \"Marker\": marker,\n            \"MaxKeys\": max_keys,\n            \"IsTruncated\": truncated,\n            \"Contents\": contents,\n        }})\n\n    def put(self, bucket_name):\n        path = os.path.abspath(os.path.join(\n            self.application.directory, bucket_name))\n        if not path.startswith(self.application.directory) or \\\n           os.path.exists(path):\n            raise web.HTTPError(403)\n        os.makedirs(path)\n        self.finish()\n\n    def delete(self, bucket_name):\n        path = os.path.abspath(os.path.join(\n            self.application.directory, bucket_name))\n        if not path.startswith(self.application.directory) or \\\n           not os.path.isdir(path):\n            raise web.HTTPError(404)\n        if len(os.listdir(path)) > 0:\n            raise web.HTTPError(403)\n        os.rmdir(path)\n        self.set_status(204)\n        self.finish()\n\n\nclass ObjectHandler(BaseRequestHandler):\n    def get(self, bucket, object_name):\n        object_name = urllib.unquote(object_name)\n        path = self._object_path(bucket, object_name)\n        if not path.startswith(self.application.directory) or \\\n           not os.path.isfile(path):\n            raise web.HTTPError(404)\n        info = os.stat(path)\n        self.set_header(\"Content-Type\", \"application/unknown\")\n        self.set_header(\"Last-Modified\", datetime.datetime.utcfromtimestamp(\n            info.st_mtime))\n        object_file = open(path, \"rb\")\n        try:\n            self.finish(object_file.read())\n        finally:\n            object_file.close()\n\n    def put(self, bucket, object_name):\n        object_name = urllib.unquote(object_name)\n        bucket_dir = os.path.abspath(os.path.join(\n            self.application.directory, bucket))\n        if not bucket_dir.startswith(self.application.directory) or \\\n           not os.path.isdir(bucket_dir):\n            raise web.HTTPError(404)\n        path = self._object_path(bucket, object_name)\n        if not path.startswith(bucket_dir) or os.path.isdir(path):\n            raise web.HTTPError(403)\n        directory = os.path.dirname(path)\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n        object_file = open(path, \"w\")\n        object_file.write(self.request.body)\n        object_file.close()\n        self.finish()\n\n    def delete(self, bucket, object_name):\n        object_name = urllib.unquote(object_name)\n        path = self._object_path(bucket, object_name)\n        if not path.startswith(self.application.directory) or \\\n           not os.path.isfile(path):\n            raise web.HTTPError(404)\n        os.unlink(path)\n        self.set_status(204)\n        self.finish()\n", "description": "Tornado is a Python web framework and asynchronous networking library, originally developed at FriendFeed.", "file_name": "s3server.py", "id": "be0a2d079cdf2f0cc4882c156362707f", "language": "Python", "project_name": "tornado", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tornadoweb-tornado/tornadoweb-tornado-9a97ffb/demos/s3server/s3server.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:52:45Z", "url": "https://github.com/tornadoweb/tornado", "wiki": true}