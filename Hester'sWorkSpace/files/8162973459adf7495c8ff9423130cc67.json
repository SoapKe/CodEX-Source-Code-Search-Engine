{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\nr\"\"\" Script to train and test the grid navigation agent.\nUsage:\n  1. Testing a model.\n  CUDA_VISIBLE_DEVICES=0 LD_LIBRARY_PATH=/opt/cuda-8.0/lib64:/opt/cudnnv51/lib64 \\\n    PYTHONPATH='.' PYOPENGL_PLATFORM=egl python scripts/script_nav_agent_release.py \\\n    --config_name cmp.lmap_Msc.clip5.sbpd_d_r2r+bench_test \\\n    --logdir output/cmp.lmap_Msc.clip5.sbpd_d_r2r\n\n  2. Training a model (locally).\n  CUDA_VISIBLE_DEVICES=0 LD_LIBRARY_PATH=/opt/cuda-8.0/lib64:/opt/cudnnv51/lib64 \\\n    PYTHONPATH='.' PYOPENGL_PLATFORM=egl python scripts/script_nav_agent_release.py \\\n    --config_name cmp.lmap_Msc.clip5.sbpd_d_r2r+train_train \\\n    --logdir output/cmp.lmap_Msc.clip5.sbpd_d_r2r_\n\n  3. Training a model (distributed).\n   See https://www.tensorflow.org/deploy/distributed on how to setup distributed\n   training.\n  CUDA_VISIBLE_DEVICES=0 LD_LIBRARY_PATH=/opt/cuda-8.0/lib64:/opt/cudnnv51/lib64 \\\n    PYTHONPATH='.' PYOPENGL_PLATFORM=egl python scripts/script_nav_agent_release.py \\\n    --config_name cmp.lmap_Msc.clip5.sbpd_d_r2r+train_train \\\n    --logdir output/cmp.lmap_Msc.clip5.sbpd_d_r2r_ \\\n    --ps_tasks $num_ps --master $master_name --task $worker_id\n\"\"\"\n\nimport sys, os, numpy as np\nimport copy\nimport argparse, pprint\nimport time\nimport cProfile\nimport platform\n\n\nimport tensorflow as tf\nfrom tensorflow.contrib import slim\nfrom tensorflow.python.framework import ops\nfrom tensorflow.contrib.framework.python.ops import variables\n\nimport logging\nfrom tensorflow.python.platform import gfile\nfrom tensorflow.python.platform import app\nfrom tensorflow.python.platform import flags\nfrom cfgs import config_cmp\nfrom cfgs import config_vision_baseline\nimport datasets.nav_env as nav_env\nimport src.file_utils as fu \nimport src.utils as utils\nimport tfcode.cmp as cmp \nfrom tfcode import tf_utils\nfrom tfcode import vision_baseline_lstm\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string('master', '',\n                    'The address of the tensorflow master')\nflags.DEFINE_integer('ps_tasks', 0, 'The number of parameter servers. If the '\n                     'value is 0, then the parameters are handled locally by '\n                     'the worker.')\nflags.DEFINE_integer('task', 0, 'The Task ID. This value is used when training '\n                     'with multiple workers to identify each worker.')\n\nflags.DEFINE_integer('num_workers', 1, '')\n\nflags.DEFINE_string('config_name', '', '')\n\nflags.DEFINE_string('logdir', '', '')\n\nflags.DEFINE_integer('solver_seed', 0, '')\n\nflags.DEFINE_integer('delay_start_iters', 20, '')\n\nlogging.basicConfig(level=logging.INFO)\n\ndef main(_):\n  _launcher(FLAGS.config_name, FLAGS.logdir)\n\ndef _launcher(config_name, logdir):\n  args = _setup_args(config_name, logdir)\n\n  fu.makedirs(args.logdir)\n\n  if args.control.train:\n    _train(args)\n\n  if args.control.test:\n    _test(args)\n\ndef get_args_for_config(config_name):\n  configs = config_name.split('.')\n  type = configs[0]\n  config_name = '.'.join(configs[1:])\n  if type == 'cmp':\n    args = config_cmp.get_args_for_config(config_name)\n    args.setup_to_run = cmp.setup_to_run\n    args.setup_train_step_kwargs = cmp.setup_train_step_kwargs\n\n  elif type == 'bl':\n    args = config_vision_baseline.get_args_for_config(config_name)\n    args.setup_to_run = vision_baseline_lstm.setup_to_run\n    args.setup_train_step_kwargs = vision_baseline_lstm.setup_train_step_kwargs\n\n  else:\n    logging.fatal('Unknown type: {:s}'.format(type))\n  return args\n\ndef _setup_args(config_name, logdir):\n  args = get_args_for_config(config_name)\n  args.solver.num_workers = FLAGS.num_workers\n  args.solver.task = FLAGS.task\n  args.solver.ps_tasks = FLAGS.ps_tasks\n  args.solver.master = FLAGS.master\n  args.solver.seed = FLAGS.solver_seed\n  args.logdir = logdir\n  args.navtask.logdir = None\n  return args\n\ndef _train(args):\n  container_name = \"\"\n\n  R = lambda: nav_env.get_multiplexer_class(args.navtask, args.solver.task)\n  m = utils.Foo()\n  m.tf_graph = tf.Graph()\n\n  config = tf.ConfigProto()\n  config.device_count['GPU'] = 1\n\n  with m.tf_graph.as_default():\n    with tf.device(tf.train.replica_device_setter(args.solver.ps_tasks,\n                                          merge_devices=True)):\n      with tf.container(container_name):\n        m = args.setup_to_run(m, args, is_training=True,\n                             batch_norm_is_training=True, summary_mode='train')\n\n        train_step_kwargs = args.setup_train_step_kwargs(\n            m, R(), os.path.join(args.logdir, 'train'), rng_seed=args.solver.task,\n            is_chief=args.solver.task==0,\n            num_steps=args.navtask.task_params.num_steps*args.navtask.task_params.num_goals, iters=1,\n            train_display_interval=args.summary.display_interval,\n            dagger_sample_bn_false=args.arch.dagger_sample_bn_false)\n\n        delay_start = (args.solver.task*(args.solver.task+1))/2 * FLAGS.delay_start_iters\n        logging.error('delaying start for task %d by %d steps.',\n                      args.solver.task, delay_start)\n\n        additional_args = {}\n        final_loss = slim.learning.train(\n            train_op=m.train_op,\n            logdir=args.logdir,\n            master=args.solver.master,\n            is_chief=args.solver.task == 0,\n            number_of_steps=args.solver.max_steps,\n            train_step_fn=tf_utils.train_step_custom_online_sampling,\n            train_step_kwargs=train_step_kwargs,\n            global_step=m.global_step_op,\n            init_op=m.init_op,\n            init_fn=m.init_fn,\n            sync_optimizer=m.sync_optimizer,\n            saver=m.saver_op,\n            startup_delay_steps=delay_start,\n            summary_op=None, session_config=config, **additional_args)\n\ndef _test(args):\n  args.solver.master = ''\n  container_name = \"\"\n  checkpoint_dir = os.path.join(format(args.logdir))\n  logging.error('Checkpoint_dir: %s', args.logdir)\n\n  config = tf.ConfigProto();\n  config.device_count['GPU'] = 1;\n\n  m = utils.Foo()\n  m.tf_graph = tf.Graph()\n\n  rng_data_seed = 0; rng_action_seed = 0;\n  R = lambda: nav_env.get_multiplexer_class(args.navtask, rng_data_seed)\n  with m.tf_graph.as_default():\n    with tf.container(container_name):\n      m = args.setup_to_run(\n        m, args, is_training=False,\n        batch_norm_is_training=args.control.force_batchnorm_is_training_at_test,\n        summary_mode=args.control.test_mode)\n      train_step_kwargs = args.setup_train_step_kwargs(\n        m, R(), os.path.join(args.logdir, args.control.test_name),\n        rng_seed=rng_data_seed, is_chief=True,\n        num_steps=args.navtask.task_params.num_steps*args.navtask.task_params.num_goals,\n        iters=args.summary.test_iters, train_display_interval=None,\n        dagger_sample_bn_false=args.arch.dagger_sample_bn_false)\n\n      saver = slim.learning.tf_saver.Saver(variables.get_variables_to_restore())\n\n      sv = slim.learning.supervisor.Supervisor(\n          graph=ops.get_default_graph(), logdir=None, init_op=m.init_op,\n          summary_op=None, summary_writer=None, global_step=None, saver=m.saver_op)\n\n      last_checkpoint = None\n      reported = False\n      while True:\n        last_checkpoint_ = None\n        while last_checkpoint_ is None:\n          last_checkpoint_ = slim.evaluation.wait_for_new_checkpoint(\n            checkpoint_dir, last_checkpoint, seconds_to_sleep=10, timeout=60)\n        if last_checkpoint_ is None: break\n\n        last_checkpoint = last_checkpoint_\n        checkpoint_iter = int(os.path.basename(last_checkpoint).split('-')[1])\n\n        logging.info('Starting evaluation at %s using checkpoint %s.',\n                     time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime()),\n                     last_checkpoint)\n\n        if (args.control.only_eval_when_done == False or \n            checkpoint_iter >= args.solver.max_steps):\n          start = time.time()\n          logging.info('Starting evaluation at %s using checkpoint %s.', \n                       time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime()),\n                       last_checkpoint)\n\n          with sv.managed_session(args.solver.master, config=config,\n                                  start_standard_services=False) as sess:\n            sess.run(m.init_op)\n            sv.saver.restore(sess, last_checkpoint)\n            sv.start_queue_runners(sess)\n            if args.control.reset_rng_seed:\n              train_step_kwargs['rng_data'] = [np.random.RandomState(rng_data_seed),\n                                               np.random.RandomState(rng_data_seed)]\n              train_step_kwargs['rng_action'] = np.random.RandomState(rng_action_seed)\n            vals, _ = tf_utils.train_step_custom_online_sampling(\n                sess, None, m.global_step_op, train_step_kwargs,\n                mode=args.control.test_mode)\n            should_stop = False\n\n            if checkpoint_iter >= args.solver.max_steps: \n              should_stop = True\n\n            if should_stop:\n              break\n\nif __name__ == '__main__':\n  app.run()\n", "comments": "    script train test grid navigation agent  usage    1  testing model    cuda visible devices 0 ld library path  opt cuda 8 0 lib64  opt cudnnv51 lib64       pythonpath     pyopengl platform egl python scripts script nav agent release py         config name cmp lmap msc clip5 sbpd r2r bench test         logdir output cmp lmap msc clip5 sbpd r2r    2  training model (locally)    cuda visible devices 0 ld library path  opt cuda 8 0 lib64  opt cudnnv51 lib64       pythonpath     pyopengl platform egl python scripts script nav agent release py         config name cmp lmap msc clip5 sbpd r2r train train         logdir output cmp lmap msc clip5 sbpd r2r     3  training model (distributed)      see https   www tensorflow org deploy distributed setup distributed     training    cuda visible devices 0 ld library path  opt cuda 8 0 lib64  opt cudnnv51 lib64       pythonpath     pyopengl platform egl python scripts script nav agent release py         config name cmp lmap msc clip5 sbpd r2r train train         logdir output cmp lmap msc clip5 sbpd r2r          ps tasks  num ps   master  master name   task  worker id        copyright 2016 the tensorflow authors all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                       see https   www tensorflow org deploy distributed setup distributed    training  ", "content": "# Copyright 2016 The TensorFlow Authors All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nr\"\"\" Script to train and test the grid navigation agent.\nUsage:\n  1. Testing a model.\n  CUDA_VISIBLE_DEVICES=0 LD_LIBRARY_PATH=/opt/cuda-8.0/lib64:/opt/cudnnv51/lib64 \\\n    PYTHONPATH='.' PYOPENGL_PLATFORM=egl python scripts/script_nav_agent_release.py \\\n    --config_name cmp.lmap_Msc.clip5.sbpd_d_r2r+bench_test \\\n    --logdir output/cmp.lmap_Msc.clip5.sbpd_d_r2r\n\n  2. Training a model (locally).\n  CUDA_VISIBLE_DEVICES=0 LD_LIBRARY_PATH=/opt/cuda-8.0/lib64:/opt/cudnnv51/lib64 \\\n    PYTHONPATH='.' PYOPENGL_PLATFORM=egl python scripts/script_nav_agent_release.py \\\n    --config_name cmp.lmap_Msc.clip5.sbpd_d_r2r+train_train \\\n    --logdir output/cmp.lmap_Msc.clip5.sbpd_d_r2r_\n\n  3. Training a model (distributed).\n  # See https://www.tensorflow.org/deploy/distributed on how to setup distributed\n  # training.\n  CUDA_VISIBLE_DEVICES=0 LD_LIBRARY_PATH=/opt/cuda-8.0/lib64:/opt/cudnnv51/lib64 \\\n    PYTHONPATH='.' PYOPENGL_PLATFORM=egl python scripts/script_nav_agent_release.py \\\n    --config_name cmp.lmap_Msc.clip5.sbpd_d_r2r+train_train \\\n    --logdir output/cmp.lmap_Msc.clip5.sbpd_d_r2r_ \\\n    --ps_tasks $num_ps --master $master_name --task $worker_id\n\"\"\"\n\nimport sys, os, numpy as np\nimport copy\nimport argparse, pprint\nimport time\nimport cProfile\nimport platform\n\n\nimport tensorflow as tf\nfrom tensorflow.contrib import slim\nfrom tensorflow.python.framework import ops\nfrom tensorflow.contrib.framework.python.ops import variables\n\nimport logging\nfrom tensorflow.python.platform import gfile\nfrom tensorflow.python.platform import app\nfrom tensorflow.python.platform import flags\nfrom cfgs import config_cmp\nfrom cfgs import config_vision_baseline\nimport datasets.nav_env as nav_env\nimport src.file_utils as fu \nimport src.utils as utils\nimport tfcode.cmp as cmp \nfrom tfcode import tf_utils\nfrom tfcode import vision_baseline_lstm\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string('master', '',\n                    'The address of the tensorflow master')\nflags.DEFINE_integer('ps_tasks', 0, 'The number of parameter servers. If the '\n                     'value is 0, then the parameters are handled locally by '\n                     'the worker.')\nflags.DEFINE_integer('task', 0, 'The Task ID. This value is used when training '\n                     'with multiple workers to identify each worker.')\n\nflags.DEFINE_integer('num_workers', 1, '')\n\nflags.DEFINE_string('config_name', '', '')\n\nflags.DEFINE_string('logdir', '', '')\n\nflags.DEFINE_integer('solver_seed', 0, '')\n\nflags.DEFINE_integer('delay_start_iters', 20, '')\n\nlogging.basicConfig(level=logging.INFO)\n\ndef main(_):\n  _launcher(FLAGS.config_name, FLAGS.logdir)\n\ndef _launcher(config_name, logdir):\n  args = _setup_args(config_name, logdir)\n\n  fu.makedirs(args.logdir)\n\n  if args.control.train:\n    _train(args)\n\n  if args.control.test:\n    _test(args)\n\ndef get_args_for_config(config_name):\n  configs = config_name.split('.')\n  type = configs[0]\n  config_name = '.'.join(configs[1:])\n  if type == 'cmp':\n    args = config_cmp.get_args_for_config(config_name)\n    args.setup_to_run = cmp.setup_to_run\n    args.setup_train_step_kwargs = cmp.setup_train_step_kwargs\n\n  elif type == 'bl':\n    args = config_vision_baseline.get_args_for_config(config_name)\n    args.setup_to_run = vision_baseline_lstm.setup_to_run\n    args.setup_train_step_kwargs = vision_baseline_lstm.setup_train_step_kwargs\n\n  else:\n    logging.fatal('Unknown type: {:s}'.format(type))\n  return args\n\ndef _setup_args(config_name, logdir):\n  args = get_args_for_config(config_name)\n  args.solver.num_workers = FLAGS.num_workers\n  args.solver.task = FLAGS.task\n  args.solver.ps_tasks = FLAGS.ps_tasks\n  args.solver.master = FLAGS.master\n  args.solver.seed = FLAGS.solver_seed\n  args.logdir = logdir\n  args.navtask.logdir = None\n  return args\n\ndef _train(args):\n  container_name = \"\"\n\n  R = lambda: nav_env.get_multiplexer_class(args.navtask, args.solver.task)\n  m = utils.Foo()\n  m.tf_graph = tf.Graph()\n\n  config = tf.ConfigProto()\n  config.device_count['GPU'] = 1\n\n  with m.tf_graph.as_default():\n    with tf.device(tf.train.replica_device_setter(args.solver.ps_tasks,\n                                          merge_devices=True)):\n      with tf.container(container_name):\n        m = args.setup_to_run(m, args, is_training=True,\n                             batch_norm_is_training=True, summary_mode='train')\n\n        train_step_kwargs = args.setup_train_step_kwargs(\n            m, R(), os.path.join(args.logdir, 'train'), rng_seed=args.solver.task,\n            is_chief=args.solver.task==0,\n            num_steps=args.navtask.task_params.num_steps*args.navtask.task_params.num_goals, iters=1,\n            train_display_interval=args.summary.display_interval,\n            dagger_sample_bn_false=args.arch.dagger_sample_bn_false)\n\n        delay_start = (args.solver.task*(args.solver.task+1))/2 * FLAGS.delay_start_iters\n        logging.error('delaying start for task %d by %d steps.',\n                      args.solver.task, delay_start)\n\n        additional_args = {}\n        final_loss = slim.learning.train(\n            train_op=m.train_op,\n            logdir=args.logdir,\n            master=args.solver.master,\n            is_chief=args.solver.task == 0,\n            number_of_steps=args.solver.max_steps,\n            train_step_fn=tf_utils.train_step_custom_online_sampling,\n            train_step_kwargs=train_step_kwargs,\n            global_step=m.global_step_op,\n            init_op=m.init_op,\n            init_fn=m.init_fn,\n            sync_optimizer=m.sync_optimizer,\n            saver=m.saver_op,\n            startup_delay_steps=delay_start,\n            summary_op=None, session_config=config, **additional_args)\n\ndef _test(args):\n  args.solver.master = ''\n  container_name = \"\"\n  checkpoint_dir = os.path.join(format(args.logdir))\n  logging.error('Checkpoint_dir: %s', args.logdir)\n\n  config = tf.ConfigProto();\n  config.device_count['GPU'] = 1;\n\n  m = utils.Foo()\n  m.tf_graph = tf.Graph()\n\n  rng_data_seed = 0; rng_action_seed = 0;\n  R = lambda: nav_env.get_multiplexer_class(args.navtask, rng_data_seed)\n  with m.tf_graph.as_default():\n    with tf.container(container_name):\n      m = args.setup_to_run(\n        m, args, is_training=False,\n        batch_norm_is_training=args.control.force_batchnorm_is_training_at_test,\n        summary_mode=args.control.test_mode)\n      train_step_kwargs = args.setup_train_step_kwargs(\n        m, R(), os.path.join(args.logdir, args.control.test_name),\n        rng_seed=rng_data_seed, is_chief=True,\n        num_steps=args.navtask.task_params.num_steps*args.navtask.task_params.num_goals,\n        iters=args.summary.test_iters, train_display_interval=None,\n        dagger_sample_bn_false=args.arch.dagger_sample_bn_false)\n\n      saver = slim.learning.tf_saver.Saver(variables.get_variables_to_restore())\n\n      sv = slim.learning.supervisor.Supervisor(\n          graph=ops.get_default_graph(), logdir=None, init_op=m.init_op,\n          summary_op=None, summary_writer=None, global_step=None, saver=m.saver_op)\n\n      last_checkpoint = None\n      reported = False\n      while True:\n        last_checkpoint_ = None\n        while last_checkpoint_ is None:\n          last_checkpoint_ = slim.evaluation.wait_for_new_checkpoint(\n            checkpoint_dir, last_checkpoint, seconds_to_sleep=10, timeout=60)\n        if last_checkpoint_ is None: break\n\n        last_checkpoint = last_checkpoint_\n        checkpoint_iter = int(os.path.basename(last_checkpoint).split('-')[1])\n\n        logging.info('Starting evaluation at %s using checkpoint %s.',\n                     time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime()),\n                     last_checkpoint)\n\n        if (args.control.only_eval_when_done == False or \n            checkpoint_iter >= args.solver.max_steps):\n          start = time.time()\n          logging.info('Starting evaluation at %s using checkpoint %s.', \n                       time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime()),\n                       last_checkpoint)\n\n          with sv.managed_session(args.solver.master, config=config,\n                                  start_standard_services=False) as sess:\n            sess.run(m.init_op)\n            sv.saver.restore(sess, last_checkpoint)\n            sv.start_queue_runners(sess)\n            if args.control.reset_rng_seed:\n              train_step_kwargs['rng_data'] = [np.random.RandomState(rng_data_seed),\n                                               np.random.RandomState(rng_data_seed)]\n              train_step_kwargs['rng_action'] = np.random.RandomState(rng_action_seed)\n            vals, _ = tf_utils.train_step_custom_online_sampling(\n                sess, None, m.global_step_op, train_step_kwargs,\n                mode=args.control.test_mode)\n            should_stop = False\n\n            if checkpoint_iter >= args.solver.max_steps: \n              should_stop = True\n\n            if should_stop:\n              break\n\nif __name__ == '__main__':\n  app.run()\n", "description": "Models and examples built with TensorFlow", "file_name": "script_nav_agent_release.py", "id": "8162973459adf7495c8ff9423130cc67", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-models/tensorflow-models-086d914/research/cognitive_mapping_and_planning/scripts/script_nav_agent_release.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:59:19Z", "url": "https://github.com/tensorflow/models", "wiki": true}