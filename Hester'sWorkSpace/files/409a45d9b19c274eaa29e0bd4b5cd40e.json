{"author": "scikit-learn", "code": "\n\n\n\nimport sys\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.datasets import load_files\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\n\nif __name__ == \"__main__\":\n    \n    \n    \n    \n    \n\n    \n    movie_reviews_data_folder = sys.argv[1]\n    dataset = load_files(movie_reviews_data_folder, shuffle=False)\n    print(\"n_samples: %d\" % len(dataset.data))\n\n    \n    docs_train, docs_test, y_train, y_test = train_test_split(\n        dataset.data, dataset.target, test_size=0.25, random_state=None)\n\n    \n    \n    pipeline = Pipeline([\n        ('vect', TfidfVectorizer(min_df=3, max_df=0.95)),\n        ('clf', LinearSVC(C=1000)),\n    ])\n\n    \n    \n    \n    parameters = {\n        'vect__ngram_range': [(1, 1), (1, 2)],\n    }\n    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n    grid_search.fit(docs_train, y_train)\n\n    \n    \n    n_candidates = len(grid_search.cv_results_['params'])\n    for i in range(n_candidates):\n        print(i, 'params - %s; mean - %0.2f; std - %0.2f'\n                 % (grid_search.cv_results_['params'][i],\n                    grid_search.cv_results_['mean_test_score'][i],\n                    grid_search.cv_results_['std_test_score'][i]))\n\n    \n    \n    y_predicted = grid_search.predict(docs_test)\n\n    \n    print(metrics.classification_report(y_test, y_predicted,\n                                        target_names=dataset.target_names))\n\n    \n    cm = metrics.confusion_matrix(y_test, y_predicted)\n    print(cm)\n\n    \n    # plt.matshow(cm)\n    ()\n", "comments": "   build sentiment analysis   polarity model  sentiment analysis casted binary text classification problem  fitting linear classifier features extracted text user messages guess wether opinion author positive negative   in examples use movie review dataset          author  olivier grisel  olivier grisel ensta org     license  simplified bsd    note  put following    name         main     protected    block able use multi core grid search also works    windows  see  http   docs python org library multiprocessing html windows    the multiprocessing module used backend joblib parallel    used n jobs    1 gridsearchcv    training data folder must passed first argument    split dataset training test set     task  build vectorizer   classifier pipeline filters tokens    rare frequent    task  build grid search find whether unigrams bigrams    useful     fit pipeline training set using grid search parameters    task  print mean std candidate along parameter    settings candidates explored grid search     task  predict outcome testing set store variable    named predicted    print classification report    print plot confusion matrix    import matplotlib pyplot plt    plt matshow(cm)    plt show() ", "content": "\"\"\"Build a sentiment analysis / polarity model\n\nSentiment analysis can be casted as a binary text classification problem,\nthat is fitting a linear classifier on features extracted from the text\nof the user messages so as to guess wether the opinion of the author is\npositive or negative.\n\nIn this examples we will use a movie review dataset.\n\n\"\"\"\n# Author: Olivier Grisel <olivier.grisel@ensta.org>\n# License: Simplified BSD\n\nimport sys\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.datasets import load_files\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\n\nif __name__ == \"__main__\":\n    # NOTE: we put the following in a 'if __name__ == \"__main__\"' protected\n    # block to be able to use a multi-core grid search that also works under\n    # Windows, see: http://docs.python.org/library/multiprocessing.html#windows\n    # The multiprocessing module is used as the backend of joblib.Parallel\n    # that is used when n_jobs != 1 in GridSearchCV\n\n    # the training data folder must be passed as first argument\n    movie_reviews_data_folder = sys.argv[1]\n    dataset = load_files(movie_reviews_data_folder, shuffle=False)\n    print(\"n_samples: %d\" % len(dataset.data))\n\n    # split the dataset in training and test set:\n    docs_train, docs_test, y_train, y_test = train_test_split(\n        dataset.data, dataset.target, test_size=0.25, random_state=None)\n\n    # TASK: Build a vectorizer / classifier pipeline that filters out tokens\n    # that are too rare or too frequent\n    pipeline = Pipeline([\n        ('vect', TfidfVectorizer(min_df=3, max_df=0.95)),\n        ('clf', LinearSVC(C=1000)),\n    ])\n\n    # TASK: Build a grid search to find out whether unigrams or bigrams are\n    # more useful.\n    # Fit the pipeline on the training set using grid search for the parameters\n    parameters = {\n        'vect__ngram_range': [(1, 1), (1, 2)],\n    }\n    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n    grid_search.fit(docs_train, y_train)\n\n    # TASK: print the mean and std for each candidate along with the parameter\n    # settings for all the candidates explored by grid search.\n    n_candidates = len(grid_search.cv_results_['params'])\n    for i in range(n_candidates):\n        print(i, 'params - %s; mean - %0.2f; std - %0.2f'\n                 % (grid_search.cv_results_['params'][i],\n                    grid_search.cv_results_['mean_test_score'][i],\n                    grid_search.cv_results_['std_test_score'][i]))\n\n    # TASK: Predict the outcome on the testing set and store it in a variable\n    # named y_predicted\n    y_predicted = grid_search.predict(docs_test)\n\n    # Print the classification report\n    print(metrics.classification_report(y_test, y_predicted,\n                                        target_names=dataset.target_names))\n\n    # Print and plot the confusion matrix\n    cm = metrics.confusion_matrix(y_test, y_predicted)\n    print(cm)\n\n    # import matplotlib.pyplot as plt\n    # plt.matshow(cm)\n    # plt.show()\n", "description": "scikit-learn: machine learning in Python", "file_name": "exercise_02_sentiment.py", "id": "409a45d9b19c274eaa29e0bd4b5cd40e", "language": "Python", "project_name": "scikit-learn", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/scikit-learn-scikit-learn/scikit-learn-scikit-learn-94ed5a8/doc/tutorial/text_analytics/solutions/exercise_02_sentiment.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:58:59Z", "url": "https://github.com/scikit-learn/scikit-learn", "wiki": true}