{"author": "rg3", "code": "\nfrom __future__ import unicode_literals\n\nimport itertools\n\nfrom .amp import AMPIE\nfrom ..compat import (\n    compat_HTTPError,\n    compat_urlparse,\n)\nfrom ..utils import (\n    ExtractorError,\n    clean_html,\n    int_or_none,\n    remove_end,\n    sanitized_Request,\n    urlencode_postdata\n)\n\n\nclass DramaFeverBaseIE(AMPIE):\n    _LOGIN_URL = 'https://www.dramafever.com/accounts/login/'\n    _NETRC_MACHINE = 'dramafever'\n    _GEO_COUNTRIES = ['US', 'CA']\n\n    _CONSUMER_SECRET = 'DA59dtVXYLxajktV'\n\n    _consumer_secret = None\n\n    def _get_consumer_secret(self):\n        mainjs = self._download_webpage(\n            'http://www.dramafever.com/static/51afe95/df2014/scripts/main.js',\n            None, 'Downloading main.js', fatal=False)\n        if not mainjs:\n            return self._CONSUMER_SECRET\n        return self._search_regex(\n            r\"var\\s+cs\\s*=\\s*'([^']+)'\", mainjs,\n            'consumer secret', default=self._CONSUMER_SECRET)\n\n    def _real_initialize(self):\n        self._login()\n        self._consumer_secret = self._get_consumer_secret()\n\n    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'username': username,\n            'password': password,\n        }\n\n        request = sanitized_Request(\n            self._LOGIN_URL, urlencode_postdata(login_form))\n        response = self._download_webpage(\n            request, None, 'Logging in')\n\n        if all(logout_pattern not in response\n               for logout_pattern in ['href=\"/accounts/logout/\"', '>Log out<']):\n            error = self._html_search_regex(\n                r'(?s)<h\\d[^>]+\\bclass=\"hidden-xs prompt\"[^>]*>(.+?)</h\\d',\n                response, 'error message', default=None)\n            if error:\n                raise ExtractorError('Unable to login: %s' % error, expected=True)\n            raise ExtractorError('Unable to log in')\n\n\nclass DramaFeverIE(DramaFeverBaseIE):\n    IE_NAME = 'dramafever'\n    _VALID_URL = r'https?://(?:www\\.)?dramafever\\.com/(?:[^/]+/)?drama/(?P<id>[0-9]+/[0-9]+)(?:/|$)'\n    _TESTS = [{\n        'url': 'http://www.dramafever.com/drama/4512/1/Cooking_with_Shin/',\n        'info_dict': {\n            'id': '4512.1',\n            'ext': 'flv',\n            'title': 'Cooking with Shin',\n            'description': 'md5:a8eec7942e1664a6896fcd5e1287bfd0',\n            'episode': 'Episode 1',\n            'episode_number': 1,\n            'thumbnail': r're:^https?://.*\\.jpg',\n            'timestamp': 1404336058,\n            'upload_date': '20140702',\n            'duration': 344,\n        },\n        'params': {\n            \n            'skip_download': True,\n        },\n    }, {\n        'url': 'http://www.dramafever.com/drama/4826/4/Mnet_Asian_Music_Awards_2015/?ap=1',\n        'info_dict': {\n            'id': '4826.4',\n            'ext': 'flv',\n            'title': 'Mnet Asian Music Awards 2015',\n            'description': 'md5:3ff2ee8fedaef86e076791c909cf2e91',\n            'episode': 'Mnet Asian Music Awards 2015 - Part 3',\n            'episode_number': 4,\n            'thumbnail': r're:^https?://.*\\.jpg',\n            'timestamp': 1450213200,\n            'upload_date': '20151215',\n            'duration': 5359,\n        },\n        'params': {\n            \n            'skip_download': True,\n        },\n    }, {\n        'url': 'https://www.dramafever.com/zh-cn/drama/4972/15/Doctor_Romantic/',\n        'only_matching': True,\n    }]\n\n    def _real_extract(self, url):\n        video_id = self._match_id(url).replace('/', '.')\n\n        try:\n            info = self._extract_feed_info(\n                'http://www.dramafever.com/amp/episode/feed.json?guid=%s' % video_id)\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError):\n                self.raise_geo_restricted(\n                    msg='Currently unavailable in your country',\n                    countries=self._GEO_COUNTRIES)\n            raise\n\n        \n        if info.get('title'):\n            info['title'] = remove_end(info['title'], video_id).strip()\n\n        series_id, episode_number = video_id.split('.')\n        episode_info = self._download_json(\n            \n            \n            r'http://www.dramafever.com/api/4/episode/series/?cs=%s&series_id=%s&page_number=%s&page_size=1'\n            % (self._consumer_secret, series_id, episode_number),\n            video_id, 'Downloading episode info JSON', fatal=False)\n        if episode_info:\n            value = episode_info.get('value')\n            if isinstance(value, list):\n                for v in value:\n                    if v.get('type') == 'Episode':\n                        subfile = v.get('subfile') or v.get('new_subfile')\n                        if subfile and subfile != 'http://www.dramafever.com/st/':\n                            info.setdefault('subtitles', {}).setdefault('English', []).append({\n                                'ext': 'srt',\n                                'url': subfile,\n                            })\n                        episode_number = int_or_none(v.get('number'))\n                        episode_fallback = 'Episode'\n                        if episode_number:\n                            episode_fallback += ' %d' % episode_number\n                        info['episode'] = v.get('title') or episode_fallback\n                        info['episode_number'] = episode_number\n                        break\n\n        return info\n\n\nclass DramaFeverSeriesIE(DramaFeverBaseIE):\n    IE_NAME = 'dramafever:series'\n    _VALID_URL = r'https?://(?:www\\.)?dramafever\\.com/(?:[^/]+/)?drama/(?P<id>[0-9]+)(?:/(?:(?!\\d+(?:/|$)).+)?)?$'\n    _TESTS = [{\n        'url': 'http://www.dramafever.com/drama/4512/Cooking_with_Shin/',\n        'info_dict': {\n            'id': '4512',\n            'title': 'Cooking with Shin',\n            'description': 'md5:84a3f26e3cdc3fb7f500211b3593b5c1',\n        },\n        'playlist_count': 4,\n    }, {\n        'url': 'http://www.dramafever.com/drama/124/IRIS/',\n        'info_dict': {\n            'id': '124',\n            'title': 'IRIS',\n            'description': 'md5:b3a30e587cf20c59bd1c01ec0ee1b862',\n        },\n        'playlist_count': 20,\n    }]\n\n    _PAGE_SIZE = 60  \n\n    def _real_extract(self, url):\n        series_id = self._match_id(url)\n\n        series = self._download_json(\n            'http://www.dramafever.com/api/4/series/query/?cs=%s&series_id=%s'\n            % (self._consumer_secret, series_id),\n            series_id, 'Downloading series JSON')['series'][series_id]\n\n        title = clean_html(series['name'])\n        description = clean_html(series.get('description') or series.get('description_short'))\n\n        entries = []\n        for page_num in itertools.count(1):\n            episodes = self._download_json(\n                'http://www.dramafever.com/api/4/episode/series/?cs=%s&series_id=%s&page_size=%d&page_number=%d'\n                % (self._consumer_secret, series_id, self._PAGE_SIZE, page_num),\n                series_id, 'Downloading episodes JSON page \n            for episode in episodes.get('value', []):\n                episode_url = episode.get('episode_url')\n                if not episode_url:\n                    continue\n                entries.append(self.url_result(\n                    compat_urlparse.urljoin(url, episode_url),\n                    'DramaFever', episode.get('guid')))\n            if page_num == episodes['num_pages']:\n                break\n\n        return self.playlist_result(entries, series_id, title, description)\n", "comments": "# coding: utf-8\n# m3u8 download\n# m3u8 download\n# title is postfixed with video id for some reason, removing\n# We only need a single episode info, so restricting page size to one episode\n# and dealing with page number as with episode number\n# max is 60 (see http://api.drama9.com/#get--api-4-episode-series-)\n#%d' % page_num)\n", "content": "# coding: utf-8\nfrom __future__ import unicode_literals\n\nimport itertools\n\nfrom .amp import AMPIE\nfrom ..compat import (\n    compat_HTTPError,\n    compat_urlparse,\n)\nfrom ..utils import (\n    ExtractorError,\n    clean_html,\n    int_or_none,\n    remove_end,\n    sanitized_Request,\n    urlencode_postdata\n)\n\n\nclass DramaFeverBaseIE(AMPIE):\n    _LOGIN_URL = 'https://www.dramafever.com/accounts/login/'\n    _NETRC_MACHINE = 'dramafever'\n    _GEO_COUNTRIES = ['US', 'CA']\n\n    _CONSUMER_SECRET = 'DA59dtVXYLxajktV'\n\n    _consumer_secret = None\n\n    def _get_consumer_secret(self):\n        mainjs = self._download_webpage(\n            'http://www.dramafever.com/static/51afe95/df2014/scripts/main.js',\n            None, 'Downloading main.js', fatal=False)\n        if not mainjs:\n            return self._CONSUMER_SECRET\n        return self._search_regex(\n            r\"var\\s+cs\\s*=\\s*'([^']+)'\", mainjs,\n            'consumer secret', default=self._CONSUMER_SECRET)\n\n    def _real_initialize(self):\n        self._login()\n        self._consumer_secret = self._get_consumer_secret()\n\n    def _login(self):\n        (username, password) = self._get_login_info()\n        if username is None:\n            return\n\n        login_form = {\n            'username': username,\n            'password': password,\n        }\n\n        request = sanitized_Request(\n            self._LOGIN_URL, urlencode_postdata(login_form))\n        response = self._download_webpage(\n            request, None, 'Logging in')\n\n        if all(logout_pattern not in response\n               for logout_pattern in ['href=\"/accounts/logout/\"', '>Log out<']):\n            error = self._html_search_regex(\n                r'(?s)<h\\d[^>]+\\bclass=\"hidden-xs prompt\"[^>]*>(.+?)</h\\d',\n                response, 'error message', default=None)\n            if error:\n                raise ExtractorError('Unable to login: %s' % error, expected=True)\n            raise ExtractorError('Unable to log in')\n\n\nclass DramaFeverIE(DramaFeverBaseIE):\n    IE_NAME = 'dramafever'\n    _VALID_URL = r'https?://(?:www\\.)?dramafever\\.com/(?:[^/]+/)?drama/(?P<id>[0-9]+/[0-9]+)(?:/|$)'\n    _TESTS = [{\n        'url': 'http://www.dramafever.com/drama/4512/1/Cooking_with_Shin/',\n        'info_dict': {\n            'id': '4512.1',\n            'ext': 'flv',\n            'title': 'Cooking with Shin',\n            'description': 'md5:a8eec7942e1664a6896fcd5e1287bfd0',\n            'episode': 'Episode 1',\n            'episode_number': 1,\n            'thumbnail': r're:^https?://.*\\.jpg',\n            'timestamp': 1404336058,\n            'upload_date': '20140702',\n            'duration': 344,\n        },\n        'params': {\n            # m3u8 download\n            'skip_download': True,\n        },\n    }, {\n        'url': 'http://www.dramafever.com/drama/4826/4/Mnet_Asian_Music_Awards_2015/?ap=1',\n        'info_dict': {\n            'id': '4826.4',\n            'ext': 'flv',\n            'title': 'Mnet Asian Music Awards 2015',\n            'description': 'md5:3ff2ee8fedaef86e076791c909cf2e91',\n            'episode': 'Mnet Asian Music Awards 2015 - Part 3',\n            'episode_number': 4,\n            'thumbnail': r're:^https?://.*\\.jpg',\n            'timestamp': 1450213200,\n            'upload_date': '20151215',\n            'duration': 5359,\n        },\n        'params': {\n            # m3u8 download\n            'skip_download': True,\n        },\n    }, {\n        'url': 'https://www.dramafever.com/zh-cn/drama/4972/15/Doctor_Romantic/',\n        'only_matching': True,\n    }]\n\n    def _real_extract(self, url):\n        video_id = self._match_id(url).replace('/', '.')\n\n        try:\n            info = self._extract_feed_info(\n                'http://www.dramafever.com/amp/episode/feed.json?guid=%s' % video_id)\n        except ExtractorError as e:\n            if isinstance(e.cause, compat_HTTPError):\n                self.raise_geo_restricted(\n                    msg='Currently unavailable in your country',\n                    countries=self._GEO_COUNTRIES)\n            raise\n\n        # title is postfixed with video id for some reason, removing\n        if info.get('title'):\n            info['title'] = remove_end(info['title'], video_id).strip()\n\n        series_id, episode_number = video_id.split('.')\n        episode_info = self._download_json(\n            # We only need a single episode info, so restricting page size to one episode\n            # and dealing with page number as with episode number\n            r'http://www.dramafever.com/api/4/episode/series/?cs=%s&series_id=%s&page_number=%s&page_size=1'\n            % (self._consumer_secret, series_id, episode_number),\n            video_id, 'Downloading episode info JSON', fatal=False)\n        if episode_info:\n            value = episode_info.get('value')\n            if isinstance(value, list):\n                for v in value:\n                    if v.get('type') == 'Episode':\n                        subfile = v.get('subfile') or v.get('new_subfile')\n                        if subfile and subfile != 'http://www.dramafever.com/st/':\n                            info.setdefault('subtitles', {}).setdefault('English', []).append({\n                                'ext': 'srt',\n                                'url': subfile,\n                            })\n                        episode_number = int_or_none(v.get('number'))\n                        episode_fallback = 'Episode'\n                        if episode_number:\n                            episode_fallback += ' %d' % episode_number\n                        info['episode'] = v.get('title') or episode_fallback\n                        info['episode_number'] = episode_number\n                        break\n\n        return info\n\n\nclass DramaFeverSeriesIE(DramaFeverBaseIE):\n    IE_NAME = 'dramafever:series'\n    _VALID_URL = r'https?://(?:www\\.)?dramafever\\.com/(?:[^/]+/)?drama/(?P<id>[0-9]+)(?:/(?:(?!\\d+(?:/|$)).+)?)?$'\n    _TESTS = [{\n        'url': 'http://www.dramafever.com/drama/4512/Cooking_with_Shin/',\n        'info_dict': {\n            'id': '4512',\n            'title': 'Cooking with Shin',\n            'description': 'md5:84a3f26e3cdc3fb7f500211b3593b5c1',\n        },\n        'playlist_count': 4,\n    }, {\n        'url': 'http://www.dramafever.com/drama/124/IRIS/',\n        'info_dict': {\n            'id': '124',\n            'title': 'IRIS',\n            'description': 'md5:b3a30e587cf20c59bd1c01ec0ee1b862',\n        },\n        'playlist_count': 20,\n    }]\n\n    _PAGE_SIZE = 60  # max is 60 (see http://api.drama9.com/#get--api-4-episode-series-)\n\n    def _real_extract(self, url):\n        series_id = self._match_id(url)\n\n        series = self._download_json(\n            'http://www.dramafever.com/api/4/series/query/?cs=%s&series_id=%s'\n            % (self._consumer_secret, series_id),\n            series_id, 'Downloading series JSON')['series'][series_id]\n\n        title = clean_html(series['name'])\n        description = clean_html(series.get('description') or series.get('description_short'))\n\n        entries = []\n        for page_num in itertools.count(1):\n            episodes = self._download_json(\n                'http://www.dramafever.com/api/4/episode/series/?cs=%s&series_id=%s&page_size=%d&page_number=%d'\n                % (self._consumer_secret, series_id, self._PAGE_SIZE, page_num),\n                series_id, 'Downloading episodes JSON page #%d' % page_num)\n            for episode in episodes.get('value', []):\n                episode_url = episode.get('episode_url')\n                if not episode_url:\n                    continue\n                entries.append(self.url_result(\n                    compat_urlparse.urljoin(url, episode_url),\n                    'DramaFever', episode.get('guid')))\n            if page_num == episodes['num_pages']:\n                break\n\n        return self.playlist_result(entries, series_id, title, description)\n", "description": "Command-line program to download videos from YouTube.com and other video sites", "file_name": "dramafever.py", "language": "Python", "project_name": "youtube-dl", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/rg3_youtube-dl/rg3-youtube-dl-6202f08/youtube_dl/extractor/dramafever.py", "save_time": "", "source": "", "update_at": "2018-03-07T09:18:39Z", "url": "https://github.com/rg3/youtube-dl", "wiki": false}