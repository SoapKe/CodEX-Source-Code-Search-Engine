{"author": "tensorflow", "code": "\n\n Copyright 2016 Google Inc. All Rights Reserved.\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\n\"\"\"Converts a Glove binary co-occurrence matrix into Swivel shards.\n\nUsage:\n\n  glove_to_shards.py --input <coocs> --vocab <vocab> --output_dir <output_dir>\n\nOptions\n\n  --input <coocs>\n      The Glove co-occurrence file.\n\n  --vocab <vocab>\n      Path to the vocabulary text file, one token per line.\n\n  --output_dir <directory>\n      Specifies the touput directory where the various Swivel data\n      files sohuld be placed.\n\n  --shard_size <int>\n      Specifies the shard size; default 4096.\n\"\"\"\n\nfrom __future__ import print_function\n\nimport itertools\nimport os\nimport struct\nimport sys\n\nimport tensorflow as tf\n\nfrom six.moves import xrange\n\nflags = tf.app.flags\n\nflags.DEFINE_string('input', 'coocurrences.bin', 'Vocabulary file')\nflags.DEFINE_string('vocab', 'vocab.txt', 'Vocabulary file')\nflags.DEFINE_string('output_dir', '/tmp/swivel_data', 'Output directory')\nflags.DEFINE_integer('shard_size', 4096, 'Shard size')\n\nFLAGS = tf.app.flags.FLAGS\n\nglove_cooc_fmt = struct.Struct('iid')\nshard_cooc_fmt = struct.Struct('if')\n\n\ndef make_shard_files(coocs, nshards, vocab_sz):\n  \"\"\"Chops the binary Glove co-occurrence matrix into shards.\n\n  This reads the Glove binary co-occurrence file and assigns individual\n  co-occurrence counts to the appropriate Swivel shard.\n\n  Args:\n    coocs: the co-occurrnece file to read\n    nshards: the number of shards along one dimension of the square matrix\n    vocab_sz: the vocabulary size\n\n  Returns:\n    A (shard_table, marginals) tuple.  The shard_table maps the row and column\n    shard ID to a file handle containing the co-occurrences for that shard; the\n    marginals contain the marginal sums.\n  \"\"\"\n  row_sums = [0] * vocab_sz\n  col_sums = [0] * vocab_sz\n\n  coocs.seek(0, os.SEEK_END)\n  ncoocs = coocs.tell() / glove_cooc_fmt.size\n  coocs.seek(0, os.SEEK_SET)\n\n  shard_files = {}\n\n  for row in range(nshards):\n    for col in range(nshards):\n      filename = os.path.join(\n          FLAGS.output_dir, 'shard-%03d-%03d.bin' % (row, col))\n\n      shard_files[(row, col)] = open(filename, 'w+')\n\n  for ix in xrange(ncoocs):\n    if ix % 1000000 == 0:\n      sys.stdout.write('\\rsharding co-occurrences: %0.1f%% (%d/%d)' % (\n          100.0 * ix / ncoocs, ix, ncoocs))\n\n      sys.stdout.flush()\n\n    bits = coocs.read(glove_cooc_fmt.size)\n    if not bits:\n      break\n\n     Glove has 1-indexed IDs.\n    row_id, col_id, cnt = glove_cooc_fmt.unpack(bits)\n    if row_id > vocab_sz or col_id > vocab_sz:\n      continue\n\n    row_id -= 1\n    row_shard = row_id % nshards\n    row_off = row_id / nshards\n\n    col_id -= 1\n    col_shard = col_id % nshards\n    col_off = col_id / nshards\n\n    shard_pos = row_off * FLAGS.shard_size + col_off   row major\n\n    shard_files[(row_shard, col_shard)].write(\n        shard_cooc_fmt.pack(shard_pos, cnt))\n\n     Accumulate marginals.\n    row_sums[row_id] += cnt\n    col_sums[col_id] += cnt\n\n  sys.stdout.write('\\n')\n\n  if any(abs(r - c) > 0.1 for r, c in itertools.izip(row_sums, col_sums)):\n    print('WARNING! Row and column marginals differ; is your matrix symmetric?',\n          file=sys.stderr)\n\n  return (shard_files, row_sums)\n\n\ndef main(_):\n  with open(FLAGS.vocab, 'r') as lines:\n    orig_vocab_sz = sum(1 for _ in lines)\n\n  shard_sz = FLAGS.shard_size\n  vocab_sz = orig_vocab_sz - orig_vocab_sz % shard_sz\n  nshards = vocab_sz / shard_sz\n\n  print('vocab size is %d (originally %d), %d %dx%d-element shards' % (\n      vocab_sz, orig_vocab_sz, nshards * nshards, shard_sz, shard_sz))\n\n   Create the output directory, if necessary\n  if FLAGS.output_dir and not os.path.isdir(FLAGS.output_dir):\n    os.makedirs(FLAGS.output_dir)\n\n  with open(FLAGS.input, 'r') as coocs:\n    shard_files, marginals = make_shard_files(coocs, nshards, vocab_sz)\n\n   Now sort the shards and write the TFRecords.\n  filename = os.path.join(FLAGS.output_dir, 'shards.recs')\n  with tf.python_io.TFRecordWriter(filename) as writer:\n    ix = 0\n    for (row, col), fh in shard_files.iteritems():\n      ix += 1\n      sys.stdout.write('\\rwriting shard %d/%d' % (ix, len(shard_files)))\n      sys.stdout.flush()\n\n      fh.seek(0)\n      buf = fh.read()\n      os.unlink(fh.name)\n      fh.close()\n\n      coocs = [\n          shard_cooc_fmt.unpack_from(buf, off)\n          for off in range(0, len(buf), shard_cooc_fmt.size)]\n\n       N.B. we assume that there aren't any duplicates here!\n      coocs.sort(key=lambda kv: kv[0])\n\n      def _int64s(xs):\n        return tf.train.Feature(int64_list=tf.train.Int64List(value=list(xs)))\n\n      def _floats(xs):\n        return tf.train.Feature(float_list=tf.train.FloatList(value=list(xs)))\n\n      example = tf.train.Example(features=tf.train.Features(feature={\n          'global_row': _int64s(row + nshards * i for i in range(shard_sz)),\n          'global_col': _int64s(col + nshards * i for i in range(shard_sz)),\n          'sparse_local_row': _int64s(pos / shard_sz for pos, _ in coocs),\n          'sparse_local_col': _int64s(pos % shard_sz for pos, _ in coocs),\n          'sparse_value': _floats(cnt for _, cnt in coocs)}))\n\n      writer.write(example.SerializeToString())\n\n  print('\\nwriting marginals...')\n\n  with open(os.path.join(FLAGS.output_dir, 'marginals.txt'), 'w') as fh:\n    for cnt in marginals:\n      fh.write('%0.1f\\n' % cnt)\n\n  print('done!')\n\n\nif __name__ == '__main__':\n  tf.app.run()\n", "comments": "   converts glove binary co occurrence matrix swivel shards   usage     glove shards py   input  coocs    vocab  vocab    output dir  output dir   options      input  coocs        the glove co occurrence file       vocab  vocab        path vocabulary text file  one token per line       output dir  directory        specifies touput directory various swivel data       files sohuld placed       shard size  int        specifies shard size  default 4096         future   import print function  import itertools import os import struct import sys  import tensorflow tf  six moves import xrange  flags   tf app flags  flags define string( input    coocurrences bin    vocabulary file ) flags define string( vocab    vocab txt    vocabulary file ) flags define string( output dir     tmp swivel data    output directory ) flags define integer( shard size   4096   shard size )  flags   tf app flags flags  glove cooc fmt   struct struct( iid ) shard cooc fmt   struct struct( )   def make shard files(coocs  nshards  vocab sz)       chops binary glove co occurrence matrix shards     this reads glove binary co occurrence file assigns individual   co occurrence counts appropriate swivel shard     args      coocs  co occurrnece file read     nshards  number shards along one dimension square matrix     vocab sz  vocabulary size    returns      a (shard table  marginals) tuple   the shard table maps row column     shard id file handle containing co occurrences shard      marginals contain marginal sums            usr bin env python       copyright 2016 google inc  all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license     glove 1 indexed ids     row major    accumulate marginals     create output directory  necessary    now sort shards write tfrecords     n b  assume duplicates  ", "content": "#!/usr/bin/env python\n#\n# Copyright 2016 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Converts a Glove binary co-occurrence matrix into Swivel shards.\n\nUsage:\n\n  glove_to_shards.py --input <coocs> --vocab <vocab> --output_dir <output_dir>\n\nOptions\n\n  --input <coocs>\n      The Glove co-occurrence file.\n\n  --vocab <vocab>\n      Path to the vocabulary text file, one token per line.\n\n  --output_dir <directory>\n      Specifies the touput directory where the various Swivel data\n      files sohuld be placed.\n\n  --shard_size <int>\n      Specifies the shard size; default 4096.\n\"\"\"\n\nfrom __future__ import print_function\n\nimport itertools\nimport os\nimport struct\nimport sys\n\nimport tensorflow as tf\n\nfrom six.moves import xrange\n\nflags = tf.app.flags\n\nflags.DEFINE_string('input', 'coocurrences.bin', 'Vocabulary file')\nflags.DEFINE_string('vocab', 'vocab.txt', 'Vocabulary file')\nflags.DEFINE_string('output_dir', '/tmp/swivel_data', 'Output directory')\nflags.DEFINE_integer('shard_size', 4096, 'Shard size')\n\nFLAGS = tf.app.flags.FLAGS\n\nglove_cooc_fmt = struct.Struct('iid')\nshard_cooc_fmt = struct.Struct('if')\n\n\ndef make_shard_files(coocs, nshards, vocab_sz):\n  \"\"\"Chops the binary Glove co-occurrence matrix into shards.\n\n  This reads the Glove binary co-occurrence file and assigns individual\n  co-occurrence counts to the appropriate Swivel shard.\n\n  Args:\n    coocs: the co-occurrnece file to read\n    nshards: the number of shards along one dimension of the square matrix\n    vocab_sz: the vocabulary size\n\n  Returns:\n    A (shard_table, marginals) tuple.  The shard_table maps the row and column\n    shard ID to a file handle containing the co-occurrences for that shard; the\n    marginals contain the marginal sums.\n  \"\"\"\n  row_sums = [0] * vocab_sz\n  col_sums = [0] * vocab_sz\n\n  coocs.seek(0, os.SEEK_END)\n  ncoocs = coocs.tell() / glove_cooc_fmt.size\n  coocs.seek(0, os.SEEK_SET)\n\n  shard_files = {}\n\n  for row in range(nshards):\n    for col in range(nshards):\n      filename = os.path.join(\n          FLAGS.output_dir, 'shard-%03d-%03d.bin' % (row, col))\n\n      shard_files[(row, col)] = open(filename, 'w+')\n\n  for ix in xrange(ncoocs):\n    if ix % 1000000 == 0:\n      sys.stdout.write('\\rsharding co-occurrences: %0.1f%% (%d/%d)' % (\n          100.0 * ix / ncoocs, ix, ncoocs))\n\n      sys.stdout.flush()\n\n    bits = coocs.read(glove_cooc_fmt.size)\n    if not bits:\n      break\n\n    # Glove has 1-indexed IDs.\n    row_id, col_id, cnt = glove_cooc_fmt.unpack(bits)\n    if row_id > vocab_sz or col_id > vocab_sz:\n      continue\n\n    row_id -= 1\n    row_shard = row_id % nshards\n    row_off = row_id / nshards\n\n    col_id -= 1\n    col_shard = col_id % nshards\n    col_off = col_id / nshards\n\n    shard_pos = row_off * FLAGS.shard_size + col_off  # row major\n\n    shard_files[(row_shard, col_shard)].write(\n        shard_cooc_fmt.pack(shard_pos, cnt))\n\n    # Accumulate marginals.\n    row_sums[row_id] += cnt\n    col_sums[col_id] += cnt\n\n  sys.stdout.write('\\n')\n\n  if any(abs(r - c) > 0.1 for r, c in itertools.izip(row_sums, col_sums)):\n    print('WARNING! Row and column marginals differ; is your matrix symmetric?',\n          file=sys.stderr)\n\n  return (shard_files, row_sums)\n\n\ndef main(_):\n  with open(FLAGS.vocab, 'r') as lines:\n    orig_vocab_sz = sum(1 for _ in lines)\n\n  shard_sz = FLAGS.shard_size\n  vocab_sz = orig_vocab_sz - orig_vocab_sz % shard_sz\n  nshards = vocab_sz / shard_sz\n\n  print('vocab size is %d (originally %d), %d %dx%d-element shards' % (\n      vocab_sz, orig_vocab_sz, nshards * nshards, shard_sz, shard_sz))\n\n  # Create the output directory, if necessary\n  if FLAGS.output_dir and not os.path.isdir(FLAGS.output_dir):\n    os.makedirs(FLAGS.output_dir)\n\n  with open(FLAGS.input, 'r') as coocs:\n    shard_files, marginals = make_shard_files(coocs, nshards, vocab_sz)\n\n  # Now sort the shards and write the TFRecords.\n  filename = os.path.join(FLAGS.output_dir, 'shards.recs')\n  with tf.python_io.TFRecordWriter(filename) as writer:\n    ix = 0\n    for (row, col), fh in shard_files.iteritems():\n      ix += 1\n      sys.stdout.write('\\rwriting shard %d/%d' % (ix, len(shard_files)))\n      sys.stdout.flush()\n\n      fh.seek(0)\n      buf = fh.read()\n      os.unlink(fh.name)\n      fh.close()\n\n      coocs = [\n          shard_cooc_fmt.unpack_from(buf, off)\n          for off in range(0, len(buf), shard_cooc_fmt.size)]\n\n      # N.B. we assume that there aren't any duplicates here!\n      coocs.sort(key=lambda kv: kv[0])\n\n      def _int64s(xs):\n        return tf.train.Feature(int64_list=tf.train.Int64List(value=list(xs)))\n\n      def _floats(xs):\n        return tf.train.Feature(float_list=tf.train.FloatList(value=list(xs)))\n\n      example = tf.train.Example(features=tf.train.Features(feature={\n          'global_row': _int64s(row + nshards * i for i in range(shard_sz)),\n          'global_col': _int64s(col + nshards * i for i in range(shard_sz)),\n          'sparse_local_row': _int64s(pos / shard_sz for pos, _ in coocs),\n          'sparse_local_col': _int64s(pos % shard_sz for pos, _ in coocs),\n          'sparse_value': _floats(cnt for _, cnt in coocs)}))\n\n      writer.write(example.SerializeToString())\n\n  print('\\nwriting marginals...')\n\n  with open(os.path.join(FLAGS.output_dir, 'marginals.txt'), 'w') as fh:\n    for cnt in marginals:\n      fh.write('%0.1f\\n' % cnt)\n\n  print('done!')\n\n\nif __name__ == '__main__':\n  tf.app.run()\n", "description": "Models and examples built with TensorFlow", "file_name": "glove_to_shards.py", "id": "c102f0bef1affeb916aa4c9d015a1204", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-models/tensorflow-models-086d914/research/swivel/glove_to_shards.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:59:19Z", "url": "https://github.com/tensorflow/models", "wiki": true}