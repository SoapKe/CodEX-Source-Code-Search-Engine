{"author": "rg3", "code": "\nfrom __future__ import unicode_literals\n\nimport re\n\nfrom .common import InfoExtractor\nfrom ..compat import compat_str\nfrom ..utils import (\n    int_or_none,\n    parse_iso8601,\n    unescapeHTML,\n    qualities,\n)\n\n\nclass Revision3EmbedIE(InfoExtractor):\n    IE_NAME = 'revision3:embed'\n    _VALID_URL = r'(?:revision3:(?:(?P<playlist_type>[^:]+):)?|https?://(?:(?:(?:www|embed)\\.)?(?:revision3|animalist)|(?:(?:api|embed)\\.)?seekernetwork)\\.com/player/embed\\?videoId=)(?P<playlist_id>\\d+)'\n    _TEST = {\n        'url': 'http://api.seekernetwork.com/player/embed?videoId=67558',\n        'md5': '83bcd157cab89ad7318dd7b8c9cf1306',\n        'info_dict': {\n            'id': '67558',\n            'ext': 'mp4',\n            'title': 'The Pros & Cons Of Zoos',\n            'description': 'Zoos are often depicted as a terrible place for animals to live, but is there any truth to this?',\n            'uploader_id': 'dnews',\n            'uploader': 'DNews',\n        }\n    }\n    _API_KEY = 'ba9c741bce1b9d8e3defcc22193f3651b8867e62'\n\n    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('playlist_id')\n        playlist_type = mobj.group('playlist_type') or 'video_id'\n        video_data = self._download_json(\n            'http://revision3.com/api/getPlaylist.json', playlist_id, query={\n                'api_key': self._API_KEY,\n                'codecs': 'h264,vp8,theora',\n                playlist_type: playlist_id,\n            })['items'][0]\n\n        formats = []\n        for vcodec, media in video_data['media'].items():\n            for quality_id, quality in media.items():\n                if quality_id == 'hls':\n                    formats.extend(self._extract_m3u8_formats(\n                        quality['url'], playlist_id, 'mp4',\n                        'm3u8_native', m3u8_id='hls', fatal=False))\n                else:\n                    formats.append({\n                        'url': quality['url'],\n                        'format_id': '%s-%s' % (vcodec, quality_id),\n                        'tbr': int_or_none(quality.get('bitrate')),\n                        'vcodec': vcodec,\n                    })\n        self._sort_formats(formats)\n\n        return {\n            'id': playlist_id,\n            'title': unescapeHTML(video_data['title']),\n            'description': unescapeHTML(video_data.get('summary')),\n            'uploader': video_data.get('show', {}).get('name'),\n            'uploader_id': video_data.get('show', {}).get('slug'),\n            'duration': int_or_none(video_data.get('duration')),\n            'formats': formats,\n        }\n\n\nclass Revision3IE(InfoExtractor):\n    IE_NAME = 'revision'\n    _VALID_URL = r'https?://(?:www\\.)?(?P<domain>(?:revision3|animalist)\\.com)/(?P<id>[^/]+(?:/[^/?\n    _TESTS = [{\n        'url': 'http://www.revision3.com/technobuffalo/5-google-predictions-for-2016',\n        'md5': 'd94a72d85d0a829766de4deb8daaf7df',\n        'info_dict': {\n            'id': '71089',\n            'display_id': 'technobuffalo/5-google-predictions-for-2016',\n            'ext': 'webm',\n            'title': '5 Google Predictions for 2016',\n            'description': 'Google had a great 2015, but it\\'s already time to look ahead. Here are our five predictions for 2016.',\n            'upload_date': '20151228',\n            'timestamp': 1451325600,\n            'duration': 187,\n            'uploader': 'TechnoBuffalo',\n            'uploader_id': 'technobuffalo',\n        }\n    }, {\n        \n        'url': 'http://revision3.com/variant',\n        'only_matching': True,\n    }, {\n        \n        'url': 'http://revision3.com/vr',\n        'only_matching': True,\n    }]\n    _PAGE_DATA_TEMPLATE = 'http://www.%s/apiProxy/ddn/%s?domain=%s'\n\n    def _real_extract(self, url):\n        domain, display_id = re.match(self._VALID_URL, url).groups()\n        site = domain.split('.')[0]\n        page_info = self._download_json(\n            self._PAGE_DATA_TEMPLATE % (domain, display_id, domain), display_id)\n\n        page_data = page_info['data']\n        page_type = page_data['type']\n        if page_type in ('episode', 'embed'):\n            show_data = page_data['show']['data']\n            page_id = compat_str(page_data['id'])\n            video_id = compat_str(page_data['video']['data']['id'])\n\n            preference = qualities(['mini', 'small', 'medium', 'large'])\n            thumbnails = [{\n                'url': image_url,\n                'id': image_id,\n                'preference': preference(image_id)\n            } for image_id, image_url in page_data.get('images', {}).items()]\n\n            info = {\n                'id': page_id,\n                'display_id': display_id,\n                'title': unescapeHTML(page_data['name']),\n                'description': unescapeHTML(page_data.get('summary')),\n                'timestamp': parse_iso8601(page_data.get('publishTime'), ' '),\n                'author': page_data.get('author'),\n                'uploader': show_data.get('name'),\n                'uploader_id': show_data.get('slug'),\n                'thumbnails': thumbnails,\n                'extractor_key': site,\n            }\n\n            if page_type == 'embed':\n                info.update({\n                    '_type': 'url_transparent',\n                    'url': page_data['video']['data']['embed'],\n                })\n                return info\n\n            info.update({\n                '_type': 'url_transparent',\n                'url': 'revision3:%s' % video_id,\n            })\n            return info\n        else:\n            list_data = page_info[page_type]['data']\n            episodes_data = page_info['episodes']['data']\n            num_episodes = page_info['meta']['totalEpisodes']\n            processed_episodes = 0\n            entries = []\n            page_num = 1\n            while True:\n                entries.extend([{\n                    '_type': 'url',\n                    'url': 'http://%s%s' % (domain, episode['path']),\n                    'id': compat_str(episode['id']),\n                    'ie_key': 'Revision3',\n                    'extractor_key': site,\n                } for episode in episodes_data])\n                processed_episodes += len(episodes_data)\n                if processed_episodes == num_episodes:\n                    break\n                page_num += 1\n                episodes_data = self._download_json(self._PAGE_DATA_TEMPLATE % (\n                    domain, display_id + '/' + compat_str(page_num), domain),\n                    display_id)['episodes']['data']\n\n            return self.playlist_result(\n                entries, compat_str(list_data['id']),\n                list_data.get('name'), list_data.get('summary'))\n", "comments": "# coding: utf-8\n#]+)?)'\n# Show\n# Tag\n", "content": "# coding: utf-8\nfrom __future__ import unicode_literals\n\nimport re\n\nfrom .common import InfoExtractor\nfrom ..compat import compat_str\nfrom ..utils import (\n    int_or_none,\n    parse_iso8601,\n    unescapeHTML,\n    qualities,\n)\n\n\nclass Revision3EmbedIE(InfoExtractor):\n    IE_NAME = 'revision3:embed'\n    _VALID_URL = r'(?:revision3:(?:(?P<playlist_type>[^:]+):)?|https?://(?:(?:(?:www|embed)\\.)?(?:revision3|animalist)|(?:(?:api|embed)\\.)?seekernetwork)\\.com/player/embed\\?videoId=)(?P<playlist_id>\\d+)'\n    _TEST = {\n        'url': 'http://api.seekernetwork.com/player/embed?videoId=67558',\n        'md5': '83bcd157cab89ad7318dd7b8c9cf1306',\n        'info_dict': {\n            'id': '67558',\n            'ext': 'mp4',\n            'title': 'The Pros & Cons Of Zoos',\n            'description': 'Zoos are often depicted as a terrible place for animals to live, but is there any truth to this?',\n            'uploader_id': 'dnews',\n            'uploader': 'DNews',\n        }\n    }\n    _API_KEY = 'ba9c741bce1b9d8e3defcc22193f3651b8867e62'\n\n    def _real_extract(self, url):\n        mobj = re.match(self._VALID_URL, url)\n        playlist_id = mobj.group('playlist_id')\n        playlist_type = mobj.group('playlist_type') or 'video_id'\n        video_data = self._download_json(\n            'http://revision3.com/api/getPlaylist.json', playlist_id, query={\n                'api_key': self._API_KEY,\n                'codecs': 'h264,vp8,theora',\n                playlist_type: playlist_id,\n            })['items'][0]\n\n        formats = []\n        for vcodec, media in video_data['media'].items():\n            for quality_id, quality in media.items():\n                if quality_id == 'hls':\n                    formats.extend(self._extract_m3u8_formats(\n                        quality['url'], playlist_id, 'mp4',\n                        'm3u8_native', m3u8_id='hls', fatal=False))\n                else:\n                    formats.append({\n                        'url': quality['url'],\n                        'format_id': '%s-%s' % (vcodec, quality_id),\n                        'tbr': int_or_none(quality.get('bitrate')),\n                        'vcodec': vcodec,\n                    })\n        self._sort_formats(formats)\n\n        return {\n            'id': playlist_id,\n            'title': unescapeHTML(video_data['title']),\n            'description': unescapeHTML(video_data.get('summary')),\n            'uploader': video_data.get('show', {}).get('name'),\n            'uploader_id': video_data.get('show', {}).get('slug'),\n            'duration': int_or_none(video_data.get('duration')),\n            'formats': formats,\n        }\n\n\nclass Revision3IE(InfoExtractor):\n    IE_NAME = 'revision'\n    _VALID_URL = r'https?://(?:www\\.)?(?P<domain>(?:revision3|animalist)\\.com)/(?P<id>[^/]+(?:/[^/?#]+)?)'\n    _TESTS = [{\n        'url': 'http://www.revision3.com/technobuffalo/5-google-predictions-for-2016',\n        'md5': 'd94a72d85d0a829766de4deb8daaf7df',\n        'info_dict': {\n            'id': '71089',\n            'display_id': 'technobuffalo/5-google-predictions-for-2016',\n            'ext': 'webm',\n            'title': '5 Google Predictions for 2016',\n            'description': 'Google had a great 2015, but it\\'s already time to look ahead. Here are our five predictions for 2016.',\n            'upload_date': '20151228',\n            'timestamp': 1451325600,\n            'duration': 187,\n            'uploader': 'TechnoBuffalo',\n            'uploader_id': 'technobuffalo',\n        }\n    }, {\n        # Show\n        'url': 'http://revision3.com/variant',\n        'only_matching': True,\n    }, {\n        # Tag\n        'url': 'http://revision3.com/vr',\n        'only_matching': True,\n    }]\n    _PAGE_DATA_TEMPLATE = 'http://www.%s/apiProxy/ddn/%s?domain=%s'\n\n    def _real_extract(self, url):\n        domain, display_id = re.match(self._VALID_URL, url).groups()\n        site = domain.split('.')[0]\n        page_info = self._download_json(\n            self._PAGE_DATA_TEMPLATE % (domain, display_id, domain), display_id)\n\n        page_data = page_info['data']\n        page_type = page_data['type']\n        if page_type in ('episode', 'embed'):\n            show_data = page_data['show']['data']\n            page_id = compat_str(page_data['id'])\n            video_id = compat_str(page_data['video']['data']['id'])\n\n            preference = qualities(['mini', 'small', 'medium', 'large'])\n            thumbnails = [{\n                'url': image_url,\n                'id': image_id,\n                'preference': preference(image_id)\n            } for image_id, image_url in page_data.get('images', {}).items()]\n\n            info = {\n                'id': page_id,\n                'display_id': display_id,\n                'title': unescapeHTML(page_data['name']),\n                'description': unescapeHTML(page_data.get('summary')),\n                'timestamp': parse_iso8601(page_data.get('publishTime'), ' '),\n                'author': page_data.get('author'),\n                'uploader': show_data.get('name'),\n                'uploader_id': show_data.get('slug'),\n                'thumbnails': thumbnails,\n                'extractor_key': site,\n            }\n\n            if page_type == 'embed':\n                info.update({\n                    '_type': 'url_transparent',\n                    'url': page_data['video']['data']['embed'],\n                })\n                return info\n\n            info.update({\n                '_type': 'url_transparent',\n                'url': 'revision3:%s' % video_id,\n            })\n            return info\n        else:\n            list_data = page_info[page_type]['data']\n            episodes_data = page_info['episodes']['data']\n            num_episodes = page_info['meta']['totalEpisodes']\n            processed_episodes = 0\n            entries = []\n            page_num = 1\n            while True:\n                entries.extend([{\n                    '_type': 'url',\n                    'url': 'http://%s%s' % (domain, episode['path']),\n                    'id': compat_str(episode['id']),\n                    'ie_key': 'Revision3',\n                    'extractor_key': site,\n                } for episode in episodes_data])\n                processed_episodes += len(episodes_data)\n                if processed_episodes == num_episodes:\n                    break\n                page_num += 1\n                episodes_data = self._download_json(self._PAGE_DATA_TEMPLATE % (\n                    domain, display_id + '/' + compat_str(page_num), domain),\n                    display_id)['episodes']['data']\n\n            return self.playlist_result(\n                entries, compat_str(list_data['id']),\n                list_data.get('name'), list_data.get('summary'))\n", "description": "Command-line program to download videos from YouTube.com and other video sites", "file_name": "revision3.py", "language": "Python", "project_name": "youtube-dl", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/rg3_youtube-dl/rg3-youtube-dl-6202f08/youtube_dl/extractor/revision3.py", "save_time": "", "source": "", "update_at": "2018-03-07T09:18:39Z", "url": "https://github.com/rg3/youtube-dl", "wiki": false}