{"author": "deepfakes", "code": "import time\nimport cv2\nimport numpy as np\n\nfrom keras.layers import *\nfrom tensorflow.contrib.distributions import Beta\nimport tensorflow as tf\nfrom keras.optimizers import Adam\nfrom keras import backend as K\n\nfrom lib.training_data import TrainingDataGenerator, stack_images\n\nclass GANTrainingDataGenerator(TrainingDataGenerator):\n    def __init__(self, random_transform_args, coverage, scale, zoom):\n        super().__init__(random_transform_args, coverage, scale, zoom)\n\n    def color_adjust(self, img):\n        return img / 255.0 * 2 - 1\n\nclass Trainer():\n    random_transform_args = {\n        'rotation_range': 20,\n        'zoom_range': 0.1,\n        'shift_range': 0.05,\n        'random_flip': 0.5,\n        }\n\n    def __init__(self, model, fn_A, fn_B, batch_size, perceptual_loss):\n        K.set_learning_phase(1)\n\n        assert batch_size % 2 == 0, \"batch_size must be an even number\"\n        self.batch_size = batch_size\n        self.model = model\n\n        self.use_lsgan = True\n        self.use_mixup = True\n        self.mixup_alpha = 0.2\n        self.use_perceptual_loss = perceptual_loss\n        self.use_instancenorm = False\n\n        self.lrD = 1e-4 \n        self.lrG = 1e-4 \n\n        generator = GANTrainingDataGenerator(self.random_transform_args, 220, 6, 1)\n        self.train_batchA = generator.minibatchAB(fn_A, batch_size)\n        self.train_batchB = generator.minibatchAB(fn_B, batch_size)\n\n        self.avg_counter = self.errDA_sum = self.errDB_sum = self.errGA_sum = self.errGB_sum = 0\n\n        self.setup()\n\n    def setup(self):\n        distorted_A, fake_A, mask_A, self.path_A, self.path_mask_A, self.path_abgr_A, self.path_bgr_A = self.cycle_variables(self.model.netGA)\n        distorted_B, fake_B, mask_B, self.path_B, self.path_mask_B, self.path_abgr_B, self.path_bgr_B = self.cycle_variables(self.model.netGB)\n        real_A = Input(shape=self.model.img_shape)\n        real_B = Input(shape=self.model.img_shape)\n\n        if self.use_lsgan:\n            self.loss_fn = lambda output, target : K.mean(K.abs(K.square(output-target)))\n        else:\n            self.loss_fn = lambda output, target : -K.mean(K.log(output+1e-12)*target+K.log(1-output+1e-12)*(1-target))\n\n        \n        if self.use_perceptual_loss:\n            from keras.models import Model\n            from keras_vggface.vggface import VGGFace\n            vggface = VGGFace(include_top=False, model='resnet50', input_shape=(224, 224, 3))\n            vggface.trainable = False\n            out_size55 = vggface.layers[36].output\n            out_size28 = vggface.layers[78].output\n            out_size7 = vggface.layers[-2].output\n            vggface_feat = Model(vggface.input, [out_size55, out_size28, out_size7])\n            vggface_feat.trainable = False\n        else:\n            vggface_feat = None\n\n        #TODO check \"Tips for mask refinement (optional after >15k iters)\" => https://render.githubusercontent.com/view/ipynb?commit=87d6e7a28ce754acd38d885367b6ceb0be92ec54&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f7368616f616e6c752f66616365737761702d47414e2f383764366537613238636537353461636433386438383533363762366365623062653932656335342f46616365537761705f47414e5f76325f737a3132385f747261696e2e6970796e62&nwo=shaoanlu%2Ffaceswap-GAN&path=FaceSwap_GAN_v2_sz128_train.ipynb&repository_id=115182783&repository_type=Repository#Tips-for-mask-refinement-(optional-after-%3E15k-iters)\n        loss_DA, loss_GA = self.define_loss(self.model.netDA, real_A, fake_A, distorted_A, vggface_feat)\n        loss_DB, loss_GB = self.define_loss(self.model.netDB, real_B, fake_B, distorted_B, vggface_feat)\n\n        loss_GA += 1e-3 * K.mean(K.abs(mask_A))\n        loss_GB += 1e-3 * K.mean(K.abs(mask_B))\n\n        w_fo = 0.01\n        loss_GA += w_fo * K.mean(self.first_order(mask_A, axis=1))\n        loss_GA += w_fo * K.mean(self.first_order(mask_A, axis=2))\n        loss_GB += w_fo * K.mean(self.first_order(mask_B, axis=1))\n        loss_GB += w_fo * K.mean(self.first_order(mask_B, axis=2))\n\n        weightsDA = self.model.netDA.trainable_weights\n        weightsGA = self.model.netGA.trainable_weights\n        weightsDB = self.model.netDB.trainable_weights\n        weightsGB = self.model.netGB.trainable_weights\n\n        # Adam(..).get_updates(...)\n        training_updates = Adam(lr=self.lrD, beta_1=0.5).get_updates(weightsDA,[],loss_DA)\n        self.netDA_train = K.function([distorted_A, real_A],[loss_DA], training_updates)\n        training_updates = Adam(lr=self.lrG, beta_1=0.5).get_updates(weightsGA,[], loss_GA)\n        self.netGA_train = K.function([distorted_A, real_A], [loss_GA], training_updates)\n\n        training_updates = Adam(lr=self.lrD, beta_1=0.5).get_updates(weightsDB,[],loss_DB)\n        self.netDB_train = K.function([distorted_B, real_B],[loss_DB], training_updates)\n        training_updates = Adam(lr=self.lrG, beta_1=0.5).get_updates(weightsGB,[], loss_GB)\n        self.netGB_train = K.function([distorted_B, real_B], [loss_GB], training_updates)\n\n    def first_order(self, x, axis=1):\n        img_nrows = x.shape[1]\n        img_ncols = x.shape[2]\n        if axis == 1:\n            return K.abs(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n        elif axis == 2:\n            return K.abs(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n        else:\n            return None\n\n    def train_one_step(self, iter, viewer):\n        \n        \n        \n\n        \n        epoch, warped_A, target_A = next(self.train_batchA)\n        epoch, warped_B, target_B = next(self.train_batchB)\n\n        \n        errDA  = self.netDA_train([warped_A, target_A])\n        errDB  = self.netDB_train([warped_B, target_B])\n\n        \n        errGA = self.netGA_train([warped_A, target_A])\n        errGB = self.netGB_train([warped_B, target_B])\n\n        \n        self.errDA_sum += errDA[0]\n        self.errDB_sum += errDB[0]\n        self.errGA_sum += errGA[0]\n        self.errGB_sum += errGB[0]\n        self.avg_counter += 1\n\n        print('[%s] [%d/%s][%d] Loss_DA: %f Loss_DB: %f Loss_GA: %f Loss_GB: %f'\n              % (time.strftime(\"%H:%M:%S\"), epoch, \"num_epochs\", iter, self.errDA_sum/self.avg_counter, self.errDB_sum/self.avg_counter, self.errGA_sum/self.avg_counter, self.errGB_sum/self.avg_counter),\n              end='\\r')\n\n        if viewer is not None:\n            self.show_sample(viewer)\n\n    def cycle_variables(self, netG):\n        distorted_input = netG.inputs[0]\n        fake_output = netG.outputs[0]\n        alpha = Lambda(lambda x: x[:,:,:, :1])(fake_output)\n        rgb = Lambda(lambda x: x[:,:,:, 1:])(fake_output)\n\n        masked_fake_output = alpha * rgb + (1-alpha) * distorted_input\n\n        fn_generate = K.function([distorted_input], [masked_fake_output])\n        fn_mask = K.function([distorted_input], [concatenate([alpha, alpha, alpha])])\n        fn_abgr = K.function([distorted_input], [concatenate([alpha, rgb])])\n        fn_bgr = K.function([distorted_input], [rgb])\n        return distorted_input, fake_output, alpha, fn_generate, fn_mask, fn_abgr, fn_bgr\n\n    def define_loss(self, netD, real, fake_argb, distorted, vggface_feat=None):\n        alpha = Lambda(lambda x: x[:,:,:, :1])(fake_argb)\n        fake_rgb = Lambda(lambda x: x[:,:,:, 1:])(fake_argb)\n        fake = alpha * fake_rgb + (1-alpha) * distorted\n\n        if self.use_mixup:\n            dist = Beta(self.mixup_alpha, self.mixup_alpha)\n            lam = dist.sample()\n            \n            mixup = lam * concatenate([real, distorted]) + (1 - lam) * concatenate([fake, distorted])\n            \n            output_mixup = netD(mixup)\n            loss_D = self.loss_fn(output_mixup, lam * K.ones_like(output_mixup))\n            output_fake = netD(concatenate([fake, distorted])) \n            loss_G = .5 * self.loss_fn(output_mixup, (1 - lam) * K.ones_like(output_mixup))\n        else:\n            output_real = netD(concatenate([real, distorted])) \n            output_fake = netD(concatenate([fake, distorted])) \n            loss_D_real = self.loss_fn(output_real, K.ones_like(output_real))\n            loss_D_fake = self.loss_fn(output_fake, K.zeros_like(output_fake))\n            loss_D = loss_D_real + loss_D_fake\n            loss_G = .5 * self.loss_fn(output_fake, K.ones_like(output_fake))\n        \n        loss_G += K.mean(K.abs(fake_rgb - real))\n        \n\n        # Edge loss (similar with total variation loss)\n        loss_G += 1 * K.mean(K.abs(self.first_order(fake_rgb, axis=1) - self.first_order(real, axis=1)))\n        loss_G += 1 * K.mean(K.abs(self.first_order(fake_rgb, axis=2) - self.first_order(real, axis=2)))\n\n\n        \n        if not vggface_feat is None:\n            def preprocess_vggface(x):\n                x = (x + 1)/2 * 255 \n                #x[..., 0] -= 93.5940\n                #x[..., 1] -= 104.7624\n                #x[..., 2] -= 129.\n                x -= [91.4953, 103.8827, 131.0912]\n                return x\n            pl_params = (0.011, 0.11, 0.1919)\n            real_sz224 = tf.image.resize_images(real, [224, 224])\n            real_sz224 = Lambda(preprocess_vggface)(real_sz224)\n            \n            fake_sz224 = tf.image.resize_images(fake_rgb, [224, 224])\n            fake_sz224 = Lambda(preprocess_vggface)(fake_sz224)\n            \n            real_feat55, real_feat28, real_feat7 = vggface_feat(real_sz224)\n            fake_feat55, fake_feat28, fake_feat7  = vggface_feat(fake_sz224)\n            loss_G += pl_params[0] * K.mean(K.abs(fake_feat7 - real_feat7))\n            loss_G += pl_params[1] * K.mean(K.abs(fake_feat28 - real_feat28))\n            loss_G += pl_params[2] * K.mean(K.abs(fake_feat55 - real_feat55))\n\n        return loss_D, loss_G\n\n    def show_sample(self, display_fn):\n        _, wA, tA = next(self.train_batchA)\n        _, wB, tB = next(self.train_batchB)\n        display_fn(self.showG(tA, tB, self.path_A, self.path_B), \"raw\")\n        display_fn(self.showG(tA, tB, self.path_bgr_A, self.path_bgr_B), \"masked\")\n        display_fn(self.showG_mask(tA, tB, self.path_mask_A, self.path_mask_B), \"mask\")\n        \n        self.errDA_sum = self.errDB_sum = self.errGA_sum = self.errGB_sum = 0\n        self.avg_counter = 0\n\n    def showG(self, test_A, test_B, path_A, path_B):\n        figure_A = np.stack([\n            test_A,\n            np.squeeze(np.array([path_A([test_A[i:i+1]]) for i in range(test_A.shape[0])])),\n            np.squeeze(np.array([path_B([test_A[i:i+1]]) for i in range(test_A.shape[0])])),\n            ], axis=1 )\n        figure_B = np.stack([\n            test_B,\n            np.squeeze(np.array([path_B([test_B[i:i+1]]) for i in range(test_B.shape[0])])),\n            np.squeeze(np.array([path_A([test_B[i:i+1]]) for i in range(test_B.shape[0])])),\n            ], axis=1 )\n\n        figure = np.concatenate([figure_A, figure_B], axis=0 )\n        figure = figure.reshape((4,self.batch_size // 2) + figure.shape[1:])\n        figure = stack_images(figure)\n        figure = np.clip((figure + 1) * 255 / 2, 0, 255).astype('uint8')\n        return figure\n\n    def showG_mask(self, test_A, test_B, path_A, path_B):\n        figure_A = np.stack([\n            test_A,\n            (np.squeeze(np.array([path_A([test_A[i:i+1]]) for i in range(test_A.shape[0])])))*2-1,\n            (np.squeeze(np.array([path_B([test_A[i:i+1]]) for i in range(test_A.shape[0])])))*2-1,\n            ], axis=1 )\n        figure_B = np.stack([\n            test_B,\n            (np.squeeze(np.array([path_B([test_B[i:i+1]]) for i in range(test_B.shape[0])])))*2-1,\n            (np.squeeze(np.array([path_A([test_B[i:i+1]]) for i in range(test_B.shape[0])])))*2-1,\n            ], axis=1 )\n\n        figure = np.concatenate([figure_A, figure_B], axis=0 )\n        figure = figure.reshape((4,self.batch_size // 2) + figure.shape[1:])\n        figure = stack_images(figure)\n        figure = np.clip((figure + 1) * 255 / 2, 0, 255).astype('uint8')\n        return figure\n", "comments": "  discriminator learning rate    generator learning rate               define perceptual loss model             todo check  tips mask refinement (optional  15k iters)     https   render githubusercontent com view ipynb commit 87d6e7a28ce754acd38d885367b6ceb0be92ec54 enc url 68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f7368616f616e6c752f66616365737761702d47414e2f383764366537613238636537353461636433386438383533363762366365623062653932656335342f46616365537761705f47414e5f76325f737a3132385f747261696e2e6970796e62 nwo shaoanlu 2ffaceswap gan path faceswap gan v2 sz128 train ipynb repository id 115182783 repository type repository tips mask refinement (optional  3e15k iters)    adam(  ) get updates(   )                              train discriminators                             select random half batch images    train dicriminators one batch    train generators one batch    for calculating average losses                                dummy    positive sample    negative sample                                edge loss (similar total variation loss)    perceptual loss    channel order  bgr   x      0     93 5940   x      1     104 7624   x      2     129                                 reset averages ", "content": "import time\nimport cv2\nimport numpy as np\n\nfrom keras.layers import *\nfrom tensorflow.contrib.distributions import Beta\nimport tensorflow as tf\nfrom keras.optimizers import Adam\nfrom keras import backend as K\n\nfrom lib.training_data import TrainingDataGenerator, stack_images\n\nclass GANTrainingDataGenerator(TrainingDataGenerator):\n    def __init__(self, random_transform_args, coverage, scale, zoom):\n        super().__init__(random_transform_args, coverage, scale, zoom)\n\n    def color_adjust(self, img):\n        return img / 255.0 * 2 - 1\n\nclass Trainer():\n    random_transform_args = {\n        'rotation_range': 20,\n        'zoom_range': 0.1,\n        'shift_range': 0.05,\n        'random_flip': 0.5,\n        }\n\n    def __init__(self, model, fn_A, fn_B, batch_size, perceptual_loss):\n        K.set_learning_phase(1)\n\n        assert batch_size % 2 == 0, \"batch_size must be an even number\"\n        self.batch_size = batch_size\n        self.model = model\n\n        self.use_lsgan = True\n        self.use_mixup = True\n        self.mixup_alpha = 0.2\n        self.use_perceptual_loss = perceptual_loss\n        self.use_instancenorm = False\n\n        self.lrD = 1e-4 # Discriminator learning rate\n        self.lrG = 1e-4 # Generator learning rate\n\n        generator = GANTrainingDataGenerator(self.random_transform_args, 220, 6, 1)\n        self.train_batchA = generator.minibatchAB(fn_A, batch_size)\n        self.train_batchB = generator.minibatchAB(fn_B, batch_size)\n\n        self.avg_counter = self.errDA_sum = self.errDB_sum = self.errGA_sum = self.errGB_sum = 0\n\n        self.setup()\n\n    def setup(self):\n        distorted_A, fake_A, mask_A, self.path_A, self.path_mask_A, self.path_abgr_A, self.path_bgr_A = self.cycle_variables(self.model.netGA)\n        distorted_B, fake_B, mask_B, self.path_B, self.path_mask_B, self.path_abgr_B, self.path_bgr_B = self.cycle_variables(self.model.netGB)\n        real_A = Input(shape=self.model.img_shape)\n        real_B = Input(shape=self.model.img_shape)\n\n        if self.use_lsgan:\n            self.loss_fn = lambda output, target : K.mean(K.abs(K.square(output-target)))\n        else:\n            self.loss_fn = lambda output, target : -K.mean(K.log(output+1e-12)*target+K.log(1-output+1e-12)*(1-target))\n\n        # ========== Define Perceptual Loss Model==========\n        if self.use_perceptual_loss:\n            from keras.models import Model\n            from keras_vggface.vggface import VGGFace\n            vggface = VGGFace(include_top=False, model='resnet50', input_shape=(224, 224, 3))\n            vggface.trainable = False\n            out_size55 = vggface.layers[36].output\n            out_size28 = vggface.layers[78].output\n            out_size7 = vggface.layers[-2].output\n            vggface_feat = Model(vggface.input, [out_size55, out_size28, out_size7])\n            vggface_feat.trainable = False\n        else:\n            vggface_feat = None\n\n        #TODO check \"Tips for mask refinement (optional after >15k iters)\" => https://render.githubusercontent.com/view/ipynb?commit=87d6e7a28ce754acd38d885367b6ceb0be92ec54&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f7368616f616e6c752f66616365737761702d47414e2f383764366537613238636537353461636433386438383533363762366365623062653932656335342f46616365537761705f47414e5f76325f737a3132385f747261696e2e6970796e62&nwo=shaoanlu%2Ffaceswap-GAN&path=FaceSwap_GAN_v2_sz128_train.ipynb&repository_id=115182783&repository_type=Repository#Tips-for-mask-refinement-(optional-after-%3E15k-iters)\n        loss_DA, loss_GA = self.define_loss(self.model.netDA, real_A, fake_A, distorted_A, vggface_feat)\n        loss_DB, loss_GB = self.define_loss(self.model.netDB, real_B, fake_B, distorted_B, vggface_feat)\n\n        loss_GA += 1e-3 * K.mean(K.abs(mask_A))\n        loss_GB += 1e-3 * K.mean(K.abs(mask_B))\n\n        w_fo = 0.01\n        loss_GA += w_fo * K.mean(self.first_order(mask_A, axis=1))\n        loss_GA += w_fo * K.mean(self.first_order(mask_A, axis=2))\n        loss_GB += w_fo * K.mean(self.first_order(mask_B, axis=1))\n        loss_GB += w_fo * K.mean(self.first_order(mask_B, axis=2))\n\n        weightsDA = self.model.netDA.trainable_weights\n        weightsGA = self.model.netGA.trainable_weights\n        weightsDB = self.model.netDB.trainable_weights\n        weightsGB = self.model.netGB.trainable_weights\n\n        # Adam(..).get_updates(...)\n        training_updates = Adam(lr=self.lrD, beta_1=0.5).get_updates(weightsDA,[],loss_DA)\n        self.netDA_train = K.function([distorted_A, real_A],[loss_DA], training_updates)\n        training_updates = Adam(lr=self.lrG, beta_1=0.5).get_updates(weightsGA,[], loss_GA)\n        self.netGA_train = K.function([distorted_A, real_A], [loss_GA], training_updates)\n\n        training_updates = Adam(lr=self.lrD, beta_1=0.5).get_updates(weightsDB,[],loss_DB)\n        self.netDB_train = K.function([distorted_B, real_B],[loss_DB], training_updates)\n        training_updates = Adam(lr=self.lrG, beta_1=0.5).get_updates(weightsGB,[], loss_GB)\n        self.netGB_train = K.function([distorted_B, real_B], [loss_GB], training_updates)\n\n    def first_order(self, x, axis=1):\n        img_nrows = x.shape[1]\n        img_ncols = x.shape[2]\n        if axis == 1:\n            return K.abs(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n        elif axis == 2:\n            return K.abs(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n        else:\n            return None\n\n    def train_one_step(self, iter, viewer):\n        # ---------------------\n        #  Train Discriminators\n        # ---------------------\n\n        # Select a random half batch of images\n        epoch, warped_A, target_A = next(self.train_batchA)\n        epoch, warped_B, target_B = next(self.train_batchB)\n\n        # Train dicriminators for one batch\n        errDA  = self.netDA_train([warped_A, target_A])\n        errDB  = self.netDB_train([warped_B, target_B])\n\n        # Train generators for one batch\n        errGA = self.netGA_train([warped_A, target_A])\n        errGB = self.netGB_train([warped_B, target_B])\n\n        # For calculating average losses\n        self.errDA_sum += errDA[0]\n        self.errDB_sum += errDB[0]\n        self.errGA_sum += errGA[0]\n        self.errGB_sum += errGB[0]\n        self.avg_counter += 1\n\n        print('[%s] [%d/%s][%d] Loss_DA: %f Loss_DB: %f Loss_GA: %f Loss_GB: %f'\n              % (time.strftime(\"%H:%M:%S\"), epoch, \"num_epochs\", iter, self.errDA_sum/self.avg_counter, self.errDB_sum/self.avg_counter, self.errGA_sum/self.avg_counter, self.errGB_sum/self.avg_counter),\n              end='\\r')\n\n        if viewer is not None:\n            self.show_sample(viewer)\n\n    def cycle_variables(self, netG):\n        distorted_input = netG.inputs[0]\n        fake_output = netG.outputs[0]\n        alpha = Lambda(lambda x: x[:,:,:, :1])(fake_output)\n        rgb = Lambda(lambda x: x[:,:,:, 1:])(fake_output)\n\n        masked_fake_output = alpha * rgb + (1-alpha) * distorted_input\n\n        fn_generate = K.function([distorted_input], [masked_fake_output])\n        fn_mask = K.function([distorted_input], [concatenate([alpha, alpha, alpha])])\n        fn_abgr = K.function([distorted_input], [concatenate([alpha, rgb])])\n        fn_bgr = K.function([distorted_input], [rgb])\n        return distorted_input, fake_output, alpha, fn_generate, fn_mask, fn_abgr, fn_bgr\n\n    def define_loss(self, netD, real, fake_argb, distorted, vggface_feat=None):\n        alpha = Lambda(lambda x: x[:,:,:, :1])(fake_argb)\n        fake_rgb = Lambda(lambda x: x[:,:,:, 1:])(fake_argb)\n        fake = alpha * fake_rgb + (1-alpha) * distorted\n\n        if self.use_mixup:\n            dist = Beta(self.mixup_alpha, self.mixup_alpha)\n            lam = dist.sample()\n            # ==========\n            mixup = lam * concatenate([real, distorted]) + (1 - lam) * concatenate([fake, distorted])\n            # ==========\n            output_mixup = netD(mixup)\n            loss_D = self.loss_fn(output_mixup, lam * K.ones_like(output_mixup))\n            output_fake = netD(concatenate([fake, distorted])) # dummy\n            loss_G = .5 * self.loss_fn(output_mixup, (1 - lam) * K.ones_like(output_mixup))\n        else:\n            output_real = netD(concatenate([real, distorted])) # positive sample\n            output_fake = netD(concatenate([fake, distorted])) # negative sample\n            loss_D_real = self.loss_fn(output_real, K.ones_like(output_real))\n            loss_D_fake = self.loss_fn(output_fake, K.zeros_like(output_fake))\n            loss_D = loss_D_real + loss_D_fake\n            loss_G = .5 * self.loss_fn(output_fake, K.ones_like(output_fake))\n        # ==========\n        loss_G += K.mean(K.abs(fake_rgb - real))\n        # ==========\n\n        # Edge loss (similar with total variation loss)\n        loss_G += 1 * K.mean(K.abs(self.first_order(fake_rgb, axis=1) - self.first_order(real, axis=1)))\n        loss_G += 1 * K.mean(K.abs(self.first_order(fake_rgb, axis=2) - self.first_order(real, axis=2)))\n\n\n        # Perceptual Loss\n        if not vggface_feat is None:\n            def preprocess_vggface(x):\n                x = (x + 1)/2 * 255 # channel order: BGR\n                #x[..., 0] -= 93.5940\n                #x[..., 1] -= 104.7624\n                #x[..., 2] -= 129.\n                x -= [91.4953, 103.8827, 131.0912]\n                return x\n            pl_params = (0.011, 0.11, 0.1919)\n            real_sz224 = tf.image.resize_images(real, [224, 224])\n            real_sz224 = Lambda(preprocess_vggface)(real_sz224)\n            # ==========\n            fake_sz224 = tf.image.resize_images(fake_rgb, [224, 224])\n            fake_sz224 = Lambda(preprocess_vggface)(fake_sz224)\n            # ==========\n            real_feat55, real_feat28, real_feat7 = vggface_feat(real_sz224)\n            fake_feat55, fake_feat28, fake_feat7  = vggface_feat(fake_sz224)\n            loss_G += pl_params[0] * K.mean(K.abs(fake_feat7 - real_feat7))\n            loss_G += pl_params[1] * K.mean(K.abs(fake_feat28 - real_feat28))\n            loss_G += pl_params[2] * K.mean(K.abs(fake_feat55 - real_feat55))\n\n        return loss_D, loss_G\n\n    def show_sample(self, display_fn):\n        _, wA, tA = next(self.train_batchA)\n        _, wB, tB = next(self.train_batchB)\n        display_fn(self.showG(tA, tB, self.path_A, self.path_B), \"raw\")\n        display_fn(self.showG(tA, tB, self.path_bgr_A, self.path_bgr_B), \"masked\")\n        display_fn(self.showG_mask(tA, tB, self.path_mask_A, self.path_mask_B), \"mask\")\n        # Reset the averages\n        self.errDA_sum = self.errDB_sum = self.errGA_sum = self.errGB_sum = 0\n        self.avg_counter = 0\n\n    def showG(self, test_A, test_B, path_A, path_B):\n        figure_A = np.stack([\n            test_A,\n            np.squeeze(np.array([path_A([test_A[i:i+1]]) for i in range(test_A.shape[0])])),\n            np.squeeze(np.array([path_B([test_A[i:i+1]]) for i in range(test_A.shape[0])])),\n            ], axis=1 )\n        figure_B = np.stack([\n            test_B,\n            np.squeeze(np.array([path_B([test_B[i:i+1]]) for i in range(test_B.shape[0])])),\n            np.squeeze(np.array([path_A([test_B[i:i+1]]) for i in range(test_B.shape[0])])),\n            ], axis=1 )\n\n        figure = np.concatenate([figure_A, figure_B], axis=0 )\n        figure = figure.reshape((4,self.batch_size // 2) + figure.shape[1:])\n        figure = stack_images(figure)\n        figure = np.clip((figure + 1) * 255 / 2, 0, 255).astype('uint8')\n        return figure\n\n    def showG_mask(self, test_A, test_B, path_A, path_B):\n        figure_A = np.stack([\n            test_A,\n            (np.squeeze(np.array([path_A([test_A[i:i+1]]) for i in range(test_A.shape[0])])))*2-1,\n            (np.squeeze(np.array([path_B([test_A[i:i+1]]) for i in range(test_A.shape[0])])))*2-1,\n            ], axis=1 )\n        figure_B = np.stack([\n            test_B,\n            (np.squeeze(np.array([path_B([test_B[i:i+1]]) for i in range(test_B.shape[0])])))*2-1,\n            (np.squeeze(np.array([path_A([test_B[i:i+1]]) for i in range(test_B.shape[0])])))*2-1,\n            ], axis=1 )\n\n        figure = np.concatenate([figure_A, figure_B], axis=0 )\n        figure = figure.reshape((4,self.batch_size // 2) + figure.shape[1:])\n        figure = stack_images(figure)\n        figure = np.clip((figure + 1) * 255 / 2, 0, 255).astype('uint8')\n        return figure\n", "description": "Non official project based on original /r/Deepfakes thread. Many thanks to him!", "file_name": "Trainer.py", "id": "fe4fb5117f22756c260063c05f2cf839", "language": "Python", "project_name": "faceswap", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/deepfakes-faceswap/deepfakes-faceswap-6ff64ef/plugins/Model_GAN/Trainer.py", "save_time": "", "source": "", "update_at": "2018-03-18T16:27:43Z", "url": "https://github.com/deepfakes/faceswap", "wiki": true}