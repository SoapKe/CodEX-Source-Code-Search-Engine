{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\"\"\"Utilities for training adversarial text models.\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport time\n\n Dependency imports\n\nimport numpy as np\nimport tensorflow as tf\n\nflags = tf.app.flags\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string('master', '', 'Master address.')\nflags.DEFINE_integer('task', 0, 'Task id of the replica running the training.')\nflags.DEFINE_integer('ps_tasks', 0, 'Number of parameter servers.')\nflags.DEFINE_string('train_dir', '/tmp/text_train',\n                    'Directory for logs and checkpoints.')\nflags.DEFINE_integer('max_steps', 1000000, 'Number of batches to run.')\nflags.DEFINE_boolean('log_device_placement', False,\n                     'Whether to log device placement.')\n\n\ndef run_training(train_op,\n                 loss,\n                 global_step,\n                 variables_to_restore=None,\n                 pretrained_model_dir=None):\n  \"\"\"Sets up and runs training loop.\"\"\"\n  tf.gfile.MakeDirs(FLAGS.train_dir)\n\n   Create pretrain Saver\n  if pretrained_model_dir:\n    assert variables_to_restore\n    tf.logging.info('Will attempt restore from %s: %s', pretrained_model_dir,\n                    variables_to_restore)\n    saver_for_restore = tf.train.Saver(variables_to_restore)\n\n   Init ops\n  if FLAGS.sync_replicas:\n    local_init_op = tf.get_collection('local_init_op')[0]\n    ready_for_local_init_op = tf.get_collection('ready_for_local_init_op')[0]\n  else:\n    local_init_op = tf.train.Supervisor.USE_DEFAULT\n    ready_for_local_init_op = tf.train.Supervisor.USE_DEFAULT\n\n  is_chief = FLAGS.task == 0\n  sv = tf.train.Supervisor(\n      logdir=FLAGS.train_dir,\n      is_chief=is_chief,\n      save_summaries_secs=30,\n      save_model_secs=30,\n      local_init_op=local_init_op,\n      ready_for_local_init_op=ready_for_local_init_op,\n      global_step=global_step)\n\n   Delay starting standard services to allow possible pretrained model restore.\n  with sv.managed_session(\n      master=FLAGS.master,\n      config=tf.ConfigProto(log_device_placement=FLAGS.log_device_placement),\n      start_standard_services=False) as sess:\n     Initialization\n    if is_chief:\n      if pretrained_model_dir:\n        maybe_restore_pretrained_model(sess, saver_for_restore,\n                                       pretrained_model_dir)\n      if FLAGS.sync_replicas:\n        sess.run(tf.get_collection('chief_init_op')[0])\n      sv.start_standard_services(sess)\n\n    sv.start_queue_runners(sess)\n\n     Training loop\n    global_step_val = 0\n    while not sv.should_stop() and global_step_val < FLAGS.max_steps:\n      global_step_val = train_step(sess, train_op, loss, global_step)\n\n     Final checkpoint\n    if is_chief and global_step_val >= FLAGS.max_steps:\n      sv.saver.save(sess, sv.save_path, global_step=global_step)\n\n\ndef maybe_restore_pretrained_model(sess, saver_for_restore, model_dir):\n  \"\"\"Restores pretrained model if there is no ckpt model.\"\"\"\n  ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\n  checkpoint_exists = ckpt and ckpt.model_checkpoint_path\n  if checkpoint_exists:\n    tf.logging.info('Checkpoint exists in FLAGS.train_dir; skipping '\n                    'pretraining restore')\n    return\n\n  pretrain_ckpt = tf.train.get_checkpoint_state(model_dir)\n  if not (pretrain_ckpt and pretrain_ckpt.model_checkpoint_path):\n    raise ValueError(\n        'Asked to restore model from %s but no checkpoint found.' % model_dir)\n  saver_for_restore.restore(sess, pretrain_ckpt.model_checkpoint_path)\n\n\ndef train_step(sess, train_op, loss, global_step):\n  \"\"\"Runs a single training step.\"\"\"\n  start_time = time.time()\n  _, loss_val, global_step_val = sess.run([train_op, loss, global_step])\n  duration = time.time() - start_time\n\n   Logging\n  if global_step_val % 10 == 0:\n    examples_per_sec = FLAGS.batch_size / duration\n    sec_per_batch = float(duration)\n\n    format_str = ('step %d, loss = %.2f (%.1f examples/sec; %.3f ' 'sec/batch)')\n    tf.logging.info(format_str % (global_step_val, loss_val, examples_per_sec,\n                                  sec_per_batch))\n\n  if np.isnan(loss_val):\n    raise OverflowError('Loss is nan')\n\n  return global_step_val\n", "comments": "   utilities training adversarial text models       future   import absolute import   future   import division   future   import print function  import time    dependency imports  import numpy np import tensorflow tf  flags   tf app flags flags   flags flags  flags define string( master        master address  ) flags define integer( task   0   task id replica running training  ) flags define integer( ps tasks   0   number parameter servers  ) flags define string( train dir     tmp text train                        directory logs checkpoints  ) flags define integer( max steps   1000000   number batches run  ) flags define boolean( log device placement   false                        whether log device placement  )   def run training(train op                   loss                   global step                   variables restore none                   pretrained model dir none)       sets runs training loop       tf gfile makedirs(flags train dir)      create pretrain saver   pretrained model dir      assert variables restore     tf logging info( will attempt restore      pretrained model dir                      variables restore)     saver restore   tf train saver(variables restore)      init ops   flags sync replicas      local init op   tf get collection( local init op ) 0      ready local init op   tf get collection( ready local init op ) 0    else      local init op   tf train supervisor use default     ready local init op   tf train supervisor use default    chief   flags task    0   sv   tf train supervisor(       logdir flags train dir        chief chief        save summaries secs 30        save model secs 30        local init op local init op        ready local init op ready local init op        global step global step)      delay starting standard services allow possible pretrained model restore    sv managed session(       master flags master        config tf configproto(log device placement flags log device placement)        start standard services false) sess        initialization     chief        pretrained model dir          maybe restore pretrained model(sess  saver restore                                         pretrained model dir)       flags sync replicas          sess run(tf get collection( chief init op ) 0 )       sv start standard services(sess)      sv start queue runners(sess)        training loop     global step val   0     sv stop() global step val   flags max steps        global step val   train step(sess  train op  loss  global step)        final checkpoint     chief global step val    flags max steps        sv saver save(sess  sv save path  global step global step)   def maybe restore pretrained model(sess  saver restore  model dir)       restores pretrained model ckpt model       ckpt   tf train get checkpoint state(flags train dir)   checkpoint exists   ckpt ckpt model checkpoint path   checkpoint exists      tf logging info( checkpoint exists flags train dir  skipping                        pretraining restore )     return    pretrain ckpt   tf train get checkpoint state(model dir)   (pretrain ckpt pretrain ckpt model checkpoint path)      raise valueerror(          asked restore model  checkpoint found     model dir)   saver restore restore(sess  pretrain ckpt model checkpoint path)   def train step(sess  train op  loss  global step)       runs single training step        copyright 2017 google inc  all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                       dependency imports    create pretrain saver    init ops    delay starting standard services allow possible pretrained model restore     initialization    training loop    final checkpoint    logging ", "content": "# Copyright 2017 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Utilities for training adversarial text models.\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport time\n\n# Dependency imports\n\nimport numpy as np\nimport tensorflow as tf\n\nflags = tf.app.flags\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string('master', '', 'Master address.')\nflags.DEFINE_integer('task', 0, 'Task id of the replica running the training.')\nflags.DEFINE_integer('ps_tasks', 0, 'Number of parameter servers.')\nflags.DEFINE_string('train_dir', '/tmp/text_train',\n                    'Directory for logs and checkpoints.')\nflags.DEFINE_integer('max_steps', 1000000, 'Number of batches to run.')\nflags.DEFINE_boolean('log_device_placement', False,\n                     'Whether to log device placement.')\n\n\ndef run_training(train_op,\n                 loss,\n                 global_step,\n                 variables_to_restore=None,\n                 pretrained_model_dir=None):\n  \"\"\"Sets up and runs training loop.\"\"\"\n  tf.gfile.MakeDirs(FLAGS.train_dir)\n\n  # Create pretrain Saver\n  if pretrained_model_dir:\n    assert variables_to_restore\n    tf.logging.info('Will attempt restore from %s: %s', pretrained_model_dir,\n                    variables_to_restore)\n    saver_for_restore = tf.train.Saver(variables_to_restore)\n\n  # Init ops\n  if FLAGS.sync_replicas:\n    local_init_op = tf.get_collection('local_init_op')[0]\n    ready_for_local_init_op = tf.get_collection('ready_for_local_init_op')[0]\n  else:\n    local_init_op = tf.train.Supervisor.USE_DEFAULT\n    ready_for_local_init_op = tf.train.Supervisor.USE_DEFAULT\n\n  is_chief = FLAGS.task == 0\n  sv = tf.train.Supervisor(\n      logdir=FLAGS.train_dir,\n      is_chief=is_chief,\n      save_summaries_secs=30,\n      save_model_secs=30,\n      local_init_op=local_init_op,\n      ready_for_local_init_op=ready_for_local_init_op,\n      global_step=global_step)\n\n  # Delay starting standard services to allow possible pretrained model restore.\n  with sv.managed_session(\n      master=FLAGS.master,\n      config=tf.ConfigProto(log_device_placement=FLAGS.log_device_placement),\n      start_standard_services=False) as sess:\n    # Initialization\n    if is_chief:\n      if pretrained_model_dir:\n        maybe_restore_pretrained_model(sess, saver_for_restore,\n                                       pretrained_model_dir)\n      if FLAGS.sync_replicas:\n        sess.run(tf.get_collection('chief_init_op')[0])\n      sv.start_standard_services(sess)\n\n    sv.start_queue_runners(sess)\n\n    # Training loop\n    global_step_val = 0\n    while not sv.should_stop() and global_step_val < FLAGS.max_steps:\n      global_step_val = train_step(sess, train_op, loss, global_step)\n\n    # Final checkpoint\n    if is_chief and global_step_val >= FLAGS.max_steps:\n      sv.saver.save(sess, sv.save_path, global_step=global_step)\n\n\ndef maybe_restore_pretrained_model(sess, saver_for_restore, model_dir):\n  \"\"\"Restores pretrained model if there is no ckpt model.\"\"\"\n  ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\n  checkpoint_exists = ckpt and ckpt.model_checkpoint_path\n  if checkpoint_exists:\n    tf.logging.info('Checkpoint exists in FLAGS.train_dir; skipping '\n                    'pretraining restore')\n    return\n\n  pretrain_ckpt = tf.train.get_checkpoint_state(model_dir)\n  if not (pretrain_ckpt and pretrain_ckpt.model_checkpoint_path):\n    raise ValueError(\n        'Asked to restore model from %s but no checkpoint found.' % model_dir)\n  saver_for_restore.restore(sess, pretrain_ckpt.model_checkpoint_path)\n\n\ndef train_step(sess, train_op, loss, global_step):\n  \"\"\"Runs a single training step.\"\"\"\n  start_time = time.time()\n  _, loss_val, global_step_val = sess.run([train_op, loss, global_step])\n  duration = time.time() - start_time\n\n  # Logging\n  if global_step_val % 10 == 0:\n    examples_per_sec = FLAGS.batch_size / duration\n    sec_per_batch = float(duration)\n\n    format_str = ('step %d, loss = %.2f (%.1f examples/sec; %.3f ' 'sec/batch)')\n    tf.logging.info(format_str % (global_step_val, loss_val, examples_per_sec,\n                                  sec_per_batch))\n\n  if np.isnan(loss_val):\n    raise OverflowError('Loss is nan')\n\n  return global_step_val\n", "description": "Models and examples built with TensorFlow", "file_name": "train_utils.py", "id": "66943808d3e1182e863372ecfab88415", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-models/tensorflow-models-086d914/research/adversarial_text/train_utils.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:59:19Z", "url": "https://github.com/tensorflow/models", "wiki": true}