{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\"\"\"Generates stylized images with different strengths of a stylization.\n\nFor each pair of the content and style images this script computes stylized\nimages with different strengths of stylization (interpolates between the\nidentity transform parameters and the style parameters for the style image) and\nsaves them to the given output_dir.\nSee run_interpolation_with_identity.sh for example usage.\n\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport ast\nimport os\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom magenta.models.arbitrary_image_stylization import arbitrary_image_stylization_build_model as build_model\nfrom magenta.models.image_stylization import image_utils\n\nslim = tf.contrib.slim\n\nflags = tf.flags\nflags.DEFINE_string('checkpoint', None, 'Path to the model checkpoint.')\nflags.DEFINE_string('style_images_paths', None, 'Paths to the style images'\n                    'for evaluation.')\nflags.DEFINE_string('content_images_paths', None, 'Paths to the content images'\n                    'for evaluation.')\nflags.DEFINE_string('output_dir', None, 'Output directory.')\nflags.DEFINE_integer('image_size', 256, 'Image size.')\nflags.DEFINE_boolean('content_square_crop', False, 'Wheather to center crop'\n                     'the content image to be a square or not.')\nflags.DEFINE_integer('style_image_size', 256, 'Style image size.')\nflags.DEFINE_boolean('style_square_crop', False, 'Wheather to center crop'\n                     'the style image to be a square or not.')\nflags.DEFINE_integer('maximum_styles_to_evaluate', 1024, 'Maximum number of'\n                     'styles to evaluate.')\nflags.DEFINE_string('interpolation_weights', '[1.0]', 'List of weights'\n                    'for interpolation between the parameters of the identity'\n                    'transform and the style parameters of the style image. The'\n                    'larger the weight is the strength of stylization is more.'\n                    'Weight of 1.0 means the normal style transfer and weight'\n                    'of 0.0 means identity transform.')\nFLAGS = flags.FLAGS\n\n\ndef main(unused_argv=None):\n  tf.logging.set_verbosity(tf.logging.INFO)\n  if not tf.gfile.Exists(FLAGS.output_dir):\n    tf.gfile.MkDir(FLAGS.output_dir)\n\n  with tf.Graph().as_default(), tf.Session() as sess:\n     Defines place holder for the style image.\n    style_img_ph = tf.placeholder(tf.float32, shape=[None, None, 3])\n    if FLAGS.style_square_crop:\n      style_img_preprocessed = image_utils.center_crop_resize_image(\n          style_img_ph, FLAGS.style_image_size)\n    else:\n      style_img_preprocessed = image_utils.resize_image(style_img_ph,\n                                                        FLAGS.style_image_size)\n\n     Defines place holder for the content image.\n    content_img_ph = tf.placeholder(tf.float32, shape=[None, None, 3])\n    if FLAGS.content_square_crop:\n      content_img_preprocessed = image_utils.center_crop_resize_image(\n          content_img_ph, FLAGS.image_size)\n    else:\n      content_img_preprocessed = image_utils.resize_image(\n          content_img_ph, FLAGS.image_size)\n\n     Defines the model.\n    stylized_images, _, _, bottleneck_feat = build_model.build_model(\n        content_img_preprocessed,\n        style_img_preprocessed,\n        trainable=False,\n        is_training=False,\n        inception_end_point='Mixed_6e',\n        style_prediction_bottleneck=100,\n        adds_losses=False)\n\n    if tf.gfile.IsDirectory(FLAGS.checkpoint):\n      checkpoint = tf.train.latest_checkpoint(FLAGS.checkpoint)\n    else:\n      checkpoint = FLAGS.checkpoint\n      tf.logging.info('loading latest checkpoint file: {}'.format(checkpoint))\n\n    init_fn = slim.assign_from_checkpoint_fn(checkpoint,\n                                             slim.get_variables_to_restore())\n    sess.run([tf.local_variables_initializer()])\n    init_fn(sess)\n\n     Gets the list of the input style images.\n    style_img_list = tf.gfile.Glob(FLAGS.style_images_paths)\n    if len(style_img_list) > FLAGS.maximum_styles_to_evaluate:\n      np.random.seed(1234)\n      style_img_list = np.random.permutation(style_img_list)\n      style_img_list = style_img_list[:FLAGS.maximum_styles_to_evaluate]\n\n     Gets list of input content images.\n    content_img_list = tf.gfile.Glob(FLAGS.content_images_paths)\n\n    for content_i, content_img_path in enumerate(content_img_list):\n      content_img_np = image_utils.load_np_image_uint8(content_img_path)[:, :, :\n                                                                         3]\n      content_img_name = os.path.basename(content_img_path)[:-4]\n\n       Saves preprocessed content image.\n      inp_img_croped_resized_np = sess.run(\n          content_img_preprocessed, feed_dict={\n              content_img_ph: content_img_np\n          })\n      image_utils.save_np_image(inp_img_croped_resized_np,\n                                os.path.join(FLAGS.output_dir,\n                                             '%s.jpg' % (content_img_name)))\n\n       Computes bottleneck features of the style prediction network for the\n       identity transform.\n      identity_params = sess.run(\n          bottleneck_feat, feed_dict={style_img_ph: content_img_np})\n\n      for style_i, style_img_path in enumerate(style_img_list):\n        if style_i > FLAGS.maximum_styles_to_evaluate:\n          break\n        style_img_name = os.path.basename(style_img_path)[:-4]\n        style_image_np = image_utils.load_np_image_uint8(style_img_path)[:, :, :\n                                                                         3]\n\n        if style_i % 10 == 0:\n          tf.logging.info('Stylizing (%d) %s with (%d) %s' %\n                          (content_i, content_img_name, style_i,\n                           style_img_name))\n\n         Saves preprocessed style image.\n        style_img_croped_resized_np = sess.run(\n            style_img_preprocessed, feed_dict={\n                style_img_ph: style_image_np\n            })\n        image_utils.save_np_image(style_img_croped_resized_np,\n                                  os.path.join(FLAGS.output_dir,\n                                               '%s.jpg' % (style_img_name)))\n\n         Computes bottleneck features of the style prediction network for the\n         given style image.\n        style_params = sess.run(\n            bottleneck_feat, feed_dict={style_img_ph: style_image_np})\n\n        interpolation_weights = ast.literal_eval(FLAGS.interpolation_weights)\n         Interpolates between the parameters of the identity transform and\n         style parameters of the given style image.\n        for interp_i, wi in enumerate(interpolation_weights):\n          stylized_image_res = sess.run(\n              stylized_images,\n              feed_dict={\n                  bottleneck_feat:\n                      identity_params * (1 - wi) + style_params * wi,\n                  content_img_ph:\n                      content_img_np\n              })\n\n           Saves stylized image.\n          image_utils.save_np_image(\n              stylized_image_res,\n              os.path.join(FLAGS.output_dir, '%s_stylized_%s_%d.jpg' %\n                           (content_img_name, style_img_name, interp_i)))\n\n\nif __name__ == '__main__':\n  tf.app.run(main)\n\n", "comments": "   generates stylized images different strengths stylization   for pair content style images script computes stylized images different strengths stylization (interpolates identity transform parameters style parameters style image) saves given output dir  see run interpolation identity sh example usage         copyright 2017 google inc  all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license          http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license     defines place holder style image     defines place holder content image     defines model     gets list input style images     gets list input content images     saves preprocessed content image     computes bottleneck features style prediction network    identity transform     saves preprocessed style image     computes bottleneck features style prediction network    given style image     interpolates parameters identity transform    style parameters given style image     saves stylized image  ", "content": "# Copyright 2017 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Generates stylized images with different strengths of a stylization.\n\nFor each pair of the content and style images this script computes stylized\nimages with different strengths of stylization (interpolates between the\nidentity transform parameters and the style parameters for the style image) and\nsaves them to the given output_dir.\nSee run_interpolation_with_identity.sh for example usage.\n\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport ast\nimport os\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom magenta.models.arbitrary_image_stylization import arbitrary_image_stylization_build_model as build_model\nfrom magenta.models.image_stylization import image_utils\n\nslim = tf.contrib.slim\n\nflags = tf.flags\nflags.DEFINE_string('checkpoint', None, 'Path to the model checkpoint.')\nflags.DEFINE_string('style_images_paths', None, 'Paths to the style images'\n                    'for evaluation.')\nflags.DEFINE_string('content_images_paths', None, 'Paths to the content images'\n                    'for evaluation.')\nflags.DEFINE_string('output_dir', None, 'Output directory.')\nflags.DEFINE_integer('image_size', 256, 'Image size.')\nflags.DEFINE_boolean('content_square_crop', False, 'Wheather to center crop'\n                     'the content image to be a square or not.')\nflags.DEFINE_integer('style_image_size', 256, 'Style image size.')\nflags.DEFINE_boolean('style_square_crop', False, 'Wheather to center crop'\n                     'the style image to be a square or not.')\nflags.DEFINE_integer('maximum_styles_to_evaluate', 1024, 'Maximum number of'\n                     'styles to evaluate.')\nflags.DEFINE_string('interpolation_weights', '[1.0]', 'List of weights'\n                    'for interpolation between the parameters of the identity'\n                    'transform and the style parameters of the style image. The'\n                    'larger the weight is the strength of stylization is more.'\n                    'Weight of 1.0 means the normal style transfer and weight'\n                    'of 0.0 means identity transform.')\nFLAGS = flags.FLAGS\n\n\ndef main(unused_argv=None):\n  tf.logging.set_verbosity(tf.logging.INFO)\n  if not tf.gfile.Exists(FLAGS.output_dir):\n    tf.gfile.MkDir(FLAGS.output_dir)\n\n  with tf.Graph().as_default(), tf.Session() as sess:\n    # Defines place holder for the style image.\n    style_img_ph = tf.placeholder(tf.float32, shape=[None, None, 3])\n    if FLAGS.style_square_crop:\n      style_img_preprocessed = image_utils.center_crop_resize_image(\n          style_img_ph, FLAGS.style_image_size)\n    else:\n      style_img_preprocessed = image_utils.resize_image(style_img_ph,\n                                                        FLAGS.style_image_size)\n\n    # Defines place holder for the content image.\n    content_img_ph = tf.placeholder(tf.float32, shape=[None, None, 3])\n    if FLAGS.content_square_crop:\n      content_img_preprocessed = image_utils.center_crop_resize_image(\n          content_img_ph, FLAGS.image_size)\n    else:\n      content_img_preprocessed = image_utils.resize_image(\n          content_img_ph, FLAGS.image_size)\n\n    # Defines the model.\n    stylized_images, _, _, bottleneck_feat = build_model.build_model(\n        content_img_preprocessed,\n        style_img_preprocessed,\n        trainable=False,\n        is_training=False,\n        inception_end_point='Mixed_6e',\n        style_prediction_bottleneck=100,\n        adds_losses=False)\n\n    if tf.gfile.IsDirectory(FLAGS.checkpoint):\n      checkpoint = tf.train.latest_checkpoint(FLAGS.checkpoint)\n    else:\n      checkpoint = FLAGS.checkpoint\n      tf.logging.info('loading latest checkpoint file: {}'.format(checkpoint))\n\n    init_fn = slim.assign_from_checkpoint_fn(checkpoint,\n                                             slim.get_variables_to_restore())\n    sess.run([tf.local_variables_initializer()])\n    init_fn(sess)\n\n    # Gets the list of the input style images.\n    style_img_list = tf.gfile.Glob(FLAGS.style_images_paths)\n    if len(style_img_list) > FLAGS.maximum_styles_to_evaluate:\n      np.random.seed(1234)\n      style_img_list = np.random.permutation(style_img_list)\n      style_img_list = style_img_list[:FLAGS.maximum_styles_to_evaluate]\n\n    # Gets list of input content images.\n    content_img_list = tf.gfile.Glob(FLAGS.content_images_paths)\n\n    for content_i, content_img_path in enumerate(content_img_list):\n      content_img_np = image_utils.load_np_image_uint8(content_img_path)[:, :, :\n                                                                         3]\n      content_img_name = os.path.basename(content_img_path)[:-4]\n\n      # Saves preprocessed content image.\n      inp_img_croped_resized_np = sess.run(\n          content_img_preprocessed, feed_dict={\n              content_img_ph: content_img_np\n          })\n      image_utils.save_np_image(inp_img_croped_resized_np,\n                                os.path.join(FLAGS.output_dir,\n                                             '%s.jpg' % (content_img_name)))\n\n      # Computes bottleneck features of the style prediction network for the\n      # identity transform.\n      identity_params = sess.run(\n          bottleneck_feat, feed_dict={style_img_ph: content_img_np})\n\n      for style_i, style_img_path in enumerate(style_img_list):\n        if style_i > FLAGS.maximum_styles_to_evaluate:\n          break\n        style_img_name = os.path.basename(style_img_path)[:-4]\n        style_image_np = image_utils.load_np_image_uint8(style_img_path)[:, :, :\n                                                                         3]\n\n        if style_i % 10 == 0:\n          tf.logging.info('Stylizing (%d) %s with (%d) %s' %\n                          (content_i, content_img_name, style_i,\n                           style_img_name))\n\n        # Saves preprocessed style image.\n        style_img_croped_resized_np = sess.run(\n            style_img_preprocessed, feed_dict={\n                style_img_ph: style_image_np\n            })\n        image_utils.save_np_image(style_img_croped_resized_np,\n                                  os.path.join(FLAGS.output_dir,\n                                               '%s.jpg' % (style_img_name)))\n\n        # Computes bottleneck features of the style prediction network for the\n        # given style image.\n        style_params = sess.run(\n            bottleneck_feat, feed_dict={style_img_ph: style_image_np})\n\n        interpolation_weights = ast.literal_eval(FLAGS.interpolation_weights)\n        # Interpolates between the parameters of the identity transform and\n        # style parameters of the given style image.\n        for interp_i, wi in enumerate(interpolation_weights):\n          stylized_image_res = sess.run(\n              stylized_images,\n              feed_dict={\n                  bottleneck_feat:\n                      identity_params * (1 - wi) + style_params * wi,\n                  content_img_ph:\n                      content_img_np\n              })\n\n          # Saves stylized image.\n          image_utils.save_np_image(\n              stylized_image_res,\n              os.path.join(FLAGS.output_dir, '%s_stylized_%s_%d.jpg' %\n                           (content_img_name, style_img_name, interp_i)))\n\n\nif __name__ == '__main__':\n  tf.app.run(main)\n\n", "description": "Magenta: Music and Art Generation with Machine Intelligence", "file_name": "arbitrary_image_stylization_with_weights.py", "id": "3da811039984a2b864ddcfe1439d3429", "language": "Python", "project_name": "magenta", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tensorflow-magenta/tensorflow-magenta-ca73164/magenta/models/arbitrary_image_stylization/arbitrary_image_stylization_with_weights.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:00:14Z", "url": "https://github.com/tensorflow/magenta", "wiki": false}