{"author": "reddit-archive", "code": "import hashlib\nimport hmac\nfrom pylons import app_globals as g\n\n\n\nCACHE_POLICY_DIRECTIVES = {\n    \"loggedin_www\": {\n        \"cache-control\": {\"private\", \"no-cache\"},\n        \"pragma\": {\"no-cache\"},\n        \"expires\": set(),\n    },\n    \"loggedin_www_new\": {\n        \"cache-control\": {\"private\", \"max-age=0\", \"must-revalidate\"},\n        \"pragma\": set(),\n        \"expires\": {\"-1\"},\n    },\n    \"loggedin_mweb\": {\n        \"cache-control\": {\"private\", \"no-cache\"},\n        \"pragma\": set(),\n        \"expires\": set(),\n    },\n}\n\n\ndef make_poisoning_report_mac(\n        poisoner_canary,\n        poisoner_name,\n        poisoner_id,\n        cache_policy,\n        source,\n        \n        \n        route_name,\n):\n    \"\"\"\n    Make a MAC to send with cache poisoning reports for this page\n    \"\"\"\n    mac_key = g.secrets[\"cache_poisoning\"]\n    mac_data = (\n        poisoner_canary,\n        poisoner_name,\n        str(poisoner_id),\n        cache_policy,\n        source,\n        route_name,\n    )\n    return hmac.new(mac_key, \"|\".join(mac_data), hashlib.sha1).hexdigest()\n\n\ndef cache_headers_valid(policy_name, headers):\n    \"\"\"Check if a response's headers make sense given a cache policy\"\"\"\n\n    policy_headers = CACHE_POLICY_DIRECTIVES[policy_name]\n\n    for header_name, expected_vals in policy_headers.items():\n        \n        \n        found_vals = set(headers.get(header_name, []))\n        if header_name == \"cache-control\":\n            parsed_cache_control = set()\n            for cache_header in found_vals:\n                for split_header in cache_header.split(\",\"):\n                    cache_directive = split_header.strip().lower()\n                    parsed_cache_control.add(cache_directive)\n            if parsed_cache_control != expected_vals:\n                return False\n        elif found_vals != expected_vals:\n            return False\n    return True\n", "comments": "        make mac send cache poisoning reports page             mac key   g secrets  cache poisoning       mac data   (         poisoner canary          poisoner name          str(poisoner id)          cache policy          source          route name      )     return hmac new(mac key      join(mac data)  hashlib sha1) hexdigest()   def cache headers valid(policy name  headers)         check response headers make sense given cache policy       a map cache policies respective cache headers    loggedout omitted loggedout responses intentionally cacheable    can mac based url  caches care    order query params suchlike     cache control little special  multiple directives    multiple headers ", "content": "import hashlib\nimport hmac\nfrom pylons import app_globals as g\n\n# A map of cache policies to their respective cache headers\n# loggedout omitted because loggedout responses are intentionally cacheable\nCACHE_POLICY_DIRECTIVES = {\n    \"loggedin_www\": {\n        \"cache-control\": {\"private\", \"no-cache\"},\n        \"pragma\": {\"no-cache\"},\n        \"expires\": set(),\n    },\n    \"loggedin_www_new\": {\n        \"cache-control\": {\"private\", \"max-age=0\", \"must-revalidate\"},\n        \"pragma\": set(),\n        \"expires\": {\"-1\"},\n    },\n    \"loggedin_mweb\": {\n        \"cache-control\": {\"private\", \"no-cache\"},\n        \"pragma\": set(),\n        \"expires\": set(),\n    },\n}\n\n\ndef make_poisoning_report_mac(\n        poisoner_canary,\n        poisoner_name,\n        poisoner_id,\n        cache_policy,\n        source,\n        # Can't MAC based on URL, some caches don't care about the\n        # order of query params and suchlike.\n        route_name,\n):\n    \"\"\"\n    Make a MAC to send with cache poisoning reports for this page\n    \"\"\"\n    mac_key = g.secrets[\"cache_poisoning\"]\n    mac_data = (\n        poisoner_canary,\n        poisoner_name,\n        str(poisoner_id),\n        cache_policy,\n        source,\n        route_name,\n    )\n    return hmac.new(mac_key, \"|\".join(mac_data), hashlib.sha1).hexdigest()\n\n\ndef cache_headers_valid(policy_name, headers):\n    \"\"\"Check if a response's headers make sense given a cache policy\"\"\"\n\n    policy_headers = CACHE_POLICY_DIRECTIVES[policy_name]\n\n    for header_name, expected_vals in policy_headers.items():\n        # Cache-Control is a little special, you can have multiple directives\n        # in multiple headers\n        found_vals = set(headers.get(header_name, []))\n        if header_name == \"cache-control\":\n            parsed_cache_control = set()\n            for cache_header in found_vals:\n                for split_header in cache_header.split(\",\"):\n                    cache_directive = split_header.strip().lower()\n                    parsed_cache_control.add(cache_directive)\n            if parsed_cache_control != expected_vals:\n                return False\n        elif found_vals != expected_vals:\n            return False\n    return True\n", "description": "historical code from reddit.com", "file_name": "cache_poisoning.py", "id": "6001467643d1c18646ad41d50cfc4475", "language": "Python", "project_name": "reddit", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/reddit-archive-reddit/reddit-archive-reddit-753b174/r2/r2/lib/cache_poisoning.py", "save_time": "", "source": "", "update_at": "2018-03-18T11:55:36Z", "url": "https://github.com/reddit-archive/reddit", "wiki": true}