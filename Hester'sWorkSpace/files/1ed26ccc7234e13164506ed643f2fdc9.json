{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\n\n\nimport sys, os, numpy as np\nimport matplotlib.pyplot as plt\n\n\nimport tensorflow as tf\n\nfrom tensorflow.contrib import slim\nfrom tensorflow.contrib.slim import arg_scope\n\nimport logging\nfrom tensorflow.python.platform import app\nfrom tensorflow.python.platform import flags\nfrom src import utils \nimport src.file_utils as fu\nimport tfcode.nav_utils as nu \n\ndef _vis_readout_maps(outputs, global_step, output_dir, metric_summary, N):\n   outputs is [gt_map, pred_map]:\n  if N >= 0:\n    outputs = outputs[:N]\n  N = len(outputs)\n\n  plt.set_cmap('jet')\n  fig, axes = utils.subplot(plt, (N, outputs[0][0].shape[4]*2), (5,5))\n  axes = axes.ravel()[::-1].tolist()\n  for i in range(N):\n    gt_map, pred_map = outputs[i]\n    for j in [0]:\n      for k in range(gt_map.shape[4]):\n         Display something like the midpoint of the trajectory.\n        id = np.int(gt_map.shape[1]/2)\n\n        ax = axes.pop();\n        ax.imshow(gt_map[j,id,:,:,k], origin='lower', interpolation='none',\n                  vmin=0., vmax=1.)\n        ax.set_axis_off();\n        if i == 0: ax.set_title('gt_map')\n\n        ax = axes.pop();\n        ax.imshow(pred_map[j,id,:,:,k], origin='lower', interpolation='none',\n                  vmin=0., vmax=1.)\n        ax.set_axis_off();\n        if i == 0: ax.set_title('pred_map')\n\n  file_name = os.path.join(output_dir, 'readout_map_{:d}.png'.format(global_step))\n  with fu.fopen(file_name, 'w') as f:\n    fig.savefig(f, bbox_inches='tight', transparent=True, pad_inches=0)\n  plt.close(fig)\n\ndef _vis(outputs, global_step, output_dir, metric_summary, N):\n   Plot the value map, goal for various maps to see what if the model is\n   learning anything useful.\n  \n   outputs is [values, goals, maps, occupancy, conf].\n  \n  if N >= 0:\n    outputs = outputs[:N]\n  N = len(outputs)\n\n  plt.set_cmap('jet')\n  fig, axes = utils.subplot(plt, (N, outputs[0][0].shape[4]*5), (5,5))\n  axes = axes.ravel()[::-1].tolist()\n  for i in range(N):\n    values, goals, maps, occupancy, conf = outputs[i]\n    for j in [0]:\n      for k in range(values.shape[4]):\n         Display something like the midpoint of the trajectory.\n        id = np.int(values.shape[1]/2)\n\n        ax = axes.pop();\n        ax.imshow(goals[j,id,:,:,k], origin='lower', interpolation='none')\n        ax.set_axis_off();\n        if i == 0: ax.set_title('goal')\n\n        ax = axes.pop();\n        ax.imshow(occupancy[j,id,:,:,k], origin='lower', interpolation='none')\n        ax.set_axis_off();\n        if i == 0: ax.set_title('occupancy')\n\n        ax = axes.pop();\n        ax.imshow(conf[j,id,:,:,k], origin='lower', interpolation='none',\n                  vmin=0., vmax=1.)\n        ax.set_axis_off();\n        if i == 0: ax.set_title('conf')\n\n        ax = axes.pop();\n        ax.imshow(values[j,id,:,:,k], origin='lower', interpolation='none')\n        ax.set_axis_off();\n        if i == 0: ax.set_title('value')\n\n        ax = axes.pop();\n        ax.imshow(maps[j,id,:,:,k], origin='lower', interpolation='none')\n        ax.set_axis_off();\n        if i == 0: ax.set_title('incr map')\n\n  file_name = os.path.join(output_dir, 'value_vis_{:d}.png'.format(global_step))\n  with fu.fopen(file_name, 'w') as f:\n    fig.savefig(f, bbox_inches='tight', transparent=True, pad_inches=0)\n  plt.close(fig)\n\ndef _summary_vis(m, batch_size, num_steps, arop_full_summary_iters):\n  arop = []; arop_summary_iters = []; arop_eval_fns = [];\n  vis_value_ops = []; vis_goal_ops = []; vis_map_ops = []; \n  vis_occupancy_ops = []; vis_conf_ops = [];\n  for i, val_op in enumerate(m.value_ops):\n    vis_value_op = tf.reduce_mean(tf.abs(val_op), axis=3, keep_dims=True)\n    vis_value_ops.append(vis_value_op)\n    \n    vis_occupancy_op = tf.reduce_mean(tf.abs(m.occupancys[i]), 3, True)\n    vis_occupancy_ops.append(vis_occupancy_op)\n    \n    vis_conf_op = tf.reduce_max(tf.abs(m.confs[i]), axis=3, keep_dims=True)\n    vis_conf_ops.append(vis_conf_op)\n    \n    ego_goal_imgs_i_op = m.input_tensors['step']['ego_goal_imgs_{:d}'.format(i)]\n    vis_goal_op = tf.reduce_max(ego_goal_imgs_i_op, 4, True)\n    vis_goal_ops.append(vis_goal_op)\n    \n    vis_map_op = tf.reduce_mean(tf.abs(m.ego_map_ops[i]), 4, True)\n    vis_map_ops.append(vis_map_op)\n\n  vis_goal_ops = tf.concat(vis_goal_ops, 4)\n  vis_map_ops = tf.concat(vis_map_ops, 4)\n  vis_value_ops = tf.concat(vis_value_ops, 3)\n  vis_occupancy_ops = tf.concat(vis_occupancy_ops, 3)\n  vis_conf_ops = tf.concat(vis_conf_ops, 3)\n\n  sh = tf.unstack(tf.shape(vis_value_ops))[1:]\n  vis_value_ops = tf.reshape(vis_value_ops, shape=[batch_size, -1] + sh)\n\n  sh = tf.unstack(tf.shape(vis_conf_ops))[1:]\n  vis_conf_ops = tf.reshape(vis_conf_ops, shape=[batch_size, -1] + sh)\n\n  sh = tf.unstack(tf.shape(vis_occupancy_ops))[1:]\n  vis_occupancy_ops = tf.reshape(vis_occupancy_ops, shape=[batch_size,-1] + sh)\n\n   Save memory, only return time steps that need to be visualized, factor of\n   32 CPU memory saving.\n  id = np.int(num_steps/2)\n  vis_goal_ops = tf.expand_dims(vis_goal_ops[:,id,:,:,:], axis=1)\n  vis_map_ops = tf.expand_dims(vis_map_ops[:,id,:,:,:], axis=1)\n  vis_value_ops = tf.expand_dims(vis_value_ops[:,id,:,:,:], axis=1)\n  vis_conf_ops = tf.expand_dims(vis_conf_ops[:,id,:,:,:], axis=1)\n  vis_occupancy_ops = tf.expand_dims(vis_occupancy_ops[:,id,:,:,:], axis=1)\n\n  arop += [[vis_value_ops, vis_goal_ops, vis_map_ops, vis_occupancy_ops,\n            vis_conf_ops]]\n  arop_summary_iters += [arop_full_summary_iters]\n  arop_eval_fns += [_vis]\n  return arop, arop_summary_iters, arop_eval_fns\n\ndef _summary_readout_maps(m, num_steps, arop_full_summary_iters):\n  arop = []; arop_summary_iters = []; arop_eval_fns = [];\n  id = np.int(num_steps-1)\n  vis_readout_maps_gt = m.readout_maps_gt\n  vis_readout_maps_prob = tf.reshape(m.readout_maps_probs,\n                                     shape=tf.shape(vis_readout_maps_gt))\n  vis_readout_maps_gt = tf.expand_dims(vis_readout_maps_gt[:,id,:,:,:], 1)\n  vis_readout_maps_prob = tf.expand_dims(vis_readout_maps_prob[:,id,:,:,:], 1)\n  arop += [[vis_readout_maps_gt, vis_readout_maps_prob]]\n  arop_summary_iters += [arop_full_summary_iters]\n  arop_eval_fns += [_vis_readout_maps]\n  return arop, arop_summary_iters, arop_eval_fns\n\ndef _add_summaries(m, args, summary_mode, arop_full_summary_iters):\n  task_params = args.navtask.task_params\n  \n  summarize_ops = [m.lr_op, m.global_step_op, m.sample_gt_prob_op] + \\\n      m.loss_ops + m.acc_ops\n  summarize_names = ['lr', 'global_step', 'sample_gt_prob_op'] + \\\n      m.loss_ops_names + ['acc_{:d}'.format(i) for i in range(len(m.acc_ops))]\n  to_aggregate = [0, 0, 0] + [1]*len(m.loss_ops_names) + [1]*len(m.acc_ops)\n\n  scope_name = 'summary'\n  with tf.name_scope(scope_name):\n    s_ops = nu.add_default_summaries(summary_mode, arop_full_summary_iters,\n                                     summarize_ops, summarize_names,\n                                     to_aggregate, m.action_prob_op,\n                                     m.input_tensors, scope_name=scope_name)\n    if summary_mode == 'val':\n      arop, arop_summary_iters, arop_eval_fns = _summary_vis(\n          m, task_params.batch_size, task_params.num_steps,\n          arop_full_summary_iters)\n      s_ops.additional_return_ops += arop\n      s_ops.arop_summary_iters += arop_summary_iters\n      s_ops.arop_eval_fns += arop_eval_fns\n      \n      if args.arch.readout_maps:\n        arop, arop_summary_iters, arop_eval_fns = _summary_readout_maps(\n            m, task_params.num_steps, arop_full_summary_iters)\n        s_ops.additional_return_ops += arop\n        s_ops.arop_summary_iters += arop_summary_iters\n        s_ops.arop_eval_fns += arop_eval_fns\n  \n  return s_ops\n", "comments": "   code setting summaries cmp         copyright 2016 the tensorflow authors all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                       outputs  gt map  pred map      display something like midpoint trajectory     plot value map  goal various maps see model    learning anything useful        outputs  values  goals  maps  occupancy  conf         display something like midpoint trajectory     save memory  return time steps need visualized  factor    32 cpu memory saving  ", "content": "# Copyright 2016 The TensorFlow Authors All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n\"\"\"Code for setting up summaries for CMP.\n\"\"\"\n\nimport sys, os, numpy as np\nimport matplotlib.pyplot as plt\n\n\nimport tensorflow as tf\n\nfrom tensorflow.contrib import slim\nfrom tensorflow.contrib.slim import arg_scope\n\nimport logging\nfrom tensorflow.python.platform import app\nfrom tensorflow.python.platform import flags\nfrom src import utils \nimport src.file_utils as fu\nimport tfcode.nav_utils as nu \n\ndef _vis_readout_maps(outputs, global_step, output_dir, metric_summary, N):\n  # outputs is [gt_map, pred_map]:\n  if N >= 0:\n    outputs = outputs[:N]\n  N = len(outputs)\n\n  plt.set_cmap('jet')\n  fig, axes = utils.subplot(plt, (N, outputs[0][0].shape[4]*2), (5,5))\n  axes = axes.ravel()[::-1].tolist()\n  for i in range(N):\n    gt_map, pred_map = outputs[i]\n    for j in [0]:\n      for k in range(gt_map.shape[4]):\n        # Display something like the midpoint of the trajectory.\n        id = np.int(gt_map.shape[1]/2)\n\n        ax = axes.pop();\n        ax.imshow(gt_map[j,id,:,:,k], origin='lower', interpolation='none',\n                  vmin=0., vmax=1.)\n        ax.set_axis_off();\n        if i == 0: ax.set_title('gt_map')\n\n        ax = axes.pop();\n        ax.imshow(pred_map[j,id,:,:,k], origin='lower', interpolation='none',\n                  vmin=0., vmax=1.)\n        ax.set_axis_off();\n        if i == 0: ax.set_title('pred_map')\n\n  file_name = os.path.join(output_dir, 'readout_map_{:d}.png'.format(global_step))\n  with fu.fopen(file_name, 'w') as f:\n    fig.savefig(f, bbox_inches='tight', transparent=True, pad_inches=0)\n  plt.close(fig)\n\ndef _vis(outputs, global_step, output_dir, metric_summary, N):\n  # Plot the value map, goal for various maps to see what if the model is\n  # learning anything useful.\n  #\n  # outputs is [values, goals, maps, occupancy, conf].\n  #\n  if N >= 0:\n    outputs = outputs[:N]\n  N = len(outputs)\n\n  plt.set_cmap('jet')\n  fig, axes = utils.subplot(plt, (N, outputs[0][0].shape[4]*5), (5,5))\n  axes = axes.ravel()[::-1].tolist()\n  for i in range(N):\n    values, goals, maps, occupancy, conf = outputs[i]\n    for j in [0]:\n      for k in range(values.shape[4]):\n        # Display something like the midpoint of the trajectory.\n        id = np.int(values.shape[1]/2)\n\n        ax = axes.pop();\n        ax.imshow(goals[j,id,:,:,k], origin='lower', interpolation='none')\n        ax.set_axis_off();\n        if i == 0: ax.set_title('goal')\n\n        ax = axes.pop();\n        ax.imshow(occupancy[j,id,:,:,k], origin='lower', interpolation='none')\n        ax.set_axis_off();\n        if i == 0: ax.set_title('occupancy')\n\n        ax = axes.pop();\n        ax.imshow(conf[j,id,:,:,k], origin='lower', interpolation='none',\n                  vmin=0., vmax=1.)\n        ax.set_axis_off();\n        if i == 0: ax.set_title('conf')\n\n        ax = axes.pop();\n        ax.imshow(values[j,id,:,:,k], origin='lower', interpolation='none')\n        ax.set_axis_off();\n        if i == 0: ax.set_title('value')\n\n        ax = axes.pop();\n        ax.imshow(maps[j,id,:,:,k], origin='lower', interpolation='none')\n        ax.set_axis_off();\n        if i == 0: ax.set_title('incr map')\n\n  file_name = os.path.join(output_dir, 'value_vis_{:d}.png'.format(global_step))\n  with fu.fopen(file_name, 'w') as f:\n    fig.savefig(f, bbox_inches='tight', transparent=True, pad_inches=0)\n  plt.close(fig)\n\ndef _summary_vis(m, batch_size, num_steps, arop_full_summary_iters):\n  arop = []; arop_summary_iters = []; arop_eval_fns = [];\n  vis_value_ops = []; vis_goal_ops = []; vis_map_ops = []; \n  vis_occupancy_ops = []; vis_conf_ops = [];\n  for i, val_op in enumerate(m.value_ops):\n    vis_value_op = tf.reduce_mean(tf.abs(val_op), axis=3, keep_dims=True)\n    vis_value_ops.append(vis_value_op)\n    \n    vis_occupancy_op = tf.reduce_mean(tf.abs(m.occupancys[i]), 3, True)\n    vis_occupancy_ops.append(vis_occupancy_op)\n    \n    vis_conf_op = tf.reduce_max(tf.abs(m.confs[i]), axis=3, keep_dims=True)\n    vis_conf_ops.append(vis_conf_op)\n    \n    ego_goal_imgs_i_op = m.input_tensors['step']['ego_goal_imgs_{:d}'.format(i)]\n    vis_goal_op = tf.reduce_max(ego_goal_imgs_i_op, 4, True)\n    vis_goal_ops.append(vis_goal_op)\n    \n    vis_map_op = tf.reduce_mean(tf.abs(m.ego_map_ops[i]), 4, True)\n    vis_map_ops.append(vis_map_op)\n\n  vis_goal_ops = tf.concat(vis_goal_ops, 4)\n  vis_map_ops = tf.concat(vis_map_ops, 4)\n  vis_value_ops = tf.concat(vis_value_ops, 3)\n  vis_occupancy_ops = tf.concat(vis_occupancy_ops, 3)\n  vis_conf_ops = tf.concat(vis_conf_ops, 3)\n\n  sh = tf.unstack(tf.shape(vis_value_ops))[1:]\n  vis_value_ops = tf.reshape(vis_value_ops, shape=[batch_size, -1] + sh)\n\n  sh = tf.unstack(tf.shape(vis_conf_ops))[1:]\n  vis_conf_ops = tf.reshape(vis_conf_ops, shape=[batch_size, -1] + sh)\n\n  sh = tf.unstack(tf.shape(vis_occupancy_ops))[1:]\n  vis_occupancy_ops = tf.reshape(vis_occupancy_ops, shape=[batch_size,-1] + sh)\n\n  # Save memory, only return time steps that need to be visualized, factor of\n  # 32 CPU memory saving.\n  id = np.int(num_steps/2)\n  vis_goal_ops = tf.expand_dims(vis_goal_ops[:,id,:,:,:], axis=1)\n  vis_map_ops = tf.expand_dims(vis_map_ops[:,id,:,:,:], axis=1)\n  vis_value_ops = tf.expand_dims(vis_value_ops[:,id,:,:,:], axis=1)\n  vis_conf_ops = tf.expand_dims(vis_conf_ops[:,id,:,:,:], axis=1)\n  vis_occupancy_ops = tf.expand_dims(vis_occupancy_ops[:,id,:,:,:], axis=1)\n\n  arop += [[vis_value_ops, vis_goal_ops, vis_map_ops, vis_occupancy_ops,\n            vis_conf_ops]]\n  arop_summary_iters += [arop_full_summary_iters]\n  arop_eval_fns += [_vis]\n  return arop, arop_summary_iters, arop_eval_fns\n\ndef _summary_readout_maps(m, num_steps, arop_full_summary_iters):\n  arop = []; arop_summary_iters = []; arop_eval_fns = [];\n  id = np.int(num_steps-1)\n  vis_readout_maps_gt = m.readout_maps_gt\n  vis_readout_maps_prob = tf.reshape(m.readout_maps_probs,\n                                     shape=tf.shape(vis_readout_maps_gt))\n  vis_readout_maps_gt = tf.expand_dims(vis_readout_maps_gt[:,id,:,:,:], 1)\n  vis_readout_maps_prob = tf.expand_dims(vis_readout_maps_prob[:,id,:,:,:], 1)\n  arop += [[vis_readout_maps_gt, vis_readout_maps_prob]]\n  arop_summary_iters += [arop_full_summary_iters]\n  arop_eval_fns += [_vis_readout_maps]\n  return arop, arop_summary_iters, arop_eval_fns\n\ndef _add_summaries(m, args, summary_mode, arop_full_summary_iters):\n  task_params = args.navtask.task_params\n  \n  summarize_ops = [m.lr_op, m.global_step_op, m.sample_gt_prob_op] + \\\n      m.loss_ops + m.acc_ops\n  summarize_names = ['lr', 'global_step', 'sample_gt_prob_op'] + \\\n      m.loss_ops_names + ['acc_{:d}'.format(i) for i in range(len(m.acc_ops))]\n  to_aggregate = [0, 0, 0] + [1]*len(m.loss_ops_names) + [1]*len(m.acc_ops)\n\n  scope_name = 'summary'\n  with tf.name_scope(scope_name):\n    s_ops = nu.add_default_summaries(summary_mode, arop_full_summary_iters,\n                                     summarize_ops, summarize_names,\n                                     to_aggregate, m.action_prob_op,\n                                     m.input_tensors, scope_name=scope_name)\n    if summary_mode == 'val':\n      arop, arop_summary_iters, arop_eval_fns = _summary_vis(\n          m, task_params.batch_size, task_params.num_steps,\n          arop_full_summary_iters)\n      s_ops.additional_return_ops += arop\n      s_ops.arop_summary_iters += arop_summary_iters\n      s_ops.arop_eval_fns += arop_eval_fns\n      \n      if args.arch.readout_maps:\n        arop, arop_summary_iters, arop_eval_fns = _summary_readout_maps(\n            m, task_params.num_steps, arop_full_summary_iters)\n        s_ops.additional_return_ops += arop\n        s_ops.arop_summary_iters += arop_summary_iters\n        s_ops.arop_eval_fns += arop_eval_fns\n  \n  return s_ops\n", "description": "Models and examples built with TensorFlow", "file_name": "cmp_summary.py", "id": "1ed26ccc7234e13164506ed643f2fdc9", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tensorflow-models/tensorflow-models-7e4c66b/research/cognitive_mapping_and_planning/tfcode/cmp_summary.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:59:36Z", "url": "https://github.com/tensorflow/models", "wiki": true}