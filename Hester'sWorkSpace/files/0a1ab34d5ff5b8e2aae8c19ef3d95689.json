{"author": "tflearn", "code": "from __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nfrom .utils import get_from_module\n\n\ndef get(identifier):\n    return get_from_module(identifier, globals(), 'optimizer')\n\n\nclass Optimizer(object):\n    \"\"\" Base Optimizer class.\n\n    A basic class to create optimizers to be used with TFLearn estimators.\n    First, The Optimizer class is initialized with given parameters,\n    but no Tensor is created. In a second step, invoking `get_tensor` method\n    will actually build the Tensorflow `Optimizer` Tensor, and return it.\n\n    This way, a user can easily specifies an optimizer with non default\n    parameters and learning rate decay, while TFLearn estimators will\n    build the optimizer and a step tensor by itself.\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. The optimizer name.\n\n    Attributes:\n        tensor: `Optimizer`. The optimizer tensor.\n        has_decay: `bool`. True if optimizer has a learning rate decay.\n\n    \"\"\"\n\n    def __init__(self, learning_rate, use_locking, name):\n        self.learning_rate = learning_rate\n        self.use_locking = use_locking\n        self.name = name\n        self.tensor = None\n        self.has_decay = False\n        self.built = False\n\n    def build(self, step_tensor=None):\n        \"\"\" build optimizer tensor.\n\n        This method creates the optimizer with specified parameters. It must\n        be implemented for every `Optimizer`.\n\n        Arguments:\n            step_tensor: `tf.Tensor`. A variable holding the training step.\n                Only necessary when optimizer has a learning rate decay.\n\n        \"\"\"\n        raise NotImplementedError\n\n    def get_tensor(self):\n        \"\"\" get_tensor.\n\n        A method to retrieve the optimizer tensor.\n\n        Returns:\n            The `Optimizer`.\n\n        \"\"\"\n        if not self.built:\n            self.build()\n        return self.tensor\n\n    def __call__(self):\n        \"\"\" __call__\n\n        A shortcut for `get_tensor`. Retrieve the optimizer tensor.\n\n        Returns:\n            The `Optimizer`.\n\n        \"\"\"\n        return self.get_tensor()\n\n\nclass SGD(Optimizer):\n    \"\"\" Stochastic Gradient Descent.\n\n    SGD Optimizer accepts learning rate decay. When training a model,\n    it is often recommended to lower the learning rate as the training\n    progresses. The function returns the decayed learning rate.  It is\n    computed as:\n\n    ```python\n    decayed_learning_rate = learning_rate *\n                          decay_rate ^ (global_step / decay_steps)\n    ```\n\n    Examples:\n        ```python\n        \n        sgd = SGD(learning_rate=0.01, lr_decay=0.96, decay_step=100)\n        regression = regression(net, optimizer=sgd)\n\n        # Without TFLearn estimators (returns tf.Optimizer).\n        sgd = SGD(learning_rate=0.01).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        use_locking: `bool`. If True use locks for update operation.\n        lr_decay: `float`. The learning rate decay to apply.\n        decay_step: `int`. Apply decay every provided steps.\n        staircase: `bool`. It `True` decay learning rate at discrete intervals.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to \"GradientDescent\".\n\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, lr_decay=0., decay_step=100,\n                 staircase=False, use_locking=False, name=\"SGD\"):\n        super(SGD, self).__init__(learning_rate, use_locking, name)\n        self.lr_decay = lr_decay\n        if self.lr_decay > 0.:\n            self.has_decay = True\n        self.decay_step = decay_step\n        self.staircase = staircase\n\n    def build(self, step_tensor=None):\n        self.built = True\n        if self.has_decay:\n            if not step_tensor:\n                raise Exception(\"Learning rate decay but no step_tensor \"\n                                \"provided.\")\n            self.learning_rate = tf.train.exponential_decay(\n                self.learning_rate, step_tensor,\n                self.decay_step, self.lr_decay,\n                staircase=self.staircase)\n            tf.add_to_collection(tf.GraphKeys.LR_VARIABLES, self.learning_rate)\n        self.tensor = tf.train.GradientDescentOptimizer(\n            learning_rate=self.learning_rate,\n            use_locking=self.use_locking,\n            name=self.name)\n\n\nsgd = SGD\n\n\nclass RMSProp(Optimizer):\n    \"\"\" RMSprop.\n\n    Maintain a moving (discounted) average of the square of gradients.\n    Divide gradient by the root of this average.\n\n    Examples:\n        ```python\n        \n        rmsprop = RMSProp(learning_rate=0.1, decay=0.999)\n        regression = regression(net, optimizer=rmsprop)\n\n        # Without TFLearn estimators (returns tf.Optimizer).\n        rmsprop = RMSProp(learning_rate=0.01, decay=0.999).get_tensor()\n        \n        rmsprop = RMSProp(learning_rate=0.01, decay=0.999)()\n\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        decay: `float`. Discounting factor for the history/coming gradient.\n        momentum: `float`. Momentum.\n        epsilon: `float`. Small value to avoid zero denominator.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to \"RMSProp\".\n\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, decay=0.9, momentum=0.0,\n                 epsilon=1e-10, use_locking=False, name=\"RMSProp\"):\n        super(RMSProp, self).__init__(learning_rate, use_locking, name)\n        self.decay = decay\n        self.momentum = momentum\n        self.epsilon = epsilon\n\n    def build(self, step_tensor=None):\n        self.built = True\n        self.tensor = tf.train.RMSPropOptimizer(\n            learning_rate=self.learning_rate, decay=self.decay,\n            momentum=self.momentum, epsilon=self.epsilon,\n            use_locking=self.use_locking, name=self.name)\n\nrmsprop = RMSProp\n\n\nclass Adam(Optimizer):\n    \"\"\" Adam.\n\n    The default value of 1e-8 for epsilon might not be a good default in\n    general. For example, when training an Inception network on ImageNet a\n    current good choice is 1.0 or 0.1.\n\n    Examples:\n        ```python\n        \n        adam = Adam(learning_rate=0.001, beta1=0.99)\n        regression = regression(net, optimizer=adam)\n\n        # Without TFLearn estimators (returns tf.Optimizer)\n        adam = Adam(learning_rate=0.01).get_tensor()\n\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        beta1: `float`. The exponential decay rate for the 1st moment\n            estimates.\n        beta2: `float`. The exponential decay rate for the 2nd moment\n            estimates.\n        epsilon: `float`. A small constant for numerical stability.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to \"Adam\".\n\n    References:\n        Adam: A Method for Stochastic Optimization. Diederik Kingma,\n        Jimmy Ba. ICLR 2015.\n\n    Links:\n        [Paper](http://arxiv.org/pdf/1412.6980v8.pdf)\n\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999,\n                 epsilon=1e-8, use_locking=False, name=\"Adam\"):\n        super(Adam, self).__init__(learning_rate, use_locking, name)\n        self.beta1 = beta1\n        self.beta2 = beta2\n        self.epsilon = epsilon\n\n    def build(self, step_tensor=None):\n        self.built = True\n        self.tensor = tf.train.AdamOptimizer(\n            learning_rate=self.learning_rate, beta1=self.beta1,\n            beta2=self.beta2, epsilon=self.epsilon,\n            use_locking=self.use_locking, name=self.name)\n\nadam = Adam\n\n\nclass Momentum(Optimizer):\n    \"\"\" Momentum.\n\n    Momentum Optimizer accepts learning rate decay. When training a model,\n    it is often recommended to lower the learning rate as the training\n    progresses. The function returns the decayed learning rate.  It is\n    computed as:\n\n    ```python\n    decayed_learning_rate = learning_rate *\n                          decay_rate ^ (global_step / decay_steps)\n    ```\n\n    Examples:\n        ```python\n        \n        momentum = Momentum(learning_rate=0.01, lr_decay=0.96, decay_step=100)\n        regression = regression(net, optimizer=momentum)\n\n        # Without TFLearn estimators (returns tf.Optimizer)\n        mm = Momentum(learning_rate=0.01, lr_decay=0.96).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        momentum: `float`. Momentum.\n        lr_decay: `float`. The learning rate decay to apply.\n        decay_step: `int`. Apply decay every provided steps.\n        staircase: `bool`. It `True` decay learning rate at discrete intervals.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to \"Momentum\".\n\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, momentum=0.9, lr_decay=0.,\n                 decay_step=100, staircase=False, use_locking=False,\n                 name=\"Momentum\"):\n        super(Momentum, self).__init__(learning_rate, use_locking, name)\n        self.momentum = momentum\n        self.lr_decay = lr_decay\n        if self.lr_decay > 0.:\n            self.has_decay = True\n        self.decay_step = decay_step\n        self.staircase = staircase\n\n    def build(self, step_tensor=None):\n        self.built = True\n        if self.has_decay:\n            if not step_tensor:\n                raise Exception(\"Learning rate decay but no step_tensor \"\n                                \"provided.\")\n            self.learning_rate = tf.train.exponential_decay(\n                self.learning_rate, step_tensor,\n                self.decay_step, self.lr_decay,\n                staircase=self.staircase)\n            tf.add_to_collection(tf.GraphKeys.LR_VARIABLES, self.learning_rate)\n        self.tensor = tf.train.MomentumOptimizer(\n            learning_rate=self.learning_rate,\n            momentum=self.momentum,\n            use_locking=self.use_locking,\n            name=self.name)\n\nmomentum = Momentum\n\n\nclass AdaGrad(Optimizer):\n    \"\"\" AdaGrad.\n\n    Examples:\n        ```python\n        \n        adagrad = AdaGrad(learning_rate=0.01, initial_accumulator_value=0.01)\n        regression = regression(net, optimizer=adagrad)\n\n        # Without TFLearn estimators (returns tf.Optimizer)\n        adagrad = AdaGrad(learning_rate=0.01).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        initial_accumulator_value: `float`. Starting value for the\n            accumulators, must be positive\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to \"AdaGrad\".\n\n    References:\n        Adaptive Subgradient Methods for Online Learning and Stochastic\n        Optimization. J. Duchi, E. Hazan & Y. Singer. Journal of Machine\n        Learning Research 12 (2011) 2121-2159.\n\n    Links:\n        [Paper](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, initial_accumulator_value=0.1,\n                 use_locking=False, name=\"AdaGrad\"):\n        super(AdaGrad, self).__init__(learning_rate, use_locking, name)\n        self.initial_accumulator_value = initial_accumulator_value\n\n    def build(self, step_tensor=None):\n        self.built = True\n        self.tensor = tf.train.AdagradOptimizer(\n            self.learning_rate,\n            initial_accumulator_value=self.initial_accumulator_value,\n            use_locking=self.use_locking, name=self.name)\n\nadagrad = AdaGrad\n\n\nclass Ftrl(Optimizer):\n    \"\"\" Ftrl Proximal.\n\n    The Ftrl-proximal algorithm, abbreviated for Follow-the-regularized-leader,\n    is described in the paper below.\n\n    It can give a good performance vs. sparsity tradeoff.\n\n    Ftrl-proximal uses its own global base learning rate and can behave like\n    Adagrad with `learning_rate_power=-0.5`, or like gradient descent with\n    `learning_rate_power=0.0`.\n\n    Examples:\n        ```python\n        \n        ftrl = Ftrl(learning_rate=0.01, learning_rate_power=-0.1)\n        regression = regression(net, optimizer=ftrl)\n\n        # Without TFLearn estimators (returns tf.Optimizer).\n        ftrl = Ftrl(learning_rate=0.01).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        learning_rate_power: `float`. Must be less or equal to zero.\n        initial_accumulator_value: `float`. The starting value for accumulators.\n            Only positive values are allowed.\n        l1_regularization_strength: `float`. Must be less or equal to zero.\n        l2_regularization_strength: `float`. Must be less or equal to zero.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to \"Ftrl\".\n\n    Links:\n        [Ad Click Prediction: a View from the Trenches](https://www.eecs.tufts.\n        edu/~dsculley/papers/ad-click-prediction.pdf)\n\n    \"\"\"\n\n    def __init__(self, learning_rate=3.0, learning_rate_power=-0.5,\n                 initial_accumulator_value=0.1, l1_regularization_strength=0.0,\n                 l2_regularization_strength=0.0, use_locking=False,\n                 name=\"Ftrl\"):\n        super(Ftrl, self).__init__(learning_rate, use_locking, name)\n        self.learning_rate_power = learning_rate_power\n        self.initial_accumulator_value = initial_accumulator_value\n        self.l1_regularization_strength = l1_regularization_strength\n        self.l2_regularization_strength = l2_regularization_strength\n\n    def build(self, step_tensor=None):\n        self.built = True\n        with tf.device('/cpu:0'):\n            self.tensor = tf.train.FtrlOptimizer(\n                self.learning_rate,\n                learning_rate_power=self.learning_rate_power,\n                initial_accumulator_value=self.initial_accumulator_value,\n                l1_regularization_strength=self.l1_regularization_strength,\n                l2_regularization_strength=self.l2_regularization_strength,\n                use_locking=self.use_locking, name=self.name)\n\nftrl = Ftrl\n\n\nclass AdaDelta(Optimizer):\n    \"\"\" AdaDelta.\n\n    Construct a new Adadelta optimizer.\n\n    Arguments:\n        learning_rate: A `Tensor` or a floating point value. The learning rate.\n        rho: A `Tensor` or a floating point value. The decay rate.\n        epsilon: A `Tensor` or a floating point value.  A constant epsilon used\n            to better conditioning the grad update.\n        use_locking: If `True` use locks for update operations.\n        name: Optional name prefix for the operations created when applying\n            gradients.  Defaults to \"Adadelta\".\n\n    References:\n        ADADELTA: An Adaptive Learning Rate Method, Matthew D. Zeiler, 2012.\n\n    Links:\n        [http://arxiv.org/abs/1212.5701](http://arxiv.org/abs/1212.5701)\n\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, rho=0.1, epsilon=1e-08,\n                 use_locking=False, name=\"AdaDelta\"):\n        super(AdaDelta, self).__init__(learning_rate, use_locking, name)\n        self.rho = rho\n        self.epsilon = epsilon\n\n    def build(self, step_tensor=None):\n        self.built = True\n        self.tensor = tf.train.AdadeltaOptimizer(\n            self.learning_rate,\n            rho=self.rho, epsilon=self.epsilon,\n            use_locking=self.use_locking, name=self.name)\n\nadadelta = AdaDelta\n\n\nclass ProximalAdaGrad(Optimizer):\n    \"\"\" ProximalAdaGrad.\n\n    Examples:\n        ```python\n        \n        proxi_adagrad = ProximalAdaGrad(learning_rate=0.01,\n                                        l2_regularization_strength=0.01,\n                                        initial_accumulator_value=0.01)\n        regression = regression(net, optimizer=proxi_adagrad)\n\n        # Without TFLearn estimators (returns tf.Optimizer)\n        adagrad = ProximalAdaGrad(learning_rate=0.01).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        initial_accumulator_value: `float`. Starting value for the\n            accumulators, must be positive\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to \"AdaGrad\".\n\n    References:\n        Efficient Learning using Forward-Backward Splitting. J. Duchi, Yoram\n        Singer, 2009.\n\n    Links:\n        [Paper](http://papers.nips.cc/paper/3793-efficient-learning-using-forward-backward-splitting.pdf)\n\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, initial_accumulator_value=0.1,\n                 use_locking=False, name=\"AdaGrad\"):\n        super(ProximalAdaGrad, self).__init__(learning_rate, use_locking, name)\n        self.initial_accumulator_value = initial_accumulator_value\n\n    def build(self, step_tensor=None):\n        self.built = True\n        self.tensor = tf.train.AdagradOptimizer(\n            self.learning_rate,\n            initial_accumulator_value=self.initial_accumulator_value,\n            use_locking=self.use_locking, name=self.name)\n\nproximaladagrad = ProximalAdaGrad\n\n\nclass Nesterov(Optimizer):\n    \"\"\" Nesterov.\n\n    The main difference between classical momentum and nesterov is:\n    In classical momentum you first correct your velocity and \n    then make a big step according to that velocity (and then repeat), \n    but in Nesterov momentum you first making a step into velocity \n    direction and then make a correction to a velocity vector based on\n    new location (then repeat).\n    See [Sutskever et. al., 2013](\n            http://jmlr.org/proceedings/papers/v28/sutskever13.pdf)\n\n    Examples:\n        ```python\n        \n        nesterov = Nesterov(learning_rate=0.01, lr_decay=0.96, decay_step=100)\n        regression = regression(net, optimizer=nesterov)\n\n        # Without TFLearn estimators (returns tf.Optimizer)\n        mm = Neserov(learning_rate=0.01, lr_decay=0.96).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        momentum: `float`. Momentum.\n        lr_decay: `float`. The learning rate decay to apply.\n        decay_step: `int`. Apply decay every provided steps.\n        staircase: `bool`. It `True` decay learning rate at discrete intervals.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to \"Momentum\".\n\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, momentum=0.9, lr_decay=0.,\n                 decay_step=100, staircase=False, use_locking=False,\n                 name=\"Nesterov\"):\n        super(Nesterov, self).__init__(learning_rate, use_locking, name)\n        self.momentum = momentum\n        self.lr_decay = lr_decay\n        if self.lr_decay > 0.:\n            self.has_decay = True\n        self.decay_step = decay_step\n        self.staircase = staircase\n\n    def build(self, step_tensor=None):\n        self.built = True\n        if self.has_decay:\n            if not step_tensor:\n                raise Exception(\"Learning rate decay but no step_tensor \"\n                                \"provided.\")\n            self.learning_rate = tf.train.exponential_decay(\n                self.learning_rate, step_tensor,\n                self.decay_step, self.lr_decay,\n                staircase=self.staircase)\n            tf.add_to_collection(tf.GraphKeys.LR_VARIABLES, self.learning_rate)\n        self.tensor = tf.train.MomentumOptimizer(\n            learning_rate=self.learning_rate,\n            momentum=self.momentum,\n            use_locking=self.use_locking,\n            name=self.name,use_nesterov=True)\n\nnesterov = Nesterov\n", "comments": "    base optimizer class       a basic class create optimizers used tflearn estimators      first  the optimizer class initialized given parameters      tensor created  in second step  invoking  get tensor  method     actually build tensorflow  optimizer  tensor  return       this way  user easily specifies optimizer non default     parameters learning rate decay  tflearn estimators     build optimizer step tensor       arguments          learning rate   float   learning rate          use locking   bool   if true use locks update operation          name   str   the optimizer name       attributes          tensor   optimizer   the optimizer tensor          decay   bool   true optimizer learning rate decay                def   init  (self  learning rate  use locking  name)          self learning rate   learning rate         self use locking   use locking         self name   name         self tensor   none         self decay   false         self built   false      def build(self  step tensor none)              build optimizer tensor           this method creates optimizer specified parameters  it must         implemented every  optimizer            arguments              step tensor   tf tensor   a variable holding training step                  only necessary optimizer learning rate decay                       raise notimplementederror      def get tensor(self)              get tensor           a method retrieve optimizer tensor           returns              the  optimizer                        self built              self build()         return self tensor      def   call  (self)                call            a shortcut  get tensor   retrieve optimizer tensor           returns              the  optimizer                        return self get tensor()   class sgd(optimizer)          stochastic gradient descent       sgd optimizer accepts learning rate decay  when training model      often recommended lower learning rate training     progresses  the function returns decayed learning rate   it     computed          python     decayed learning rate   learning rate                             decay rate   (global step   decay steps)              examples             python           with tflearn estimators          sgd   sgd(learning rate 0 01  lr decay 0 96  decay step 100)         regression   regression(net  optimizer sgd)            without tflearn estimators (returns tf optimizer)          sgd   sgd(learning rate 0 01) get tensor()                  arguments          learning rate   float   learning rate          use locking   bool   if true use locks update operation          lr decay   float   the learning rate decay apply          decay step   int   apply decay every provided steps          staircase   bool   it  true  decay learning rate discrete intervals          use locking   bool   if true use locks update operation          name   str   optional name prefix operations created             applying gradients  defaults  gradientdescent                 def   init  (self  learning rate 0 001  lr decay 0   decay step 100                   staircase false  use locking false  name  sgd )          super(sgd  self)   init  (learning rate  use locking  name)         self lr decay   lr decay         self lr decay   0               self decay   true         self decay step   decay step         self staircase   staircase      def build(self  step tensor none)          self built   true         self decay              step tensor                  raise exception( learning rate decay step tensor                                    provided  )             self learning rate   tf train exponential decay(                 self learning rate  step tensor                  self decay step  self lr decay                  staircase self staircase)             tf add collection(tf graphkeys lr variables  self learning rate)         self tensor   tf train gradientdescentoptimizer(             learning rate self learning rate              use locking self use locking              name self name)    shortcut sgd   sgd   class rmsprop(optimizer)          rmsprop       maintain moving (discounted) average square gradients      divide gradient root average       examples             python           with tflearn estimators          rmsprop   rmsprop(learning rate 0 1  decay 0 999)         regression   regression(net  optimizer rmsprop)            without tflearn estimators (returns tf optimizer)          rmsprop   rmsprop(learning rate 0 01  decay 0 999) get tensor()                   rmsprop   rmsprop(learning rate 0 01  decay 0 999)()                   arguments          learning rate   float   learning rate          decay   float   discounting factor history coming gradient          momentum   float   momentum          epsilon   float   small value avoid zero denominator          use locking   bool   if true use locks update operation          name   str   optional name prefix operations created             applying gradients  defaults  rmsprop                 def   init  (self  learning rate 0 001  decay 0 9  momentum 0 0                   epsilon 1e 10  use locking false  name  rmsprop )          super(rmsprop  self)   init  (learning rate  use locking  name)         self decay   decay         self momentum   momentum         self epsilon   epsilon      def build(self  step tensor none)          self built   true         self tensor   tf train rmspropoptimizer(             learning rate self learning rate  decay self decay              momentum self momentum  epsilon self epsilon              use locking self use locking  name self name)  rmsprop   rmsprop   class adam(optimizer)          adam       the default value 1e 8 epsilon might good default     general  for example  training inception network imagenet     current good choice 1 0 0 1       examples             python           with tflearn estimators         adam   adam(learning rate 0 001  beta1 0 99)         regression   regression(net  optimizer adam)            without tflearn estimators (returns tf optimizer)         adam   adam(learning rate 0 01) get tensor()                   arguments          learning rate   float   learning rate          beta1   float   the exponential decay rate 1st moment             estimates          beta2   float   the exponential decay rate 2nd moment             estimates          epsilon   float   a small constant numerical stability          use locking   bool   if true use locks update operation          name   str   optional name prefix operations created             applying gradients  defaults  adam        references          adam  a method stochastic optimization  diederik kingma          jimmy ba  iclr 2015       links           paper (http   arxiv org pdf 1412 6980v8 pdf)               def   init  (self  learning rate 0 001  beta1 0 9  beta2 0 999                   epsilon 1e 8  use locking false  name  adam )          super(adam  self)   init  (learning rate  use locking  name)         self beta1   beta1         self beta2   beta2         self epsilon   epsilon      def build(self  step tensor none)          self built   true         self tensor   tf train adamoptimizer(             learning rate self learning rate  beta1 self beta1              beta2 self beta2  epsilon self epsilon              use locking self use locking  name self name)  adam   adam   class momentum(optimizer)          momentum       momentum optimizer accepts learning rate decay  when training model      often recommended lower learning rate training     progresses  the function returns decayed learning rate   it     computed          python     decayed learning rate   learning rate                             decay rate   (global step   decay steps)              examples             python           with tflearn estimators         momentum   momentum(learning rate 0 01  lr decay 0 96  decay step 100)         regression   regression(net  optimizer momentum)            without tflearn estimators (returns tf optimizer)         mm   momentum(learning rate 0 01  lr decay 0 96) get tensor()                  arguments          learning rate   float   learning rate          momentum   float   momentum          lr decay   float   the learning rate decay apply          decay step   int   apply decay every provided steps          staircase   bool   it  true  decay learning rate discrete intervals          use locking   bool   if true use locks update operation          name   str   optional name prefix operations created             applying gradients  defaults  momentum                 def   init  (self  learning rate 0 001  momentum 0 9  lr decay 0                    decay step 100  staircase false  use locking false                   name  momentum )          super(momentum  self)   init  (learning rate  use locking  name)         self momentum   momentum         self lr decay   lr decay         self lr decay   0               self decay   true         self decay step   decay step         self staircase   staircase      def build(self  step tensor none)          self built   true         self decay              step tensor                  raise exception( learning rate decay step tensor                                    provided  )             self learning rate   tf train exponential decay(                 self learning rate  step tensor                  self decay step  self lr decay                  staircase self staircase)             tf add collection(tf graphkeys lr variables  self learning rate)         self tensor   tf train momentumoptimizer(             learning rate self learning rate              momentum self momentum              use locking self use locking              name self name)  momentum   momentum   class adagrad(optimizer)          adagrad       examples             python           with tflearn estimators         adagrad   adagrad(learning rate 0 01  initial accumulator value 0 01)         regression   regression(net  optimizer adagrad)            without tflearn estimators (returns tf optimizer)         adagrad   adagrad(learning rate 0 01) get tensor()                  arguments          learning rate   float   learning rate          initial accumulator value   float   starting value             accumulators  must positive         use locking   bool   if true use locks update operation          name   str   optional name prefix operations created             applying gradients  defaults  adagrad        references          adaptive subgradient methods online learning stochastic         optimization  j  duchi  e  hazan   y  singer  journal machine         learning research 12 (2011) 2121 2159       links           paper (http   www jmlr org papers volume12 duchi11a duchi11a pdf)               def   init  (self  learning rate 0 001  initial accumulator value 0 1                   use locking false  name  adagrad )          super(adagrad  self)   init  (learning rate  use locking  name)         self initial accumulator value   initial accumulator value      def build(self  step tensor none)          self built   true         self tensor   tf train adagradoptimizer(             self learning rate              initial accumulator value self initial accumulator value              use locking self use locking  name self name)  adagrad   adagrad   class ftrl(optimizer)          ftrl proximal       the ftrl proximal algorithm  abbreviated follow regularized leader      described paper       it give good performance vs  sparsity tradeoff       ftrl proximal uses global base learning rate behave like     adagrad  learning rate power  0 5   like gradient descent      learning rate power 0 0        examples             python           with tflearn estimators          ftrl   ftrl(learning rate 0 01  learning rate power  0 1)         regression   regression(net  optimizer ftrl)            without tflearn estimators (returns tf optimizer)          ftrl   ftrl(learning rate 0 01) get tensor()                  arguments          learning rate   float   learning rate          learning rate power   float   must less equal zero          initial accumulator value   float   the starting value accumulators              only positive values allowed          l1 regularization strength   float   must less equal zero          l2 regularization strength   float   must less equal zero          use locking   bool   if true use locks update operation          name   str   optional name prefix operations created             applying gradients  defaults  ftrl        links           ad click prediction  view trenches (https   www eecs tufts          edu  dsculley papers ad click prediction pdf)               def   init  (self  learning rate 3 0  learning rate power  0 5                   initial accumulator value 0 1  l1 regularization strength 0 0                   l2 regularization strength 0 0  use locking false                   name  ftrl )          super(ftrl  self)   init  (learning rate  use locking  name)         self learning rate power   learning rate power         self initial accumulator value   initial accumulator value         self l1 regularization strength   l1 regularization strength         self l2 regularization strength   l2 regularization strength      def build(self  step tensor none)          self built   true         tf device(  cpu 0 )              self tensor   tf train ftrloptimizer(                 self learning rate                  learning rate power self learning rate power                  initial accumulator value self initial accumulator value                  l1 regularization strength self l1 regularization strength                  l2 regularization strength self l2 regularization strength                  use locking self use locking  name self name)  ftrl   ftrl   class adadelta(optimizer)          adadelta       construct new adadelta optimizer       arguments          learning rate  a  tensor  floating point value  the learning rate          rho  a  tensor  floating point value  the decay rate          epsilon  a  tensor  floating point value   a constant epsilon used             better conditioning grad update          use locking  if  true  use locks update operations          name  optional name prefix operations created applying             gradients   defaults  adadelta        references          adadelta  an adaptive learning rate method  matthew d  zeiler  2012       links           http   arxiv org abs 1212 5701 (http   arxiv org abs 1212 5701)               def   init  (self  learning rate 0 001  rho 0 1  epsilon 1e 08                   use locking false  name  adadelta )          super(adadelta  self)   init  (learning rate  use locking  name)         self rho   rho         self epsilon   epsilon      def build(self  step tensor none)          self built   true         self tensor   tf train adadeltaoptimizer(             self learning rate              rho self rho  epsilon self epsilon              use locking self use locking  name self name)  adadelta   adadelta   class proximaladagrad(optimizer)          proximaladagrad       examples             python           with tflearn estimators         proxi adagrad   proximaladagrad(learning rate 0 01                                          l2 regularization strength 0 01                                          initial accumulator value 0 01)         regression   regression(net  optimizer proxi adagrad)            without tflearn estimators (returns tf optimizer)         adagrad   proximaladagrad(learning rate 0 01) get tensor()                  arguments          learning rate   float   learning rate          initial accumulator value   float   starting value             accumulators  must positive         use locking   bool   if true use locks update operation          name   str   optional name prefix operations created             applying gradients  defaults  adagrad        references          efficient learning using forward backward splitting  j  duchi  yoram         singer  2009       links           paper (http   papers nips cc paper 3793 efficient learning using forward backward splitting pdf)               def   init  (self  learning rate 0 001  initial accumulator value 0 1                   use locking false  name  adagrad )          super(proximaladagrad  self)   init  (learning rate  use locking  name)         self initial accumulator value   initial accumulator value      def build(self  step tensor none)          self built   true         self tensor   tf train adagradoptimizer(             self learning rate              initial accumulator value self initial accumulator value              use locking self use locking  name self name)  proximaladagrad   proximaladagrad   class nesterov(optimizer)          nesterov       the main difference classical momentum nesterov      in classical momentum first correct velocity      make big step according velocity (and repeat)       nesterov momentum first making step velocity      direction make correction velocity vector based     new location (then repeat)      see  sutskever et  al   2013 (             http   jmlr org proceedings papers v28 sutskever13 pdf)      examples             python           with tflearn estimators         nesterov   nesterov(learning rate 0 01  lr decay 0 96  decay step 100)         regression   regression(net  optimizer nesterov)            without tflearn estimators (returns tf optimizer)         mm   neserov(learning rate 0 01  lr decay 0 96) get tensor()                  arguments          learning rate   float   learning rate          momentum   float   momentum          lr decay   float   the learning rate decay apply          decay step   int   apply decay every provided steps          staircase   bool   it  true  decay learning rate discrete intervals          use locking   bool   if true use locks update operation          name   str   optional name prefix operations created             applying gradients  defaults  momentum               with tflearn estimators     without tflearn estimators (returns tf optimizer)     shortcut    with tflearn estimators     without tflearn estimators (returns tf optimizer)        with tflearn estimators    without tflearn estimators (returns tf optimizer)    with tflearn estimators    without tflearn estimators (returns tf optimizer)    with tflearn estimators    without tflearn estimators (returns tf optimizer)    with tflearn estimators     without tflearn estimators (returns tf optimizer)     with tflearn estimators    without tflearn estimators (returns tf optimizer)    with tflearn estimators    without tflearn estimators (returns tf optimizer) ", "content": "from __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nfrom .utils import get_from_module\n\n\ndef get(identifier):\n    return get_from_module(identifier, globals(), 'optimizer')\n\n\nclass Optimizer(object):\n    \"\"\" Base Optimizer class.\n\n    A basic class to create optimizers to be used with TFLearn estimators.\n    First, The Optimizer class is initialized with given parameters,\n    but no Tensor is created. In a second step, invoking `get_tensor` method\n    will actually build the Tensorflow `Optimizer` Tensor, and return it.\n\n    This way, a user can easily specifies an optimizer with non default\n    parameters and learning rate decay, while TFLearn estimators will\n    build the optimizer and a step tensor by itself.\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. The optimizer name.\n\n    Attributes:\n        tensor: `Optimizer`. The optimizer tensor.\n        has_decay: `bool`. True if optimizer has a learning rate decay.\n\n    \"\"\"\n\n    def __init__(self, learning_rate, use_locking, name):\n        self.learning_rate = learning_rate\n        self.use_locking = use_locking\n        self.name = name\n        self.tensor = None\n        self.has_decay = False\n        self.built = False\n\n    def build(self, step_tensor=None):\n        \"\"\" build optimizer tensor.\n\n        This method creates the optimizer with specified parameters. It must\n        be implemented for every `Optimizer`.\n\n        Arguments:\n            step_tensor: `tf.Tensor`. A variable holding the training step.\n                Only necessary when optimizer has a learning rate decay.\n\n        \"\"\"\n        raise NotImplementedError\n\n    def get_tensor(self):\n        \"\"\" get_tensor.\n\n        A method to retrieve the optimizer tensor.\n\n        Returns:\n            The `Optimizer`.\n\n        \"\"\"\n        if not self.built:\n            self.build()\n        return self.tensor\n\n    def __call__(self):\n        \"\"\" __call__\n\n        A shortcut for `get_tensor`. Retrieve the optimizer tensor.\n\n        Returns:\n            The `Optimizer`.\n\n        \"\"\"\n        return self.get_tensor()\n\n\nclass SGD(Optimizer):\n    \"\"\" Stochastic Gradient Descent.\n\n    SGD Optimizer accepts learning rate decay. When training a model,\n    it is often recommended to lower the learning rate as the training\n    progresses. The function returns the decayed learning rate.  It is\n    computed as:\n\n    ```python\n    decayed_learning_rate = learning_rate *\n                          decay_rate ^ (global_step / decay_steps)\n    ```\n\n    Examples:\n        ```python\n        # With TFLearn estimators.\n        sgd = SGD(learning_rate=0.01, lr_decay=0.96, decay_step=100)\n        regression = regression(net, optimizer=sgd)\n\n        # Without TFLearn estimators (returns tf.Optimizer).\n        sgd = SGD(learning_rate=0.01).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        use_locking: `bool`. If True use locks for update operation.\n        lr_decay: `float`. The learning rate decay to apply.\n        decay_step: `int`. Apply decay every provided steps.\n        staircase: `bool`. It `True` decay learning rate at discrete intervals.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to \"GradientDescent\".\n\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, lr_decay=0., decay_step=100,\n                 staircase=False, use_locking=False, name=\"SGD\"):\n        super(SGD, self).__init__(learning_rate, use_locking, name)\n        self.lr_decay = lr_decay\n        if self.lr_decay > 0.:\n            self.has_decay = True\n        self.decay_step = decay_step\n        self.staircase = staircase\n\n    def build(self, step_tensor=None):\n        self.built = True\n        if self.has_decay:\n            if not step_tensor:\n                raise Exception(\"Learning rate decay but no step_tensor \"\n                                \"provided.\")\n            self.learning_rate = tf.train.exponential_decay(\n                self.learning_rate, step_tensor,\n                self.decay_step, self.lr_decay,\n                staircase=self.staircase)\n            tf.add_to_collection(tf.GraphKeys.LR_VARIABLES, self.learning_rate)\n        self.tensor = tf.train.GradientDescentOptimizer(\n            learning_rate=self.learning_rate,\n            use_locking=self.use_locking,\n            name=self.name)\n\n# Shortcut\nsgd = SGD\n\n\nclass RMSProp(Optimizer):\n    \"\"\" RMSprop.\n\n    Maintain a moving (discounted) average of the square of gradients.\n    Divide gradient by the root of this average.\n\n    Examples:\n        ```python\n        # With TFLearn estimators.\n        rmsprop = RMSProp(learning_rate=0.1, decay=0.999)\n        regression = regression(net, optimizer=rmsprop)\n\n        # Without TFLearn estimators (returns tf.Optimizer).\n        rmsprop = RMSProp(learning_rate=0.01, decay=0.999).get_tensor()\n        # or\n        rmsprop = RMSProp(learning_rate=0.01, decay=0.999)()\n\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        decay: `float`. Discounting factor for the history/coming gradient.\n        momentum: `float`. Momentum.\n        epsilon: `float`. Small value to avoid zero denominator.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to \"RMSProp\".\n\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, decay=0.9, momentum=0.0,\n                 epsilon=1e-10, use_locking=False, name=\"RMSProp\"):\n        super(RMSProp, self).__init__(learning_rate, use_locking, name)\n        self.decay = decay\n        self.momentum = momentum\n        self.epsilon = epsilon\n\n    def build(self, step_tensor=None):\n        self.built = True\n        self.tensor = tf.train.RMSPropOptimizer(\n            learning_rate=self.learning_rate, decay=self.decay,\n            momentum=self.momentum, epsilon=self.epsilon,\n            use_locking=self.use_locking, name=self.name)\n\nrmsprop = RMSProp\n\n\nclass Adam(Optimizer):\n    \"\"\" Adam.\n\n    The default value of 1e-8 for epsilon might not be a good default in\n    general. For example, when training an Inception network on ImageNet a\n    current good choice is 1.0 or 0.1.\n\n    Examples:\n        ```python\n        # With TFLearn estimators\n        adam = Adam(learning_rate=0.001, beta1=0.99)\n        regression = regression(net, optimizer=adam)\n\n        # Without TFLearn estimators (returns tf.Optimizer)\n        adam = Adam(learning_rate=0.01).get_tensor()\n\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        beta1: `float`. The exponential decay rate for the 1st moment\n            estimates.\n        beta2: `float`. The exponential decay rate for the 2nd moment\n            estimates.\n        epsilon: `float`. A small constant for numerical stability.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to \"Adam\".\n\n    References:\n        Adam: A Method for Stochastic Optimization. Diederik Kingma,\n        Jimmy Ba. ICLR 2015.\n\n    Links:\n        [Paper](http://arxiv.org/pdf/1412.6980v8.pdf)\n\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999,\n                 epsilon=1e-8, use_locking=False, name=\"Adam\"):\n        super(Adam, self).__init__(learning_rate, use_locking, name)\n        self.beta1 = beta1\n        self.beta2 = beta2\n        self.epsilon = epsilon\n\n    def build(self, step_tensor=None):\n        self.built = True\n        self.tensor = tf.train.AdamOptimizer(\n            learning_rate=self.learning_rate, beta1=self.beta1,\n            beta2=self.beta2, epsilon=self.epsilon,\n            use_locking=self.use_locking, name=self.name)\n\nadam = Adam\n\n\nclass Momentum(Optimizer):\n    \"\"\" Momentum.\n\n    Momentum Optimizer accepts learning rate decay. When training a model,\n    it is often recommended to lower the learning rate as the training\n    progresses. The function returns the decayed learning rate.  It is\n    computed as:\n\n    ```python\n    decayed_learning_rate = learning_rate *\n                          decay_rate ^ (global_step / decay_steps)\n    ```\n\n    Examples:\n        ```python\n        # With TFLearn estimators\n        momentum = Momentum(learning_rate=0.01, lr_decay=0.96, decay_step=100)\n        regression = regression(net, optimizer=momentum)\n\n        # Without TFLearn estimators (returns tf.Optimizer)\n        mm = Momentum(learning_rate=0.01, lr_decay=0.96).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        momentum: `float`. Momentum.\n        lr_decay: `float`. The learning rate decay to apply.\n        decay_step: `int`. Apply decay every provided steps.\n        staircase: `bool`. It `True` decay learning rate at discrete intervals.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to \"Momentum\".\n\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, momentum=0.9, lr_decay=0.,\n                 decay_step=100, staircase=False, use_locking=False,\n                 name=\"Momentum\"):\n        super(Momentum, self).__init__(learning_rate, use_locking, name)\n        self.momentum = momentum\n        self.lr_decay = lr_decay\n        if self.lr_decay > 0.:\n            self.has_decay = True\n        self.decay_step = decay_step\n        self.staircase = staircase\n\n    def build(self, step_tensor=None):\n        self.built = True\n        if self.has_decay:\n            if not step_tensor:\n                raise Exception(\"Learning rate decay but no step_tensor \"\n                                \"provided.\")\n            self.learning_rate = tf.train.exponential_decay(\n                self.learning_rate, step_tensor,\n                self.decay_step, self.lr_decay,\n                staircase=self.staircase)\n            tf.add_to_collection(tf.GraphKeys.LR_VARIABLES, self.learning_rate)\n        self.tensor = tf.train.MomentumOptimizer(\n            learning_rate=self.learning_rate,\n            momentum=self.momentum,\n            use_locking=self.use_locking,\n            name=self.name)\n\nmomentum = Momentum\n\n\nclass AdaGrad(Optimizer):\n    \"\"\" AdaGrad.\n\n    Examples:\n        ```python\n        # With TFLearn estimators\n        adagrad = AdaGrad(learning_rate=0.01, initial_accumulator_value=0.01)\n        regression = regression(net, optimizer=adagrad)\n\n        # Without TFLearn estimators (returns tf.Optimizer)\n        adagrad = AdaGrad(learning_rate=0.01).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        initial_accumulator_value: `float`. Starting value for the\n            accumulators, must be positive\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to \"AdaGrad\".\n\n    References:\n        Adaptive Subgradient Methods for Online Learning and Stochastic\n        Optimization. J. Duchi, E. Hazan & Y. Singer. Journal of Machine\n        Learning Research 12 (2011) 2121-2159.\n\n    Links:\n        [Paper](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, initial_accumulator_value=0.1,\n                 use_locking=False, name=\"AdaGrad\"):\n        super(AdaGrad, self).__init__(learning_rate, use_locking, name)\n        self.initial_accumulator_value = initial_accumulator_value\n\n    def build(self, step_tensor=None):\n        self.built = True\n        self.tensor = tf.train.AdagradOptimizer(\n            self.learning_rate,\n            initial_accumulator_value=self.initial_accumulator_value,\n            use_locking=self.use_locking, name=self.name)\n\nadagrad = AdaGrad\n\n\nclass Ftrl(Optimizer):\n    \"\"\" Ftrl Proximal.\n\n    The Ftrl-proximal algorithm, abbreviated for Follow-the-regularized-leader,\n    is described in the paper below.\n\n    It can give a good performance vs. sparsity tradeoff.\n\n    Ftrl-proximal uses its own global base learning rate and can behave like\n    Adagrad with `learning_rate_power=-0.5`, or like gradient descent with\n    `learning_rate_power=0.0`.\n\n    Examples:\n        ```python\n        # With TFLearn estimators.\n        ftrl = Ftrl(learning_rate=0.01, learning_rate_power=-0.1)\n        regression = regression(net, optimizer=ftrl)\n\n        # Without TFLearn estimators (returns tf.Optimizer).\n        ftrl = Ftrl(learning_rate=0.01).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        learning_rate_power: `float`. Must be less or equal to zero.\n        initial_accumulator_value: `float`. The starting value for accumulators.\n            Only positive values are allowed.\n        l1_regularization_strength: `float`. Must be less or equal to zero.\n        l2_regularization_strength: `float`. Must be less or equal to zero.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to \"Ftrl\".\n\n    Links:\n        [Ad Click Prediction: a View from the Trenches](https://www.eecs.tufts.\n        edu/~dsculley/papers/ad-click-prediction.pdf)\n\n    \"\"\"\n\n    def __init__(self, learning_rate=3.0, learning_rate_power=-0.5,\n                 initial_accumulator_value=0.1, l1_regularization_strength=0.0,\n                 l2_regularization_strength=0.0, use_locking=False,\n                 name=\"Ftrl\"):\n        super(Ftrl, self).__init__(learning_rate, use_locking, name)\n        self.learning_rate_power = learning_rate_power\n        self.initial_accumulator_value = initial_accumulator_value\n        self.l1_regularization_strength = l1_regularization_strength\n        self.l2_regularization_strength = l2_regularization_strength\n\n    def build(self, step_tensor=None):\n        self.built = True\n        with tf.device('/cpu:0'):\n            self.tensor = tf.train.FtrlOptimizer(\n                self.learning_rate,\n                learning_rate_power=self.learning_rate_power,\n                initial_accumulator_value=self.initial_accumulator_value,\n                l1_regularization_strength=self.l1_regularization_strength,\n                l2_regularization_strength=self.l2_regularization_strength,\n                use_locking=self.use_locking, name=self.name)\n\nftrl = Ftrl\n\n\nclass AdaDelta(Optimizer):\n    \"\"\" AdaDelta.\n\n    Construct a new Adadelta optimizer.\n\n    Arguments:\n        learning_rate: A `Tensor` or a floating point value. The learning rate.\n        rho: A `Tensor` or a floating point value. The decay rate.\n        epsilon: A `Tensor` or a floating point value.  A constant epsilon used\n            to better conditioning the grad update.\n        use_locking: If `True` use locks for update operations.\n        name: Optional name prefix for the operations created when applying\n            gradients.  Defaults to \"Adadelta\".\n\n    References:\n        ADADELTA: An Adaptive Learning Rate Method, Matthew D. Zeiler, 2012.\n\n    Links:\n        [http://arxiv.org/abs/1212.5701](http://arxiv.org/abs/1212.5701)\n\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, rho=0.1, epsilon=1e-08,\n                 use_locking=False, name=\"AdaDelta\"):\n        super(AdaDelta, self).__init__(learning_rate, use_locking, name)\n        self.rho = rho\n        self.epsilon = epsilon\n\n    def build(self, step_tensor=None):\n        self.built = True\n        self.tensor = tf.train.AdadeltaOptimizer(\n            self.learning_rate,\n            rho=self.rho, epsilon=self.epsilon,\n            use_locking=self.use_locking, name=self.name)\n\nadadelta = AdaDelta\n\n\nclass ProximalAdaGrad(Optimizer):\n    \"\"\" ProximalAdaGrad.\n\n    Examples:\n        ```python\n        # With TFLearn estimators\n        proxi_adagrad = ProximalAdaGrad(learning_rate=0.01,\n                                        l2_regularization_strength=0.01,\n                                        initial_accumulator_value=0.01)\n        regression = regression(net, optimizer=proxi_adagrad)\n\n        # Without TFLearn estimators (returns tf.Optimizer)\n        adagrad = ProximalAdaGrad(learning_rate=0.01).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        initial_accumulator_value: `float`. Starting value for the\n            accumulators, must be positive\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to \"AdaGrad\".\n\n    References:\n        Efficient Learning using Forward-Backward Splitting. J. Duchi, Yoram\n        Singer, 2009.\n\n    Links:\n        [Paper](http://papers.nips.cc/paper/3793-efficient-learning-using-forward-backward-splitting.pdf)\n\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, initial_accumulator_value=0.1,\n                 use_locking=False, name=\"AdaGrad\"):\n        super(ProximalAdaGrad, self).__init__(learning_rate, use_locking, name)\n        self.initial_accumulator_value = initial_accumulator_value\n\n    def build(self, step_tensor=None):\n        self.built = True\n        self.tensor = tf.train.AdagradOptimizer(\n            self.learning_rate,\n            initial_accumulator_value=self.initial_accumulator_value,\n            use_locking=self.use_locking, name=self.name)\n\nproximaladagrad = ProximalAdaGrad\n\n\nclass Nesterov(Optimizer):\n    \"\"\" Nesterov.\n\n    The main difference between classical momentum and nesterov is:\n    In classical momentum you first correct your velocity and \n    then make a big step according to that velocity (and then repeat), \n    but in Nesterov momentum you first making a step into velocity \n    direction and then make a correction to a velocity vector based on\n    new location (then repeat).\n    See [Sutskever et. al., 2013](\n            http://jmlr.org/proceedings/papers/v28/sutskever13.pdf)\n\n    Examples:\n        ```python\n        # With TFLearn estimators\n        nesterov = Nesterov(learning_rate=0.01, lr_decay=0.96, decay_step=100)\n        regression = regression(net, optimizer=nesterov)\n\n        # Without TFLearn estimators (returns tf.Optimizer)\n        mm = Neserov(learning_rate=0.01, lr_decay=0.96).get_tensor()\n        ```\n\n    Arguments:\n        learning_rate: `float`. Learning rate.\n        momentum: `float`. Momentum.\n        lr_decay: `float`. The learning rate decay to apply.\n        decay_step: `int`. Apply decay every provided steps.\n        staircase: `bool`. It `True` decay learning rate at discrete intervals.\n        use_locking: `bool`. If True use locks for update operation.\n        name: `str`. Optional name prefix for the operations created when\n            applying gradients. Defaults to \"Momentum\".\n\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, momentum=0.9, lr_decay=0.,\n                 decay_step=100, staircase=False, use_locking=False,\n                 name=\"Nesterov\"):\n        super(Nesterov, self).__init__(learning_rate, use_locking, name)\n        self.momentum = momentum\n        self.lr_decay = lr_decay\n        if self.lr_decay > 0.:\n            self.has_decay = True\n        self.decay_step = decay_step\n        self.staircase = staircase\n\n    def build(self, step_tensor=None):\n        self.built = True\n        if self.has_decay:\n            if not step_tensor:\n                raise Exception(\"Learning rate decay but no step_tensor \"\n                                \"provided.\")\n            self.learning_rate = tf.train.exponential_decay(\n                self.learning_rate, step_tensor,\n                self.decay_step, self.lr_decay,\n                staircase=self.staircase)\n            tf.add_to_collection(tf.GraphKeys.LR_VARIABLES, self.learning_rate)\n        self.tensor = tf.train.MomentumOptimizer(\n            learning_rate=self.learning_rate,\n            momentum=self.momentum,\n            use_locking=self.use_locking,\n            name=self.name,use_nesterov=True)\n\nnesterov = Nesterov\n", "description": "Deep learning library featuring a higher-level API for TensorFlow.", "file_name": "optimizers.py", "id": "0a1ab34d5ff5b8e2aae8c19ef3d95689", "language": "Python", "project_name": "tflearn", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tflearn-tflearn/tflearn-tflearn-70fb38a/tflearn/optimizers.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:15:41Z", "url": "https://github.com/tflearn/tflearn", "wiki": true}