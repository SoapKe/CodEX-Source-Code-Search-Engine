{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\nr\nimport numpy as np\nimport os, glob\nimport platform\n\nimport logging\nfrom tensorflow.python.platform import app\nfrom tensorflow.python.platform import flags\n\nimport render.swiftshader_renderer as renderer \nimport src.file_utils as fu\nimport src.utils as utils\n\ndef get_dataset(dataset_name):\n  if dataset_name == 'sbpd':\n    dataset = StanfordBuildingParserDataset(dataset_name)\n  else:\n    logging.fatal('Not one of sbpd')\n  return dataset\n\nclass Loader():\n  def get_data_dir():\n    pass\n\n  def get_meta_data(self, file_name, data_dir=None):\n    if data_dir is None:\n      data_dir = self.get_data_dir()\n    full_file_name = os.path.join(data_dir, 'meta', file_name)\n    assert(fu.exists(full_file_name)), \\\n      '{:s} does not exist'.format(full_file_name)\n    ext = os.path.splitext(full_file_name)[1]\n    if ext == '.txt':\n      ls = []\n      with fu.fopen(full_file_name, 'r') as f:\n        for l in f:\n          ls.append(l.rstrip())\n    elif ext == '.pkl':\n      ls = utils.load_variables(full_file_name)\n    return ls\n\n  def load_building(self, name, data_dir=None):\n    if data_dir is None:\n      data_dir = self.get_data_dir()\n    out = {}\n    out['name'] = name\n    out['data_dir'] = data_dir\n    out['room_dimension_file'] = os.path.join(data_dir, 'room-dimension',\n                                              name+'.pkl')\n    out['class_map_folder'] = os.path.join(data_dir, 'class-maps')\n    return out\n\n  def load_building_meshes(self, building):\n    dir_name = os.path.join(building['data_dir'], 'mesh', building['name'])\n    mesh_file_name = glob.glob1(dir_name, '*.obj')[0]\n    mesh_file_name_full = os.path.join(dir_name, mesh_file_name)\n    logging.error('Loading building from obj file: %s', mesh_file_name_full)\n    shape = renderer.Shape(mesh_file_name_full, load_materials=True, \n                           name_prefix=building['name']+'_')\n    return [shape]\n\nclass StanfordBuildingParserDataset(Loader):\n  def __init__(self, ver):\n    self.ver = ver\n    self.data_dir = None\n  \n  def get_data_dir(self):\n    if self.data_dir is None:\n      self.data_dir = 'data/stanford_building_parser_dataset/'\n    return self.data_dir\n\n  def get_benchmark_sets(self):\n    return self._get_benchmark_sets()\n\n  def get_split(self, split_name):\n    if self.ver == 'sbpd':\n      return self._get_split(split_name)\n    else:\n      logging.fatal('Unknown version.')\n\n  def _get_benchmark_sets(self):\n    sets = ['train1', 'val', 'test']\n    return sets\n\n  def _get_split(self, split_name):\n    train = ['area1', 'area5a', 'area5b', 'area6']\n    train1 = ['area1']\n    val = ['area3']\n    test = ['area4']\n\n    sets = {}\n    sets['train'] = train\n    sets['train1'] = train1\n    sets['val'] = val\n    sets['test'] = test\n    sets['all'] = sorted(list(set(train + val + test)))\n    return sets[split_name]\n", "comments": "   wrapper selecting navigation environment want train test         copyright 2016 the tensorflow authors all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                    ", "content": "# Copyright 2016 The TensorFlow Authors All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nr\"\"\"Wrapper for selecting the navigation environment that we want to train and\ntest on.\n\"\"\"\nimport numpy as np\nimport os, glob\nimport platform\n\nimport logging\nfrom tensorflow.python.platform import app\nfrom tensorflow.python.platform import flags\n\nimport render.swiftshader_renderer as renderer \nimport src.file_utils as fu\nimport src.utils as utils\n\ndef get_dataset(dataset_name):\n  if dataset_name == 'sbpd':\n    dataset = StanfordBuildingParserDataset(dataset_name)\n  else:\n    logging.fatal('Not one of sbpd')\n  return dataset\n\nclass Loader():\n  def get_data_dir():\n    pass\n\n  def get_meta_data(self, file_name, data_dir=None):\n    if data_dir is None:\n      data_dir = self.get_data_dir()\n    full_file_name = os.path.join(data_dir, 'meta', file_name)\n    assert(fu.exists(full_file_name)), \\\n      '{:s} does not exist'.format(full_file_name)\n    ext = os.path.splitext(full_file_name)[1]\n    if ext == '.txt':\n      ls = []\n      with fu.fopen(full_file_name, 'r') as f:\n        for l in f:\n          ls.append(l.rstrip())\n    elif ext == '.pkl':\n      ls = utils.load_variables(full_file_name)\n    return ls\n\n  def load_building(self, name, data_dir=None):\n    if data_dir is None:\n      data_dir = self.get_data_dir()\n    out = {}\n    out['name'] = name\n    out['data_dir'] = data_dir\n    out['room_dimension_file'] = os.path.join(data_dir, 'room-dimension',\n                                              name+'.pkl')\n    out['class_map_folder'] = os.path.join(data_dir, 'class-maps')\n    return out\n\n  def load_building_meshes(self, building):\n    dir_name = os.path.join(building['data_dir'], 'mesh', building['name'])\n    mesh_file_name = glob.glob1(dir_name, '*.obj')[0]\n    mesh_file_name_full = os.path.join(dir_name, mesh_file_name)\n    logging.error('Loading building from obj file: %s', mesh_file_name_full)\n    shape = renderer.Shape(mesh_file_name_full, load_materials=True, \n                           name_prefix=building['name']+'_')\n    return [shape]\n\nclass StanfordBuildingParserDataset(Loader):\n  def __init__(self, ver):\n    self.ver = ver\n    self.data_dir = None\n  \n  def get_data_dir(self):\n    if self.data_dir is None:\n      self.data_dir = 'data/stanford_building_parser_dataset/'\n    return self.data_dir\n\n  def get_benchmark_sets(self):\n    return self._get_benchmark_sets()\n\n  def get_split(self, split_name):\n    if self.ver == 'sbpd':\n      return self._get_split(split_name)\n    else:\n      logging.fatal('Unknown version.')\n\n  def _get_benchmark_sets(self):\n    sets = ['train1', 'val', 'test']\n    return sets\n\n  def _get_split(self, split_name):\n    train = ['area1', 'area5a', 'area5b', 'area6']\n    train1 = ['area1']\n    val = ['area3']\n    test = ['area4']\n\n    sets = {}\n    sets['train'] = train\n    sets['train1'] = train1\n    sets['val'] = val\n    sets['test'] = test\n    sets['all'] = sorted(list(set(train + val + test)))\n    return sets[split_name]\n", "description": "Models and examples built with TensorFlow", "file_name": "factory.py", "id": "0d635d06a25c6bcfbe7f6176be7cf415", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-models/tensorflow-models-086d914/research/cognitive_mapping_and_planning/datasets/factory.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:59:19Z", "url": "https://github.com/tensorflow/models", "wiki": true}