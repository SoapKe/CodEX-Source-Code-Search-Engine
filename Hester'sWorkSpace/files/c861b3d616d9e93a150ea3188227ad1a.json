{"author": "rushter", "code": "import logging\n\nfrom mla.datasets import load_mnist\nfrom mla.metrics import accuracy\nfrom mla.neuralnet import NeuralNet\nfrom mla.neuralnet.layers import Activation, Convolution, MaxPooling, Flatten, Dropout, Parameters\nfrom mla.neuralnet.layers import Dense\nfrom mla.neuralnet.optimizers import Adadelta\nfrom mla.utils import one_hot\n\nlogging.basicConfig(level=logging.DEBUG)\n\n\n\nX_train, X_test, y_train, y_test = load_mnist()\n\n\nX_train /= 255.\nX_test /= 255.\n\ny_train = one_hot(y_train.flatten())\ny_test = one_hot(y_test.flatten())\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n\n\nmodel = NeuralNet(\n    layers=[\n        Convolution(n_filters=32, filter_shape=(3, 3), padding=(1, 1), stride=(1, 1)),\n        Activation('relu'),\n        Convolution(n_filters=32, filter_shape=(3, 3), padding=(1, 1), stride=(1, 1)),\n        Activation('relu'),\n        MaxPooling(pool_shape=(2, 2), stride=(2, 2)),\n        Dropout(0.5),\n\n        Flatten(),\n        Dense(128),\n        Activation('relu'),\n        Dropout(0.5),\n        Dense(10),\n        Activation('softmax'),\n    ],\n    loss='categorical_crossentropy',\n    optimizer=Adadelta(),\n    metric='accuracy',\n    batch_size=128,\n    max_epochs=3,\n)\n\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)\nprint(accuracy(y_test, predictions))\n", "comments": "  load mnist dataset    normalize data    approx  15 20 min  per epoch ", "content": "import logging\n\nfrom mla.datasets import load_mnist\nfrom mla.metrics import accuracy\nfrom mla.neuralnet import NeuralNet\nfrom mla.neuralnet.layers import Activation, Convolution, MaxPooling, Flatten, Dropout, Parameters\nfrom mla.neuralnet.layers import Dense\nfrom mla.neuralnet.optimizers import Adadelta\nfrom mla.utils import one_hot\n\nlogging.basicConfig(level=logging.DEBUG)\n\n\n# Load MNIST dataset\nX_train, X_test, y_train, y_test = load_mnist()\n\n# Normalize data\nX_train /= 255.\nX_test /= 255.\n\ny_train = one_hot(y_train.flatten())\ny_test = one_hot(y_test.flatten())\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n\n# Approx. 15-20 min. per epoch\nmodel = NeuralNet(\n    layers=[\n        Convolution(n_filters=32, filter_shape=(3, 3), padding=(1, 1), stride=(1, 1)),\n        Activation('relu'),\n        Convolution(n_filters=32, filter_shape=(3, 3), padding=(1, 1), stride=(1, 1)),\n        Activation('relu'),\n        MaxPooling(pool_shape=(2, 2), stride=(2, 2)),\n        Dropout(0.5),\n\n        Flatten(),\n        Dense(128),\n        Activation('relu'),\n        Dropout(0.5),\n        Dense(10),\n        Activation('softmax'),\n    ],\n    loss='categorical_crossentropy',\n    optimizer=Adadelta(),\n    metric='accuracy',\n    batch_size=128,\n    max_epochs=3,\n)\n\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)\nprint(accuracy(y_test, predictions))\n", "description": "Minimal and clean examples of machine learning algorithms", "file_name": "nnet_convnet_mnist.py", "id": "c861b3d616d9e93a150ea3188227ad1a", "language": "Python", "project_name": "MLAlgorithms", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/rushter-MLAlgorithms/rushter-MLAlgorithms-d398777/examples/nnet_convnet_mnist.py", "save_time": "", "source": "", "update_at": "2018-03-18T15:25:48Z", "url": "https://github.com/rushter/MLAlgorithms", "wiki": false}