{"author": "deepfakes", "code": "import cv2\n\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport os\nimport numpy as np\n\nfrom lib.cli import DirectoryProcessor, rotate_image\nfrom lib.utils import get_folder\nfrom lib.multithreading import pool_process\nfrom lib.detect_blur import is_blurry\nfrom plugins.PluginLoader import PluginLoader\n\nclass ExtractTrainingData(DirectoryProcessor):\n    def create_parser(self, subparser, command, description):\n        self.parser = subparser.add_parser(\n            command,\n            help=\"Extract the faces from a pictures.\",\n            description=description,\n            epilog=\"Questions and feedback: \\\n            https://github.com/deepfakes/faceswap-playground\"\n            )\n\n    def add_optional_arguments(self, parser):\n        parser.add_argument('-D', '--detector',\n                            type=str,\n                            choices=(\"hog\", \"cnn\", \"all\"), \n                            default=\"hog\",\n                            help=\"Detector to use. 'cnn' detects much more angles but will be much more resource intensive and may fail on large files.\")\n\n        parser.add_argument('-l', '--ref_threshold',\n                            type=float,\n                            dest=\"ref_threshold\",\n                            default=0.6,\n                            help=\"Threshold for positive face recognition\"\n                            )\n\n        parser.add_argument('-n', '--nfilter',\n                            type=str,\n                            dest=\"nfilter\",\n                            nargs='+',\n                            default=\"nfilter.jpg\",\n                            help=\"Reference image for the persons you do not want to process. Should be a front portrait\"\n                            )\n\n        parser.add_argument('-f', '--filter',\n                            type=str,\n                            dest=\"filter\",\n                            nargs='+',\n                            default=\"filter.jpg\",\n                            help=\"Reference image for the person you want to process. Should be a front portrait\"\n                            )\n\n        parser.add_argument('-j', '--processes',\n                            type=int,\n                            default=1,\n                            help=\"Number of processes to use.\")\n\n        parser.add_argument('-s', '--skip-existing',\n                            action='store_true',\n                            dest='skip_existing',\n                            default=False,\n                            help=\"Skips frames already extracted.\")\n\n        parser.add_argument('-dl', '--debug-landmarks',\n                            action=\"store_true\",\n                            dest=\"debug_landmarks\",\n                            default=False,\n                            help=\"Draw landmarks for debug.\")\n\n        parser.add_argument('-r', '--rotate-images',\n                            type=str,\n                            dest=\"rotate_images\",\n                            choices=(\"on\", \"off\"),\n                            default=\"off\",\n                            help=\"If a face isn't found, rotate the images through 90 degree \"\n                                 \"iterations to try to find a face. Can find more faces at the \"\n                                 \"cost of extraction speed.\")\n\n        parser.add_argument('-ae', '--align-eyes',\n                            action=\"store_true\",\n                            dest=\"align_eyes\",\n                            default=False,\n                            help=\"Perform extra alignment to ensure left/right eyes lie at the same height\")\n\n        parser.add_argument('-bt', '--blur-threshold',\n                            type=int,\n                            dest=\"blur_thresh\",\n                            default=None,\n                            help=\"Automatically discard images blurrier than the specified threshold. Discarded images are moved into a \\\"blurry\\\" sub-folder. Lower values allow more blur\")\n\n        return parser\n\n    def process(self):\n        extractor_name = \"Align\" \n        self.extractor = PluginLoader.get_extractor(extractor_name)()\n        processes = self.arguments.processes\n        try:\n            if processes != 1:\n                files = list(self.read_directory())\n                for filename, faces in tqdm(pool_process(self.processFiles, files, processes=processes), total = len(files)):\n                    self.num_faces_detected += 1\n                    self.faces_detected[os.path.basename(filename)] = faces\n            else:\n                for filename in tqdm(self.read_directory()):\n                    try:\n                        image = cv2.imread(filename)\n                        self.faces_detected[os.path.basename(filename)] = self.handleImage(image, filename)\n                    except Exception as e:\n                        if self.arguments.verbose:\n                            print('Failed to extract from image: {}. Reason: {}'.format(filename, e))\n                        pass\n        finally:\n            self.write_alignments()\n\n    def processFiles(self, filename):\n        try:\n            image = cv2.imread(filename)\n            return filename, self.handleImage(image, filename)\n        except Exception as e:\n            if self.arguments.verbose:\n                print('Failed to extract from image: {}. Reason: {}'.format(filename, e))\n            pass\n        return filename, []\n\n    def imageRotator(self, image):\n        \n        angle = 90\n        while angle <= 270:\n            rotated_image = rotate_image(image, angle)\n            faces = self.get_faces(rotated_image, rotation=angle)\n            rotated_faces = [(idx, face) for idx, face in faces]\n            if len(rotated_faces) != 0:\n                if self.arguments.verbose:\n                    print('found face(s) by rotating image {} degrees'.format(angle))\n                break\n            angle += 90\n        return rotated_faces, rotated_image\n\n    def handleImage(self, image, filename):\n        faces = self.get_faces(image)\n        process_faces = [(idx, face) for idx, face in faces]\n\n        \n        if self.arguments.rotate_images.lower() == 'on' and len(process_faces) == 0:\n            process_faces, image = self.imageRotator(image)\n\n        rvals = []\n        for idx, face in process_faces:\n            \n            if self.arguments.debug_landmarks:\n                for (x, y) in face.landmarksAsXY():\n                    cv2.circle(image, (x, y), 2, (0, 0, 255), -1)\n\n            resized_image, t_mat = self.extractor.extract(image, face, 256, self.arguments.align_eyes)\n            output_file = get_folder(self.output_dir) / Path(filename).stem\n\n            \n            if self.arguments.blur_thresh is not None:\n                aligned_landmarks = self.extractor.transform_points(face.landmarksAsXY(), t_mat, 256, 48)\n                feature_mask = self.extractor.get_feature_mask(aligned_landmarks / 256, 256, 48)\n                feature_mask = cv2.blur(feature_mask, (10, 10))\n                isolated_face = cv2.multiply(feature_mask, resized_image.astype(float)).astype(np.uint8)\n                blurry, focus_measure = is_blurry(isolated_face, self.arguments.blur_thresh)\n                # print(\"{} focus measure: {}\".format(Path(filename).stem, focus_measure))\n                # cv2.imshow(\"Isolated Face\", isolated_face)\n                # cv2.waitKey(0)\n                ()\n                if blurry:\n                    print(\"{}'s focus measure of {} was below the blur threshold, moving to \\\"blurry\\\"\".format(Path(filename).stem, focus_measure))\n                    output_file = get_folder(Path(self.output_dir) / Path(\"blurry\")) / Path(filename).stem\n\n            cv2.imwrite('{}_{}{}'.format(str(output_file), str(idx), Path(filename).suffix), resized_image)\n            f = {\n                \"r\": face.r,\n                \"x\": face.x,\n                \"w\": face.w,\n                \"y\": face.y,\n                \"h\": face.h,\n                \"landmarksXY\": face.landmarksAsXY()\n            }\n            rvals.append(f)\n        return rvals\n", "comments": "    rotates image 90 degree iterations find face        case sensitive used load plugin     todo pass argument    run image rotator requested faces found    draws landmarks debug    detect blurry images    print(    focus measure      format(path(filename) stem  focus measure))    cv2 imshow( isolated face   isolated face)    cv2 waitkey(0)    cv2 destroyallwindows() ", "content": "import cv2\n\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport os\nimport numpy as np\n\nfrom lib.cli import DirectoryProcessor, rotate_image\nfrom lib.utils import get_folder\nfrom lib.multithreading import pool_process\nfrom lib.detect_blur import is_blurry\nfrom plugins.PluginLoader import PluginLoader\n\nclass ExtractTrainingData(DirectoryProcessor):\n    def create_parser(self, subparser, command, description):\n        self.parser = subparser.add_parser(\n            command,\n            help=\"Extract the faces from a pictures.\",\n            description=description,\n            epilog=\"Questions and feedback: \\\n            https://github.com/deepfakes/faceswap-playground\"\n            )\n\n    def add_optional_arguments(self, parser):\n        parser.add_argument('-D', '--detector',\n                            type=str,\n                            choices=(\"hog\", \"cnn\", \"all\"), # case sensitive because this is used to load a plugin.\n                            default=\"hog\",\n                            help=\"Detector to use. 'cnn' detects much more angles but will be much more resource intensive and may fail on large files.\")\n\n        parser.add_argument('-l', '--ref_threshold',\n                            type=float,\n                            dest=\"ref_threshold\",\n                            default=0.6,\n                            help=\"Threshold for positive face recognition\"\n                            )\n\n        parser.add_argument('-n', '--nfilter',\n                            type=str,\n                            dest=\"nfilter\",\n                            nargs='+',\n                            default=\"nfilter.jpg\",\n                            help=\"Reference image for the persons you do not want to process. Should be a front portrait\"\n                            )\n\n        parser.add_argument('-f', '--filter',\n                            type=str,\n                            dest=\"filter\",\n                            nargs='+',\n                            default=\"filter.jpg\",\n                            help=\"Reference image for the person you want to process. Should be a front portrait\"\n                            )\n\n        parser.add_argument('-j', '--processes',\n                            type=int,\n                            default=1,\n                            help=\"Number of processes to use.\")\n\n        parser.add_argument('-s', '--skip-existing',\n                            action='store_true',\n                            dest='skip_existing',\n                            default=False,\n                            help=\"Skips frames already extracted.\")\n\n        parser.add_argument('-dl', '--debug-landmarks',\n                            action=\"store_true\",\n                            dest=\"debug_landmarks\",\n                            default=False,\n                            help=\"Draw landmarks for debug.\")\n\n        parser.add_argument('-r', '--rotate-images',\n                            type=str,\n                            dest=\"rotate_images\",\n                            choices=(\"on\", \"off\"),\n                            default=\"off\",\n                            help=\"If a face isn't found, rotate the images through 90 degree \"\n                                 \"iterations to try to find a face. Can find more faces at the \"\n                                 \"cost of extraction speed.\")\n\n        parser.add_argument('-ae', '--align-eyes',\n                            action=\"store_true\",\n                            dest=\"align_eyes\",\n                            default=False,\n                            help=\"Perform extra alignment to ensure left/right eyes lie at the same height\")\n\n        parser.add_argument('-bt', '--blur-threshold',\n                            type=int,\n                            dest=\"blur_thresh\",\n                            default=None,\n                            help=\"Automatically discard images blurrier than the specified threshold. Discarded images are moved into a \\\"blurry\\\" sub-folder. Lower values allow more blur\")\n\n        return parser\n\n    def process(self):\n        extractor_name = \"Align\" # TODO Pass as argument\n        self.extractor = PluginLoader.get_extractor(extractor_name)()\n        processes = self.arguments.processes\n        try:\n            if processes != 1:\n                files = list(self.read_directory())\n                for filename, faces in tqdm(pool_process(self.processFiles, files, processes=processes), total = len(files)):\n                    self.num_faces_detected += 1\n                    self.faces_detected[os.path.basename(filename)] = faces\n            else:\n                for filename in tqdm(self.read_directory()):\n                    try:\n                        image = cv2.imread(filename)\n                        self.faces_detected[os.path.basename(filename)] = self.handleImage(image, filename)\n                    except Exception as e:\n                        if self.arguments.verbose:\n                            print('Failed to extract from image: {}. Reason: {}'.format(filename, e))\n                        pass\n        finally:\n            self.write_alignments()\n\n    def processFiles(self, filename):\n        try:\n            image = cv2.imread(filename)\n            return filename, self.handleImage(image, filename)\n        except Exception as e:\n            if self.arguments.verbose:\n                print('Failed to extract from image: {}. Reason: {}'.format(filename, e))\n            pass\n        return filename, []\n\n    def imageRotator(self, image):\n        ''' rotates the image through 90 degree iterations to find a face '''\n        angle = 90\n        while angle <= 270:\n            rotated_image = rotate_image(image, angle)\n            faces = self.get_faces(rotated_image, rotation=angle)\n            rotated_faces = [(idx, face) for idx, face in faces]\n            if len(rotated_faces) != 0:\n                if self.arguments.verbose:\n                    print('found face(s) by rotating image {} degrees'.format(angle))\n                break\n            angle += 90\n        return rotated_faces, rotated_image\n\n    def handleImage(self, image, filename):\n        faces = self.get_faces(image)\n        process_faces = [(idx, face) for idx, face in faces]\n\n        # Run image rotator if requested and no faces found\n        if self.arguments.rotate_images.lower() == 'on' and len(process_faces) == 0:\n            process_faces, image = self.imageRotator(image)\n\n        rvals = []\n        for idx, face in process_faces:\n            # Draws landmarks for debug\n            if self.arguments.debug_landmarks:\n                for (x, y) in face.landmarksAsXY():\n                    cv2.circle(image, (x, y), 2, (0, 0, 255), -1)\n\n            resized_image, t_mat = self.extractor.extract(image, face, 256, self.arguments.align_eyes)\n            output_file = get_folder(self.output_dir) / Path(filename).stem\n\n            # Detect blurry images\n            if self.arguments.blur_thresh is not None:\n                aligned_landmarks = self.extractor.transform_points(face.landmarksAsXY(), t_mat, 256, 48)\n                feature_mask = self.extractor.get_feature_mask(aligned_landmarks / 256, 256, 48)\n                feature_mask = cv2.blur(feature_mask, (10, 10))\n                isolated_face = cv2.multiply(feature_mask, resized_image.astype(float)).astype(np.uint8)\n                blurry, focus_measure = is_blurry(isolated_face, self.arguments.blur_thresh)\n                # print(\"{} focus measure: {}\".format(Path(filename).stem, focus_measure))\n                # cv2.imshow(\"Isolated Face\", isolated_face)\n                # cv2.waitKey(0)\n                # cv2.destroyAllWindows()\n                if blurry:\n                    print(\"{}'s focus measure of {} was below the blur threshold, moving to \\\"blurry\\\"\".format(Path(filename).stem, focus_measure))\n                    output_file = get_folder(Path(self.output_dir) / Path(\"blurry\")) / Path(filename).stem\n\n            cv2.imwrite('{}_{}{}'.format(str(output_file), str(idx), Path(filename).suffix), resized_image)\n            f = {\n                \"r\": face.r,\n                \"x\": face.x,\n                \"w\": face.w,\n                \"y\": face.y,\n                \"h\": face.h,\n                \"landmarksXY\": face.landmarksAsXY()\n            }\n            rvals.append(f)\n        return rvals\n", "description": "Non official project based on original /r/Deepfakes thread. Many thanks to him!", "file_name": "extract.py", "id": "4307f6b1fb11bb3092bdd9aeee77fd4c", "language": "Python", "project_name": "faceswap", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/deepfakes-faceswap/deepfakes-faceswap-6ff64ef/scripts/extract.py", "save_time": "", "source": "", "update_at": "2018-03-18T16:27:43Z", "url": "https://github.com/deepfakes/faceswap", "wiki": true}