{"author": "tensorflow", "code": "import tensorflow as tf\n\nclass VariationalAutoencoder(object):\n\n    def __init__(self, n_input, n_hidden, optimizer = tf.train.AdamOptimizer()):\n        self.n_input = n_input\n        self.n_hidden = n_hidden\n\n        network_weights = self._initialize_weights()\n        self.weights = network_weights\n\n        \n        self.x = tf.placeholder(tf.float32, [None, self.n_input])\n        self.z_mean = tf.add(tf.matmul(self.x, self.weights['w1']), self.weights['b1'])\n        self.z_log_sigma_sq = tf.add(tf.matmul(self.x, self.weights['log_sigma_w1']), self.weights['log_sigma_b1'])\n\n        \n        eps = tf.random_normal(tf.stack([tf.shape(self.x)[0], self.n_hidden]), 0, 1, dtype = tf.float32)\n        self.z = tf.add(self.z_mean, tf.multiply(tf.sqrt(tf.exp(self.z_log_sigma_sq)), eps))\n\n        self.reconstruction = tf.add(tf.matmul(self.z, self.weights['w2']), self.weights['b2'])\n\n        \n        reconstr_loss = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n        latent_loss = -0.5 * tf.reduce_sum(1 + self.z_log_sigma_sq\n                                           - tf.square(self.z_mean)\n                                           - tf.exp(self.z_log_sigma_sq), 1)\n        self.cost = tf.reduce_mean(reconstr_loss + latent_loss)\n        self.optimizer = optimizer.minimize(self.cost)\n\n        init = tf.global_variables_initializer()\n        self.sess = tf.Session()\n        self.sess.run(init)\n\n    def _initialize_weights(self):\n        all_weights = dict()\n        all_weights['w1'] = tf.get_variable(\"w1\", shape=[self.n_input, self.n_hidden],\n            initializer=tf.contrib.layers.xavier_initializer())\n        all_weights['log_sigma_w1'] = tf.get_variable(\"log_sigma_w1\", shape=[self.n_input, self.n_hidden],\n            initializer=tf.contrib.layers.xavier_initializer())\n        all_weights['b1'] = tf.Variable(tf.zeros([self.n_hidden], dtype=tf.float32))\n        all_weights['log_sigma_b1'] = tf.Variable(tf.zeros([self.n_hidden], dtype=tf.float32))\n        all_weights['w2'] = tf.Variable(tf.zeros([self.n_hidden, self.n_input], dtype=tf.float32))\n        all_weights['b2'] = tf.Variable(tf.zeros([self.n_input], dtype=tf.float32))\n        return all_weights\n\n    def partial_fit(self, X):\n        cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict={self.x: X})\n        return cost\n\n    def calc_total_cost(self, X):\n        return self.sess.run(self.cost, feed_dict = {self.x: X})\n\n    def transform(self, X):\n        return self.sess.run(self.z_mean, feed_dict={self.x: X})\n\n    def generate(self, hidden = None):\n        if hidden is None:\n            hidden = self.sess.run(tf.random_normal([1, self.n_hidden]))\n        return self.sess.run(self.reconstruction, feed_dict={self.z: hidden})\n\n    def reconstruct(self, X):\n        return self.sess.run(self.reconstruction, feed_dict={self.x: X})\n\n    def getWeights(self):\n        return self.sess.run(self.weights['w1'])\n\n    def getBiases(self):\n        return self.sess.run(self.weights['b1'])\n\n", "comments": "model sample gaussian distribution cost", "content": "import tensorflow as tf\n\nclass VariationalAutoencoder(object):\n\n    def __init__(self, n_input, n_hidden, optimizer = tf.train.AdamOptimizer()):\n        self.n_input = n_input\n        self.n_hidden = n_hidden\n\n        network_weights = self._initialize_weights()\n        self.weights = network_weights\n\n        # model\n        self.x = tf.placeholder(tf.float32, [None, self.n_input])\n        self.z_mean = tf.add(tf.matmul(self.x, self.weights['w1']), self.weights['b1'])\n        self.z_log_sigma_sq = tf.add(tf.matmul(self.x, self.weights['log_sigma_w1']), self.weights['log_sigma_b1'])\n\n        # sample from gaussian distribution\n        eps = tf.random_normal(tf.stack([tf.shape(self.x)[0], self.n_hidden]), 0, 1, dtype = tf.float32)\n        self.z = tf.add(self.z_mean, tf.multiply(tf.sqrt(tf.exp(self.z_log_sigma_sq)), eps))\n\n        self.reconstruction = tf.add(tf.matmul(self.z, self.weights['w2']), self.weights['b2'])\n\n        # cost\n        reconstr_loss = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n        latent_loss = -0.5 * tf.reduce_sum(1 + self.z_log_sigma_sq\n                                           - tf.square(self.z_mean)\n                                           - tf.exp(self.z_log_sigma_sq), 1)\n        self.cost = tf.reduce_mean(reconstr_loss + latent_loss)\n        self.optimizer = optimizer.minimize(self.cost)\n\n        init = tf.global_variables_initializer()\n        self.sess = tf.Session()\n        self.sess.run(init)\n\n    def _initialize_weights(self):\n        all_weights = dict()\n        all_weights['w1'] = tf.get_variable(\"w1\", shape=[self.n_input, self.n_hidden],\n            initializer=tf.contrib.layers.xavier_initializer())\n        all_weights['log_sigma_w1'] = tf.get_variable(\"log_sigma_w1\", shape=[self.n_input, self.n_hidden],\n            initializer=tf.contrib.layers.xavier_initializer())\n        all_weights['b1'] = tf.Variable(tf.zeros([self.n_hidden], dtype=tf.float32))\n        all_weights['log_sigma_b1'] = tf.Variable(tf.zeros([self.n_hidden], dtype=tf.float32))\n        all_weights['w2'] = tf.Variable(tf.zeros([self.n_hidden, self.n_input], dtype=tf.float32))\n        all_weights['b2'] = tf.Variable(tf.zeros([self.n_input], dtype=tf.float32))\n        return all_weights\n\n    def partial_fit(self, X):\n        cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict={self.x: X})\n        return cost\n\n    def calc_total_cost(self, X):\n        return self.sess.run(self.cost, feed_dict = {self.x: X})\n\n    def transform(self, X):\n        return self.sess.run(self.z_mean, feed_dict={self.x: X})\n\n    def generate(self, hidden = None):\n        if hidden is None:\n            hidden = self.sess.run(tf.random_normal([1, self.n_hidden]))\n        return self.sess.run(self.reconstruction, feed_dict={self.z: hidden})\n\n    def reconstruct(self, X):\n        return self.sess.run(self.reconstruction, feed_dict={self.x: X})\n\n    def getWeights(self):\n        return self.sess.run(self.weights['w1'])\n\n    def getBiases(self):\n        return self.sess.run(self.weights['b1'])\n\n", "description": "Models and examples built with TensorFlow", "file_name": "VariationalAutoencoder.py", "id": "4987363caa99189f579554d15076ed51", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-models/tensorflow-models-086d914/research/autoencoder/autoencoder_models/VariationalAutoencoder.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:59:19Z", "url": "https://github.com/tensorflow/models", "wiki": true}