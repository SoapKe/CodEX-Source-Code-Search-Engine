{"author": "gunthercox", "code": "from unittest import TestCase, expectedFailure\n\n\nclass TuringTests(TestCase):\n\n    def setUp(self):\n        from chatterbot import ChatBot\n\n        self.chatbot = ChatBot('Agent Jr.')\n\n    @expectedFailure\n    def test_ask_name(self):\n        response = self.chatbot.get_response(\n            'What is your name?'\n        )\n        self.assertIn('Agent', response.text)\n\n    @expectedFailure\n    def test_repeat_information(self):\n        \"\"\"\n        Test if we can detect any repeat responses from the agent.\n        \"\"\"\n        self.fail('Condition not met.')\n\n    @expectedFailure\n    def test_repeat_input(self):\n        \"\"\"\n        Test what the responses are like if we keep giving the same input.\n        \"\"\"\n        self.fail('Condition not met.')\n\n    @expectedFailure\n    def test_contradicting_responses(self):\n        \"\"\"\n        Test if we can get the agent to contradict themselves.\n        \"\"\"\n        self.fail('Condition not met.')\n\n    @expectedFailure\n    def test_mathematical_ability(self):\n        \"\"\"\n        The math questions inherently suggest that the agent\n        should get some math problems wrong in order to seem\n        more human. My view on this is that it is more useful\n        to have a bot that is good at math, which could just\n        as easily be a human.\n        \"\"\"\n        self.fail('Condition not met.')\n\n    @expectedFailure\n    def test_response_time(self):\n        \"\"\"\n        Does the agent respond in a realistic amount of time?\n        \"\"\"\n        self.fail('Condition not met.')\n", "comments": "            test detect repeat responses agent                      self fail( condition met  )       expectedfailure     def test repeat input(self)                      test responses like keep giving input                      self fail( condition met  )       expectedfailure     def test contradicting responses(self)                      test get agent contradict                      self fail( condition met  )       expectedfailure     def test mathematical ability(self)                      the math questions inherently suggest agent         get math problems wrong order seem         human  my view useful         bot good math  could         easily human                      self fail( condition met  )       expectedfailure     def test response time(self)                      does agent respond realistic amount time              ", "content": "from unittest import TestCase, expectedFailure\n\n\nclass TuringTests(TestCase):\n\n    def setUp(self):\n        from chatterbot import ChatBot\n\n        self.chatbot = ChatBot('Agent Jr.')\n\n    @expectedFailure\n    def test_ask_name(self):\n        response = self.chatbot.get_response(\n            'What is your name?'\n        )\n        self.assertIn('Agent', response.text)\n\n    @expectedFailure\n    def test_repeat_information(self):\n        \"\"\"\n        Test if we can detect any repeat responses from the agent.\n        \"\"\"\n        self.fail('Condition not met.')\n\n    @expectedFailure\n    def test_repeat_input(self):\n        \"\"\"\n        Test what the responses are like if we keep giving the same input.\n        \"\"\"\n        self.fail('Condition not met.')\n\n    @expectedFailure\n    def test_contradicting_responses(self):\n        \"\"\"\n        Test if we can get the agent to contradict themselves.\n        \"\"\"\n        self.fail('Condition not met.')\n\n    @expectedFailure\n    def test_mathematical_ability(self):\n        \"\"\"\n        The math questions inherently suggest that the agent\n        should get some math problems wrong in order to seem\n        more human. My view on this is that it is more useful\n        to have a bot that is good at math, which could just\n        as easily be a human.\n        \"\"\"\n        self.fail('Condition not met.')\n\n    @expectedFailure\n    def test_response_time(self):\n        \"\"\"\n        Does the agent respond in a realistic amount of time?\n        \"\"\"\n        self.fail('Condition not met.')\n", "description": "ChatterBot is a machine learning, conversational dialog engine for creating chat bots", "file_name": "test_turing.py", "id": "c48e3451402df458566639692ac297bb", "language": "Python", "project_name": "ChatterBot", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/gunthercox-ChatterBot/gunthercox-ChatterBot-f20c412/tests/test_turing.py", "save_time": "", "source": "", "update_at": "2018-03-18T16:44:53Z", "url": "https://github.com/gunthercox/ChatterBot", "wiki": true}