{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\"\"\"Provides utilities to preprocess images.\n\nTraining images are sampled using the provided bounding boxes, and subsequently\ncropped to the sampled bounding box. Images are additionally flipped randomly,\nthen resized to the target output size (without aspect-ratio preservation).\n\nImages used during evaluation are resized (with aspect-ratio preservation) and\ncentrally cropped.\n\nAll images undergo mean color subtraction.\n\nNote that these steps are colloquially referred to as \"ResNet preprocessing,\"\nand they differ from \"VGG preprocessing,\" which does not use bounding boxes\nand instead does an aspect-preserving resize followed by random crop during\ntraining. (These both differ from \"Inception preprocessing,\" which introduces\ncolor distortion steps.)\n\n\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n_R_MEAN = 123.68\n_G_MEAN = 116.78\n_B_MEAN = 103.94\n_CHANNEL_MEANS = [_R_MEAN, _G_MEAN, _B_MEAN]\n\n The lower bound for the smallest side of the image for aspect-preserving\n resizing. For example, if an image is 500 x 1000, it will be resized to\n _RESIZE_MIN x (_RESIZE_MIN * 2).\n_RESIZE_MIN = 256\n\n\ndef _decode_crop_and_flip(image_buffer, bbox, num_channels):\n  \"\"\"Crops the given image to a random part of the image, and randomly flips.\n\n  We use the fused decode_and_crop op, which performs better than the two ops\n  used separately in series, but note that this requires that the image be\n  passed in as an un-decoded string Tensor.\n\n  Args:\n    image_buffer: scalar string Tensor representing the raw JPEG image buffer.\n    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\n      where each coordinate is [0, 1) and the coordinates are arranged as\n      [ymin, xmin, ymax, xmax].\n    num_channels: Integer depth of the image buffer for decoding.\n\n  Returns:\n    3-D tensor with cropped image.\n\n  \"\"\"\n   A large fraction of image datasets contain a human-annotated bounding box\n   delineating the region of the image containing the object of interest.  We\n   choose to create a new bounding box for the object which is a randomly\n   distorted version of the human-annotated bounding box that obeys an\n   allowed range of aspect ratios, sizes and overlap with the human-annotated\n   bounding box. If no box is supplied, then we assume the bounding box is\n   the entire image.\n  sample_distorted_bounding_box = tf.image.sample_distorted_bounding_box(\n      tf.image.extract_jpeg_shape(image_buffer),\n      bounding_boxes=bbox,\n      min_object_covered=0.1,\n      aspect_ratio_range=[0.75, 1.33],\n      area_range=[0.05, 1.0],\n      max_attempts=100,\n      use_image_if_no_bounding_boxes=True)\n  bbox_begin, bbox_size, _ = sample_distorted_bounding_box\n\n   Reassemble the bounding box in the format the crop op requires.\n  offset_y, offset_x, _ = tf.unstack(bbox_begin)\n  target_height, target_width, _ = tf.unstack(bbox_size)\n  crop_window = tf.stack([offset_y, offset_x, target_height, target_width])\n\n   Use the fused decode and crop op here, which is faster than each in series.\n  cropped = tf.image.decode_and_crop_jpeg(\n      image_buffer, crop_window, channels=num_channels)\n\n   Flip to add a little more random distortion in.\n  cropped = tf.image.random_flip_left_right(cropped)\n  return cropped\n\n\ndef _central_crop(image, crop_height, crop_width):\n  \"\"\"Performs central crops of the given image list.\n\n  Args:\n    image: a 3-D image tensor\n    crop_height: the height of the image following the crop.\n    crop_width: the width of the image following the crop.\n\n  Returns:\n    3-D tensor with cropped image.\n  \"\"\"\n  shape = tf.shape(image)\n  height, width = shape[0], shape[1]\n\n  amount_to_be_cropped_h = (height - crop_height)\n  crop_top = amount_to_be_cropped_h // 2\n  amount_to_be_cropped_w = (width - crop_width)\n  crop_left = amount_to_be_cropped_w // 2\n  return tf.slice(\n      image, [crop_top, crop_left, 0], [crop_height, crop_width, -1])\n\n\ndef _mean_image_subtraction(image, means, num_channels):\n  \"\"\"Subtracts the given means from each image channel.\n\n  For example:\n    means = [123.68, 116.779, 103.939]\n    image = _mean_image_subtraction(image, means)\n\n  Note that the rank of `image` must be known.\n\n  Args:\n    image: a tensor of size [height, width, C].\n    means: a C-vector of values to subtract from each channel.\n    num_channels: number of color channels in the image that will be distorted.\n\n  Returns:\n    the centered image.\n\n  Raises:\n    ValueError: If the rank of `image` is unknown, if `image` has a rank other\n      than three or if the number of channels in `image` doesn't match the\n      number of values in `means`.\n  \"\"\"\n  if image.get_shape().ndims != 3:\n    raise ValueError('Input must be of size [height, width, C>0]')\n\n  if len(means) != num_channels:\n    raise ValueError('len(means) must match the number of channels')\n\n   We have a 1-D tensor of means; convert to 3-D.\n  means = tf.expand_dims(tf.expand_dims(means, 0), 0)\n\n  return image - means\n\n\ndef _smallest_size_at_least(height, width, resize_min):\n  \"\"\"Computes new shape with the smallest side equal to `smallest_side`.\n\n  Computes new shape with the smallest side equal to `smallest_side` while\n  preserving the original aspect ratio.\n\n  Args:\n    height: an int32 scalar tensor indicating the current height.\n    width: an int32 scalar tensor indicating the current width.\n    resize_min: A python integer or scalar `Tensor` indicating the size of\n      the smallest side after resize.\n\n  Returns:\n    new_height: an int32 scalar tensor indicating the new height.\n    new_width: an int32 scalar tensor indicating the new width.\n  \"\"\"\n  resize_min = tf.cast(resize_min, tf.float32)\n\n   Convert to floats to make subsequent calculations go smoothly.\n  height, width = tf.cast(height, tf.float32), tf.cast(width, tf.float32)\n\n  smaller_dim = tf.minimum(height, width)\n  scale_ratio = resize_min / smaller_dim\n\n   Convert back to ints to make heights and widths that TF ops will accept.\n  new_height = tf.cast(height * scale_ratio, tf.int32)\n  new_width = tf.cast(width * scale_ratio, tf.int32)\n\n  return new_height, new_width\n\n\ndef _aspect_preserving_resize(image, resize_min):\n  \"\"\"Resize images preserving the original aspect ratio.\n\n  Args:\n    image: A 3-D image `Tensor`.\n    resize_min: A python integer or scalar `Tensor` indicating the size of\n      the smallest side after resize.\n\n  Returns:\n    resized_image: A 3-D tensor containing the resized image.\n  \"\"\"\n  shape = tf.shape(image)\n  height, width = shape[0], shape[1]\n\n  new_height, new_width = _smallest_size_at_least(height, width, resize_min)\n\n  return _resize_image(image, new_height, new_width)\n\n\ndef _resize_image(image, height, width):\n  \"\"\"Simple wrapper around tf.resize_images to make sure we use the same\n  `method` and other details each time.\n\n  Args:\n    image: A 3-D image `Tensor`.\n    height: The target height for the resized image.\n    width: The target width for the resized image.\n\n  Returns:\n    resized_image: A 3-D tensor containing the resized image. The first two\n      dimensions have the shape [height, width].\n  \"\"\"\n  return tf.image.resize_images(\n      image, [height, width], method=tf.image.ResizeMethod.BILINEAR,\n      align_corners=False)\n\ndef preprocess_image(image_buffer, bbox, output_height, output_width,\n                     num_channels, is_training=False):\n  \"\"\"Preprocesses the given image.\n\n  Preprocessing includes decoding, cropping, and resizing for both training\n  and eval images. Training preprocessing, however, introduces some random\n  distortion of the image to improve accuracy.\n\n  Args:\n    image_buffer: scalar string Tensor representing the raw JPEG image buffer.\n    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\n      where each coordinate is [0, 1) and the coordinates are arranged as\n      [ymin, xmin, ymax, xmax].\n    output_height: The height of the image after preprocessing.\n    output_width: The width of the image after preprocessing.\n    num_channels: Integer depth of the image buffer for decoding.\n    is_training: `True` if we're preprocessing the image for training and\n      `False` otherwise.\n\n  Returns:\n    A preprocessed image.\n  \"\"\"\n  if is_training:\n     For training, we want to randomize some of the distortions.\n    image = _decode_crop_and_flip(image_buffer, bbox, num_channels)\n    image = _resize_image(image, output_height, output_width)\n  else:\n     For validation, we want to decode, resize, then just crop the middle.\n    image = tf.image.decode_jpeg(image_buffer, channels=num_channels)\n    image = _aspect_preserving_resize(image, _RESIZE_MIN)\n    image = _central_crop(image, output_height, output_width)\n\n  image.set_shape([output_height, output_width, num_channels])\n\n  return _mean_image_subtraction(image, _CHANNEL_MEANS, num_channels)\n", "comments": "   provides utilities preprocess images   training images sampled using provided bounding boxes  subsequently cropped sampled bounding box  images additionally flipped randomly  resized target output size (without aspect ratio preservation)   images used evaluation resized (with aspect ratio preservation) centrally cropped   all images undergo mean color subtraction   note steps colloquially referred  resnet preprocessing   differ  vgg preprocessing   use bounding boxes instead aspect preserving resize followed random crop training  (these differ  inception preprocessing   introduces color distortion steps )         future   import absolute import   future   import division   future   import print function  import tensorflow tf   r mean   123 68  g mean   116 78  b mean   103 94  channel means     r mean   g mean   b mean     the lower bound smallest side image aspect preserving   resizing  for example  image 500 x 1000  resized    resize min x ( resize min   2)   resize min   256   def  decode crop flip(image buffer  bbox  num channels)       crops given image random part image  randomly flips     we use fused decode crop op  performs better two ops   used separately series  note requires image   passed un decoded string tensor     args      image buffer  scalar string tensor representing raw jpeg image buffer      bbox  3 d float tensor bounding boxes arranged  1  num boxes  coords        coordinate  0  1) coordinates arranged        ymin  xmin  ymax  xmax       num channels  integer depth image buffer decoding     returns      3 d tensor cropped image             a large fraction image datasets contain human annotated bounding box     delineating region image containing object interest   we     choose create new bounding box object randomly     distorted version human annotated bounding box obeys     allowed range aspect ratios  sizes overlap human annotated     bounding box  if box supplied  assume bounding box     entire image    sample distorted bounding box   tf image sample distorted bounding box(       tf image extract jpeg shape(image buffer)        bounding boxes bbox        min object covered 0 1        aspect ratio range  0 75  1 33         area range  0 05  1 0         max attempts 100        use image bounding boxes true)   bbox begin  bbox size      sample distorted bounding box      reassemble bounding box format crop op requires    offset  offset x      tf unstack(bbox begin)   target height  target width      tf unstack(bbox size)   crop window   tf stack( offset  offset x  target height  target width )      use fused decode crop op  faster series    cropped   tf image decode crop jpeg(       image buffer  crop window  channels num channels)      flip add little random distortion    cropped   tf image random flip left right(cropped)   return cropped   def  central crop(image  crop height  crop width)       performs central crops given image list     args      image  3 d image tensor     crop height  height image following crop      crop width  width image following crop     returns      3 d tensor cropped image          shape   tf shape(image)   height  width   shape 0   shape 1     amount cropped h   (height   crop height)   crop top   amount cropped h    2   amount cropped w   (width   crop width)   crop left   amount cropped w    2   return tf slice(       image   crop top  crop left  0    crop height  crop width   1 )   def  mean image subtraction(image  means  num channels)       subtracts given means image channel     for example      means    123 68  116 779  103 939      image    mean image subtraction(image  means)    note rank  image  must known     args      image  tensor size  height  width  c       means  c vector values subtract channel      num channels  number color channels image distorted     returns      centered image     raises      valueerror  if rank  image  unknown   image  rank       three number channels  image  match       number values  means           image get shape() ndims    3      raise valueerror( input must size  height  width  c 0  )    len(means)    num channels      raise valueerror( len(means) must match number channels )      we 1 d tensor means  convert 3 d    means   tf expand dims(tf expand dims(means  0)  0)    return image   means   def  smallest size least(height  width  resize min)       computes new shape smallest side equal  smallest side      computes new shape smallest side equal  smallest side    preserving original aspect ratio     args      height  int32 scalar tensor indicating current height      width  int32 scalar tensor indicating current width      resize min  a python integer scalar  tensor  indicating size       smallest side resize     returns      new height  int32 scalar tensor indicating new height      new width  int32 scalar tensor indicating new width          resize min   tf cast(resize min  tf float32)      convert floats make subsequent calculations go smoothly    height  width   tf cast(height  tf float32)  tf cast(width  tf float32)    smaller dim   tf minimum(height  width)   scale ratio   resize min   smaller dim      convert back ints make heights widths tf ops accept    new height   tf cast(height   scale ratio  tf int32)   new width   tf cast(width   scale ratio  tf int32)    return new height  new width   def  aspect preserving resize(image  resize min)       resize images preserving original aspect ratio     args      image  a 3 d image  tensor       resize min  a python integer scalar  tensor  indicating size       smallest side resize     returns      resized image  a 3 d tensor containing resized image          shape   tf shape(image)   height  width   shape 0   shape 1     new height  new width    smallest size least(height  width  resize min)    return  resize image(image  new height  new width)   def  resize image(image  height  width)       simple wrapper around tf resize images make sure use    method  details time     args      image  a 3 d image  tensor       height  the target height resized image      width  the target width resized image     returns      resized image  a 3 d tensor containing resized image  the first two       dimensions shape  height  width           return tf image resize images(       image   height  width   method tf image resizemethod bilinear        align corners false)  def preprocess image(image buffer  bbox  output height  output width                       num channels  training false)       preprocesses given image     preprocessing includes decoding  cropping  resizing training   eval images  training preprocessing  however  introduces random   distortion image improve accuracy     args      image buffer  scalar string tensor representing raw jpeg image buffer      bbox  3 d float tensor bounding boxes arranged  1  num boxes  coords        coordinate  0  1) coordinates arranged        ymin  xmin  ymax  xmax       output height  the height image preprocessing      output width  the width image preprocessing      num channels  integer depth image buffer decoding      training   true  preprocessing image training        false  otherwise     returns      a preprocessed image           copyright 2016 the tensorflow authors  all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                       the lower bound smallest side image aspect preserving    resizing  for example  image 500 x 1000  resized     resize min x ( resize min   2)     a large fraction image datasets contain human annotated bounding box    delineating region image containing object interest   we    choose create new bounding box object randomly    distorted version human annotated bounding box obeys    allowed range aspect ratios  sizes overlap human annotated    bounding box  if box supplied  assume bounding box    entire image     reassemble bounding box format crop op requires     use fused decode crop op  faster series     flip add little random distortion     we 1 d tensor means  convert 3 d     convert floats make subsequent calculations go smoothly     convert back ints make heights widths tf ops accept     for training  want randomize distortions     for validation  want decode  resize  crop middle  ", "content": "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Provides utilities to preprocess images.\n\nTraining images are sampled using the provided bounding boxes, and subsequently\ncropped to the sampled bounding box. Images are additionally flipped randomly,\nthen resized to the target output size (without aspect-ratio preservation).\n\nImages used during evaluation are resized (with aspect-ratio preservation) and\ncentrally cropped.\n\nAll images undergo mean color subtraction.\n\nNote that these steps are colloquially referred to as \"ResNet preprocessing,\"\nand they differ from \"VGG preprocessing,\" which does not use bounding boxes\nand instead does an aspect-preserving resize followed by random crop during\ntraining. (These both differ from \"Inception preprocessing,\" which introduces\ncolor distortion steps.)\n\n\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n_R_MEAN = 123.68\n_G_MEAN = 116.78\n_B_MEAN = 103.94\n_CHANNEL_MEANS = [_R_MEAN, _G_MEAN, _B_MEAN]\n\n# The lower bound for the smallest side of the image for aspect-preserving\n# resizing. For example, if an image is 500 x 1000, it will be resized to\n# _RESIZE_MIN x (_RESIZE_MIN * 2).\n_RESIZE_MIN = 256\n\n\ndef _decode_crop_and_flip(image_buffer, bbox, num_channels):\n  \"\"\"Crops the given image to a random part of the image, and randomly flips.\n\n  We use the fused decode_and_crop op, which performs better than the two ops\n  used separately in series, but note that this requires that the image be\n  passed in as an un-decoded string Tensor.\n\n  Args:\n    image_buffer: scalar string Tensor representing the raw JPEG image buffer.\n    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\n      where each coordinate is [0, 1) and the coordinates are arranged as\n      [ymin, xmin, ymax, xmax].\n    num_channels: Integer depth of the image buffer for decoding.\n\n  Returns:\n    3-D tensor with cropped image.\n\n  \"\"\"\n  # A large fraction of image datasets contain a human-annotated bounding box\n  # delineating the region of the image containing the object of interest.  We\n  # choose to create a new bounding box for the object which is a randomly\n  # distorted version of the human-annotated bounding box that obeys an\n  # allowed range of aspect ratios, sizes and overlap with the human-annotated\n  # bounding box. If no box is supplied, then we assume the bounding box is\n  # the entire image.\n  sample_distorted_bounding_box = tf.image.sample_distorted_bounding_box(\n      tf.image.extract_jpeg_shape(image_buffer),\n      bounding_boxes=bbox,\n      min_object_covered=0.1,\n      aspect_ratio_range=[0.75, 1.33],\n      area_range=[0.05, 1.0],\n      max_attempts=100,\n      use_image_if_no_bounding_boxes=True)\n  bbox_begin, bbox_size, _ = sample_distorted_bounding_box\n\n  # Reassemble the bounding box in the format the crop op requires.\n  offset_y, offset_x, _ = tf.unstack(bbox_begin)\n  target_height, target_width, _ = tf.unstack(bbox_size)\n  crop_window = tf.stack([offset_y, offset_x, target_height, target_width])\n\n  # Use the fused decode and crop op here, which is faster than each in series.\n  cropped = tf.image.decode_and_crop_jpeg(\n      image_buffer, crop_window, channels=num_channels)\n\n  # Flip to add a little more random distortion in.\n  cropped = tf.image.random_flip_left_right(cropped)\n  return cropped\n\n\ndef _central_crop(image, crop_height, crop_width):\n  \"\"\"Performs central crops of the given image list.\n\n  Args:\n    image: a 3-D image tensor\n    crop_height: the height of the image following the crop.\n    crop_width: the width of the image following the crop.\n\n  Returns:\n    3-D tensor with cropped image.\n  \"\"\"\n  shape = tf.shape(image)\n  height, width = shape[0], shape[1]\n\n  amount_to_be_cropped_h = (height - crop_height)\n  crop_top = amount_to_be_cropped_h // 2\n  amount_to_be_cropped_w = (width - crop_width)\n  crop_left = amount_to_be_cropped_w // 2\n  return tf.slice(\n      image, [crop_top, crop_left, 0], [crop_height, crop_width, -1])\n\n\ndef _mean_image_subtraction(image, means, num_channels):\n  \"\"\"Subtracts the given means from each image channel.\n\n  For example:\n    means = [123.68, 116.779, 103.939]\n    image = _mean_image_subtraction(image, means)\n\n  Note that the rank of `image` must be known.\n\n  Args:\n    image: a tensor of size [height, width, C].\n    means: a C-vector of values to subtract from each channel.\n    num_channels: number of color channels in the image that will be distorted.\n\n  Returns:\n    the centered image.\n\n  Raises:\n    ValueError: If the rank of `image` is unknown, if `image` has a rank other\n      than three or if the number of channels in `image` doesn't match the\n      number of values in `means`.\n  \"\"\"\n  if image.get_shape().ndims != 3:\n    raise ValueError('Input must be of size [height, width, C>0]')\n\n  if len(means) != num_channels:\n    raise ValueError('len(means) must match the number of channels')\n\n  # We have a 1-D tensor of means; convert to 3-D.\n  means = tf.expand_dims(tf.expand_dims(means, 0), 0)\n\n  return image - means\n\n\ndef _smallest_size_at_least(height, width, resize_min):\n  \"\"\"Computes new shape with the smallest side equal to `smallest_side`.\n\n  Computes new shape with the smallest side equal to `smallest_side` while\n  preserving the original aspect ratio.\n\n  Args:\n    height: an int32 scalar tensor indicating the current height.\n    width: an int32 scalar tensor indicating the current width.\n    resize_min: A python integer or scalar `Tensor` indicating the size of\n      the smallest side after resize.\n\n  Returns:\n    new_height: an int32 scalar tensor indicating the new height.\n    new_width: an int32 scalar tensor indicating the new width.\n  \"\"\"\n  resize_min = tf.cast(resize_min, tf.float32)\n\n  # Convert to floats to make subsequent calculations go smoothly.\n  height, width = tf.cast(height, tf.float32), tf.cast(width, tf.float32)\n\n  smaller_dim = tf.minimum(height, width)\n  scale_ratio = resize_min / smaller_dim\n\n  # Convert back to ints to make heights and widths that TF ops will accept.\n  new_height = tf.cast(height * scale_ratio, tf.int32)\n  new_width = tf.cast(width * scale_ratio, tf.int32)\n\n  return new_height, new_width\n\n\ndef _aspect_preserving_resize(image, resize_min):\n  \"\"\"Resize images preserving the original aspect ratio.\n\n  Args:\n    image: A 3-D image `Tensor`.\n    resize_min: A python integer or scalar `Tensor` indicating the size of\n      the smallest side after resize.\n\n  Returns:\n    resized_image: A 3-D tensor containing the resized image.\n  \"\"\"\n  shape = tf.shape(image)\n  height, width = shape[0], shape[1]\n\n  new_height, new_width = _smallest_size_at_least(height, width, resize_min)\n\n  return _resize_image(image, new_height, new_width)\n\n\ndef _resize_image(image, height, width):\n  \"\"\"Simple wrapper around tf.resize_images to make sure we use the same\n  `method` and other details each time.\n\n  Args:\n    image: A 3-D image `Tensor`.\n    height: The target height for the resized image.\n    width: The target width for the resized image.\n\n  Returns:\n    resized_image: A 3-D tensor containing the resized image. The first two\n      dimensions have the shape [height, width].\n  \"\"\"\n  return tf.image.resize_images(\n      image, [height, width], method=tf.image.ResizeMethod.BILINEAR,\n      align_corners=False)\n\ndef preprocess_image(image_buffer, bbox, output_height, output_width,\n                     num_channels, is_training=False):\n  \"\"\"Preprocesses the given image.\n\n  Preprocessing includes decoding, cropping, and resizing for both training\n  and eval images. Training preprocessing, however, introduces some random\n  distortion of the image to improve accuracy.\n\n  Args:\n    image_buffer: scalar string Tensor representing the raw JPEG image buffer.\n    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\n      where each coordinate is [0, 1) and the coordinates are arranged as\n      [ymin, xmin, ymax, xmax].\n    output_height: The height of the image after preprocessing.\n    output_width: The width of the image after preprocessing.\n    num_channels: Integer depth of the image buffer for decoding.\n    is_training: `True` if we're preprocessing the image for training and\n      `False` otherwise.\n\n  Returns:\n    A preprocessed image.\n  \"\"\"\n  if is_training:\n    # For training, we want to randomize some of the distortions.\n    image = _decode_crop_and_flip(image_buffer, bbox, num_channels)\n    image = _resize_image(image, output_height, output_width)\n  else:\n    # For validation, we want to decode, resize, then just crop the middle.\n    image = tf.image.decode_jpeg(image_buffer, channels=num_channels)\n    image = _aspect_preserving_resize(image, _RESIZE_MIN)\n    image = _central_crop(image, output_height, output_width)\n\n  image.set_shape([output_height, output_width, num_channels])\n\n  return _mean_image_subtraction(image, _CHANNEL_MEANS, num_channels)\n", "description": "Models and examples built with TensorFlow", "file_name": "imagenet_preprocessing.py", "id": "8b152c4bd452f9cca96f65b7c096198b", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-models/tensorflow-models-086d914/official/resnet/imagenet_preprocessing.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:59:19Z", "url": "https://github.com/tensorflow/models", "wiki": true}