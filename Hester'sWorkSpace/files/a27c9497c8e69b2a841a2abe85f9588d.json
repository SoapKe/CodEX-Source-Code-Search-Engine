{"author": "reddit-archive", "code": "\n\n License Version 1.0. (the \"License\"); you may not use this file except in\n\n\n\n\n\n\n\n Software distributed under the License is distributed on an \"AS IS\" basis,\n WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License for\n the specific language governing rights and limitations under the License.\n\n The Original Code is reddit.\n\n The Original Developer is the Initial Developer.  The Initial Developer of\n the Original Code is reddit Inc.\n\n All portions of the code written by reddit are Copyright (c) 2006-2015 reddit\n Inc. All Rights Reserved.\n\n\n\nimport os\nimport argparse\nimport mimetypes\nimport urlparse\n\nimport boto\n\n\nNEVER = 'Thu, 31 Dec 2037 23:59:59 GMT'\n\n\ndef upload(static_root, bucket_url):\n    s3 = boto.connect_s3()\n    bucket = s3.get_bucket(bucket_url.netloc, validate=False)\n\n     build a list of files already in the bucket\n    print \"checking existing files on s3...\"\n    remote_files = {key.name : key.etag.strip('\"') for key in bucket.list()}\n\n     upload local files not already in the bucket\n    for root, dirs, files in os.walk(static_root):\n        for file in files:\n            absolute_path = os.path.join(root, file)\n            relative_path = os.path.relpath(absolute_path, start=static_root)\n            key_name = os.path.join(bucket_url.path, relative_path).lstrip(\"/\")\n\n            type, encoding = mimetypes.guess_type(file)\n            if not type:\n                continue\n            headers = {}\n            headers['Expires'] = NEVER\n            headers['Content-Type'] = type\n            if encoding:\n                headers['Content-Encoding'] = encoding\n\n            key = bucket.new_key(key_name)\n            with open(absolute_path, 'rb') as f:\n                etag, base64_tag = key.compute_md5(f)\n\n                 don't upload the file if it already exists unmodified in the bucket\n                if remote_files.get(key_name, None) == etag:\n                    continue\n\n                print \"uploading\", key_name, \"to S3...\"\n                key.set_contents_from_file(\n                    f,\n                    headers=headers,\n                    policy='public-read',\n                    md5=(etag, base64_tag),\n                )\n\n    print \"all done\"\n\n\ndef s3_url(text):\n    parsed = urlparse.urlparse(text)\n    if parsed.scheme != \"s3\":\n        raise ValueError(\"not an s3 url\")\n    if parsed.params or parsed.query or parsed.fragment:\n        raise ValueError(\"params, query, and fragment not supported\")\n    return parsed\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"root\")\n    parser.add_argument(\"bucket\", type=s3_url)\n    args = parser.parse_args()\n    upload(args.root, args.bucket)\n\n\nif __name__ == \"__main__\":\n    main()\n", "comments": "   usr bin python    the contents file subject common public attribution    license version 1 0  (the  license )  may use file except    compliance license  you may obtain copy license    http   code reddit com license  the license based mozilla public    license version 1 1  sections 14 15 added cover use    software computer network provide limited attribution    original developer  in addition  exhibit a modified consistent    exhibit b        software distributed license distributed  as is  basis     without warranty of any kind  either express implied  see license    specific language governing rights limitations license        the original code reddit        the original developer initial developer   the initial developer    original code reddit inc        all portions code written reddit copyright (c) 2006 2015 reddit    inc  all rights reserved                                                                                      build list files already bucket    upload local files already bucket    upload file already exists unmodified bucket ", "content": "#!/usr/bin/python\n# The contents of this file are subject to the Common Public Attribution\n# License Version 1.0. (the \"License\"); you may not use this file except in\n# compliance with the License. You may obtain a copy of the License at\n# http://code.reddit.com/LICENSE. The License is based on the Mozilla Public\n# License Version 1.1, but Sections 14 and 15 have been added to cover use of\n# software over a computer network and provide for limited attribution for the\n# Original Developer. In addition, Exhibit A has been modified to be consistent\n# with Exhibit B.\n#\n# Software distributed under the License is distributed on an \"AS IS\" basis,\n# WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License for\n# the specific language governing rights and limitations under the License.\n#\n# The Original Code is reddit.\n#\n# The Original Developer is the Initial Developer.  The Initial Developer of\n# the Original Code is reddit Inc.\n#\n# All portions of the code written by reddit are Copyright (c) 2006-2015 reddit\n# Inc. All Rights Reserved.\n###############################################################################\n\n\nimport os\nimport argparse\nimport mimetypes\nimport urlparse\n\nimport boto\n\n\nNEVER = 'Thu, 31 Dec 2037 23:59:59 GMT'\n\n\ndef upload(static_root, bucket_url):\n    s3 = boto.connect_s3()\n    bucket = s3.get_bucket(bucket_url.netloc, validate=False)\n\n    # build a list of files already in the bucket\n    print \"checking existing files on s3...\"\n    remote_files = {key.name : key.etag.strip('\"') for key in bucket.list()}\n\n    # upload local files not already in the bucket\n    for root, dirs, files in os.walk(static_root):\n        for file in files:\n            absolute_path = os.path.join(root, file)\n            relative_path = os.path.relpath(absolute_path, start=static_root)\n            key_name = os.path.join(bucket_url.path, relative_path).lstrip(\"/\")\n\n            type, encoding = mimetypes.guess_type(file)\n            if not type:\n                continue\n            headers = {}\n            headers['Expires'] = NEVER\n            headers['Content-Type'] = type\n            if encoding:\n                headers['Content-Encoding'] = encoding\n\n            key = bucket.new_key(key_name)\n            with open(absolute_path, 'rb') as f:\n                etag, base64_tag = key.compute_md5(f)\n\n                # don't upload the file if it already exists unmodified in the bucket\n                if remote_files.get(key_name, None) == etag:\n                    continue\n\n                print \"uploading\", key_name, \"to S3...\"\n                key.set_contents_from_file(\n                    f,\n                    headers=headers,\n                    policy='public-read',\n                    md5=(etag, base64_tag),\n                )\n\n    print \"all done\"\n\n\ndef s3_url(text):\n    parsed = urlparse.urlparse(text)\n    if parsed.scheme != \"s3\":\n        raise ValueError(\"not an s3 url\")\n    if parsed.params or parsed.query or parsed.fragment:\n        raise ValueError(\"params, query, and fragment not supported\")\n    return parsed\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"root\")\n    parser.add_argument(\"bucket\", type=s3_url)\n    args = parser.parse_args()\n    upload(args.root, args.bucket)\n\n\nif __name__ == \"__main__\":\n    main()\n", "description": "historical code from reddit.com", "file_name": "upload_static_files_to_s3.py", "id": "a27c9497c8e69b2a841a2abe85f9588d", "language": "Python", "project_name": "reddit", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/reddit-archive-reddit/reddit-archive-reddit-753b174/scripts/upload_static_files_to_s3.py", "save_time": "", "source": "", "update_at": "2018-03-18T11:55:36Z", "url": "https://github.com/reddit-archive/reddit", "wiki": true}