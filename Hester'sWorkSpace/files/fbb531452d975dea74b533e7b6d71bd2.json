{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\n\n\nimport tensorflow as tf\n\nimport data_provider\nimport networks\nimport util\n\nflags = tf.flags\ntfgan = tf.contrib.gan\n\n\nflags.DEFINE_integer('batch_size', 32, 'The number of images in each batch.')\n\nflags.DEFINE_string('train_log_dir', '/tmp/mnist/',\n                    'Directory where to write event logs.')\n\nflags.DEFINE_string('dataset_dir', None, 'Location of data.')\n\nflags.DEFINE_integer('max_number_of_steps', 20000,\n                     'The maximum number of gradient steps.')\n\nflags.DEFINE_string(\n    'gan_type', 'unconditional',\n    'Either `unconditional`, `conditional`, or `infogan`.')\n\nflags.DEFINE_integer(\n    'grid_size', 5, 'Grid size for image visualization.')\n\n\nflags.DEFINE_integer(\n    'noise_dims', 64, 'Dimensions of the generator noise vector.')\n\nFLAGS = flags.FLAGS\n\n\ndef _learning_rate(gan_type):\n   First is generator learning rate, second is discriminator learning rate.\n  return {\n      'unconditional': (1e-3, 1e-4),\n      'conditional': (1e-5, 1e-4),\n      'infogan': (0.001, 9e-5),\n  }[gan_type]\n\n\ndef main(_):\n  if not tf.gfile.Exists(FLAGS.train_log_dir):\n    tf.gfile.MakeDirs(FLAGS.train_log_dir)\n\n   Force all input processing onto CPU in order to reserve the GPU for\n   the forward inference and back-propagation.\n  with tf.name_scope('inputs'):\n    with tf.device('/cpu:0'):\n      images, one_hot_labels, _ = data_provider.provide_data(\n          'train', FLAGS.batch_size, FLAGS.dataset_dir, num_threads=4)\n\n   Define the GANModel tuple. Optionally, condition the GAN on the label or\n   use an InfoGAN to learn a latent representation.\n  if FLAGS.gan_type == 'unconditional':\n    gan_model = tfgan.gan_model(\n        generator_fn=networks.unconditional_generator,\n        discriminator_fn=networks.unconditional_discriminator,\n        real_data=images,\n        generator_inputs=tf.random_normal(\n            [FLAGS.batch_size, FLAGS.noise_dims]))\n  elif FLAGS.gan_type == 'conditional':\n    noise = tf.random_normal([FLAGS.batch_size, FLAGS.noise_dims])\n    gan_model = tfgan.gan_model(\n        generator_fn=networks.conditional_generator,\n        discriminator_fn=networks.conditional_discriminator,\n        real_data=images,\n        generator_inputs=(noise, one_hot_labels))\n  elif FLAGS.gan_type == 'infogan':\n    cat_dim, cont_dim = 10, 2\n    generator_fn = functools.partial(\n        networks.infogan_generator, categorical_dim=cat_dim)\n    discriminator_fn = functools.partial(\n        networks.infogan_discriminator, categorical_dim=cat_dim,\n        continuous_dim=cont_dim)\n    unstructured_inputs, structured_inputs = util.get_infogan_noise(\n        FLAGS.batch_size, cat_dim, cont_dim, FLAGS.noise_dims)\n    gan_model = tfgan.infogan_model(\n        generator_fn=generator_fn,\n        discriminator_fn=discriminator_fn,\n        real_data=images,\n        unstructured_generator_inputs=unstructured_inputs,\n        structured_generator_inputs=structured_inputs)\n  tfgan.eval.add_gan_model_image_summaries(gan_model, FLAGS.grid_size)\n\n   Get the GANLoss tuple. You can pass a custom function, use one of the\n   already-implemented losses from the losses library, or use the defaults.\n  with tf.name_scope('loss'):\n    mutual_information_penalty_weight = (1.0 if FLAGS.gan_type == 'infogan'\n                                         else 0.0)\n    gan_loss = tfgan.gan_loss(\n        gan_model,\n        gradient_penalty_weight=1.0,\n        mutual_information_penalty_weight=mutual_information_penalty_weight,\n        add_summaries=True)\n    tfgan.eval.add_regularization_loss_summaries(gan_model)\n\n   Get the GANTrain ops using custom optimizers.\n  with tf.name_scope('train'):\n    gen_lr, dis_lr = _learning_rate(FLAGS.gan_type)\n    train_ops = tfgan.gan_train_ops(\n        gan_model,\n        gan_loss,\n        generator_optimizer=tf.train.AdamOptimizer(gen_lr, 0.5),\n        discriminator_optimizer=tf.train.AdamOptimizer(dis_lr, 0.5),\n        summarize_gradients=True,\n        aggregation_method=tf.AggregationMethod.EXPERIMENTAL_ACCUMULATE_N)\n\n   Run the alternating training loop. Skip it if no steps should be taken\n   (used for graph construction tests).\n  status_message = tf.string_join(\n      ['Starting train step: ',\n       tf.as_string(tf.train.get_or_create_global_step())],\n      name='status_message')\n  if FLAGS.max_number_of_steps == 0: return\n  tfgan.gan_train(\n      train_ops,\n      hooks=[tf.train.StopAtStepHook(num_steps=FLAGS.max_number_of_steps),\n             tf.train.LoggingTensorHook([status_message], every_n_iter=10)],\n      logdir=FLAGS.train_log_dir,\n      get_hooks_fn=tfgan.get_joint_train_hooks())\n\nif __name__ == '__main__':\n  tf.logging.set_verbosity(tf.logging.INFO)\n  tf.app.run()\n", "comments": "   trains generator mnist data        copyright 2017 the tensorflow authors  all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                       first generator learning rate  second discriminator learning rate     force input processing onto cpu order reserve gpu    forward inference back propagation     define ganmodel tuple  optionally  condition gan label    use infogan learn latent representation     get ganloss tuple  you pass custom function  use one    already implemented losses losses library  use defaults     get gantrain ops using custom optimizers     run alternating training loop  skip steps taken    (used graph construction tests)  ", "content": "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Trains a generator on MNIST data.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\n\n\nimport tensorflow as tf\n\nimport data_provider\nimport networks\nimport util\n\nflags = tf.flags\ntfgan = tf.contrib.gan\n\n\nflags.DEFINE_integer('batch_size', 32, 'The number of images in each batch.')\n\nflags.DEFINE_string('train_log_dir', '/tmp/mnist/',\n                    'Directory where to write event logs.')\n\nflags.DEFINE_string('dataset_dir', None, 'Location of data.')\n\nflags.DEFINE_integer('max_number_of_steps', 20000,\n                     'The maximum number of gradient steps.')\n\nflags.DEFINE_string(\n    'gan_type', 'unconditional',\n    'Either `unconditional`, `conditional`, or `infogan`.')\n\nflags.DEFINE_integer(\n    'grid_size', 5, 'Grid size for image visualization.')\n\n\nflags.DEFINE_integer(\n    'noise_dims', 64, 'Dimensions of the generator noise vector.')\n\nFLAGS = flags.FLAGS\n\n\ndef _learning_rate(gan_type):\n  # First is generator learning rate, second is discriminator learning rate.\n  return {\n      'unconditional': (1e-3, 1e-4),\n      'conditional': (1e-5, 1e-4),\n      'infogan': (0.001, 9e-5),\n  }[gan_type]\n\n\ndef main(_):\n  if not tf.gfile.Exists(FLAGS.train_log_dir):\n    tf.gfile.MakeDirs(FLAGS.train_log_dir)\n\n  # Force all input processing onto CPU in order to reserve the GPU for\n  # the forward inference and back-propagation.\n  with tf.name_scope('inputs'):\n    with tf.device('/cpu:0'):\n      images, one_hot_labels, _ = data_provider.provide_data(\n          'train', FLAGS.batch_size, FLAGS.dataset_dir, num_threads=4)\n\n  # Define the GANModel tuple. Optionally, condition the GAN on the label or\n  # use an InfoGAN to learn a latent representation.\n  if FLAGS.gan_type == 'unconditional':\n    gan_model = tfgan.gan_model(\n        generator_fn=networks.unconditional_generator,\n        discriminator_fn=networks.unconditional_discriminator,\n        real_data=images,\n        generator_inputs=tf.random_normal(\n            [FLAGS.batch_size, FLAGS.noise_dims]))\n  elif FLAGS.gan_type == 'conditional':\n    noise = tf.random_normal([FLAGS.batch_size, FLAGS.noise_dims])\n    gan_model = tfgan.gan_model(\n        generator_fn=networks.conditional_generator,\n        discriminator_fn=networks.conditional_discriminator,\n        real_data=images,\n        generator_inputs=(noise, one_hot_labels))\n  elif FLAGS.gan_type == 'infogan':\n    cat_dim, cont_dim = 10, 2\n    generator_fn = functools.partial(\n        networks.infogan_generator, categorical_dim=cat_dim)\n    discriminator_fn = functools.partial(\n        networks.infogan_discriminator, categorical_dim=cat_dim,\n        continuous_dim=cont_dim)\n    unstructured_inputs, structured_inputs = util.get_infogan_noise(\n        FLAGS.batch_size, cat_dim, cont_dim, FLAGS.noise_dims)\n    gan_model = tfgan.infogan_model(\n        generator_fn=generator_fn,\n        discriminator_fn=discriminator_fn,\n        real_data=images,\n        unstructured_generator_inputs=unstructured_inputs,\n        structured_generator_inputs=structured_inputs)\n  tfgan.eval.add_gan_model_image_summaries(gan_model, FLAGS.grid_size)\n\n  # Get the GANLoss tuple. You can pass a custom function, use one of the\n  # already-implemented losses from the losses library, or use the defaults.\n  with tf.name_scope('loss'):\n    mutual_information_penalty_weight = (1.0 if FLAGS.gan_type == 'infogan'\n                                         else 0.0)\n    gan_loss = tfgan.gan_loss(\n        gan_model,\n        gradient_penalty_weight=1.0,\n        mutual_information_penalty_weight=mutual_information_penalty_weight,\n        add_summaries=True)\n    tfgan.eval.add_regularization_loss_summaries(gan_model)\n\n  # Get the GANTrain ops using custom optimizers.\n  with tf.name_scope('train'):\n    gen_lr, dis_lr = _learning_rate(FLAGS.gan_type)\n    train_ops = tfgan.gan_train_ops(\n        gan_model,\n        gan_loss,\n        generator_optimizer=tf.train.AdamOptimizer(gen_lr, 0.5),\n        discriminator_optimizer=tf.train.AdamOptimizer(dis_lr, 0.5),\n        summarize_gradients=True,\n        aggregation_method=tf.AggregationMethod.EXPERIMENTAL_ACCUMULATE_N)\n\n  # Run the alternating training loop. Skip it if no steps should be taken\n  # (used for graph construction tests).\n  status_message = tf.string_join(\n      ['Starting train step: ',\n       tf.as_string(tf.train.get_or_create_global_step())],\n      name='status_message')\n  if FLAGS.max_number_of_steps == 0: return\n  tfgan.gan_train(\n      train_ops,\n      hooks=[tf.train.StopAtStepHook(num_steps=FLAGS.max_number_of_steps),\n             tf.train.LoggingTensorHook([status_message], every_n_iter=10)],\n      logdir=FLAGS.train_log_dir,\n      get_hooks_fn=tfgan.get_joint_train_hooks())\n\nif __name__ == '__main__':\n  tf.logging.set_verbosity(tf.logging.INFO)\n  tf.app.run()\n", "description": "Models and examples built with TensorFlow", "file_name": "train.py", "id": "fbb531452d975dea74b533e7b6d71bd2", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tensorflow-models/tensorflow-models-7e4c66b/research/gan/mnist/train.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:59:36Z", "url": "https://github.com/tensorflow/models", "wiki": true}