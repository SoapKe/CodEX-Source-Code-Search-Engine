{"author": "tflearn", "code": "from __future__ import division, print_function, absolute_import\n\nimport time\nimport sys\n\n\ntry:\n    from IPython.core.display import clear_output\nexcept:\n    pass\n\nCURSES_SUPPORTED = True\ntry:\n    import curses\nexcept Exception:\n    print(\"curses is not supported on this machine (please install/reinstall curses for an optimal experience)\")\n    CURSES_SUPPORTED = False\n\n\nclass Callback(object):\n    \n    def __init__(self):\n        pass\n\n    def on_train_begin(self, training_state):\n        pass\n\n    def on_epoch_begin(self, training_state):\n        pass\n\n    def on_batch_begin(self, training_state):\n        pass\n\n    def on_sub_batch_begin(self, training_state):\n        pass\n\n    def on_sub_batch_end(self, training_state, train_index=0):\n        pass\n\n    def on_batch_end(self, training_state, snapshot=False):\n        pass\n\n    def on_epoch_end(self, training_state):\n        pass\n\n    def on_train_end(self, training_state):\n        pass\n\n\nclass ChainCallback(Callback):\n    def __init__(self, callbacks=[]):\n        self.callbacks = callbacks\n\n    def on_train_begin(self, training_state):\n        for callback in self.callbacks:\n            callback.on_train_begin(training_state)\n\n    def on_epoch_begin(self, training_state):\n        for callback in self.callbacks:\n            callback.on_epoch_begin(training_state)\n\n    def on_batch_begin(self, training_state):\n        for callback in self.callbacks:\n            callback.on_batch_begin(training_state)\n\n    def on_sub_batch_begin(self, training_state):\n        for callback in self.callbacks:\n            callback.on_sub_batch_begin(training_state)\n\n    def on_sub_batch_end(self, training_state, train_index=0):\n        for callback in self.callbacks:\n            callback.on_sub_batch_end(training_state, train_index)\n\n    def on_batch_end(self, training_state, snapshot=False):\n        for callback in self.callbacks:\n            callback.on_batch_end(training_state, snapshot)\n\n    def on_epoch_end(self, training_state):\n        for callback in self.callbacks:\n            callback.on_epoch_end(training_state)\n\n    def on_train_end(self, training_state):\n        for callback in self.callbacks:\n            callback.on_train_end(training_state)\n\n    def add(self, callback):\n        if not isinstance(callback, Callback):\n            raise Exception(str(callback) + \" is an invalid Callback object\")\n\n        self.callbacks.append(callback)\n\n\nclass TermLogger(Callback):\n    def __init__(self):\n        self.data = []\n        self.has_ipython = True\n        self.display_type = \"multi\"\n        self.global_data_size = 0\n        self.global_val_data_size = 0\n        self.snapped = False\n\n        global CURSES_SUPPORTED\n        if CURSES_SUPPORTED:\n            try:\n                curses.setupterm()\n                sys.stdout.write(curses.tigetstr('civis').decode())\n            except Exception:\n                CURSES_SUPPORTED = False\n        \n        try:\n            clear_output\n        except NameError:\n            self.has_ipython = False\n\n    def add(self, data_size, val_size=0, metric_name=None, name=None):\n        if not metric_name: metric_name = 'acc'\n        self.data.append({\n            'name': name if name else \"Train op. \" + str(len(self.data)),\n            'metric_name': metric_name,\n            'data_size': data_size,\n            'epoch': 0,\n            'step': 0,\n            'val_size': val_size,\n            'loss': None,\n            'acc': None,\n            'val_loss': None,\n            'val_acc': None\n        })\n        self.global_data_size += data_size\n        self.global_val_data_size += val_size\n\n    def on_epoch_begin(self, training_state):\n        training_state.step_time = time.time()\n        training_state.step_time_total = 0.\n\n    def on_epoch_end(self, training_state):\n        pass\n\n    def on_batch_begin(self, training_state):\n        training_state.step_time = time.time()\n\n    def on_batch_end(self, training_state, snapshot=False):\n\n        training_state.step_time_total += time.time() - training_state.step_time\n        if snapshot:\n            self.snapshot_termlogs(training_state)\n        else:\n            self.print_termlogs(training_state)\n\n    def on_sub_batch_begin(self, training_state):\n        pass\n\n    def on_sub_batch_end(self, training_state, train_index=0):\n\n        self.data[train_index]['loss'] = training_state.loss_value\n        self.data[train_index]['acc'] = training_state.acc_value\n        self.data[train_index]['val_loss'] = training_state.val_loss\n        self.data[train_index]['val_acc'] = training_state.val_acc\n        self.data[train_index]['epoch'] = training_state.epoch\n        self.data[train_index]['step'] = training_state.current_iter\n\n    def on_train_begin(self, training_state):\n        print(\"---------------------------------\")\n        print(\"Training samples: \" + str(self.global_data_size))\n        print(\"Validation samples: \" + str(self.global_val_data_size))\n        print(\"--\")\n        if len(self.data) == 1:\n            self.display_type = \"single\"\n\n    def on_train_end(self, training_state):\n        \n        to_be_printed = \"\"\n        if CURSES_SUPPORTED: \n            for i in range(len(self.data) + 2):\n                to_be_printed += \"\\033[B\"\n            if not self.snapped:\n                to_be_printed += \"--\\n\"\n        sys.stdout.write(to_be_printed)\n        sys.stdout.flush()\n\n        \n        if CURSES_SUPPORTED:\n            sys.stdout.write(curses.tigetstr('cvvis').decode())\n\n    def termlogs(self, step=0, global_loss=None, global_acc=None, step_time=None):\n\n        termlogs = \"Training Step: \" + str(step) + \" \"\n        if global_loss:\n            termlogs += \" | total loss: \\033[1m\\033[32m\" + \\\n                        \"%.5f\" % global_loss + \"\\033[0m\\033[0m\"\n        if global_acc and not self.display_type == \"single\":\n            termlogs += \" - avg acc: %.4f\" % float(global_acc)\n        if step_time:\n            termlogs += \" | time: %.3fs\" % step_time\n        termlogs += \"\\n\"\n        for i, data in enumerate(self.data):\n            print_loss = \"\"\n            print_acc = \"\"\n            print_val_loss = \"\"\n            print_val_acc = \"\"\n            if data['loss'] is not None:\n                print_loss = \" | loss: \" + \"%.5f\" % data['loss']\n            if data['acc'] is not None:\n                print_acc = \" - \" + data['metric_name'] + \": \" + \\\n                            \"%.4f\" % data['acc']\n            if data['val_loss'] is not None:\n                print_val_loss = \" | val_loss: \" + \"%.5f\" % data['val_loss']\n            if data['val_acc'] is not None:\n                print_val_acc = \" - val_acc: \" + \"%.4f\" % data['val_acc']\n            \n            print_epoch = data['epoch']\n            # Smoothing display, so we show display at step + 1 to show data_size/data_size at end\n            print_step = \" -- iter: \" + \\\n                         (\"%0\" + str(len(str(data['data_size']))) +\n                          \"d\") % data['step'] + \"/\" + str(data['data_size'])\n            if data['step'] == 0:\n                print_epoch = data['epoch']\n                \n                print_step = \" -- iter: \" + (\"%0\" + str(\n                    len(str(data['data_size']))) + \"d\") % 0 \\\n                             + \"/\" + str(data['data_size'])\n            termlogs += \"\\x1b[2K\\r| \" + data['name'] + \" | epoch: \" + \\\n                        \"%03d\" % print_epoch + print_loss + print_acc + \\\n                        print_val_loss + print_val_acc + print_step + \"\\n\"\n\n        return termlogs\n\n    def print_termlogs(self, training_state):\n\n        termlogs = self.termlogs(\n            step=training_state.step,\n            global_loss=training_state.global_loss,\n            global_acc=training_state.global_acc,\n            step_time=training_state.step_time_total)\n\n        if self.has_ipython and not CURSES_SUPPORTED:\n            clear_output(wait=True)\n        else:\n            for i in range(len(self.data) + 1):\n                termlogs += \"\\033[A\"\n\n        sys.stdout.write(termlogs)\n        sys.stdout.flush()\n\n    def snapshot_termlogs(self, training_state):\n\n        termlogs = self.termlogs(\n            step=training_state.step,\n            global_loss=training_state.global_loss,\n            global_acc=training_state.global_acc,\n            step_time=training_state.step_time_total)\n\n        termlogs += \"--\\n\"\n\n        sys.stdout.write(termlogs)\n        sys.stdout.flush()\n        self.snapped = True\n\n\nclass ModelSaver(Callback):\n    def __init__(self, save_func, snapshot_path, best_snapshot_path,\n                 best_val_accuracy, snapshot_step, snapshot_epoch):\n        self.save_func = save_func\n        self.snapshot_path = snapshot_path\n        self.snapshot_epoch = snapshot_epoch\n        self.best_snapshot_path = best_snapshot_path\n        self.best_val_accuracy = best_val_accuracy\n        self.snapshot_step = snapshot_step\n\n    def on_epoch_begin(self, training_state):\n        pass\n\n    def on_epoch_end(self, training_state):\n        if self.snapshot_epoch:\n            self.save(training_state.step)\n\n    def on_batch_begin(self, training_state):\n        pass\n\n    def on_batch_end(self, training_state, snapshot=False):\n\n        if snapshot & (self.snapshot_step is not None):\n            self.save(training_state.step)\n\n        if None not in (self.best_snapshot_path, self.best_val_accuracy, training_state.val_acc):\n            if training_state.val_acc > self.best_val_accuracy:\n                self.best_val_accuracy = training_state.val_acc\n                self.save_best(int(10000 * round(training_state.val_acc, 4)))\n\n    def on_sub_batch_begin(self, training_state):\n        pass\n\n    def on_sub_batch_end(self, training_state, train_index=0):\n        pass\n\n    def on_train_begin(self, training_state):\n        pass\n\n    def on_train_end(self, training_state):\n        pass\n\n    def save(self, training_step=0):\n        if self.snapshot_path:\n            self.save_func(self.snapshot_path, training_step)\n\n    def save_best(self, val_accuracy):\n        if self.best_snapshot_path:\n            snapshot_path = self.best_snapshot_path + str(val_accuracy)\n            self.save_func(snapshot_path)\n", "comments": "    callback base class         verify curses module windows notebooks support    reset caret last position   self ipython  todo check bug    set caret visible possible    fix diplay  step reached whole epoch  display epoch   1  epoch updated    smoothing display  show display step   1 show data size data size end    print step      ", "content": "from __future__ import division, print_function, absolute_import\n\nimport time\nimport sys\n\n# Verify curses module for Windows and Notebooks Support\ntry:\n    from IPython.core.display import clear_output\nexcept:\n    pass\n\nCURSES_SUPPORTED = True\ntry:\n    import curses\nexcept Exception:\n    print(\"curses is not supported on this machine (please install/reinstall curses for an optimal experience)\")\n    CURSES_SUPPORTED = False\n\n\nclass Callback(object):\n    \"\"\" Callback base class. \"\"\"\n    def __init__(self):\n        pass\n\n    def on_train_begin(self, training_state):\n        pass\n\n    def on_epoch_begin(self, training_state):\n        pass\n\n    def on_batch_begin(self, training_state):\n        pass\n\n    def on_sub_batch_begin(self, training_state):\n        pass\n\n    def on_sub_batch_end(self, training_state, train_index=0):\n        pass\n\n    def on_batch_end(self, training_state, snapshot=False):\n        pass\n\n    def on_epoch_end(self, training_state):\n        pass\n\n    def on_train_end(self, training_state):\n        pass\n\n\nclass ChainCallback(Callback):\n    def __init__(self, callbacks=[]):\n        self.callbacks = callbacks\n\n    def on_train_begin(self, training_state):\n        for callback in self.callbacks:\n            callback.on_train_begin(training_state)\n\n    def on_epoch_begin(self, training_state):\n        for callback in self.callbacks:\n            callback.on_epoch_begin(training_state)\n\n    def on_batch_begin(self, training_state):\n        for callback in self.callbacks:\n            callback.on_batch_begin(training_state)\n\n    def on_sub_batch_begin(self, training_state):\n        for callback in self.callbacks:\n            callback.on_sub_batch_begin(training_state)\n\n    def on_sub_batch_end(self, training_state, train_index=0):\n        for callback in self.callbacks:\n            callback.on_sub_batch_end(training_state, train_index)\n\n    def on_batch_end(self, training_state, snapshot=False):\n        for callback in self.callbacks:\n            callback.on_batch_end(training_state, snapshot)\n\n    def on_epoch_end(self, training_state):\n        for callback in self.callbacks:\n            callback.on_epoch_end(training_state)\n\n    def on_train_end(self, training_state):\n        for callback in self.callbacks:\n            callback.on_train_end(training_state)\n\n    def add(self, callback):\n        if not isinstance(callback, Callback):\n            raise Exception(str(callback) + \" is an invalid Callback object\")\n\n        self.callbacks.append(callback)\n\n\nclass TermLogger(Callback):\n    def __init__(self):\n        self.data = []\n        self.has_ipython = True\n        self.display_type = \"multi\"\n        self.global_data_size = 0\n        self.global_val_data_size = 0\n        self.snapped = False\n\n        global CURSES_SUPPORTED\n        if CURSES_SUPPORTED:\n            try:\n                curses.setupterm()\n                sys.stdout.write(curses.tigetstr('civis').decode())\n            except Exception:\n                CURSES_SUPPORTED = False\n        \n        try:\n            clear_output\n        except NameError:\n            self.has_ipython = False\n\n    def add(self, data_size, val_size=0, metric_name=None, name=None):\n        if not metric_name: metric_name = 'acc'\n        self.data.append({\n            'name': name if name else \"Train op. \" + str(len(self.data)),\n            'metric_name': metric_name,\n            'data_size': data_size,\n            'epoch': 0,\n            'step': 0,\n            'val_size': val_size,\n            'loss': None,\n            'acc': None,\n            'val_loss': None,\n            'val_acc': None\n        })\n        self.global_data_size += data_size\n        self.global_val_data_size += val_size\n\n    def on_epoch_begin(self, training_state):\n        training_state.step_time = time.time()\n        training_state.step_time_total = 0.\n\n    def on_epoch_end(self, training_state):\n        pass\n\n    def on_batch_begin(self, training_state):\n        training_state.step_time = time.time()\n\n    def on_batch_end(self, training_state, snapshot=False):\n\n        training_state.step_time_total += time.time() - training_state.step_time\n        if snapshot:\n            self.snapshot_termlogs(training_state)\n        else:\n            self.print_termlogs(training_state)\n\n    def on_sub_batch_begin(self, training_state):\n        pass\n\n    def on_sub_batch_end(self, training_state, train_index=0):\n\n        self.data[train_index]['loss'] = training_state.loss_value\n        self.data[train_index]['acc'] = training_state.acc_value\n        self.data[train_index]['val_loss'] = training_state.val_loss\n        self.data[train_index]['val_acc'] = training_state.val_acc\n        self.data[train_index]['epoch'] = training_state.epoch\n        self.data[train_index]['step'] = training_state.current_iter\n\n    def on_train_begin(self, training_state):\n        print(\"---------------------------------\")\n        print(\"Training samples: \" + str(self.global_data_size))\n        print(\"Validation samples: \" + str(self.global_val_data_size))\n        print(\"--\")\n        if len(self.data) == 1:\n            self.display_type = \"single\"\n\n    def on_train_end(self, training_state):\n        # Reset caret to last position\n        to_be_printed = \"\"\n        if CURSES_SUPPORTED: #if not self.has_ipython #TODO:check bug here\n            for i in range(len(self.data) + 2):\n                to_be_printed += \"\\033[B\"\n            if not self.snapped:\n                to_be_printed += \"--\\n\"\n        sys.stdout.write(to_be_printed)\n        sys.stdout.flush()\n\n        # Set caret visible if possible\n        if CURSES_SUPPORTED:\n            sys.stdout.write(curses.tigetstr('cvvis').decode())\n\n    def termlogs(self, step=0, global_loss=None, global_acc=None, step_time=None):\n\n        termlogs = \"Training Step: \" + str(step) + \" \"\n        if global_loss:\n            termlogs += \" | total loss: \\033[1m\\033[32m\" + \\\n                        \"%.5f\" % global_loss + \"\\033[0m\\033[0m\"\n        if global_acc and not self.display_type == \"single\":\n            termlogs += \" - avg acc: %.4f\" % float(global_acc)\n        if step_time:\n            termlogs += \" | time: %.3fs\" % step_time\n        termlogs += \"\\n\"\n        for i, data in enumerate(self.data):\n            print_loss = \"\"\n            print_acc = \"\"\n            print_val_loss = \"\"\n            print_val_acc = \"\"\n            if data['loss'] is not None:\n                print_loss = \" | loss: \" + \"%.5f\" % data['loss']\n            if data['acc'] is not None:\n                print_acc = \" - \" + data['metric_name'] + \": \" + \\\n                            \"%.4f\" % data['acc']\n            if data['val_loss'] is not None:\n                print_val_loss = \" | val_loss: \" + \"%.5f\" % data['val_loss']\n            if data['val_acc'] is not None:\n                print_val_acc = \" - val_acc: \" + \"%.4f\" % data['val_acc']\n            # fix diplay, if step reached the whole epoch, display epoch - 1, as epoch has been updated\n            print_epoch = data['epoch']\n            # Smoothing display, so we show display at step + 1 to show data_size/data_size at end\n            print_step = \" -- iter: \" + \\\n                         (\"%0\" + str(len(str(data['data_size']))) +\n                          \"d\") % data['step'] + \"/\" + str(data['data_size'])\n            if data['step'] == 0:\n                print_epoch = data['epoch']\n                # print_step = \"\"\n                print_step = \" -- iter: \" + (\"%0\" + str(\n                    len(str(data['data_size']))) + \"d\") % 0 \\\n                             + \"/\" + str(data['data_size'])\n            termlogs += \"\\x1b[2K\\r| \" + data['name'] + \" | epoch: \" + \\\n                        \"%03d\" % print_epoch + print_loss + print_acc + \\\n                        print_val_loss + print_val_acc + print_step + \"\\n\"\n\n        return termlogs\n\n    def print_termlogs(self, training_state):\n\n        termlogs = self.termlogs(\n            step=training_state.step,\n            global_loss=training_state.global_loss,\n            global_acc=training_state.global_acc,\n            step_time=training_state.step_time_total)\n\n        if self.has_ipython and not CURSES_SUPPORTED:\n            clear_output(wait=True)\n        else:\n            for i in range(len(self.data) + 1):\n                termlogs += \"\\033[A\"\n\n        sys.stdout.write(termlogs)\n        sys.stdout.flush()\n\n    def snapshot_termlogs(self, training_state):\n\n        termlogs = self.termlogs(\n            step=training_state.step,\n            global_loss=training_state.global_loss,\n            global_acc=training_state.global_acc,\n            step_time=training_state.step_time_total)\n\n        termlogs += \"--\\n\"\n\n        sys.stdout.write(termlogs)\n        sys.stdout.flush()\n        self.snapped = True\n\n\nclass ModelSaver(Callback):\n    def __init__(self, save_func, snapshot_path, best_snapshot_path,\n                 best_val_accuracy, snapshot_step, snapshot_epoch):\n        self.save_func = save_func\n        self.snapshot_path = snapshot_path\n        self.snapshot_epoch = snapshot_epoch\n        self.best_snapshot_path = best_snapshot_path\n        self.best_val_accuracy = best_val_accuracy\n        self.snapshot_step = snapshot_step\n\n    def on_epoch_begin(self, training_state):\n        pass\n\n    def on_epoch_end(self, training_state):\n        if self.snapshot_epoch:\n            self.save(training_state.step)\n\n    def on_batch_begin(self, training_state):\n        pass\n\n    def on_batch_end(self, training_state, snapshot=False):\n\n        if snapshot & (self.snapshot_step is not None):\n            self.save(training_state.step)\n\n        if None not in (self.best_snapshot_path, self.best_val_accuracy, training_state.val_acc):\n            if training_state.val_acc > self.best_val_accuracy:\n                self.best_val_accuracy = training_state.val_acc\n                self.save_best(int(10000 * round(training_state.val_acc, 4)))\n\n    def on_sub_batch_begin(self, training_state):\n        pass\n\n    def on_sub_batch_end(self, training_state, train_index=0):\n        pass\n\n    def on_train_begin(self, training_state):\n        pass\n\n    def on_train_end(self, training_state):\n        pass\n\n    def save(self, training_step=0):\n        if self.snapshot_path:\n            self.save_func(self.snapshot_path, training_step)\n\n    def save_best(self, val_accuracy):\n        if self.best_snapshot_path:\n            snapshot_path = self.best_snapshot_path + str(val_accuracy)\n            self.save_func(snapshot_path)\n", "description": "Deep learning library featuring a higher-level API for TensorFlow.", "file_name": "callbacks.py", "id": "f671560d17460d0e1d1e46c1830699ec", "language": "Python", "project_name": "tflearn", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tflearn-tflearn/tflearn-tflearn-70fb38a/tflearn/callbacks.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:15:41Z", "url": "https://github.com/tflearn/tflearn", "wiki": true}