{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\nr\"\"\" Script to setup the grid moving agent.\n\nblaze build --define=ION_GFX_OGLES20=1 -c opt --copt=-mavx --config=cuda_clang \\\n    learning/brain/public/tensorflow_std_server{,_gpu} \\\n    experimental/users/saurabhgupta/navigation/cmp/scripts/script_distill.par \\\n    experimental/users/saurabhgupta/navigation/cmp/scripts/script_distill\n\n\n./blaze-bin/experimental/users/saurabhgupta/navigation/cmp/scripts/script_distill \\\n  --logdir=/cns/iq-d/home/saurabhgupta/output/stanford-distill/local/v0/ \\\n  --config_name 'v0+train' --gfs_user robot-intelligence-gpu\n\n\"\"\"\nimport sys, os, numpy as np\nimport copy\nimport argparse, pprint\nimport time\nimport cProfile\n\n\nimport tensorflow as tf\nfrom tensorflow.contrib import slim\nfrom tensorflow.python.framework import ops\nfrom tensorflow.contrib.framework.python.ops import variables \n\nimport logging\nfrom tensorflow.python.platform import gfile\nfrom tensorflow.python.platform import app\nfrom tensorflow.python.platform import flags\nfrom cfgs import config_distill\nfrom tfcode import tf_utils\nimport src.utils as utils\nimport src.file_utils as fu\nimport tfcode.distillation as distill \nimport datasets.nav_env as nav_env\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string('master', 'local',\n                    'The name of the TensorFlow master to use.')\nflags.DEFINE_integer('ps_tasks', 0, 'The number of parameter servers. If the '\n                     'value is 0, then the parameters are handled locally by '\n                     'the worker.')\nflags.DEFINE_integer('task', 0, 'The Task ID. This value is used when training '\n                     'with multiple workers to identify each worker.')\n\nflags.DEFINE_integer('num_workers', 1, '')\n\nflags.DEFINE_string('config_name', '', '')\n\nflags.DEFINE_string('logdir', '', '')\n\ndef main(_):\n  args = config_distill.get_args_for_config(FLAGS.config_name)\n  args.logdir = FLAGS.logdir\n  args.solver.num_workers = FLAGS.num_workers\n  args.solver.task = FLAGS.task\n  args.solver.ps_tasks = FLAGS.ps_tasks\n  args.solver.master = FLAGS.master\n  \n  args.buildinger.env_class = nav_env.MeshMapper\n  fu.makedirs(args.logdir)\n  args.buildinger.logdir = args.logdir\n  R = nav_env.get_multiplexor_class(args.buildinger, args.solver.task)\n  \n  if False:\n    pr = cProfile.Profile()\n    pr.enable()\n    rng = np.random.RandomState(0)\n    for i in range(1):\n      b, instances_perturbs = R.sample_building(rng)\n      inputs = b.worker(*(instances_perturbs))\n      for j in range(inputs['imgs'].shape[0]):\n        p = os.path.join('tmp', '{:d}.png'.format(j))\n        img = inputs['imgs'][j,0,:,:,:3]*1\n        img = (img).astype(np.uint8)\n        fu.write_image(p, img)\n      print(inputs['imgs'].shape)\n      inputs = R.pre(inputs)\n    pr.disable()\n    pr.print_stats(2)\n\n  if args.control.train:\n    if not gfile.Exists(args.logdir):\n      gfile.MakeDirs(args.logdir)\n   \n    m = utils.Foo()\n    m.tf_graph = tf.Graph()\n    \n    config = tf.ConfigProto()\n    config.device_count['GPU'] = 1\n    config.gpu_options.allow_growth = True\n    config.gpu_options.per_process_gpu_memory_fraction = 0.8\n    \n    with m.tf_graph.as_default():\n      with tf.device(tf.train.replica_device_setter(args.solver.ps_tasks)):\n        m = distill.setup_to_run(m, args, is_training=True,\n                                batch_norm_is_training=True)\n\n        train_step_kwargs = distill.setup_train_step_kwargs_mesh(\n            m, R, os.path.join(args.logdir, 'train'),\n            rng_seed=args.solver.task, is_chief=args.solver.task==0, iters=1,\n            train_display_interval=args.summary.display_interval)\n\n        final_loss = slim.learning.train(\n            train_op=m.train_op,\n            logdir=args.logdir,\n            master=args.solver.master,\n            is_chief=args.solver.task == 0,\n            number_of_steps=args.solver.max_steps,\n            train_step_fn=tf_utils.train_step_custom,\n            train_step_kwargs=train_step_kwargs,\n            global_step=m.global_step_op,\n            init_op=m.init_op,\n            init_fn=m.init_fn,\n            sync_optimizer=m.sync_optimizer,\n            saver=m.saver_op,\n            summary_op=None, session_config=config)\n \n  if args.control.test:\n    m = utils.Foo()\n    m.tf_graph = tf.Graph()\n    checkpoint_dir = os.path.join(format(args.logdir))\n    with m.tf_graph.as_default():\n      m = distill.setup_to_run(m, args, is_training=False,\n                              batch_norm_is_training=args.control.force_batchnorm_is_training_at_test)\n      \n      train_step_kwargs = distill.setup_train_step_kwargs_mesh(\n          m, R, os.path.join(args.logdir, args.control.test_name),\n          rng_seed=args.solver.task+1, is_chief=args.solver.task==0,\n          iters=args.summary.test_iters, train_display_interval=None)\n      \n      sv = slim.learning.supervisor.Supervisor(\n          graph=ops.get_default_graph(), logdir=None, init_op=m.init_op,\n          summary_op=None, summary_writer=None, global_step=None, saver=m.saver_op)\n\n      last_checkpoint = None\n      while True:\n        last_checkpoint = slim.evaluation.wait_for_new_checkpoint(checkpoint_dir, last_checkpoint)\n        checkpoint_iter = int(os.path.basename(last_checkpoint).split('-')[1])\n        start = time.time()\n        logging.info('Starting evaluation at %s using checkpoint %s.', \n                     time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime()),\n                     last_checkpoint)\n        \n        config = tf.ConfigProto()\n        config.device_count['GPU'] = 1\n        config.gpu_options.allow_growth = True\n        config.gpu_options.per_process_gpu_memory_fraction = 0.8\n        \n        with sv.managed_session(args.solver.master,config=config,\n                                start_standard_services=False) as sess:\n          sess.run(m.init_op)\n          sv.saver.restore(sess, last_checkpoint)\n          sv.start_queue_runners(sess)\n          vals, _ = tf_utils.train_step_custom(\n              sess, None, m.global_step_op, train_step_kwargs, mode='val')\n          if checkpoint_iter >= args.solver.max_steps:\n            break\n\nif __name__ == '__main__':\n  app.run()\n", "comments": "    script setup grid moving agent   blaze build   define ion gfx ogles20 1  c opt   copt  mavx   config cuda clang       learning brain public tensorflow std server   gpu        experimental users saurabhgupta navigation cmp scripts script distill par       experimental users saurabhgupta navigation cmp scripts script distill     blaze bin experimental users saurabhgupta navigation cmp scripts script distill       logdir  cns iq home saurabhgupta output stanford distill local v0        config name  v0 train    gfs user robot intelligence gpu         copyright 2016 the tensorflow authors all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                    ", "content": "# Copyright 2016 The TensorFlow Authors All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nr\"\"\" Script to setup the grid moving agent.\n\nblaze build --define=ION_GFX_OGLES20=1 -c opt --copt=-mavx --config=cuda_clang \\\n    learning/brain/public/tensorflow_std_server{,_gpu} \\\n    experimental/users/saurabhgupta/navigation/cmp/scripts/script_distill.par \\\n    experimental/users/saurabhgupta/navigation/cmp/scripts/script_distill\n\n\n./blaze-bin/experimental/users/saurabhgupta/navigation/cmp/scripts/script_distill \\\n  --logdir=/cns/iq-d/home/saurabhgupta/output/stanford-distill/local/v0/ \\\n  --config_name 'v0+train' --gfs_user robot-intelligence-gpu\n\n\"\"\"\nimport sys, os, numpy as np\nimport copy\nimport argparse, pprint\nimport time\nimport cProfile\n\n\nimport tensorflow as tf\nfrom tensorflow.contrib import slim\nfrom tensorflow.python.framework import ops\nfrom tensorflow.contrib.framework.python.ops import variables \n\nimport logging\nfrom tensorflow.python.platform import gfile\nfrom tensorflow.python.platform import app\nfrom tensorflow.python.platform import flags\nfrom cfgs import config_distill\nfrom tfcode import tf_utils\nimport src.utils as utils\nimport src.file_utils as fu\nimport tfcode.distillation as distill \nimport datasets.nav_env as nav_env\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string('master', 'local',\n                    'The name of the TensorFlow master to use.')\nflags.DEFINE_integer('ps_tasks', 0, 'The number of parameter servers. If the '\n                     'value is 0, then the parameters are handled locally by '\n                     'the worker.')\nflags.DEFINE_integer('task', 0, 'The Task ID. This value is used when training '\n                     'with multiple workers to identify each worker.')\n\nflags.DEFINE_integer('num_workers', 1, '')\n\nflags.DEFINE_string('config_name', '', '')\n\nflags.DEFINE_string('logdir', '', '')\n\ndef main(_):\n  args = config_distill.get_args_for_config(FLAGS.config_name)\n  args.logdir = FLAGS.logdir\n  args.solver.num_workers = FLAGS.num_workers\n  args.solver.task = FLAGS.task\n  args.solver.ps_tasks = FLAGS.ps_tasks\n  args.solver.master = FLAGS.master\n  \n  args.buildinger.env_class = nav_env.MeshMapper\n  fu.makedirs(args.logdir)\n  args.buildinger.logdir = args.logdir\n  R = nav_env.get_multiplexor_class(args.buildinger, args.solver.task)\n  \n  if False:\n    pr = cProfile.Profile()\n    pr.enable()\n    rng = np.random.RandomState(0)\n    for i in range(1):\n      b, instances_perturbs = R.sample_building(rng)\n      inputs = b.worker(*(instances_perturbs))\n      for j in range(inputs['imgs'].shape[0]):\n        p = os.path.join('tmp', '{:d}.png'.format(j))\n        img = inputs['imgs'][j,0,:,:,:3]*1\n        img = (img).astype(np.uint8)\n        fu.write_image(p, img)\n      print(inputs['imgs'].shape)\n      inputs = R.pre(inputs)\n    pr.disable()\n    pr.print_stats(2)\n\n  if args.control.train:\n    if not gfile.Exists(args.logdir):\n      gfile.MakeDirs(args.logdir)\n   \n    m = utils.Foo()\n    m.tf_graph = tf.Graph()\n    \n    config = tf.ConfigProto()\n    config.device_count['GPU'] = 1\n    config.gpu_options.allow_growth = True\n    config.gpu_options.per_process_gpu_memory_fraction = 0.8\n    \n    with m.tf_graph.as_default():\n      with tf.device(tf.train.replica_device_setter(args.solver.ps_tasks)):\n        m = distill.setup_to_run(m, args, is_training=True,\n                                batch_norm_is_training=True)\n\n        train_step_kwargs = distill.setup_train_step_kwargs_mesh(\n            m, R, os.path.join(args.logdir, 'train'),\n            rng_seed=args.solver.task, is_chief=args.solver.task==0, iters=1,\n            train_display_interval=args.summary.display_interval)\n\n        final_loss = slim.learning.train(\n            train_op=m.train_op,\n            logdir=args.logdir,\n            master=args.solver.master,\n            is_chief=args.solver.task == 0,\n            number_of_steps=args.solver.max_steps,\n            train_step_fn=tf_utils.train_step_custom,\n            train_step_kwargs=train_step_kwargs,\n            global_step=m.global_step_op,\n            init_op=m.init_op,\n            init_fn=m.init_fn,\n            sync_optimizer=m.sync_optimizer,\n            saver=m.saver_op,\n            summary_op=None, session_config=config)\n \n  if args.control.test:\n    m = utils.Foo()\n    m.tf_graph = tf.Graph()\n    checkpoint_dir = os.path.join(format(args.logdir))\n    with m.tf_graph.as_default():\n      m = distill.setup_to_run(m, args, is_training=False,\n                              batch_norm_is_training=args.control.force_batchnorm_is_training_at_test)\n      \n      train_step_kwargs = distill.setup_train_step_kwargs_mesh(\n          m, R, os.path.join(args.logdir, args.control.test_name),\n          rng_seed=args.solver.task+1, is_chief=args.solver.task==0,\n          iters=args.summary.test_iters, train_display_interval=None)\n      \n      sv = slim.learning.supervisor.Supervisor(\n          graph=ops.get_default_graph(), logdir=None, init_op=m.init_op,\n          summary_op=None, summary_writer=None, global_step=None, saver=m.saver_op)\n\n      last_checkpoint = None\n      while True:\n        last_checkpoint = slim.evaluation.wait_for_new_checkpoint(checkpoint_dir, last_checkpoint)\n        checkpoint_iter = int(os.path.basename(last_checkpoint).split('-')[1])\n        start = time.time()\n        logging.info('Starting evaluation at %s using checkpoint %s.', \n                     time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime()),\n                     last_checkpoint)\n        \n        config = tf.ConfigProto()\n        config.device_count['GPU'] = 1\n        config.gpu_options.allow_growth = True\n        config.gpu_options.per_process_gpu_memory_fraction = 0.8\n        \n        with sv.managed_session(args.solver.master,config=config,\n                                start_standard_services=False) as sess:\n          sess.run(m.init_op)\n          sv.saver.restore(sess, last_checkpoint)\n          sv.start_queue_runners(sess)\n          vals, _ = tf_utils.train_step_custom(\n              sess, None, m.global_step_op, train_step_kwargs, mode='val')\n          if checkpoint_iter >= args.solver.max_steps:\n            break\n\nif __name__ == '__main__':\n  app.run()\n", "description": "Models and examples built with TensorFlow", "file_name": "script_distill.py", "id": "18deef049abb02398e37c6d80cad99ef", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tensorflow-models/tensorflow-models-7e4c66b/research/cognitive_mapping_and_planning/scripts/script_distill.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:59:36Z", "url": "https://github.com/tensorflow/models", "wiki": true}