{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\nimport os\nimport glob\nimport numpy as np\nimport logging\nimport cPickle\nfrom datasets import nav_env\nfrom datasets import factory\nfrom src import utils \nfrom src import map_utils as mu\n\nlogging.basicConfig(level=logging.INFO)\nDATA_DIR = 'data/stanford_building_parser_dataset_raw/'\n\nmkdir_if_missing = utils.mkdir_if_missing\nsave_variables = utils.save_variables\n\ndef _get_semantic_maps(building_name, transform, map_, flip, cats):\n  rooms = get_room_in_building(building_name)\n  maps = []\n  for cat in cats:\n    maps.append(np.zeros((map_.size[1], map_.size[0])))\n  \n  for r in rooms:\n    room = load_room(building_name, r, category_list=cats)\n    classes = room['class_id']\n    for i, cat in enumerate(cats):\n      c_ind = cats.index(cat)\n      ind = [_ for _, c in enumerate(classes) if c == c_ind]\n      if len(ind) > 0:\n        vs = [room['vertexs'][x]*1 for x in ind]\n        vs = np.concatenate(vs, axis=0)\n        if transform:\n          vs = np.array([vs[:,1], vs[:,0], vs[:,2]]).T\n          vs[:,0] = -vs[:,0]\n          vs[:,1] += 4.20\n          vs[:,0] += 6.20\n        vs = vs*100.\n        if flip:\n          vs[:,1] = -vs[:,1]\n        maps[i] = maps[i] + \\\n            mu._project_to_map(map_, vs, ignore_points_outside_map=True)\n  return maps\n\ndef _map_building_name(building_name):\n  b = int(building_name.split('_')[0][4])\n  out_name = 'Area_{:d}'.format(b)\n  if b == 5:\n    if int(building_name.split('_')[0][5]) == 1:\n      transform = True\n    else:\n      transform = False\n  else:\n    transform = False\n  return out_name, transform\n\ndef get_categories():\n  cats = ['beam', 'board', 'bookcase', 'ceiling', 'chair', 'clutter', 'column',\n          'door', 'floor', 'sofa', 'table', 'wall', 'window']\n  return cats\n\ndef _write_map_files(b_in, b_out, transform):\n  cats = get_categories()\n\n  env = utils.Foo(padding=10, resolution=5, num_point_threshold=2,\n                  valid_min=-10, valid_max=200, n_samples_per_face=200)\n  robot = utils.Foo(radius=15, base=10, height=140, sensor_height=120,\n                    camera_elevation_degree=-15)\n  \n  building_loader = factory.get_dataset('sbpd')\n  for flip in [False, True]:\n    b = nav_env.Building(b_out, robot, env, flip=flip,\n                         building_loader=building_loader)\n    logging.info(\"building_in: %s, building_out: %s, transform: %d\", b_in,\n                 b_out, transform)\n    maps = _get_semantic_maps(b_in, transform, b.map, flip, cats)\n    maps = np.transpose(np.array(maps), axes=[1,2,0])\n\n      Load file from the cache.\n    file_name = '{:s}_{:d}_{:d}_{:d}_{:d}_{:d}_{:d}.pkl'\n    file_name = file_name.format(b.building_name, b.map.size[0], b.map.size[1],\n                                 b.map.origin[0], b.map.origin[1],\n                                 b.map.resolution, flip)\n    out_file = os.path.join(DATA_DIR, 'processing', 'class-maps', file_name)\n    logging.info('Writing semantic maps to %s.', out_file)\n    save_variables(out_file, [maps, cats], ['maps', 'cats'], overwrite=True)\n\ndef _transform_area5b(room_dimension):\n  for a in room_dimension.keys():\n    r = room_dimension[a]*1\n    r[[0,1,3,4]] = r[[1,0,4,3]]\n    r[[0,3]] = -r[[3,0]]\n    r[[1,4]] += 4.20\n    r[[0,3]] += 6.20\n    room_dimension[a] = r\n  return room_dimension\n\ndef collect_room(building_name, room_name):\n  room_dir = os.path.join(DATA_DIR, 'Stanford3dDataset_v1.2', building_name,\n                          room_name, 'Annotations')\n  files = glob.glob1(room_dir, '*.txt')\n  files = sorted(files, key=lambda s: s.lower())\n  vertexs = []; colors = [];\n  for f in files:\n    file_name = os.path.join(room_dir, f)\n    logging.info('  %s', file_name)\n    a = np.loadtxt(file_name)\n    vertex = a[:,:3]*1.\n    color = a[:,3:]*1\n    color = color.astype(np.uint8)\n    vertexs.append(vertex)\n    colors.append(color)\n  files = [f.split('.')[0] for f in files]\n  out = {'vertexs': vertexs, 'colors': colors, 'names': files}\n  return out\n\ndef load_room(building_name, room_name, category_list=None):\n  room = collect_room(building_name, room_name)\n  room['building_name'] = building_name\n  room['room_name']     = room_name\n  instance_id = range(len(room['names']))\n  room['instance_id'] = instance_id\n  if category_list is not None:\n    name = [r.split('_')[0] for r in room['names']]\n    class_id = []\n    for n in name:\n      if n in category_list:\n        class_id.append(category_list.index(n))\n      else:\n        class_id.append(len(category_list))\n    room['class_id'] = class_id\n    room['category_list'] = category_list\n  return room\n\ndef get_room_in_building(building_name):\n  building_dir = os.path.join(DATA_DIR, 'Stanford3dDataset_v1.2', building_name)\n  rn = os.listdir(building_dir)\n  rn = [x for x in rn if os.path.isdir(os.path.join(building_dir, x))]\n  rn = sorted(rn, key=lambda s: s.lower())\n  return rn\n\ndef write_room_dimensions(b_in, b_out, transform):\n  rooms = get_room_in_building(b_in)\n  room_dimension = {}\n  for r in rooms:\n    room = load_room(b_in, r, category_list=None)\n    vertex = np.concatenate(room['vertexs'], axis=0)\n    room_dimension[r] = np.concatenate((np.min(vertex, axis=0), np.max(vertex, axis=0)), axis=0)\n  if transform == 1:\n    room_dimension = _transform_area5b(room_dimension)\n  \n  out_file = os.path.join(DATA_DIR, 'processing', 'room-dimension', b_out+'.pkl')\n  save_variables(out_file, [room_dimension], ['room_dimension'], overwrite=True)\n\ndef write_room_dimensions_all(I):\n  mkdir_if_missing(os.path.join(DATA_DIR, 'processing', 'room-dimension'))\n  bs_in = ['Area_1', 'Area_2', 'Area_3', 'Area_4', 'Area_5', 'Area_5', 'Area_6']\n  bs_out = ['area1', 'area2', 'area3', 'area4', 'area5a', 'area5b', 'area6']\n  transforms = [0, 0, 0, 0, 0, 1, 0]\n  \n  for i in I:\n    b_in = bs_in[i]\n    b_out = bs_out[i]\n    t = transforms[i]\n    write_room_dimensions(b_in, b_out, t)\n\ndef write_class_maps_all(I):\n  mkdir_if_missing(os.path.join(DATA_DIR, 'processing', 'class-maps'))\n  bs_in = ['Area_1', 'Area_2', 'Area_3', 'Area_4', 'Area_5', 'Area_5', 'Area_6']\n  bs_out = ['area1', 'area2', 'area3', 'area4', 'area5a', 'area5b', 'area6']\n  transforms = [0, 0, 0, 0, 0, 1, 0]\n  \n  for i in I:\n    b_in = bs_in[i]\n    b_out = bs_out[i]\n    t = transforms[i]\n    _write_map_files(b_in, b_out, t)\n\n\nif __name__ == '__main__':\n  write_room_dimensions_all([0, 2, 3, 4, 5, 6])\n  write_class_maps_all([0, 2, 3, 4, 5, 6])\n\n", "comments": "  copyright 2016 the tensorflow authors all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                        load file cache  ", "content": "# Copyright 2016 The TensorFlow Authors All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport glob\nimport numpy as np\nimport logging\nimport cPickle\nfrom datasets import nav_env\nfrom datasets import factory\nfrom src import utils \nfrom src import map_utils as mu\n\nlogging.basicConfig(level=logging.INFO)\nDATA_DIR = 'data/stanford_building_parser_dataset_raw/'\n\nmkdir_if_missing = utils.mkdir_if_missing\nsave_variables = utils.save_variables\n\ndef _get_semantic_maps(building_name, transform, map_, flip, cats):\n  rooms = get_room_in_building(building_name)\n  maps = []\n  for cat in cats:\n    maps.append(np.zeros((map_.size[1], map_.size[0])))\n  \n  for r in rooms:\n    room = load_room(building_name, r, category_list=cats)\n    classes = room['class_id']\n    for i, cat in enumerate(cats):\n      c_ind = cats.index(cat)\n      ind = [_ for _, c in enumerate(classes) if c == c_ind]\n      if len(ind) > 0:\n        vs = [room['vertexs'][x]*1 for x in ind]\n        vs = np.concatenate(vs, axis=0)\n        if transform:\n          vs = np.array([vs[:,1], vs[:,0], vs[:,2]]).T\n          vs[:,0] = -vs[:,0]\n          vs[:,1] += 4.20\n          vs[:,0] += 6.20\n        vs = vs*100.\n        if flip:\n          vs[:,1] = -vs[:,1]\n        maps[i] = maps[i] + \\\n            mu._project_to_map(map_, vs, ignore_points_outside_map=True)\n  return maps\n\ndef _map_building_name(building_name):\n  b = int(building_name.split('_')[0][4])\n  out_name = 'Area_{:d}'.format(b)\n  if b == 5:\n    if int(building_name.split('_')[0][5]) == 1:\n      transform = True\n    else:\n      transform = False\n  else:\n    transform = False\n  return out_name, transform\n\ndef get_categories():\n  cats = ['beam', 'board', 'bookcase', 'ceiling', 'chair', 'clutter', 'column',\n          'door', 'floor', 'sofa', 'table', 'wall', 'window']\n  return cats\n\ndef _write_map_files(b_in, b_out, transform):\n  cats = get_categories()\n\n  env = utils.Foo(padding=10, resolution=5, num_point_threshold=2,\n                  valid_min=-10, valid_max=200, n_samples_per_face=200)\n  robot = utils.Foo(radius=15, base=10, height=140, sensor_height=120,\n                    camera_elevation_degree=-15)\n  \n  building_loader = factory.get_dataset('sbpd')\n  for flip in [False, True]:\n    b = nav_env.Building(b_out, robot, env, flip=flip,\n                         building_loader=building_loader)\n    logging.info(\"building_in: %s, building_out: %s, transform: %d\", b_in,\n                 b_out, transform)\n    maps = _get_semantic_maps(b_in, transform, b.map, flip, cats)\n    maps = np.transpose(np.array(maps), axes=[1,2,0])\n\n    #  Load file from the cache.\n    file_name = '{:s}_{:d}_{:d}_{:d}_{:d}_{:d}_{:d}.pkl'\n    file_name = file_name.format(b.building_name, b.map.size[0], b.map.size[1],\n                                 b.map.origin[0], b.map.origin[1],\n                                 b.map.resolution, flip)\n    out_file = os.path.join(DATA_DIR, 'processing', 'class-maps', file_name)\n    logging.info('Writing semantic maps to %s.', out_file)\n    save_variables(out_file, [maps, cats], ['maps', 'cats'], overwrite=True)\n\ndef _transform_area5b(room_dimension):\n  for a in room_dimension.keys():\n    r = room_dimension[a]*1\n    r[[0,1,3,4]] = r[[1,0,4,3]]\n    r[[0,3]] = -r[[3,0]]\n    r[[1,4]] += 4.20\n    r[[0,3]] += 6.20\n    room_dimension[a] = r\n  return room_dimension\n\ndef collect_room(building_name, room_name):\n  room_dir = os.path.join(DATA_DIR, 'Stanford3dDataset_v1.2', building_name,\n                          room_name, 'Annotations')\n  files = glob.glob1(room_dir, '*.txt')\n  files = sorted(files, key=lambda s: s.lower())\n  vertexs = []; colors = [];\n  for f in files:\n    file_name = os.path.join(room_dir, f)\n    logging.info('  %s', file_name)\n    a = np.loadtxt(file_name)\n    vertex = a[:,:3]*1.\n    color = a[:,3:]*1\n    color = color.astype(np.uint8)\n    vertexs.append(vertex)\n    colors.append(color)\n  files = [f.split('.')[0] for f in files]\n  out = {'vertexs': vertexs, 'colors': colors, 'names': files}\n  return out\n\ndef load_room(building_name, room_name, category_list=None):\n  room = collect_room(building_name, room_name)\n  room['building_name'] = building_name\n  room['room_name']     = room_name\n  instance_id = range(len(room['names']))\n  room['instance_id'] = instance_id\n  if category_list is not None:\n    name = [r.split('_')[0] for r in room['names']]\n    class_id = []\n    for n in name:\n      if n in category_list:\n        class_id.append(category_list.index(n))\n      else:\n        class_id.append(len(category_list))\n    room['class_id'] = class_id\n    room['category_list'] = category_list\n  return room\n\ndef get_room_in_building(building_name):\n  building_dir = os.path.join(DATA_DIR, 'Stanford3dDataset_v1.2', building_name)\n  rn = os.listdir(building_dir)\n  rn = [x for x in rn if os.path.isdir(os.path.join(building_dir, x))]\n  rn = sorted(rn, key=lambda s: s.lower())\n  return rn\n\ndef write_room_dimensions(b_in, b_out, transform):\n  rooms = get_room_in_building(b_in)\n  room_dimension = {}\n  for r in rooms:\n    room = load_room(b_in, r, category_list=None)\n    vertex = np.concatenate(room['vertexs'], axis=0)\n    room_dimension[r] = np.concatenate((np.min(vertex, axis=0), np.max(vertex, axis=0)), axis=0)\n  if transform == 1:\n    room_dimension = _transform_area5b(room_dimension)\n  \n  out_file = os.path.join(DATA_DIR, 'processing', 'room-dimension', b_out+'.pkl')\n  save_variables(out_file, [room_dimension], ['room_dimension'], overwrite=True)\n\ndef write_room_dimensions_all(I):\n  mkdir_if_missing(os.path.join(DATA_DIR, 'processing', 'room-dimension'))\n  bs_in = ['Area_1', 'Area_2', 'Area_3', 'Area_4', 'Area_5', 'Area_5', 'Area_6']\n  bs_out = ['area1', 'area2', 'area3', 'area4', 'area5a', 'area5b', 'area6']\n  transforms = [0, 0, 0, 0, 0, 1, 0]\n  \n  for i in I:\n    b_in = bs_in[i]\n    b_out = bs_out[i]\n    t = transforms[i]\n    write_room_dimensions(b_in, b_out, t)\n\ndef write_class_maps_all(I):\n  mkdir_if_missing(os.path.join(DATA_DIR, 'processing', 'class-maps'))\n  bs_in = ['Area_1', 'Area_2', 'Area_3', 'Area_4', 'Area_5', 'Area_5', 'Area_6']\n  bs_out = ['area1', 'area2', 'area3', 'area4', 'area5a', 'area5b', 'area6']\n  transforms = [0, 0, 0, 0, 0, 1, 0]\n  \n  for i in I:\n    b_in = bs_in[i]\n    b_out = bs_out[i]\n    t = transforms[i]\n    _write_map_files(b_in, b_out, t)\n\n\nif __name__ == '__main__':\n  write_room_dimensions_all([0, 2, 3, 4, 5, 6])\n  write_class_maps_all([0, 2, 3, 4, 5, 6])\n\n", "description": "Models and examples built with TensorFlow", "file_name": "script_preprocess_annoations_S3DIS.py", "id": "dad9af40a887fcd59c0ef111e9452682", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tensorflow-models/tensorflow-models-7e4c66b/research/cognitive_mapping_and_planning/scripts/script_preprocess_annoations_S3DIS.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:59:36Z", "url": "https://github.com/tensorflow/models", "wiki": true}