{"author": "openai", "code": "import logging\nimport pytest\n\nimport gym\nimport numpy as np\nfrom PIL import Image\nfrom gym import spaces\nfrom universe import wrappers\nfrom universe.envs.vnc_core_env import translator\n\ndef show(obs):\n    Image.fromarray(obs).show()\n\nclass AtariMatcher(object):\n    def translator(self, env):\n        return translator.AtariTranslator(env)\n\n    def crop(self, obs):\n        return obs[20:210, :160, :]\n\n    def assert_match(self, obs, vnc_obs, extra_info=None, stage=None):\n        \n        vnc_obs_cropped = self.crop(vnc_obs)\n        obs_cropped = self.crop(obs)\n\n        if not np.all(vnc_obs_cropped == obs_cropped):\n            show(vnc_obs_cropped)\n            show(obs_cropped)\n            show(vnc_obs_cropped - obs_cropped)\n            assert False, '[{}] Observations do not match: vnc_obs_cropped={} obs_cropped={} extra_info={}'.format(stage, vnc_obs_cropped, obs_cropped, extra_info)\n\n\ndef atari_vnc_wrapper(env):\n    env = wrappers.Vision(env)\n    env = wrappers.GymCoreAction(env)\n    return env\n\nclass CartPoleLowDMatcher(object):\n    def translator(self, env):\n        return translator.CartPoleTranslator(env)\n\n    def assert_match(self, obs, vnc_obs, extra_info=None, stage=None):\n        assert np.all(np.isclose(obs, vnc_obs)), '[{}] Observations do not match: vnc_obs={} obs={}'.format(stage, vnc_obs, obs)\n\ndef reset(matcher, env, vnc_env, stage=None):\n    obs = env.reset()\n    vnc_obs = vnc_env.reset()\n    matcher.assert_match(obs, vnc_obs, stage=stage)\n\ndef rollout(matcher, env, vnc_env, timestep_limit=None, stage=None):\n    count = 0\n    actions = matcher.translator(env)\n\n    done = None\n    while True:\n        action = env.action_space.sample()\n\n        obs, reward, done, info = env.step(action)\n        if done:\n            \n            obs = env.reset()\n\n        vnc_obs, vnc_reward, vnc_done, vnc_info = vnc_env.step(action)\n        assert reward == vnc_reward\n        assert done == vnc_done\n        assert vnc_info['stats.reward.count'] == 1\n        matcher.assert_match(obs, vnc_obs, {'reward': reward, 'done': done}, stage=stage)\n\n        count += 1\n        if done or (timestep_limit is not None and count >= timestep_limit):\n            break\n\n\nspecs = [\n    (gym.spec('gym-core.PongDeterministicSync-v3'), AtariMatcher(), atari_vnc_wrapper),\n    (gym.spec('gym-core.PitfallDeterministicSync-v3'), AtariMatcher(), atari_vnc_wrapper),\n\n    \n    \n#    (gym.spec('gym-core.CartPoleLowDSync-v0'), CartPoleLowDMatcher())\n]\n\n@pytest.mark.parametrize(\"spec,matcher,wrapper\", specs)\ndef test_nice_vnc_semantics_match(spec, matcher, wrapper):\n    \n    \n    gym.undo_logger_setup()\n    logging.getLogger().setLevel(logging.INFO)\n\n    spaces.seed(0)\n\n    vnc_env = spec.make()\n    if vnc_env.metadata.get('configure.required', False):\n        vnc_env.configure(remotes=1)\n    vnc_env = wrapper(vnc_env)\n    vnc_env = wrappers.Unvectorize(vnc_env)\n\n    env = gym.make(spec._kwargs['gym_core_id'])\n\n    env.seed(0)\n    vnc_env.seed(0)\n\n    \n    reset(matcher, env, vnc_env, stage='initial reset')\n\n    \n    rollout(matcher, env, vnc_env, timestep_limit=50, stage='50 steps')\n\n    \n    reset(matcher, env, vnc_env, stage='reset to new episode')\n\n    \n    rollout(matcher, env, vnc_env, timestep_limit=1, stage='1 step in new episode')\n\n    \n    env.seed(1)\n    vnc_env.seed(1)\n    reset(matcher, env, vnc_env, 'reseeded reset')\n    rollout(matcher, env, vnc_env, timestep_limit=1, stage='reseeded step')\n", "comments": "  crop mouse    wraps atari vnc env behaves like vectorized vanilla atari env    account remote auto reset    todo  auto env spinup    this test still broken  looks like piping seed    cartpole env behind vnc       (gym spec( gym core cartpolelowdsync v0 )  cartpolelowdmatcher())    check running vnc using raw environment     semantics match exactly     check reset observations work    check full rollout    reset start new episode    check step next episode works    make sure env reseeded ", "content": "import logging\nimport pytest\n\nimport gym\nimport numpy as np\nfrom PIL import Image\nfrom gym import spaces\nfrom universe import wrappers\nfrom universe.envs.vnc_core_env import translator\n\ndef show(obs):\n    Image.fromarray(obs).show()\n\nclass AtariMatcher(object):\n    def translator(self, env):\n        return translator.AtariTranslator(env)\n\n    def crop(self, obs):\n        return obs[20:210, :160, :]\n\n    def assert_match(self, obs, vnc_obs, extra_info=None, stage=None):\n        # Crop out the mouse\n        vnc_obs_cropped = self.crop(vnc_obs)\n        obs_cropped = self.crop(obs)\n\n        if not np.all(vnc_obs_cropped == obs_cropped):\n            show(vnc_obs_cropped)\n            show(obs_cropped)\n            show(vnc_obs_cropped - obs_cropped)\n            assert False, '[{}] Observations do not match: vnc_obs_cropped={} obs_cropped={} extra_info={}'.format(stage, vnc_obs_cropped, obs_cropped, extra_info)\n\n# Wraps an Atari-over-VNC env so that it behaves like a vectorized vanilla Atari env\ndef atari_vnc_wrapper(env):\n    env = wrappers.Vision(env)\n    env = wrappers.GymCoreAction(env)\n    return env\n\nclass CartPoleLowDMatcher(object):\n    def translator(self, env):\n        return translator.CartPoleTranslator(env)\n\n    def assert_match(self, obs, vnc_obs, extra_info=None, stage=None):\n        assert np.all(np.isclose(obs, vnc_obs)), '[{}] Observations do not match: vnc_obs={} obs={}'.format(stage, vnc_obs, obs)\n\ndef reset(matcher, env, vnc_env, stage=None):\n    obs = env.reset()\n    vnc_obs = vnc_env.reset()\n    matcher.assert_match(obs, vnc_obs, stage=stage)\n\ndef rollout(matcher, env, vnc_env, timestep_limit=None, stage=None):\n    count = 0\n    actions = matcher.translator(env)\n\n    done = None\n    while True:\n        action = env.action_space.sample()\n\n        obs, reward, done, info = env.step(action)\n        if done:\n            # Account for remote auto-reset\n            obs = env.reset()\n\n        vnc_obs, vnc_reward, vnc_done, vnc_info = vnc_env.step(action)\n        assert reward == vnc_reward\n        assert done == vnc_done\n        assert vnc_info['stats.reward.count'] == 1\n        matcher.assert_match(obs, vnc_obs, {'reward': reward, 'done': done}, stage=stage)\n\n        count += 1\n        if done or (timestep_limit is not None and count >= timestep_limit):\n            break\n\n# TODO: we should have auto-env spinup\nspecs = [\n    (gym.spec('gym-core.PongDeterministicSync-v3'), AtariMatcher(), atari_vnc_wrapper),\n    (gym.spec('gym-core.PitfallDeterministicSync-v3'), AtariMatcher(), atari_vnc_wrapper),\n\n    # This test is still broken. Looks like we're not piping the seed\n    # to the CartPole env behind VNC\n#    (gym.spec('gym-core.CartPoleLowDSync-v0'), CartPoleLowDMatcher())\n]\n\n@pytest.mark.parametrize(\"spec,matcher,wrapper\", specs)\ndef test_nice_vnc_semantics_match(spec, matcher, wrapper):\n    # Check that when running over VNC or using the raw environment,\n    # semantics match exactly.\n    gym.undo_logger_setup()\n    logging.getLogger().setLevel(logging.INFO)\n\n    spaces.seed(0)\n\n    vnc_env = spec.make()\n    if vnc_env.metadata.get('configure.required', False):\n        vnc_env.configure(remotes=1)\n    vnc_env = wrapper(vnc_env)\n    vnc_env = wrappers.Unvectorize(vnc_env)\n\n    env = gym.make(spec._kwargs['gym_core_id'])\n\n    env.seed(0)\n    vnc_env.seed(0)\n\n    # Check that reset observations work\n    reset(matcher, env, vnc_env, stage='initial reset')\n\n    # Check a full rollout\n    rollout(matcher, env, vnc_env, timestep_limit=50, stage='50 steps')\n\n    # Reset to start a new episode\n    reset(matcher, env, vnc_env, stage='reset to new episode')\n\n    # Check that a step into the next episode works\n    rollout(matcher, env, vnc_env, timestep_limit=1, stage='1 step in new episode')\n\n    # Make sure env can be reseeded\n    env.seed(1)\n    vnc_env.seed(1)\n    reset(matcher, env, vnc_env, 'reseeded reset')\n    rollout(matcher, env, vnc_env, timestep_limit=1, stage='reseeded step')\n", "description": "Universe: a software platform for measuring and training an AI's general intelligence across the world's supply of games, websites and other applications.", "file_name": "test_core_envs_semantics.py", "id": "00f66ae415518992be712f94aa19ea63", "language": "Python", "project_name": "universe", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/openai-universe/openai-universe-f95a5fe/tests/functional/test_core_envs_semantics.py", "save_time": "", "source": "", "update_at": "2018-03-18T08:39:09Z", "url": "https://github.com/openai/universe", "wiki": true}