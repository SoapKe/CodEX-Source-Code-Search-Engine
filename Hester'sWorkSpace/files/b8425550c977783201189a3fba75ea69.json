{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\"\"\"Author: aneelakantan (Arvind Neelakantan)\n\"\"\"\n\nimport numpy as np\nimport tensorflow as tf\n\n\nclass Parameters:\n\n  def __init__(self, u):\n    self.utility = u\n    self.init_seed_counter = 0\n    self.word_init = {}\n\n  def parameters(self, utility):\n    params = {}\n    inits = []\n    embedding_dims = self.utility.FLAGS.embedding_dims\n    params[\"unit\"] = tf.Variable(\n        self.RandomUniformInit([len(utility.operations_set), embedding_dims]))\n    params[\"word\"] = tf.Variable(\n        self.RandomUniformInit([utility.FLAGS.vocab_size, embedding_dims]))\n    params[\"word_match_feature_column_name\"] = tf.Variable(\n        self.RandomUniformInit([1]))\n    params[\"controller\"] = tf.Variable(\n        self.RandomUniformInit([2 * embedding_dims, embedding_dims]))\n    params[\"column_controller\"] = tf.Variable(\n        self.RandomUniformInit([2 * embedding_dims, embedding_dims]))\n    params[\"column_controller_prev\"] = tf.Variable(\n        self.RandomUniformInit([embedding_dims, embedding_dims]))\n    params[\"controller_prev\"] = tf.Variable(\n        self.RandomUniformInit([embedding_dims, embedding_dims]))\n    global_step = tf.Variable(1, name=\"global_step\")\n    weigths of question and history RNN (or LSTM)\n    key_list = [\"question_lstm\"]\n    for key in key_list:\n       Weights going from inputs to nodes.\n      for wgts in [\"ix\", \"fx\", \"cx\", \"ox\"]:\n        params[key + \"_\" + wgts] = tf.Variable(\n            self.RandomUniformInit([embedding_dims, embedding_dims]))\n       Weights going from nodes to nodes.\n      for wgts in [\"im\", \"fm\", \"cm\", \"om\"]:\n        params[key + \"_\" + wgts] = tf.Variable(\n            self.RandomUniformInit([embedding_dims, embedding_dims]))\n      Biases for the gates and cell\n      for bias in [\"i\", \"f\", \"c\", \"o\"]:\n        if (bias == \"f\"):\n          print(\"forget gate bias\")\n          params[key + \"_\" + bias] = tf.Variable(\n              tf.random_uniform([embedding_dims], 1.0, 1.1, self.utility.\n                                tf_data_type[self.utility.FLAGS.data_type]))\n        else:\n          params[key + \"_\" + bias] = tf.Variable(\n              self.RandomUniformInit([embedding_dims]))\n    params[\"history_recurrent\"] = tf.Variable(\n        self.RandomUniformInit([3 * embedding_dims, embedding_dims]))\n    params[\"history_recurrent_bias\"] = tf.Variable(\n        self.RandomUniformInit([1, embedding_dims]))\n    params[\"break_conditional\"] = tf.Variable(\n        self.RandomUniformInit([2 * embedding_dims, embedding_dims]))\n    init = tf.global_variables_initializer()\n    return params, global_step, init\n\n  def RandomUniformInit(self, shape):\n    \"\"\"Returns a RandomUniform Tensor between -param_init and param_init.\"\"\"\n    param_seed = self.utility.FLAGS.param_seed\n    self.init_seed_counter += 1\n    return tf.random_uniform(\n        shape, -1.0 *\n        (np.float32(self.utility.FLAGS.param_init)\n        ).astype(self.utility.np_data_type[self.utility.FLAGS.data_type]),\n        (np.float32(self.utility.FLAGS.param_init)\n        ).astype(self.utility.np_data_type[self.utility.FLAGS.data_type]),\n        self.utility.tf_data_type[self.utility.FLAGS.data_type],\n        param_seed + self.init_seed_counter)\n", "comments": "   author  aneelakantan (arvind neelakantan)      import numpy np import tensorflow tf   class parameters     def   init  (self  u)      self utility   u     self init seed counter   0     self word init         def parameters(self  utility)      params          inits          embedding dims   self utility flags embedding dims     params  unit     tf variable(         self randomuniforminit( len(utility operations set)  embedding dims ))     params  word     tf variable(         self randomuniforminit( utility flags vocab size  embedding dims ))     params  word match feature column name     tf variable(         self randomuniforminit( 1 ))     params  controller     tf variable(         self randomuniforminit( 2   embedding dims  embedding dims ))     params  column controller     tf variable(         self randomuniforminit( 2   embedding dims  embedding dims ))     params  column controller prev     tf variable(         self randomuniforminit( embedding dims  embedding dims ))     params  controller prev     tf variable(         self randomuniforminit( embedding dims  embedding dims ))     global step   tf variable(1  name  global step )      weigths question history rnn (or lstm)     key list     question lstm       key key list          weights going inputs nodes        wgts   ix    fx    cx    ox            params key         wgts    tf variable(             self randomuniforminit( embedding dims  embedding dims ))         weights going nodes nodes        wgts   im    fm    cm    om            params key         wgts    tf variable(             self randomuniforminit( embedding dims  embedding dims ))        biases gates cell       bias      f    c               (bias     f )            print( forget gate bias )           params key         bias    tf variable(               tf random uniform( embedding dims   1 0  1 1  self utility                                  tf data type self utility flags data type ))         else            params key         bias    tf variable(               self randomuniforminit( embedding dims ))     params  history recurrent     tf variable(         self randomuniforminit( 3   embedding dims  embedding dims ))     params  history recurrent bias     tf variable(         self randomuniforminit( 1  embedding dims ))     params  break conditional     tf variable(         self randomuniforminit( 2   embedding dims  embedding dims ))     init   tf global variables initializer()     return params  global step  init    def randomuniforminit(self  shape)         returns randomuniform tensor  param init param init        copyright 2016 google inc  all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license       http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                      weigths question history rnn (or lstm)    weights going inputs nodes     weights going nodes nodes    biases gates cell ", "content": "# Copyright 2016 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Author: aneelakantan (Arvind Neelakantan)\n\"\"\"\n\nimport numpy as np\nimport tensorflow as tf\n\n\nclass Parameters:\n\n  def __init__(self, u):\n    self.utility = u\n    self.init_seed_counter = 0\n    self.word_init = {}\n\n  def parameters(self, utility):\n    params = {}\n    inits = []\n    embedding_dims = self.utility.FLAGS.embedding_dims\n    params[\"unit\"] = tf.Variable(\n        self.RandomUniformInit([len(utility.operations_set), embedding_dims]))\n    params[\"word\"] = tf.Variable(\n        self.RandomUniformInit([utility.FLAGS.vocab_size, embedding_dims]))\n    params[\"word_match_feature_column_name\"] = tf.Variable(\n        self.RandomUniformInit([1]))\n    params[\"controller\"] = tf.Variable(\n        self.RandomUniformInit([2 * embedding_dims, embedding_dims]))\n    params[\"column_controller\"] = tf.Variable(\n        self.RandomUniformInit([2 * embedding_dims, embedding_dims]))\n    params[\"column_controller_prev\"] = tf.Variable(\n        self.RandomUniformInit([embedding_dims, embedding_dims]))\n    params[\"controller_prev\"] = tf.Variable(\n        self.RandomUniformInit([embedding_dims, embedding_dims]))\n    global_step = tf.Variable(1, name=\"global_step\")\n    #weigths of question and history RNN (or LSTM)\n    key_list = [\"question_lstm\"]\n    for key in key_list:\n      # Weights going from inputs to nodes.\n      for wgts in [\"ix\", \"fx\", \"cx\", \"ox\"]:\n        params[key + \"_\" + wgts] = tf.Variable(\n            self.RandomUniformInit([embedding_dims, embedding_dims]))\n      # Weights going from nodes to nodes.\n      for wgts in [\"im\", \"fm\", \"cm\", \"om\"]:\n        params[key + \"_\" + wgts] = tf.Variable(\n            self.RandomUniformInit([embedding_dims, embedding_dims]))\n      #Biases for the gates and cell\n      for bias in [\"i\", \"f\", \"c\", \"o\"]:\n        if (bias == \"f\"):\n          print(\"forget gate bias\")\n          params[key + \"_\" + bias] = tf.Variable(\n              tf.random_uniform([embedding_dims], 1.0, 1.1, self.utility.\n                                tf_data_type[self.utility.FLAGS.data_type]))\n        else:\n          params[key + \"_\" + bias] = tf.Variable(\n              self.RandomUniformInit([embedding_dims]))\n    params[\"history_recurrent\"] = tf.Variable(\n        self.RandomUniformInit([3 * embedding_dims, embedding_dims]))\n    params[\"history_recurrent_bias\"] = tf.Variable(\n        self.RandomUniformInit([1, embedding_dims]))\n    params[\"break_conditional\"] = tf.Variable(\n        self.RandomUniformInit([2 * embedding_dims, embedding_dims]))\n    init = tf.global_variables_initializer()\n    return params, global_step, init\n\n  def RandomUniformInit(self, shape):\n    \"\"\"Returns a RandomUniform Tensor between -param_init and param_init.\"\"\"\n    param_seed = self.utility.FLAGS.param_seed\n    self.init_seed_counter += 1\n    return tf.random_uniform(\n        shape, -1.0 *\n        (np.float32(self.utility.FLAGS.param_init)\n        ).astype(self.utility.np_data_type[self.utility.FLAGS.data_type]),\n        (np.float32(self.utility.FLAGS.param_init)\n        ).astype(self.utility.np_data_type[self.utility.FLAGS.data_type]),\n        self.utility.tf_data_type[self.utility.FLAGS.data_type],\n        param_seed + self.init_seed_counter)\n", "description": "Models and examples built with TensorFlow", "file_name": "parameters.py", "id": "b8425550c977783201189a3fba75ea69", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tensorflow-models/tensorflow-models-7e4c66b/research/neural_programmer/parameters.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:59:36Z", "url": "https://github.com/tensorflow/models", "wiki": true}