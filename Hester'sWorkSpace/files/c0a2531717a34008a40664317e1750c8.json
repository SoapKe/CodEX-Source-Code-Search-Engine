{"author": "localstack", "code": "import os\nimport json\nimport requests\nfrom localstack.utils.aws import aws_stack\nfrom localstack.utils.common import short_uid\n\nTEST_BUCKET_NAME_WITH_POLICY = 'test_bucket_policy_1'\nTEST_BUCKET_WITH_NOTIFICATION = 'test_bucket_notification_1'\nTEST_QUEUE_FOR_BUCKET_WITH_NOTIFICATION = 'test_queue_for_bucket_notification_1'\n\n\ndef test_bucket_policy():\n\n    s3_resource = aws_stack.connect_to_resource('s3')\n    s3_client = aws_stack.connect_to_service('s3')\n\n    \n    s3_resource.create_bucket(Bucket=TEST_BUCKET_NAME_WITH_POLICY)\n\n    \n    policy = {\n        'Version': '2012-10-17',\n        'Statement': {\n            'Action': ['s3:GetObject'],\n            'Effect': 'Allow',\n            'Resource': 'arn:aws:s3:::bucketName/*',\n            'Principal': {\n                'AWS': ['*']\n            }\n        }\n    }\n    response = s3_client.put_bucket_policy(\n        Bucket=TEST_BUCKET_NAME_WITH_POLICY,\n        Policy=json.dumps(policy)\n    )\n    assert response['ResponseMetadata']['HTTPStatusCode'] == 204\n\n    \n    saved_policy = s3_client.get_bucket_policy(Bucket=TEST_BUCKET_NAME_WITH_POLICY)['Policy']\n    assert json.loads(saved_policy) == policy\n\n\ndef test_s3_put_object_notification():\n\n    s3_client = aws_stack.connect_to_service('s3')\n    sqs_client = aws_stack.connect_to_service('sqs')\n\n    key_by_path = 'key-by-hostname'\n    key_by_host = 'key-by-host'\n\n    \n    queue_url = sqs_client.create_queue(QueueName=TEST_QUEUE_FOR_BUCKET_WITH_NOTIFICATION)['QueueUrl']\n    queue_attributes = sqs_client.get_queue_attributes(QueueUrl=queue_url, AttributeNames=['QueueArn'])\n\n    \n    s3_client.create_bucket(Bucket=TEST_BUCKET_WITH_NOTIFICATION)\n    s3_client.put_bucket_notification_configuration(Bucket=TEST_BUCKET_WITH_NOTIFICATION,\n                                                    NotificationConfiguration={'QueueConfigurations': [\n                                                        {'QueueArn': queue_attributes['Attributes']['QueueArn'],\n                                                         'Events': ['s3:ObjectCreated:*']}]})\n\n    \n    s3_client.put_object(Bucket=TEST_BUCKET_WITH_NOTIFICATION, Key=key_by_path, Body='something')\n\n    \n    \n    headers = {'Host': '{}.s3.amazonaws.com'.format(TEST_BUCKET_WITH_NOTIFICATION), 'authorization': 'some_token'}\n    url = '{}/{}'.format(os.getenv('TEST_S3_URL'), key_by_host)\n    \n    response = requests.put(url, data='something else', headers=headers, verify=False)\n    assert response.ok\n\n    queue_attributes = sqs_client.get_queue_attributes(QueueUrl=queue_url,\n                                                       AttributeNames=['ApproximateNumberOfMessages'])\n    message_count = queue_attributes['Attributes']['ApproximateNumberOfMessages']\n    \n    assert message_count == '2'\n\n    \n    sqs_client.delete_queue(QueueUrl=queue_url)\n    s3_client.delete_objects(Bucket=TEST_BUCKET_WITH_NOTIFICATION,\n                             Delete={'Objects': [{'Key': key_by_path}, {'Key': key_by_host}]})\n    s3_client.delete_bucket(Bucket=TEST_BUCKET_WITH_NOTIFICATION)\n\n\ndef test_s3_get_response_default_content_type():\n    \n    \n    \n    bucket_name = 'test-bucket-%s' % short_uid()\n    s3_client = aws_stack.connect_to_service('s3')\n    s3_client.create_bucket(Bucket=bucket_name)\n\n    \n    object_key = 'key-by-hostname'\n    s3_client.put_object(Bucket=bucket_name, Key=object_key, Body='something')\n    url = s3_client.generate_presigned_url(\n        'get_object', Params={'Bucket': bucket_name, 'Key': object_key}\n    )\n\n    \n    response = requests.get(url, verify=False)\n    assert response.headers['content-type'] == 'binary/octet-stream'\n    \n    s3_client.delete_objects(Bucket=bucket_name, Delete={'Objects': [{'Key': object_key}]})\n    s3_client.delete_bucket(Bucket=bucket_name)\n\n\ndef test_s3_get_response_content_type_same_as_upload():\n    bucket_name = 'test-bucket-%s' % short_uid()\n    s3_client = aws_stack.connect_to_service('s3')\n    s3_client.create_bucket(Bucket=bucket_name)\n\n    \n    object_key = 'key-by-hostname'\n    s3_client.put_object(Bucket=bucket_name, Key=object_key, Body='something', ContentType='text/html; charset=utf-8')\n    url = s3_client.generate_presigned_url(\n        'get_object', Params={'Bucket': bucket_name, 'Key': object_key}\n    )\n\n    \n    response = requests.get(url, verify=False)\n    assert response.headers['content-type'] == 'text/html; charset=utf-8'\n    \n    s3_client.delete_objects(Bucket=bucket_name, Delete={'Objects': [{'Key': object_key}]})\n    s3_client.delete_bucket(Bucket=bucket_name)\n\n\ndef test_s3_get_response_headers():\n    bucket_name = 'test-bucket-%s' % short_uid()\n    s3_client = aws_stack.connect_to_service('s3')\n    s3_client.create_bucket(Bucket=bucket_name)\n\n     and CORS configuration\n    object_key = 'key-by-hostname'\n    s3_client.put_object(Bucket=bucket_name, Key=object_key, Body='something')\n    url = s3_client.generate_presigned_url(\n        'get_object', Params={'Bucket': bucket_name, 'Key': object_key}\n    )\n    s3_client.put_bucket_cors(Bucket=bucket_name,\n        CORSConfiguration={\n            'CORSRules': [{\n                'AllowedMethods': ['GET', 'PUT', 'POST'],\n                'AllowedOrigins': ['*'],\n                'ExposeHeaders': [\n                    'Date', 'x-amz-delete-marker', 'x-amz-version-id'\n                ]\n            }]\n        },\n    )\n\n    \n    url = s3_client.generate_presigned_url(\n        'get_object', Params={'Bucket': bucket_name, 'Key': object_key}\n    )\n    response = requests.get(url, verify=False)\n    assert response.headers['Date']\n    assert response.headers['x-amz-delete-marker']\n    assert response.headers['x-amz-version-id']\n    assert not response.headers.get('x-amz-id-2')\n    assert not response.headers.get('x-amz-request-id')\n    \n    s3_client.delete_objects(Bucket=bucket_name, Delete={'Objects': [{'Key': object_key}]})\n    s3_client.delete_bucket(Bucket=bucket_name)\n", "comments": "  create test bucket    put bucket policy    retrieve check policy config    create test queue    create test bucket    put object bucket name path    put object bucket name host    care authorization header long present    verify false must set test fails travis ssl error non existent locally    approximatenumberofmessages attribute string    clean    when content type provided put request     binary octet stream  used    src  https   docs aws amazon com amazons3 latest api restobjectput html    put object    get object assert headers    clean    put object    get object assert headers    clean    put object cors configuration    get object assert headers    clean ", "content": "import os\nimport json\nimport requests\nfrom localstack.utils.aws import aws_stack\nfrom localstack.utils.common import short_uid\n\nTEST_BUCKET_NAME_WITH_POLICY = 'test_bucket_policy_1'\nTEST_BUCKET_WITH_NOTIFICATION = 'test_bucket_notification_1'\nTEST_QUEUE_FOR_BUCKET_WITH_NOTIFICATION = 'test_queue_for_bucket_notification_1'\n\n\ndef test_bucket_policy():\n\n    s3_resource = aws_stack.connect_to_resource('s3')\n    s3_client = aws_stack.connect_to_service('s3')\n\n    # create test bucket\n    s3_resource.create_bucket(Bucket=TEST_BUCKET_NAME_WITH_POLICY)\n\n    # put bucket policy\n    policy = {\n        'Version': '2012-10-17',\n        'Statement': {\n            'Action': ['s3:GetObject'],\n            'Effect': 'Allow',\n            'Resource': 'arn:aws:s3:::bucketName/*',\n            'Principal': {\n                'AWS': ['*']\n            }\n        }\n    }\n    response = s3_client.put_bucket_policy(\n        Bucket=TEST_BUCKET_NAME_WITH_POLICY,\n        Policy=json.dumps(policy)\n    )\n    assert response['ResponseMetadata']['HTTPStatusCode'] == 204\n\n    # retrieve and check policy config\n    saved_policy = s3_client.get_bucket_policy(Bucket=TEST_BUCKET_NAME_WITH_POLICY)['Policy']\n    assert json.loads(saved_policy) == policy\n\n\ndef test_s3_put_object_notification():\n\n    s3_client = aws_stack.connect_to_service('s3')\n    sqs_client = aws_stack.connect_to_service('sqs')\n\n    key_by_path = 'key-by-hostname'\n    key_by_host = 'key-by-host'\n\n    # create test queue\n    queue_url = sqs_client.create_queue(QueueName=TEST_QUEUE_FOR_BUCKET_WITH_NOTIFICATION)['QueueUrl']\n    queue_attributes = sqs_client.get_queue_attributes(QueueUrl=queue_url, AttributeNames=['QueueArn'])\n\n    # create test bucket\n    s3_client.create_bucket(Bucket=TEST_BUCKET_WITH_NOTIFICATION)\n    s3_client.put_bucket_notification_configuration(Bucket=TEST_BUCKET_WITH_NOTIFICATION,\n                                                    NotificationConfiguration={'QueueConfigurations': [\n                                                        {'QueueArn': queue_attributes['Attributes']['QueueArn'],\n                                                         'Events': ['s3:ObjectCreated:*']}]})\n\n    # put an object where the bucket_name is in the path\n    s3_client.put_object(Bucket=TEST_BUCKET_WITH_NOTIFICATION, Key=key_by_path, Body='something')\n\n    # put an object where the bucket_name is in the host\n    # it doesn't care about the authorization header as long as it's present\n    headers = {'Host': '{}.s3.amazonaws.com'.format(TEST_BUCKET_WITH_NOTIFICATION), 'authorization': 'some_token'}\n    url = '{}/{}'.format(os.getenv('TEST_S3_URL'), key_by_host)\n    # verify=False must be set as this test fails on travis because of an SSL error non-existent locally\n    response = requests.put(url, data='something else', headers=headers, verify=False)\n    assert response.ok\n\n    queue_attributes = sqs_client.get_queue_attributes(QueueUrl=queue_url,\n                                                       AttributeNames=['ApproximateNumberOfMessages'])\n    message_count = queue_attributes['Attributes']['ApproximateNumberOfMessages']\n    # the ApproximateNumberOfMessages attribute is a string\n    assert message_count == '2'\n\n    # clean up\n    sqs_client.delete_queue(QueueUrl=queue_url)\n    s3_client.delete_objects(Bucket=TEST_BUCKET_WITH_NOTIFICATION,\n                             Delete={'Objects': [{'Key': key_by_path}, {'Key': key_by_host}]})\n    s3_client.delete_bucket(Bucket=TEST_BUCKET_WITH_NOTIFICATION)\n\n\ndef test_s3_get_response_default_content_type():\n    # When no content type is provided by a PUT request\n    # 'binary/octet-stream' should be used\n    # src: https://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectPUT.html\n    bucket_name = 'test-bucket-%s' % short_uid()\n    s3_client = aws_stack.connect_to_service('s3')\n    s3_client.create_bucket(Bucket=bucket_name)\n\n    # put object\n    object_key = 'key-by-hostname'\n    s3_client.put_object(Bucket=bucket_name, Key=object_key, Body='something')\n    url = s3_client.generate_presigned_url(\n        'get_object', Params={'Bucket': bucket_name, 'Key': object_key}\n    )\n\n    # get object and assert headers\n    response = requests.get(url, verify=False)\n    assert response.headers['content-type'] == 'binary/octet-stream'\n    # clean up\n    s3_client.delete_objects(Bucket=bucket_name, Delete={'Objects': [{'Key': object_key}]})\n    s3_client.delete_bucket(Bucket=bucket_name)\n\n\ndef test_s3_get_response_content_type_same_as_upload():\n    bucket_name = 'test-bucket-%s' % short_uid()\n    s3_client = aws_stack.connect_to_service('s3')\n    s3_client.create_bucket(Bucket=bucket_name)\n\n    # put object\n    object_key = 'key-by-hostname'\n    s3_client.put_object(Bucket=bucket_name, Key=object_key, Body='something', ContentType='text/html; charset=utf-8')\n    url = s3_client.generate_presigned_url(\n        'get_object', Params={'Bucket': bucket_name, 'Key': object_key}\n    )\n\n    # get object and assert headers\n    response = requests.get(url, verify=False)\n    assert response.headers['content-type'] == 'text/html; charset=utf-8'\n    # clean up\n    s3_client.delete_objects(Bucket=bucket_name, Delete={'Objects': [{'Key': object_key}]})\n    s3_client.delete_bucket(Bucket=bucket_name)\n\n\ndef test_s3_get_response_headers():\n    bucket_name = 'test-bucket-%s' % short_uid()\n    s3_client = aws_stack.connect_to_service('s3')\n    s3_client.create_bucket(Bucket=bucket_name)\n\n    # put object and CORS configuration\n    object_key = 'key-by-hostname'\n    s3_client.put_object(Bucket=bucket_name, Key=object_key, Body='something')\n    url = s3_client.generate_presigned_url(\n        'get_object', Params={'Bucket': bucket_name, 'Key': object_key}\n    )\n    s3_client.put_bucket_cors(Bucket=bucket_name,\n        CORSConfiguration={\n            'CORSRules': [{\n                'AllowedMethods': ['GET', 'PUT', 'POST'],\n                'AllowedOrigins': ['*'],\n                'ExposeHeaders': [\n                    'Date', 'x-amz-delete-marker', 'x-amz-version-id'\n                ]\n            }]\n        },\n    )\n\n    # get object and assert headers\n    url = s3_client.generate_presigned_url(\n        'get_object', Params={'Bucket': bucket_name, 'Key': object_key}\n    )\n    response = requests.get(url, verify=False)\n    assert response.headers['Date']\n    assert response.headers['x-amz-delete-marker']\n    assert response.headers['x-amz-version-id']\n    assert not response.headers.get('x-amz-id-2')\n    assert not response.headers.get('x-amz-request-id')\n    # clean up\n    s3_client.delete_objects(Bucket=bucket_name, Delete={'Objects': [{'Key': object_key}]})\n    s3_client.delete_bucket(Bucket=bucket_name)\n", "description": "\ud83d\udcbb  A fully functional local AWS cloud stack. Develop and test your cloud apps offline!", "file_name": "test_s3.py", "id": "c0a2531717a34008a40664317e1750c8", "language": "Python", "project_name": "localstack", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/localstack-localstack/localstack-localstack-865ec3a/tests/integration/test_s3.py", "save_time": "", "source": "", "update_at": "2018-03-14T00:04:55Z", "url": "https://github.com/localstack/localstack", "wiki": true}