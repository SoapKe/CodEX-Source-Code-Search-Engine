{"author": "HelloZeroNet", "code": "import json\nimport time\nimport re\nimport os\nimport copy\n\nimport gevent\n\nfrom Debug import Debug\nfrom Crypt import CryptHash\nfrom Config import config\nfrom util import helper\nfrom util import Diff\nfrom util import SafeRe\nfrom Peer import PeerHashfield\nfrom ContentDbDict import ContentDbDict\nfrom Plugin import PluginManager\n\n\nclass VerifyError(Exception):\n    pass\n\n\nclass SignError(Exception):\n    pass\n\n\n@PluginManager.acceptPlugins\nclass ContentManager(object):\n\n    def __init__(self, site):\n        self.site = site\n        self.log = self.site.log\n        self.contents = ContentDbDict(site)\n        self.hashfield = PeerHashfield()\n        self.has_optional_files = False\n\n    \n    def loadContents(self):\n        if len(self.contents) == 0:\n            self.log.debug(\"ContentDb not initialized, load files from filesystem\")\n            self.loadContent(add_bad_files=False, delete_removed_files=False)\n        self.site.settings[\"size\"], self.site.settings[\"size_optional\"] = self.getTotalSize()\n\n        \n        if \"hashfield\" in self.site.settings.get(\"cache\", {}):\n            self.hashfield.fromstring(self.site.settings[\"cache\"][\"hashfield\"].decode(\"base64\"))\n            del self.site.settings[\"cache\"][\"hashfield\"]\n        elif self.contents.get(\"content.json\") and self.site.settings[\"size_optional\"] > 0:\n            self.site.storage.updateBadFiles()  \n        self.has_optional_files = bool(self.hashfield)\n\n        self.contents.db.initSite(self.site)\n\n    \n    hanged files [\"index.html\", \"data/messages.json\"], Deleted files [\"old.jpg\"]\n    def loadContent(self, content_inner_path=\"content.json\", add_bad_files=True, delete_removed_files=True, load_includes=True, force=False):\n        content_inner_path = content_inner_path.strip(\"/\")  \n        old_content = self.contents.get(content_inner_path)\n        content_path = self.site.storage.getPath(content_inner_path)\n        content_dir = helper.getDirname(self.site.storage.getPath(content_inner_path))\n        content_inner_dir = helper.getDirname(content_inner_path)\n\n        if os.path.isfile(content_path):\n            try:\n                \n                if not force and old_content and not self.site.settings.get(\"own\"):\n                    for line in open(content_path):\n                        if '\"modified\"' not in line:\n                            continue\n                        match = re.search(\"([0-9\\.]+),$\", line.strip(\" \\r\\n\"))\n                        if match and float(match.group(1)) <= old_content.get(\"modified\", 0):\n                            self.log.debug(\"%s loadContent same json file, skipping\" % content_inner_path)\n                            return [], []\n\n                new_content = json.load(open(content_path))\n            except Exception, err:\n                self.log.warning(\"%s load error: %s\" % (content_path, Debug.formatException(err)))\n                return [], []\n        else:\n            self.log.warning(\"Content.json not exist: %s\" % content_path)\n            return [], []  \n\n        try:\n            \n            changed = []\n            deleted = []\n            \n            for relative_path, info in new_content.get(\"files\", {}).iteritems():\n                if \"sha512\" in info:\n                    hash_type = \"sha512\"\n                else:  \n                    hash_type = \"sha1\"\n\n                new_hash = info[hash_type]\n                if old_content and old_content[\"files\"].get(relative_path):  \n                    old_hash = old_content[\"files\"][relative_path].get(hash_type)\n                else:  \n                    old_hash = None\n                if old_hash != new_hash:\n                    changed.append(content_inner_dir + relative_path)\n\n             optional files\n            for relative_path, info in new_content.get(\"files_optional\", {}).iteritems():\n                file_inner_path = content_inner_dir + relative_path\n                new_hash = info[\"sha512\"]\n                if old_content and old_content.get(\"files_optional\", {}).get(relative_path):\n                    \n                    old_hash = old_content[\"files_optional\"][relative_path].get(\"sha512\")\n                    if old_hash != new_hash and self.site.isDownloadable(file_inner_path):\n                        changed.append(file_inner_path)  \n                    elif old_hash != new_hash and self.hashfield.hasHash(old_hash) and not self.site.settings.get(\"own\"):\n                        try:\n                            self.optionalRemove(file_inner_path, old_hash, old_content[\"files_optional\"][relative_path][\"size\"])\n                            self.site.storage.delete(file_inner_path)\n                            self.log.debug(\"Deleted changed optional file: %s\" % file_inner_path)\n                        except Exception, err:\n                            self.log.debug(\"Error deleting file %s: %s\" % (file_inner_path, err))\n                else:  \n                    if self.site.isDownloadable(file_inner_path):\n                        changed.append(file_inner_path)  \n\n            \n            if old_content:\n                old_files = dict(\n                    old_content.get(\"files\", {}),\n                    **old_content.get(\"files_optional\", {})\n                )\n\n                new_files = dict(\n                    new_content.get(\"files\", {}),\n                    **new_content.get(\"files_optional\", {})\n                )\n\n                deleted = [key for key in old_files if key not in new_files]\n                if deleted and not self.site.settings.get(\"own\"):\n                    \n                    for file_relative_path in deleted:\n                        file_inner_path = content_inner_dir + file_relative_path\n                        try:\n                            self.site.storage.delete(file_inner_path)\n\n                            \n                            if old_content.get(\"files_optional\") and old_content[\"files_optional\"].get(file_relative_path):\n                                old_hash = old_content[\"files_optional\"][file_relative_path].get(\"sha512\")\n                                if self.hashfield.hasHash(old_hash):\n                                    self.optionalRemove(file_inner_path, old_hash, old_content[\"files_optional\"][file_relative_path][\"size\"])\n\n                            self.log.debug(\"Deleted file: %s\" % file_inner_path)\n                        except Exception, err:\n                            self.log.debug(\"Error deleting file %s: %s\" % (file_inner_path, err))\n\n                    \n                    tree = {root: [dirs, files] for root, dirs, files in os.walk(self.site.storage.getPath(content_inner_dir))}\n                    for root in sorted(tree, key=len, reverse=True):\n                        dirs, files = tree[root]\n                        if dirs == [] and files == []:\n                            root_inner_path = self.site.storage.getInnerPath(root.replace(\"\\\\\", \"/\"))\n                            self.log.debug(\"Empty directory: %s, cleaning up.\" % root_inner_path)\n                            try:\n                                self.site.storage.deleteDir(root_inner_path)\n                                \n                                tree[os.path.dirname(root)][0].remove(os.path.basename(root))\n                            except Exception, err:\n                                self.log.debug(\"Error deleting empty directory %s: %s\" % (root_inner_path, err))\n\n            \n            if old_content and \"user_contents\" in new_content and \"archived\" in new_content[\"user_contents\"]:\n                old_archived = old_content.get(\"user_contents\", {}).get(\"archived\", {})\n                new_archived = new_content.get(\"user_contents\", {}).get(\"archived\", {})\n                self.log.debug(\"old archived: %s, new archived: %s\" % (len(old_archived), len(new_archived)))\n                archived_changed = {\n                    key: date_archived\n                    for key, date_archived in new_archived.iteritems()\n                    if old_archived.get(key) != new_archived[key]\n                }\n                if archived_changed:\n                    self.log.debug(\"Archived changed: %s\" % archived_changed)\n                    for archived_dirname, date_archived in archived_changed.iteritems():\n                        archived_inner_path = content_inner_dir + archived_dirname + \"/content.json\"\n                        if self.contents.get(archived_inner_path, {}).get(\"modified\", 0) < date_archived:\n                            self.removeContent(archived_inner_path)\n                    self.site.settings[\"size\"], self.site.settings[\"size_optional\"] = self.getTotalSize()\n\n            \n            if load_includes and \"includes\" in new_content:\n                for relative_path, info in new_content[\"includes\"].items():\n                    include_inner_path = content_inner_dir + relative_path\n                    if self.site.storage.isFile(include_inner_path):  \n                        include_changed, include_deleted = self.loadContent(\n                            include_inner_path, add_bad_files=add_bad_files, delete_removed_files=delete_removed_files\n                        )\n                        if include_changed:\n                            changed += include_changed  \n                        if include_deleted:\n                            deleted += include_deleted  \n                    else:  , add to changed files\n                        self.log.debug(\"Missing include: %s\" % include_inner_path)\n                        changed += [include_inner_path]\n\n            # Load blind user includes (all subdir)\n            if load_includes and \"user_contents\" in new_content:\n                for relative_dir in os.listdir(content_dir):\n                    include_inner_path = content_inner_dir + relative_dir + \"/content.json\"\n                    if not self.site.storage.isFile(include_inner_path):\n                        continue  \n                    include_changed, include_deleted = self.loadContent(\n                        include_inner_path, add_bad_files=add_bad_files, delete_removed_files=delete_removed_files,\n                        load_includes=False\n                    )\n                    if include_changed:\n                        changed += include_changed  \n                    if include_deleted:\n                        deleted += include_deleted  \n\n            \n            new_content[\"signs\"] = None\n            if \"cert_sign\" in new_content:\n                new_content[\"cert_sign\"] = None\n\n            if new_content.get(\"files_optional\"):\n                self.has_optional_files = True\n            \n            self.contents[content_inner_path] = new_content\n        except Exception, err:\n            self.log.warning(\"%s parse error: %s\" % (content_inner_path, Debug.formatException(err)))\n            return [], []  \n\n         to bad files\n        if add_bad_files:\n            for inner_path in changed:\n                self.site.bad_files[inner_path] = self.site.bad_files.get(inner_path, 0) + 1\n            for inner_path in deleted:\n                if inner_path in self.site.bad_files:\n                    del self.site.bad_files[inner_path]\n\n        if new_content.get(\"modified\", 0) > self.site.settings.get(\"modified\", 0):\n            # Dont store modifications in the far future (more than 10 minute)\n            self.site.settings[\"modified\"] = min(time.time() + 60 * 10, new_content[\"modified\"])\n\n        return changed, deleted\n\n    def removeContent(self, inner_path):\n        inner_dir = helper.getDirname(inner_path)\n        try:\n            content = self.contents[inner_path]\n            files = dict(\n                content.get(\"files\", {}),\n                **content.get(\"files_optional\", {})\n            )\n        except Exception, err:\n            self.log.debug(\"Error loading %s for removeContent: %s\" % (inner_path, Debug.formatException(err)))\n            files = {}\n        files[\"content.json\"] = True\n        \n        for file_relative_path in files:\n            file_inner_path = inner_dir + file_relative_path\n            try:\n                self.site.storage.delete(file_inner_path)\n                self.log.debug(\"Deleted file: %s\" % file_inner_path)\n            except Exception, err:\n                self.log.debug(\"Error deleting file %s: %s\" % (file_inner_path, err))\n        try:\n            self.site.storage.deleteDir(inner_dir)\n        except Exception, err:\n            self.log.debug(\"Error deleting dir %s: %s\" % (inner_dir, err))\n\n        try:\n            del self.contents[inner_path]\n        except Exception, err:\n            self.log.debug(\"Error key from contents: %s\" % inner_path)\n\n    \n    2819 (size of files in kb)\n    def getTotalSize(self, ignore=None):\n        return self.contents.db.getTotalSize(self.site, ignore)\n\n    def listModified(self, since):\n        return self.contents.db.listModified(self.site, since)\n\n    def listContents(self, inner_path=\"content.json\", user_files=False):\n        if inner_path not in self.contents:\n            return []\n        back = [inner_path]\n        content_inner_dir = helper.getDirname(inner_path)\n        for relative_path in self.contents[inner_path].get(\"includes\", {}).keys():\n            include_inner_path = content_inner_dir + relative_path\n            back += self.listContents(include_inner_path)\n        return back\n\n    \n    def isArchived(self, inner_path, modified):\n        file_info = self.getFileInfo(inner_path)\n        match = re.match(\".*/(.*?)/\", inner_path)\n        if not match:\n            return False\n        relative_directory = match.group(1)\n        if file_info and file_info.get(\"archived\", {}).get(relative_directory) >= modified:\n            return True\n        else:\n            return False\n\n    \n    \n    def getFileInfo(self, inner_path, new_file=False):\n        dirs = inner_path.split(\"/\")  \n        inner_path_parts = [dirs.pop()]  \n        while True:\n            content_inner_path = \"%s/content.json\" % \"/\".join(dirs)\n            content_inner_path = content_inner_path.strip(\"/\")\n            content = self.contents.get(content_inner_path)\n\n            \n            if content and \"files\" in content:\n                back = content[\"files\"].get(\"/\".join(inner_path_parts))\n                if back:\n                    back[\"content_inner_path\"] = content_inner_path\n                    back[\"optional\"] = False\n                    back[\"relative_path\"] = \"/\".join(inner_path_parts)\n                    return back\n\n            \n            if content and \"files_optional\" in content:  \n                back = content[\"files_optional\"].get(\"/\".join(inner_path_parts))\n                if back:\n                    back[\"content_inner_path\"] = content_inner_path\n                    back[\"optional\"] = True\n                    back[\"relative_path\"] = \"/\".join(inner_path_parts)\n                    return back\n\n            \n            if content and \"user_contents\" in content:\n                back = content[\"user_contents\"]\n                content_inner_path_dir = helper.getDirname(content_inner_path)\n                relative_content_path = inner_path[len(content_inner_path_dir):]\n                if \"/\" in relative_content_path:\n                    user_auth_address = re.match(\"([A-Za-z0-9]+)/.*\", relative_content_path).group(1)\n                    back[\"content_inner_path\"] = \"%s%s/content.json\" % (content_inner_path_dir, user_auth_address)\n                else:\n                    back[\"content_inner_path\"] = content_inner_path_dir + \"content.json\"\n                back[\"optional\"] = None\n                back[\"relative_path\"] = \"/\".join(inner_path_parts)\n                return back\n\n            if new_file and content:\n                back = {}\n                back[\"content_inner_path\"] = content_inner_path\n                back[\"relative_path\"] = \"/\".join(inner_path_parts)\n                back[\"optional\"] = None\n                return back\n\n            \n            if dirs:\n                inner_path_parts.insert(0, dirs.pop())\n            else:  \n                break\n\n        \n        return False\n\n    \n    \n    def getRules(self, inner_path, content=None):\n        if not inner_path.endswith(\"content.json\"):  \n            file_info = self.getFileInfo(inner_path)\n            if not file_info:\n                return False  \n            inner_path = file_info[\"content_inner_path\"]\n\n        if inner_path == \"content.json\":  \n            rules = {}\n            rules[\"signers\"] = self.getValidSigners(inner_path, content)\n            return rules\n\n        dirs = inner_path.split(\"/\")  \n        inner_path_parts = [dirs.pop()]  \n        inner_path_parts.insert(0, dirs.pop())  \n        while True:\n            content_inner_path = \"%s/content.json\" % \"/\".join(dirs)\n            parent_content = self.contents.get(content_inner_path.strip(\"/\"))\n            if parent_content and \"includes\" in parent_content:\n                return parent_content[\"includes\"].get(\"/\".join(inner_path_parts))\n            elif parent_content and \"user_contents\" in parent_content:\n                return self.getUserContentRules(parent_content, inner_path, content)\n            else:  \n                if dirs:\n                    inner_path_parts.insert(0, dirs.pop())\n                else:  \n                    break\n\n        return False\n\n    \n    \n    def getUserContentRules(self, parent_content, inner_path, content):\n        user_contents = parent_content[\"user_contents\"]\n\n        \n        if \"inner_path\" in parent_content:\n            parent_content_dir = helper.getDirname(parent_content[\"inner_path\"])\n            user_address = re.match(\"([A-Za-z0-9]*?)/\", inner_path[len(parent_content_dir):]).group(1)\n        else:\n            user_address = re.match(\".*/([A-Za-z0-9]*?)/.*?$\", inner_path).group(1)\n\n        try:\n            if not content:\n                content = self.site.storage.loadJson(inner_path)  \n            user_urn = \"%s/%s\" % (content[\"cert_auth_type\"], content[\"cert_user_id\"])  \n            cert_user_id = content[\"cert_user_id\"]\n        except Exception:  \n            user_urn = \"n-a/n-a\"\n            cert_user_id = \"n-a\"\n\n        if user_address in user_contents[\"permissions\"]:\n            rules = copy.copy(user_contents[\"permissions\"].get(user_address, {}))  \n        else:\n            rules = copy.copy(user_contents[\"permissions\"].get(cert_user_id, {}))  \n\n        if rules is False:\n            banned = True\n            rules = {}\n        else:\n            banned = False\n        if \"signers\" in rules:\n            rules[\"signers\"] = rules[\"signers\"][:]  \n        for permission_pattern, permission_rules in user_contents[\"permission_rules\"].items():  \n            if not SafeRe.match(permission_pattern, user_urn):\n                continue  \n            \n            for key, val in permission_rules.iteritems():\n                if key not in rules:\n                    if type(val) is list:\n                        rules[key] = val[:]  \n                    else:\n                        rules[key] = val\n                elif type(val) is int:  \n                    if val > rules[key]:\n                        rules[key] = val\n                elif hasattr(val, \"startswith\"):  \n                    if len(val) > len(rules[key]):\n                        rules[key] = val\n                elif type(val) is list:  \n                    rules[key] += val\n\n        rules[\"cert_signers\"] = user_contents[\"cert_signers\"]  \n        if \"signers\" not in rules:\n            rules[\"signers\"] = []\n\n        if not banned:\n            rules[\"signers\"].append(user_address)  \n        rules[\"user_address\"] = user_address\n        rules[\"includes_allowed\"] = False\n\n        return rules\n\n    \n    def getDiffs(self, inner_path, limit=30 * 1024, update_files=True):\n        if inner_path not in self.contents:\n            return {}\n        diffs = {}\n        content_inner_path_dir = helper.getDirname(inner_path)\n        for file_relative_path in self.contents[inner_path].get(\"files\", {}):\n            file_inner_path = content_inner_path_dir + file_relative_path\n            if self.site.storage.isFile(file_inner_path + \"-new\"):  \n                diffs[file_relative_path] = Diff.diff(\n                    list(self.site.storage.open(file_inner_path)),\n                    list(self.site.storage.open(file_inner_path + \"-new\")),\n                    limit=limit\n                )\n                if update_files:\n                    self.site.storage.delete(file_inner_path)\n                    self.site.storage.rename(file_inner_path + \"-new\", file_inner_path)\n            if self.site.storage.isFile(file_inner_path + \"-old\"):  \n                diffs[file_relative_path] = Diff.diff(\n                    list(self.site.storage.open(file_inner_path + \"-old\")),\n                    list(self.site.storage.open(file_inner_path)),\n                    limit=limit\n                )\n                if update_files:\n                    self.site.storage.delete(file_inner_path + \"-old\")\n        return diffs\n\n    def hashFile(self, dir_inner_path, file_relative_path, optional=False):\n        back = {}\n        file_inner_path = dir_inner_path + \"/\" + file_relative_path\n\n        file_path = self.site.storage.getPath(file_inner_path)\n        file_size = os.path.getsize(file_path)\n        sha512sum = CryptHash.sha512sum(file_path)  \n        if optional and not self.hashfield.hasHash(sha512sum):\n            self.optionalDownloaded(file_inner_path, sha512sum, file_size, own=True)\n\n        back[file_relative_path] = {\"sha512\": sha512sum, \"size\": os.path.getsize(file_path)}\n        return back\n\n    def isValidRelativePath(self, relative_path):\n        if \"..\" in relative_path:\n            return False\n        elif len(relative_path) > 255:\n            return False\n        else:\n            return re.match(\"^[a-z\\[\\]\\(\\) A-Z0-9_@=\\.\\+-/]+$\", relative_path)\n\n    def sanitizePath(self, inner_path):\n        return re.sub(\"[^a-z\\[\\]\\(\\) A-Z0-9_@=\\.\\+-/]\", \"\", inner_path)\n\n    \n    def hashFiles(self, dir_inner_path, ignore_pattern=None, optional_pattern=None):\n        files_node = {}\n        files_optional_node = {}\n        if dir_inner_path and not self.isValidRelativePath(dir_inner_path):\n            ignored = True\n            self.log.error(\"- [ERROR] Only ascii encoded directories allowed: %s\" % dir_inner_path)\n\n        for file_relative_path in self.site.storage.walk(dir_inner_path, ignore_pattern):\n            file_name = helper.getFilename(file_relative_path)\n\n            ignored = optional = False\n            if file_name == \"content.json\":\n                ignored = True\n            elif file_name.startswith(\".\") or file_name.endswith(\"-old\") or file_name.endswith(\"-new\"):\n                ignored = True\n            elif not self.isValidRelativePath(file_relative_path):\n                ignored = True\n                self.log.error(\"- [ERROR] Invalid filename: %s\" % file_relative_path)\n            elif dir_inner_path == \"\" and file_relative_path == self.site.storage.getDbFile():\n                ignored = True\n            elif optional_pattern and SafeRe.match(optional_pattern, file_relative_path):\n                optional = True\n\n            if ignored:  \n                self.log.info(\"- [SKIPPED] %s\" % file_relative_path)\n            else:\n                if optional:\n                    self.log.info(\"- [OPTIONAL] %s\" % file_relative_path)\n                    files_optional_node.update(\n                        self.hashFile(dir_inner_path, file_relative_path, optional=True)\n                    )\n                else:\n                    self.log.info(\"- %s\" % file_relative_path)\n                    files_node.update(\n                        self.hashFile(dir_inner_path, file_relative_path)\n                    )\n        return files_node, files_optional_node\n\n    \n    \n    def sign(self, inner_path=\"content.json\", privatekey=None, filewrite=True, update_changed_files=False, extend=None, remove_missing_optional=False):\n        if not inner_path.endswith(\"content.json\"):\n            raise SignError(\"Invalid file name, you can only sign content.json files\")\n\n        if inner_path in self.contents:\n            content = self.contents.get(inner_path)\n            if content and content.get(\"cert_sign\", False) is None and self.site.storage.isFile(inner_path):\n                \n                content[\"cert_sign\"] = self.site.storage.loadJson(inner_path).get(\"cert_sign\")\n        else:\n            content = None\n        if not content:  \n            self.log.info(\"File %s not exist yet, loading default values...\" % inner_path)\n\n            if self.site.storage.isFile(inner_path):\n                content = self.site.storage.loadJson(inner_path)\n                if \"files\" not in content:\n                    content[\"files\"] = {}\n                if \"signs\" not in content:\n                    content[\"signs\"] = {}\n            else:\n                content = {\"files\": {}, \"signs\": {}}  \n\n            if inner_path == \"content.json\":  \n                content[\"title\"] = \"%s - ZeroNet_\" % self.site.address\n                content[\"description\"] = \"\"\n                content[\"signs_required\"] = 1\n                content[\"ignore\"] = \"\"\n\n        if extend:\n            \n            for key, val in extend.items():\n                if not content.get(key):\n                    content[key] = val\n                    self.log.info(\"Extending content.json with: %s\" % key)\n\n        directory = helper.getDirname(self.site.storage.getPath(inner_path))\n        inner_directory = helper.getDirname(inner_path)\n        self.log.info(\"Opening site data directory: %s...\" % directory)\n\n        changed_files = [inner_path]\n        files_node, files_optional_node = self.hashFiles(\n            helper.getDirname(inner_path), content.get(\"ignore\"), content.get(\"optional\")\n        )\n\n        if not remove_missing_optional:\n            for file_inner_path, file_details in content.get(\"files_optional\", {}).iteritems():\n                if file_inner_path not in files_optional_node:\n                    files_optional_node[file_inner_path] = file_details\n\n        \n        files_merged = files_node.copy()\n        files_merged.update(files_optional_node)\n        for file_relative_path, file_details in files_merged.iteritems():\n            old_hash = content.get(\"files\", {}).get(file_relative_path, {}).get(\"sha512\")\n            new_hash = files_merged[file_relative_path][\"sha512\"]\n            if old_hash != new_hash:\n                changed_files.append(inner_directory + file_relative_path)\n\n        self.log.debug(\"Changed files: %s\" % changed_files)\n        if update_changed_files:\n            for file_path in changed_files:\n                self.site.storage.onUpdated(file_path)\n\n        \n        self.log.info(\"Adding timestamp and sha512sums to new content.json...\")\n\n        new_content = content.copy()  \n        new_content[\"files\"] = files_node  \n        if files_optional_node:\n            new_content[\"files_optional\"] = files_optional_node\n        elif \"files_optional\" in new_content:\n            del new_content[\"files_optional\"]\n\n        new_content[\"modified\"] = int(time.time())  \n        if inner_path == \"content.json\":\n            new_content[\"zeronet_version\"] = config.version\n            new_content[\"signs_required\"] = content.get(\"signs_required\", 1)\n\n        new_content[\"address\"] = self.site.address\n        new_content[\"inner_path\"] = inner_path\n\n        \n        from Crypt import CryptBitcoin\n        self.log.info(\"Verifying private key...\")\n        privatekey_address = CryptBitcoin.privatekeyToAddress(privatekey)\n        valid_signers = self.getValidSigners(inner_path, new_content)\n        if privatekey_address not in valid_signers:\n            raise SignError(\n                \"Private key invalid! Valid signers: %s, Private key address: %s\" %\n                (valid_signers, privatekey_address)\n            )\n        self.log.info(\"Correct %s in valid signers: %s\" % (privatekey_address, valid_signers))\n\n        if inner_path == \"content.json\" and privatekey_address == self.site.address:\n            \n            signers_data = \"%s:%s\" % (new_content[\"signs_required\"], \",\".join(valid_signers))\n            new_content[\"signers_sign\"] = CryptBitcoin.sign(str(signers_data), privatekey)\n            if not new_content[\"signers_sign\"]:\n                self.log.info(\"Old style address, signers_sign is none\")\n\n        self.log.info(\"Signing %s...\" % inner_path)\n\n        if \"signs\" in new_content:\n            del(new_content[\"signs\"])  \n        if \"sign\" in new_content:\n            del(new_content[\"sign\"])  # Delete old sign (backward compatibility)\n\n        sign_content = json.dumps(new_content, sort_keys=True)\n        sign = CryptBitcoin.sign(sign_content, privatekey)\n        # new_content[\"signs\"] = content.get(\"signs\", {}) # TODO: Multisig\n        if sign:  # If signing is successful (not an old address)\n            new_content[\"signs\"] = {}\n            new_content[\"signs\"][privatekey_address] = sign\n\n        self.verifyContent(inner_path, new_content)\n\n        if filewrite:\n            self.log.info(\"Saving to %s...\" % inner_path)\n            self.site.storage.writeJson(inner_path, new_content)\n            self.contents[inner_path] = new_content\n\n        self.log.info(\"File %s signed!\" % inner_path)\n\n        if filewrite:  \n            return True\n        else:  \n            return new_content\n\n    \n    # Return: [\"1KRxE1s3oDyNDawuYWpzbLUwNm8oDbeEp6\", \"13ReyhCsjhpuCVahn1DHdf6eMqqEVev162\"]\n    def getValidSigners(self, inner_path, content=None):\n        valid_signers = []\n        if inner_path == \"content.json\":  \n            if \"content.json\" in self.contents and \"signers\" in self.contents[\"content.json\"]:\n                valid_signers += self.contents[\"content.json\"][\"signers\"][:]\n        else:\n            rules = self.getRules(inner_path, content)\n            if rules and \"signers\" in rules:\n                valid_signers += rules[\"signers\"]\n\n        if self.site.address not in valid_signers:\n            valid_signers.append(self.site.address)  \n        return valid_signers\n\n    \n    def getSignsRequired(self, inner_path, content=None):\n        return 1  \n\n    def verifyCert(self, inner_path, content):\n        from Crypt import CryptBitcoin\n\n        rules = self.getRules(inner_path, content)\n\n        if not rules.get(\"cert_signers\"):\n            return True  \n\n        if \"cert_user_id\" not in content:\n            raise VerifyError(\"Missing cert_user_id\")\n\n        name, domain = content[\"cert_user_id\"].split(\"@\")\n        cert_address = rules[\"cert_signers\"].get(domain)\n        if not cert_address:  \n            raise VerifyError(\"Invalid cert signer: %s\" % domain)\n\n        try:\n            cert_subject = \"%s#%s/%s\" % (rules[\"user_address\"], content[\"cert_auth_type\"], name)\n            result = CryptBitcoin.verify(cert_subject, cert_address, content[\"cert_sign\"])\n        except Exception, err:\n            raise VerifyError(\"Certificate verify error: %s\" % err)\n        return result\n\n    \n    \n    def verifyContent(self, inner_path, content):\n        content_size = len(json.dumps(content, indent=1)) + sum([file[\"size\"] for file in content[\"files\"].values() if file[\"size\"] >= 0])  \n        \n        old_content = self.contents.get(inner_path)\n        if old_content:\n            old_content_size = len(json.dumps(old_content, indent=1)) + sum([file[\"size\"] for file in old_content.get(\"files\", {}).values()])\n            old_content_size_optional = sum([file[\"size\"] for file in old_content.get(\"files_optional\", {}).values()])\n        else:\n            old_content_size = 0\n            old_content_size_optional = 0\n\n        \n        if not old_content and inner_path == \"content.json\":\n            self.site.settings[\"size\"] = 0\n\n        content_size_optional = sum([file[\"size\"] for file in content.get(\"files_optional\", {}).values() if file[\"size\"] >= 0])\n        site_size = self.site.settings[\"size\"] - old_content_size + content_size  \n        site_size_optional = self.site.settings[\"size_optional\"] - old_content_size_optional + content_size_optional  \n\n        site_size_limit = self.site.getSizeLimit() * 1024 * 1024\n\n        \n        if content.get(\"address\") and content[\"address\"] != self.site.address:\n            raise VerifyError(\"Wrong site address: %s != %s\" % (content[\"address\"], self.site.address))\n\n        \n        if content.get(\"inner_path\") and content[\"inner_path\"] != inner_path:\n            raise VerifyError(\"Wrong inner_path: %s\" % content[\"inner_path\"])\n\n        \n        if site_size > site_size_limit:\n            if inner_path == \"content.json\" and self.site.settings[\"size\"] == 0:\n                \n                self.site.settings[\"size\"] = site_size\n            task = self.site.worker_manager.findTask(inner_path)\n            if task:  \n                self.site.worker_manager.failTask(task)\n            raise VerifyError(\"Content too large %sB > %sB, aborting task...\" % (site_size, site_size_limit))\n\n        \n        for file_relative_path in content.get(\"files\", {}).keys() + content.get(\"files_optional\", {}).keys():\n            if not self.isValidRelativePath(file_relative_path):\n                raise VerifyError(\"Invalid relative path: %s\" % file_relative_path)\n\n        if inner_path == \"content.json\":\n            self.site.settings[\"size\"] = site_size\n            self.site.settings[\"size_optional\"] = site_size_optional\n            return True   is passed\n        else:\n            if self.verifyContentInclude(inner_path, content, content_size, content_size_optional):\n                self.site.settings[\"size\"] = site_size\n                self.site.settings[\"size_optional\"] = site_size_optional\n                return True\n            else:\n                return False\n\n    def verifyContentInclude(self, inner_path, content, content_size, content_size_optional):\n        \n        rules = self.getRules(inner_path, content)\n        if not rules:\n            raise VerifyError(\"No rules\")\n\n        \n        if rules.get(\"max_size\") is not None:  \n            if content_size > rules[\"max_size\"]:\n                raise VerifyError(\"Include too large %sB > %sB\" % (content_size, rules[\"max_size\"]))\n\n        if rules.get(\"max_size_optional\") is not None:  \n            if content_size_optional > rules[\"max_size_optional\"]:\n                raise VerifyError(\"Include optional files too large %sB > %sB\" % (\n                    content_size_optional, rules[\"max_size_optional\"])\n                )\n\n        \n        if rules.get(\"files_allowed\"):\n            for file_inner_path in content[\"files\"].keys():\n                if not SafeRe.match(\"^%s$\" % rules[\"files_allowed\"], file_inner_path):\n                    raise VerifyError(\"File not allowed: %s\" % file_inner_path)\n\n        if rules.get(\"files_allowed_optional\"):\n            for file_inner_path in content.get(\"files_optional\", {}).keys():\n                if not SafeRe.match(\"^%s$\" % rules[\"files_allowed_optional\"], file_inner_path):\n                    raise VerifyError(\"Optional file not allowed: %s\" % file_inner_path)\n\n        \n        if rules.get(\"includes_allowed\") is False and content.get(\"includes\"):\n            raise VerifyError(\"Includes not allowed\")\n\n        return True  \n\n    \n    one = Same as before, False = Invalid, True = Valid\n    def verifyFile(self, inner_path, file, ignore_same=True):\n        if inner_path.endswith(\"content.json\"):  \n            from Crypt import CryptBitcoin\n            try:\n                if type(file) is dict:\n                    new_content = file\n                else:\n                    new_content = json.load(file)\n                if inner_path in self.contents:\n                    old_content = self.contents.get(inner_path, {\"modified\": 0})\n                    \n                    if old_content[\"modified\"] == new_content[\"modified\"] and ignore_same:  \n                        return None\n                    elif old_content[\"modified\"] > new_content[\"modified\"]:  \n                        raise VerifyError(\n                            \"We have newer (Our: %s, Sent: %s)\" %\n                            (old_content[\"modified\"], new_content[\"modified\"])\n                        )\n                if new_content[\"modified\"] > time.time() + 60 * 60 * 24:  # Content modified in the far future (allow 1 day+)\n                    raise VerifyError(\"Modify timestamp is in the far future!\")\n                if self.isArchived(inner_path, new_content[\"modified\"]):\n                    if inner_path in self.site.bad_files:\n                        del self.site.bad_files[inner_path]\n                    raise VerifyError(\"This file is archived!\")\n                \n                sign = new_content.get(\"sign\")\n                signs = new_content.get(\"signs\", {})\n                if \"sign\" in new_content:\n                    del(new_content[\"sign\"])  \n                if \"signs\" in new_content:\n                    del(new_content[\"signs\"])  s\n\n                sign_content = json.dumps(new_content, sort_keys=True)  \n\n                \n                modified = new_content[\"modified\"]\n                if config.fix_float_decimals and type(modified) is float and not str(modified).endswith(\".0\"):\n                    modified_fixed = \"{:.6f}\".format(modified).strip(\"0.\")\n                    sign_content = sign_content.replace(\n                        '\"modified\": %s' % repr(modified),\n                        '\"modified\": %s' % modified_fixed\n                    )\n\n                self.verifyContent(inner_path, new_content)\n\n                if signs:  \n                    valid_signers = self.getValidSigners(inner_path, new_content)\n                    signs_required = self.getSignsRequired(inner_path, new_content)\n\n                    if inner_path == \"content.json\" and len(valid_signers) > 1:  ers_sign on root content.json\n                        signers_data = \"%s:%s\" % (signs_required, \",\".join(valid_signers))\n                        if not CryptBitcoin.verify(signers_data, self.site.address, new_content[\"signers_sign\"]):\n                            raise VerifyError(\"Invalid signers_sign!\")\n\n                    if inner_path != \"content.json\" and not self.verifyCert(inner_path, new_content):  \n                        raise VerifyError(\"Invalid cert!\")\n\n                    valid_signs = 0\n                    for address in valid_signers:\n                        if address in signs:\n                            valid_signs += CryptBitcoin.verify(sign_content, address, signs[address])\n                        if valid_signs >= signs_required:\n                            break  \n                    if valid_signs < signs_required:\n                        raise VerifyError(\"Valid signs: %s/%s\" % (valid_signs, signs_required))\n                    else:\n                        return True\n                else:  \n                    if CryptBitcoin.verify(sign_content, self.site.address, sign):\n                        return True\n                    else:\n                        raise VerifyError(\"Invalid old-style sign\")\n\n            except Exception, err:\n                self.log.warning(\"%s: verify sign error: %s\" % (inner_path, Debug.formatException(err)))\n                raise err\n\n        else:  \n            file_info = self.getFileInfo(inner_path)\n            if file_info:\n                if CryptHash.sha512sum(file) != file_info.get(\"sha512\", \"\"):\n                    raise VerifyError(\"Invalid hash\")\n\n                if file_info.get(\"size\", 0) != file.tell():\n                    raise VerifyError(\n                        \"File size does not match %s <> %s\" %\n                        (inner_path, file.tell(), file_info.get(\"size\", 0))\n                    )\n\n                return True\n\n            else:  \n                raise VerifyError(\"File not in content.json\")\n\n    def optionalDownloaded(self, inner_path, hash, size=None, own=False):\n        if size is None:\n            size = self.site.storage.getSize(inner_path)\n        if type(hash) is int:\n            done = self.hashfield.appendHashId(hash)\n        else:\n            done = self.hashfield.appendHash(hash)\n        self.site.settings[\"optional_downloaded\"] += size\n        return done\n\n    def optionalRemove(self, inner_path, hash, size=None):\n        if size is None:\n            size = self.site.storage.getSize(inner_path)\n        if type(hash) is int:\n            done = self.hashfield.removeHashId(hash)\n        else:\n            done = self.hashfield.removeHash(hash)\n        self.site.settings[\"optional_downloaded\"] -= size\n        return done\n", "comments": "  load content json files    load hashfield cache    no hashfield cache created yet    load content json self content    return  changed files   index html    data messages json    deleted files   old jpg      remove   beginning    check file newer    content json exist    get files sha512 changed    check changed    backward compatibility    we file old content    the file old content    check changed optional files    we file old content    download new file    the file old content    download new file    check deleted    deleting files longer content json    check deleted file optional    cleanup empty dirs    remove tree dict reflect changed state    check archived    load includes    content json exists  load    add changed files    add changed files    content json exist  add changed files    load blind user includes (all subdir)    content json exist    add changed files    add changed files    save memory    update content    content json parse error    add changed files bad files    dont store modifications far future (more 10 minute)    deleting files longer content json    get total size site    return  32819 (size files kb)    returns file given modification date archived    find file info line self contents    return     sha512    c29d73d   21f518    size   41    content inner path    content json      parent dirs content json    filename relative content json    check files    check optional files    check file content json    return rules user dir    no inner path dir  lets try parent dir    no parent dirs    not found    get rules file    return  the rules file false allowed    find files content json first    file found    root content json    parent dirs content json    filename relative content json    dont check self dir    no inner path dir  lets try parent dir    no parent dirs    get rules user file    return  the rules file false allowed    delivered directory    read file content specified    web nofish zeroid bit    content json exist    default rules based address    default rules based username    make copy signers    regexp rules    rule valid user    update rules better current recorded ones    make copy    int  update larger    string  update longer    list  append    add valid cert signers    add user valid signer    get diffs changed files    new version present    old version present    calculate sha512 sum file    hash files directory    ignore content json  defined regexp files starting      create sign content json    return  the new content filewrite   false    recover cert sign file    content exist yet  load default one    default content json    it root content json  add fields    add extend keys exists    find changed files    generate new content json    create copy current content json    add files sha512 hash    add timestamp    verify private key    if signing using root key  sign valid signers    delete old signs    delete old sign (backward compatibility)    new content  signs     content get( signs     )   todo  multisig    if signing successful (not old address)    written file    return new content    the valid signers content json file    return    1krxe1s3odyndawuywpzbluwnm8odbeep6    13reyhcsjhpucvahn1dhdf6emqqevev162      root content json    site address always valid    return  the required number valid signs content json    todo  multisig    does need cert    cert signer allowed        (rules  user address    content  cert auth type    name)    checks content json content valid    return  true false    size new content    calculate old content size    reset site site first content json    site size without old content plus new    site size without old content plus new    check site address    check file inner path    check total site size limit    first content json download  save site size display warning    dont try download peers    verify valid filenames    root content json passed    load include details    check include size limit    include size limit    include optional files limit    filename limit    check content includes allowed    all good    verify file validity    return  none   same  false   invalid  true   valid    content json  check using sign    checks newer    ignore  content json    we newer    content modified far future (allow 1 day )    check sign    the file signed without sign    the file signed without signs    dump json string remove whitepsace    fix float representation error android    new style signing    check signers sign root content json    check cert valid    break enough signs    old style signing    check using sha512 hash    file content json ", "content": "import json\nimport time\nimport re\nimport os\nimport copy\n\nimport gevent\n\nfrom Debug import Debug\nfrom Crypt import CryptHash\nfrom Config import config\nfrom util import helper\nfrom util import Diff\nfrom util import SafeRe\nfrom Peer import PeerHashfield\nfrom ContentDbDict import ContentDbDict\nfrom Plugin import PluginManager\n\n\nclass VerifyError(Exception):\n    pass\n\n\nclass SignError(Exception):\n    pass\n\n\n@PluginManager.acceptPlugins\nclass ContentManager(object):\n\n    def __init__(self, site):\n        self.site = site\n        self.log = self.site.log\n        self.contents = ContentDbDict(site)\n        self.hashfield = PeerHashfield()\n        self.has_optional_files = False\n\n    # Load all content.json files\n    def loadContents(self):\n        if len(self.contents) == 0:\n            self.log.debug(\"ContentDb not initialized, load files from filesystem\")\n            self.loadContent(add_bad_files=False, delete_removed_files=False)\n        self.site.settings[\"size\"], self.site.settings[\"size_optional\"] = self.getTotalSize()\n\n        # Load hashfield cache\n        if \"hashfield\" in self.site.settings.get(\"cache\", {}):\n            self.hashfield.fromstring(self.site.settings[\"cache\"][\"hashfield\"].decode(\"base64\"))\n            del self.site.settings[\"cache\"][\"hashfield\"]\n        elif self.contents.get(\"content.json\") and self.site.settings[\"size_optional\"] > 0:\n            self.site.storage.updateBadFiles()  # No hashfield cache created yet\n        self.has_optional_files = bool(self.hashfield)\n\n        self.contents.db.initSite(self.site)\n\n    # Load content.json to self.content\n    # Return: Changed files [\"index.html\", \"data/messages.json\"], Deleted files [\"old.jpg\"]\n    def loadContent(self, content_inner_path=\"content.json\", add_bad_files=True, delete_removed_files=True, load_includes=True, force=False):\n        content_inner_path = content_inner_path.strip(\"/\")  # Remove / from beginning\n        old_content = self.contents.get(content_inner_path)\n        content_path = self.site.storage.getPath(content_inner_path)\n        content_dir = helper.getDirname(self.site.storage.getPath(content_inner_path))\n        content_inner_dir = helper.getDirname(content_inner_path)\n\n        if os.path.isfile(content_path):\n            try:\n                # Check if file is newer than what we have\n                if not force and old_content and not self.site.settings.get(\"own\"):\n                    for line in open(content_path):\n                        if '\"modified\"' not in line:\n                            continue\n                        match = re.search(\"([0-9\\.]+),$\", line.strip(\" \\r\\n\"))\n                        if match and float(match.group(1)) <= old_content.get(\"modified\", 0):\n                            self.log.debug(\"%s loadContent same json file, skipping\" % content_inner_path)\n                            return [], []\n\n                new_content = json.load(open(content_path))\n            except Exception, err:\n                self.log.warning(\"%s load error: %s\" % (content_path, Debug.formatException(err)))\n                return [], []\n        else:\n            self.log.warning(\"Content.json not exist: %s\" % content_path)\n            return [], []  # Content.json not exist\n\n        try:\n            # Get the files where the sha512 changed\n            changed = []\n            deleted = []\n            # Check changed\n            for relative_path, info in new_content.get(\"files\", {}).iteritems():\n                if \"sha512\" in info:\n                    hash_type = \"sha512\"\n                else:  # Backward compatibility\n                    hash_type = \"sha1\"\n\n                new_hash = info[hash_type]\n                if old_content and old_content[\"files\"].get(relative_path):  # We have the file in the old content\n                    old_hash = old_content[\"files\"][relative_path].get(hash_type)\n                else:  # The file is not in the old content\n                    old_hash = None\n                if old_hash != new_hash:\n                    changed.append(content_inner_dir + relative_path)\n\n            # Check changed optional files\n            for relative_path, info in new_content.get(\"files_optional\", {}).iteritems():\n                file_inner_path = content_inner_dir + relative_path\n                new_hash = info[\"sha512\"]\n                if old_content and old_content.get(\"files_optional\", {}).get(relative_path):\n                    # We have the file in the old content\n                    old_hash = old_content[\"files_optional\"][relative_path].get(\"sha512\")\n                    if old_hash != new_hash and self.site.isDownloadable(file_inner_path):\n                        changed.append(file_inner_path)  # Download new file\n                    elif old_hash != new_hash and self.hashfield.hasHash(old_hash) and not self.site.settings.get(\"own\"):\n                        try:\n                            self.optionalRemove(file_inner_path, old_hash, old_content[\"files_optional\"][relative_path][\"size\"])\n                            self.site.storage.delete(file_inner_path)\n                            self.log.debug(\"Deleted changed optional file: %s\" % file_inner_path)\n                        except Exception, err:\n                            self.log.debug(\"Error deleting file %s: %s\" % (file_inner_path, err))\n                else:  # The file is not in the old content\n                    if self.site.isDownloadable(file_inner_path):\n                        changed.append(file_inner_path)  # Download new file\n\n            # Check deleted\n            if old_content:\n                old_files = dict(\n                    old_content.get(\"files\", {}),\n                    **old_content.get(\"files_optional\", {})\n                )\n\n                new_files = dict(\n                    new_content.get(\"files\", {}),\n                    **new_content.get(\"files_optional\", {})\n                )\n\n                deleted = [key for key in old_files if key not in new_files]\n                if deleted and not self.site.settings.get(\"own\"):\n                    # Deleting files that no longer in content.json\n                    for file_relative_path in deleted:\n                        file_inner_path = content_inner_dir + file_relative_path\n                        try:\n                            self.site.storage.delete(file_inner_path)\n\n                            # Check if the deleted file is optional\n                            if old_content.get(\"files_optional\") and old_content[\"files_optional\"].get(file_relative_path):\n                                old_hash = old_content[\"files_optional\"][file_relative_path].get(\"sha512\")\n                                if self.hashfield.hasHash(old_hash):\n                                    self.optionalRemove(file_inner_path, old_hash, old_content[\"files_optional\"][file_relative_path][\"size\"])\n\n                            self.log.debug(\"Deleted file: %s\" % file_inner_path)\n                        except Exception, err:\n                            self.log.debug(\"Error deleting file %s: %s\" % (file_inner_path, err))\n\n                    # Cleanup empty dirs\n                    tree = {root: [dirs, files] for root, dirs, files in os.walk(self.site.storage.getPath(content_inner_dir))}\n                    for root in sorted(tree, key=len, reverse=True):\n                        dirs, files = tree[root]\n                        if dirs == [] and files == []:\n                            root_inner_path = self.site.storage.getInnerPath(root.replace(\"\\\\\", \"/\"))\n                            self.log.debug(\"Empty directory: %s, cleaning up.\" % root_inner_path)\n                            try:\n                                self.site.storage.deleteDir(root_inner_path)\n                                # Remove from tree dict to reflect changed state\n                                tree[os.path.dirname(root)][0].remove(os.path.basename(root))\n                            except Exception, err:\n                                self.log.debug(\"Error deleting empty directory %s: %s\" % (root_inner_path, err))\n\n            # Check archived\n            if old_content and \"user_contents\" in new_content and \"archived\" in new_content[\"user_contents\"]:\n                old_archived = old_content.get(\"user_contents\", {}).get(\"archived\", {})\n                new_archived = new_content.get(\"user_contents\", {}).get(\"archived\", {})\n                self.log.debug(\"old archived: %s, new archived: %s\" % (len(old_archived), len(new_archived)))\n                archived_changed = {\n                    key: date_archived\n                    for key, date_archived in new_archived.iteritems()\n                    if old_archived.get(key) != new_archived[key]\n                }\n                if archived_changed:\n                    self.log.debug(\"Archived changed: %s\" % archived_changed)\n                    for archived_dirname, date_archived in archived_changed.iteritems():\n                        archived_inner_path = content_inner_dir + archived_dirname + \"/content.json\"\n                        if self.contents.get(archived_inner_path, {}).get(\"modified\", 0) < date_archived:\n                            self.removeContent(archived_inner_path)\n                    self.site.settings[\"size\"], self.site.settings[\"size_optional\"] = self.getTotalSize()\n\n            # Load includes\n            if load_includes and \"includes\" in new_content:\n                for relative_path, info in new_content[\"includes\"].items():\n                    include_inner_path = content_inner_dir + relative_path\n                    if self.site.storage.isFile(include_inner_path):  # Content.json exists, load it\n                        include_changed, include_deleted = self.loadContent(\n                            include_inner_path, add_bad_files=add_bad_files, delete_removed_files=delete_removed_files\n                        )\n                        if include_changed:\n                            changed += include_changed  # Add changed files\n                        if include_deleted:\n                            deleted += include_deleted  # Add changed files\n                    else:  # Content.json not exist, add to changed files\n                        self.log.debug(\"Missing include: %s\" % include_inner_path)\n                        changed += [include_inner_path]\n\n            # Load blind user includes (all subdir)\n            if load_includes and \"user_contents\" in new_content:\n                for relative_dir in os.listdir(content_dir):\n                    include_inner_path = content_inner_dir + relative_dir + \"/content.json\"\n                    if not self.site.storage.isFile(include_inner_path):\n                        continue  # Content.json not exist\n                    include_changed, include_deleted = self.loadContent(\n                        include_inner_path, add_bad_files=add_bad_files, delete_removed_files=delete_removed_files,\n                        load_includes=False\n                    )\n                    if include_changed:\n                        changed += include_changed  # Add changed files\n                    if include_deleted:\n                        deleted += include_deleted  # Add changed files\n\n            # Save some memory\n            new_content[\"signs\"] = None\n            if \"cert_sign\" in new_content:\n                new_content[\"cert_sign\"] = None\n\n            if new_content.get(\"files_optional\"):\n                self.has_optional_files = True\n            # Update the content\n            self.contents[content_inner_path] = new_content\n        except Exception, err:\n            self.log.warning(\"%s parse error: %s\" % (content_inner_path, Debug.formatException(err)))\n            return [], []  # Content.json parse error\n\n        # Add changed files to bad files\n        if add_bad_files:\n            for inner_path in changed:\n                self.site.bad_files[inner_path] = self.site.bad_files.get(inner_path, 0) + 1\n            for inner_path in deleted:\n                if inner_path in self.site.bad_files:\n                    del self.site.bad_files[inner_path]\n\n        if new_content.get(\"modified\", 0) > self.site.settings.get(\"modified\", 0):\n            # Dont store modifications in the far future (more than 10 minute)\n            self.site.settings[\"modified\"] = min(time.time() + 60 * 10, new_content[\"modified\"])\n\n        return changed, deleted\n\n    def removeContent(self, inner_path):\n        inner_dir = helper.getDirname(inner_path)\n        try:\n            content = self.contents[inner_path]\n            files = dict(\n                content.get(\"files\", {}),\n                **content.get(\"files_optional\", {})\n            )\n        except Exception, err:\n            self.log.debug(\"Error loading %s for removeContent: %s\" % (inner_path, Debug.formatException(err)))\n            files = {}\n        files[\"content.json\"] = True\n        # Deleting files that no longer in content.json\n        for file_relative_path in files:\n            file_inner_path = inner_dir + file_relative_path\n            try:\n                self.site.storage.delete(file_inner_path)\n                self.log.debug(\"Deleted file: %s\" % file_inner_path)\n            except Exception, err:\n                self.log.debug(\"Error deleting file %s: %s\" % (file_inner_path, err))\n        try:\n            self.site.storage.deleteDir(inner_dir)\n        except Exception, err:\n            self.log.debug(\"Error deleting dir %s: %s\" % (inner_dir, err))\n\n        try:\n            del self.contents[inner_path]\n        except Exception, err:\n            self.log.debug(\"Error key from contents: %s\" % inner_path)\n\n    # Get total size of site\n    # Return: 32819 (size of files in kb)\n    def getTotalSize(self, ignore=None):\n        return self.contents.db.getTotalSize(self.site, ignore)\n\n    def listModified(self, since):\n        return self.contents.db.listModified(self.site, since)\n\n    def listContents(self, inner_path=\"content.json\", user_files=False):\n        if inner_path not in self.contents:\n            return []\n        back = [inner_path]\n        content_inner_dir = helper.getDirname(inner_path)\n        for relative_path in self.contents[inner_path].get(\"includes\", {}).keys():\n            include_inner_path = content_inner_dir + relative_path\n            back += self.listContents(include_inner_path)\n        return back\n\n    # Returns if file with the given modification date is archived or not\n    def isArchived(self, inner_path, modified):\n        file_info = self.getFileInfo(inner_path)\n        match = re.match(\".*/(.*?)/\", inner_path)\n        if not match:\n            return False\n        relative_directory = match.group(1)\n        if file_info and file_info.get(\"archived\", {}).get(relative_directory) >= modified:\n            return True\n        else:\n            return False\n\n    # Find the file info line from self.contents\n    # Return: { \"sha512\": \"c29d73d...21f518\", \"size\": 41 , \"content_inner_path\": \"content.json\"}\n    def getFileInfo(self, inner_path, new_file=False):\n        dirs = inner_path.split(\"/\")  # Parent dirs of content.json\n        inner_path_parts = [dirs.pop()]  # Filename relative to content.json\n        while True:\n            content_inner_path = \"%s/content.json\" % \"/\".join(dirs)\n            content_inner_path = content_inner_path.strip(\"/\")\n            content = self.contents.get(content_inner_path)\n\n            # Check in files\n            if content and \"files\" in content:\n                back = content[\"files\"].get(\"/\".join(inner_path_parts))\n                if back:\n                    back[\"content_inner_path\"] = content_inner_path\n                    back[\"optional\"] = False\n                    back[\"relative_path\"] = \"/\".join(inner_path_parts)\n                    return back\n\n            # Check in optional files\n            if content and \"files_optional\" in content:  # Check if file in this content.json\n                back = content[\"files_optional\"].get(\"/\".join(inner_path_parts))\n                if back:\n                    back[\"content_inner_path\"] = content_inner_path\n                    back[\"optional\"] = True\n                    back[\"relative_path\"] = \"/\".join(inner_path_parts)\n                    return back\n\n            # Return the rules if user dir\n            if content and \"user_contents\" in content:\n                back = content[\"user_contents\"]\n                content_inner_path_dir = helper.getDirname(content_inner_path)\n                relative_content_path = inner_path[len(content_inner_path_dir):]\n                if \"/\" in relative_content_path:\n                    user_auth_address = re.match(\"([A-Za-z0-9]+)/.*\", relative_content_path).group(1)\n                    back[\"content_inner_path\"] = \"%s%s/content.json\" % (content_inner_path_dir, user_auth_address)\n                else:\n                    back[\"content_inner_path\"] = content_inner_path_dir + \"content.json\"\n                back[\"optional\"] = None\n                back[\"relative_path\"] = \"/\".join(inner_path_parts)\n                return back\n\n            if new_file and content:\n                back = {}\n                back[\"content_inner_path\"] = content_inner_path\n                back[\"relative_path\"] = \"/\".join(inner_path_parts)\n                back[\"optional\"] = None\n                return back\n\n            # No inner path in this dir, lets try the parent dir\n            if dirs:\n                inner_path_parts.insert(0, dirs.pop())\n            else:  # No more parent dirs\n                break\n\n        # Not found\n        return False\n\n    # Get rules for the file\n    # Return: The rules for the file or False if not allowed\n    def getRules(self, inner_path, content=None):\n        if not inner_path.endswith(\"content.json\"):  # Find the files content.json first\n            file_info = self.getFileInfo(inner_path)\n            if not file_info:\n                return False  # File not found\n            inner_path = file_info[\"content_inner_path\"]\n\n        if inner_path == \"content.json\":  # Root content.json\n            rules = {}\n            rules[\"signers\"] = self.getValidSigners(inner_path, content)\n            return rules\n\n        dirs = inner_path.split(\"/\")  # Parent dirs of content.json\n        inner_path_parts = [dirs.pop()]  # Filename relative to content.json\n        inner_path_parts.insert(0, dirs.pop())  # Dont check in self dir\n        while True:\n            content_inner_path = \"%s/content.json\" % \"/\".join(dirs)\n            parent_content = self.contents.get(content_inner_path.strip(\"/\"))\n            if parent_content and \"includes\" in parent_content:\n                return parent_content[\"includes\"].get(\"/\".join(inner_path_parts))\n            elif parent_content and \"user_contents\" in parent_content:\n                return self.getUserContentRules(parent_content, inner_path, content)\n            else:  # No inner path in this dir, lets try the parent dir\n                if dirs:\n                    inner_path_parts.insert(0, dirs.pop())\n                else:  # No more parent dirs\n                    break\n\n        return False\n\n    # Get rules for a user file\n    # Return: The rules of the file or False if not allowed\n    def getUserContentRules(self, parent_content, inner_path, content):\n        user_contents = parent_content[\"user_contents\"]\n\n        # Delivered for directory\n        if \"inner_path\" in parent_content:\n            parent_content_dir = helper.getDirname(parent_content[\"inner_path\"])\n            user_address = re.match(\"([A-Za-z0-9]*?)/\", inner_path[len(parent_content_dir):]).group(1)\n        else:\n            user_address = re.match(\".*/([A-Za-z0-9]*?)/.*?$\", inner_path).group(1)\n\n        try:\n            if not content:\n                content = self.site.storage.loadJson(inner_path)  # Read the file if no content specified\n            user_urn = \"%s/%s\" % (content[\"cert_auth_type\"], content[\"cert_user_id\"])  # web/nofish@zeroid.bit\n            cert_user_id = content[\"cert_user_id\"]\n        except Exception:  # Content.json not exist\n            user_urn = \"n-a/n-a\"\n            cert_user_id = \"n-a\"\n\n        if user_address in user_contents[\"permissions\"]:\n            rules = copy.copy(user_contents[\"permissions\"].get(user_address, {}))  # Default rules based on address\n        else:\n            rules = copy.copy(user_contents[\"permissions\"].get(cert_user_id, {}))  # Default rules based on username\n\n        if rules is False:\n            banned = True\n            rules = {}\n        else:\n            banned = False\n        if \"signers\" in rules:\n            rules[\"signers\"] = rules[\"signers\"][:]  # Make copy of the signers\n        for permission_pattern, permission_rules in user_contents[\"permission_rules\"].items():  # Regexp rules\n            if not SafeRe.match(permission_pattern, user_urn):\n                continue  # Rule is not valid for user\n            # Update rules if its better than current recorded ones\n            for key, val in permission_rules.iteritems():\n                if key not in rules:\n                    if type(val) is list:\n                        rules[key] = val[:]  # Make copy\n                    else:\n                        rules[key] = val\n                elif type(val) is int:  # Int, update if larger\n                    if val > rules[key]:\n                        rules[key] = val\n                elif hasattr(val, \"startswith\"):  # String, update if longer\n                    if len(val) > len(rules[key]):\n                        rules[key] = val\n                elif type(val) is list:  # List, append\n                    rules[key] += val\n\n        rules[\"cert_signers\"] = user_contents[\"cert_signers\"]  # Add valid cert signers\n        if \"signers\" not in rules:\n            rules[\"signers\"] = []\n\n        if not banned:\n            rules[\"signers\"].append(user_address)  # Add user as valid signer\n        rules[\"user_address\"] = user_address\n        rules[\"includes_allowed\"] = False\n\n        return rules\n\n    # Get diffs for changed files\n    def getDiffs(self, inner_path, limit=30 * 1024, update_files=True):\n        if inner_path not in self.contents:\n            return {}\n        diffs = {}\n        content_inner_path_dir = helper.getDirname(inner_path)\n        for file_relative_path in self.contents[inner_path].get(\"files\", {}):\n            file_inner_path = content_inner_path_dir + file_relative_path\n            if self.site.storage.isFile(file_inner_path + \"-new\"):  # New version present\n                diffs[file_relative_path] = Diff.diff(\n                    list(self.site.storage.open(file_inner_path)),\n                    list(self.site.storage.open(file_inner_path + \"-new\")),\n                    limit=limit\n                )\n                if update_files:\n                    self.site.storage.delete(file_inner_path)\n                    self.site.storage.rename(file_inner_path + \"-new\", file_inner_path)\n            if self.site.storage.isFile(file_inner_path + \"-old\"):  # Old version present\n                diffs[file_relative_path] = Diff.diff(\n                    list(self.site.storage.open(file_inner_path + \"-old\")),\n                    list(self.site.storage.open(file_inner_path)),\n                    limit=limit\n                )\n                if update_files:\n                    self.site.storage.delete(file_inner_path + \"-old\")\n        return diffs\n\n    def hashFile(self, dir_inner_path, file_relative_path, optional=False):\n        back = {}\n        file_inner_path = dir_inner_path + \"/\" + file_relative_path\n\n        file_path = self.site.storage.getPath(file_inner_path)\n        file_size = os.path.getsize(file_path)\n        sha512sum = CryptHash.sha512sum(file_path)  # Calculate sha512 sum of file\n        if optional and not self.hashfield.hasHash(sha512sum):\n            self.optionalDownloaded(file_inner_path, sha512sum, file_size, own=True)\n\n        back[file_relative_path] = {\"sha512\": sha512sum, \"size\": os.path.getsize(file_path)}\n        return back\n\n    def isValidRelativePath(self, relative_path):\n        if \"..\" in relative_path:\n            return False\n        elif len(relative_path) > 255:\n            return False\n        else:\n            return re.match(\"^[a-z\\[\\]\\(\\) A-Z0-9_@=\\.\\+-/]+$\", relative_path)\n\n    def sanitizePath(self, inner_path):\n        return re.sub(\"[^a-z\\[\\]\\(\\) A-Z0-9_@=\\.\\+-/]\", \"\", inner_path)\n\n    # Hash files in directory\n    def hashFiles(self, dir_inner_path, ignore_pattern=None, optional_pattern=None):\n        files_node = {}\n        files_optional_node = {}\n        if dir_inner_path and not self.isValidRelativePath(dir_inner_path):\n            ignored = True\n            self.log.error(\"- [ERROR] Only ascii encoded directories allowed: %s\" % dir_inner_path)\n\n        for file_relative_path in self.site.storage.walk(dir_inner_path, ignore_pattern):\n            file_name = helper.getFilename(file_relative_path)\n\n            ignored = optional = False\n            if file_name == \"content.json\":\n                ignored = True\n            elif file_name.startswith(\".\") or file_name.endswith(\"-old\") or file_name.endswith(\"-new\"):\n                ignored = True\n            elif not self.isValidRelativePath(file_relative_path):\n                ignored = True\n                self.log.error(\"- [ERROR] Invalid filename: %s\" % file_relative_path)\n            elif dir_inner_path == \"\" and file_relative_path == self.site.storage.getDbFile():\n                ignored = True\n            elif optional_pattern and SafeRe.match(optional_pattern, file_relative_path):\n                optional = True\n\n            if ignored:  # Ignore content.json, defined regexp and files starting with .\n                self.log.info(\"- [SKIPPED] %s\" % file_relative_path)\n            else:\n                if optional:\n                    self.log.info(\"- [OPTIONAL] %s\" % file_relative_path)\n                    files_optional_node.update(\n                        self.hashFile(dir_inner_path, file_relative_path, optional=True)\n                    )\n                else:\n                    self.log.info(\"- %s\" % file_relative_path)\n                    files_node.update(\n                        self.hashFile(dir_inner_path, file_relative_path)\n                    )\n        return files_node, files_optional_node\n\n    # Create and sign a content.json\n    # Return: The new content if filewrite = False\n    def sign(self, inner_path=\"content.json\", privatekey=None, filewrite=True, update_changed_files=False, extend=None, remove_missing_optional=False):\n        if not inner_path.endswith(\"content.json\"):\n            raise SignError(\"Invalid file name, you can only sign content.json files\")\n\n        if inner_path in self.contents:\n            content = self.contents.get(inner_path)\n            if content and content.get(\"cert_sign\", False) is None and self.site.storage.isFile(inner_path):\n                # Recover cert_sign from file\n                content[\"cert_sign\"] = self.site.storage.loadJson(inner_path).get(\"cert_sign\")\n        else:\n            content = None\n        if not content:  # Content not exist yet, load default one\n            self.log.info(\"File %s not exist yet, loading default values...\" % inner_path)\n\n            if self.site.storage.isFile(inner_path):\n                content = self.site.storage.loadJson(inner_path)\n                if \"files\" not in content:\n                    content[\"files\"] = {}\n                if \"signs\" not in content:\n                    content[\"signs\"] = {}\n            else:\n                content = {\"files\": {}, \"signs\": {}}  # Default content.json\n\n            if inner_path == \"content.json\":  # It's the root content.json, add some more fields\n                content[\"title\"] = \"%s - ZeroNet_\" % self.site.address\n                content[\"description\"] = \"\"\n                content[\"signs_required\"] = 1\n                content[\"ignore\"] = \"\"\n\n        if extend:\n            # Add extend keys if not exists\n            for key, val in extend.items():\n                if not content.get(key):\n                    content[key] = val\n                    self.log.info(\"Extending content.json with: %s\" % key)\n\n        directory = helper.getDirname(self.site.storage.getPath(inner_path))\n        inner_directory = helper.getDirname(inner_path)\n        self.log.info(\"Opening site data directory: %s...\" % directory)\n\n        changed_files = [inner_path]\n        files_node, files_optional_node = self.hashFiles(\n            helper.getDirname(inner_path), content.get(\"ignore\"), content.get(\"optional\")\n        )\n\n        if not remove_missing_optional:\n            for file_inner_path, file_details in content.get(\"files_optional\", {}).iteritems():\n                if file_inner_path not in files_optional_node:\n                    files_optional_node[file_inner_path] = file_details\n\n        # Find changed files\n        files_merged = files_node.copy()\n        files_merged.update(files_optional_node)\n        for file_relative_path, file_details in files_merged.iteritems():\n            old_hash = content.get(\"files\", {}).get(file_relative_path, {}).get(\"sha512\")\n            new_hash = files_merged[file_relative_path][\"sha512\"]\n            if old_hash != new_hash:\n                changed_files.append(inner_directory + file_relative_path)\n\n        self.log.debug(\"Changed files: %s\" % changed_files)\n        if update_changed_files:\n            for file_path in changed_files:\n                self.site.storage.onUpdated(file_path)\n\n        # Generate new content.json\n        self.log.info(\"Adding timestamp and sha512sums to new content.json...\")\n\n        new_content = content.copy()  # Create a copy of current content.json\n        new_content[\"files\"] = files_node  # Add files sha512 hash\n        if files_optional_node:\n            new_content[\"files_optional\"] = files_optional_node\n        elif \"files_optional\" in new_content:\n            del new_content[\"files_optional\"]\n\n        new_content[\"modified\"] = int(time.time())  # Add timestamp\n        if inner_path == \"content.json\":\n            new_content[\"zeronet_version\"] = config.version\n            new_content[\"signs_required\"] = content.get(\"signs_required\", 1)\n\n        new_content[\"address\"] = self.site.address\n        new_content[\"inner_path\"] = inner_path\n\n        # Verify private key\n        from Crypt import CryptBitcoin\n        self.log.info(\"Verifying private key...\")\n        privatekey_address = CryptBitcoin.privatekeyToAddress(privatekey)\n        valid_signers = self.getValidSigners(inner_path, new_content)\n        if privatekey_address not in valid_signers:\n            raise SignError(\n                \"Private key invalid! Valid signers: %s, Private key address: %s\" %\n                (valid_signers, privatekey_address)\n            )\n        self.log.info(\"Correct %s in valid signers: %s\" % (privatekey_address, valid_signers))\n\n        if inner_path == \"content.json\" and privatekey_address == self.site.address:\n            # If signing using the root key, then sign the valid signers\n            signers_data = \"%s:%s\" % (new_content[\"signs_required\"], \",\".join(valid_signers))\n            new_content[\"signers_sign\"] = CryptBitcoin.sign(str(signers_data), privatekey)\n            if not new_content[\"signers_sign\"]:\n                self.log.info(\"Old style address, signers_sign is none\")\n\n        self.log.info(\"Signing %s...\" % inner_path)\n\n        if \"signs\" in new_content:\n            del(new_content[\"signs\"])  # Delete old signs\n        if \"sign\" in new_content:\n            del(new_content[\"sign\"])  # Delete old sign (backward compatibility)\n\n        sign_content = json.dumps(new_content, sort_keys=True)\n        sign = CryptBitcoin.sign(sign_content, privatekey)\n        # new_content[\"signs\"] = content.get(\"signs\", {}) # TODO: Multisig\n        if sign:  # If signing is successful (not an old address)\n            new_content[\"signs\"] = {}\n            new_content[\"signs\"][privatekey_address] = sign\n\n        self.verifyContent(inner_path, new_content)\n\n        if filewrite:\n            self.log.info(\"Saving to %s...\" % inner_path)\n            self.site.storage.writeJson(inner_path, new_content)\n            self.contents[inner_path] = new_content\n\n        self.log.info(\"File %s signed!\" % inner_path)\n\n        if filewrite:  # Written to file\n            return True\n        else:  # Return the new content\n            return new_content\n\n    # The valid signers of content.json file\n    # Return: [\"1KRxE1s3oDyNDawuYWpzbLUwNm8oDbeEp6\", \"13ReyhCsjhpuCVahn1DHdf6eMqqEVev162\"]\n    def getValidSigners(self, inner_path, content=None):\n        valid_signers = []\n        if inner_path == \"content.json\":  # Root content.json\n            if \"content.json\" in self.contents and \"signers\" in self.contents[\"content.json\"]:\n                valid_signers += self.contents[\"content.json\"][\"signers\"][:]\n        else:\n            rules = self.getRules(inner_path, content)\n            if rules and \"signers\" in rules:\n                valid_signers += rules[\"signers\"]\n\n        if self.site.address not in valid_signers:\n            valid_signers.append(self.site.address)  # Site address always valid\n        return valid_signers\n\n    # Return: The required number of valid signs for the content.json\n    def getSignsRequired(self, inner_path, content=None):\n        return 1  # Todo: Multisig\n\n    def verifyCert(self, inner_path, content):\n        from Crypt import CryptBitcoin\n\n        rules = self.getRules(inner_path, content)\n\n        if not rules.get(\"cert_signers\"):\n            return True  # Does not need cert\n\n        if \"cert_user_id\" not in content:\n            raise VerifyError(\"Missing cert_user_id\")\n\n        name, domain = content[\"cert_user_id\"].split(\"@\")\n        cert_address = rules[\"cert_signers\"].get(domain)\n        if not cert_address:  # Cert signer not allowed\n            raise VerifyError(\"Invalid cert signer: %s\" % domain)\n\n        try:\n            cert_subject = \"%s#%s/%s\" % (rules[\"user_address\"], content[\"cert_auth_type\"], name)\n            result = CryptBitcoin.verify(cert_subject, cert_address, content[\"cert_sign\"])\n        except Exception, err:\n            raise VerifyError(\"Certificate verify error: %s\" % err)\n        return result\n\n    # Checks if the content.json content is valid\n    # Return: True or False\n    def verifyContent(self, inner_path, content):\n        content_size = len(json.dumps(content, indent=1)) + sum([file[\"size\"] for file in content[\"files\"].values() if file[\"size\"] >= 0])  # Size of new content\n        # Calculate old content size\n        old_content = self.contents.get(inner_path)\n        if old_content:\n            old_content_size = len(json.dumps(old_content, indent=1)) + sum([file[\"size\"] for file in old_content.get(\"files\", {}).values()])\n            old_content_size_optional = sum([file[\"size\"] for file in old_content.get(\"files_optional\", {}).values()])\n        else:\n            old_content_size = 0\n            old_content_size_optional = 0\n\n        # Reset site site on first content.json\n        if not old_content and inner_path == \"content.json\":\n            self.site.settings[\"size\"] = 0\n\n        content_size_optional = sum([file[\"size\"] for file in content.get(\"files_optional\", {}).values() if file[\"size\"] >= 0])\n        site_size = self.site.settings[\"size\"] - old_content_size + content_size  # Site size without old content plus the new\n        site_size_optional = self.site.settings[\"size_optional\"] - old_content_size_optional + content_size_optional  # Site size without old content plus the new\n\n        site_size_limit = self.site.getSizeLimit() * 1024 * 1024\n\n        # Check site address\n        if content.get(\"address\") and content[\"address\"] != self.site.address:\n            raise VerifyError(\"Wrong site address: %s != %s\" % (content[\"address\"], self.site.address))\n\n        # Check file inner path\n        if content.get(\"inner_path\") and content[\"inner_path\"] != inner_path:\n            raise VerifyError(\"Wrong inner_path: %s\" % content[\"inner_path\"])\n\n        # Check total site size limit\n        if site_size > site_size_limit:\n            if inner_path == \"content.json\" and self.site.settings[\"size\"] == 0:\n                # First content.json download, save site size to display warning\n                self.site.settings[\"size\"] = site_size\n            task = self.site.worker_manager.findTask(inner_path)\n            if task:  # Dont try to download from other peers\n                self.site.worker_manager.failTask(task)\n            raise VerifyError(\"Content too large %sB > %sB, aborting task...\" % (site_size, site_size_limit))\n\n        # Verify valid filenames\n        for file_relative_path in content.get(\"files\", {}).keys() + content.get(\"files_optional\", {}).keys():\n            if not self.isValidRelativePath(file_relative_path):\n                raise VerifyError(\"Invalid relative path: %s\" % file_relative_path)\n\n        if inner_path == \"content.json\":\n            self.site.settings[\"size\"] = site_size\n            self.site.settings[\"size_optional\"] = site_size_optional\n            return True  # Root content.json is passed\n        else:\n            if self.verifyContentInclude(inner_path, content, content_size, content_size_optional):\n                self.site.settings[\"size\"] = site_size\n                self.site.settings[\"size_optional\"] = site_size_optional\n                return True\n            else:\n                return False\n\n    def verifyContentInclude(self, inner_path, content, content_size, content_size_optional):\n        # Load include details\n        rules = self.getRules(inner_path, content)\n        if not rules:\n            raise VerifyError(\"No rules\")\n\n        # Check include size limit\n        if rules.get(\"max_size\") is not None:  # Include size limit\n            if content_size > rules[\"max_size\"]:\n                raise VerifyError(\"Include too large %sB > %sB\" % (content_size, rules[\"max_size\"]))\n\n        if rules.get(\"max_size_optional\") is not None:  # Include optional files limit\n            if content_size_optional > rules[\"max_size_optional\"]:\n                raise VerifyError(\"Include optional files too large %sB > %sB\" % (\n                    content_size_optional, rules[\"max_size_optional\"])\n                )\n\n        # Filename limit\n        if rules.get(\"files_allowed\"):\n            for file_inner_path in content[\"files\"].keys():\n                if not SafeRe.match(\"^%s$\" % rules[\"files_allowed\"], file_inner_path):\n                    raise VerifyError(\"File not allowed: %s\" % file_inner_path)\n\n        if rules.get(\"files_allowed_optional\"):\n            for file_inner_path in content.get(\"files_optional\", {}).keys():\n                if not SafeRe.match(\"^%s$\" % rules[\"files_allowed_optional\"], file_inner_path):\n                    raise VerifyError(\"Optional file not allowed: %s\" % file_inner_path)\n\n        # Check if content includes allowed\n        if rules.get(\"includes_allowed\") is False and content.get(\"includes\"):\n            raise VerifyError(\"Includes not allowed\")\n\n        return True  # All good\n\n    # Verify file validity\n    # Return: None = Same as before, False = Invalid, True = Valid\n    def verifyFile(self, inner_path, file, ignore_same=True):\n        if inner_path.endswith(\"content.json\"):  # content.json: Check using sign\n            from Crypt import CryptBitcoin\n            try:\n                if type(file) is dict:\n                    new_content = file\n                else:\n                    new_content = json.load(file)\n                if inner_path in self.contents:\n                    old_content = self.contents.get(inner_path, {\"modified\": 0})\n                    # Checks if its newer the ours\n                    if old_content[\"modified\"] == new_content[\"modified\"] and ignore_same:  # Ignore, have the same content.json\n                        return None\n                    elif old_content[\"modified\"] > new_content[\"modified\"]:  # We have newer\n                        raise VerifyError(\n                            \"We have newer (Our: %s, Sent: %s)\" %\n                            (old_content[\"modified\"], new_content[\"modified\"])\n                        )\n                if new_content[\"modified\"] > time.time() + 60 * 60 * 24:  # Content modified in the far future (allow 1 day+)\n                    raise VerifyError(\"Modify timestamp is in the far future!\")\n                if self.isArchived(inner_path, new_content[\"modified\"]):\n                    if inner_path in self.site.bad_files:\n                        del self.site.bad_files[inner_path]\n                    raise VerifyError(\"This file is archived!\")\n                # Check sign\n                sign = new_content.get(\"sign\")\n                signs = new_content.get(\"signs\", {})\n                if \"sign\" in new_content:\n                    del(new_content[\"sign\"])  # The file signed without the sign\n                if \"signs\" in new_content:\n                    del(new_content[\"signs\"])  # The file signed without the signs\n\n                sign_content = json.dumps(new_content, sort_keys=True)  # Dump the json to string to remove whitepsace\n\n                # Fix float representation error on Android\n                modified = new_content[\"modified\"]\n                if config.fix_float_decimals and type(modified) is float and not str(modified).endswith(\".0\"):\n                    modified_fixed = \"{:.6f}\".format(modified).strip(\"0.\")\n                    sign_content = sign_content.replace(\n                        '\"modified\": %s' % repr(modified),\n                        '\"modified\": %s' % modified_fixed\n                    )\n\n                self.verifyContent(inner_path, new_content)\n\n                if signs:  # New style signing\n                    valid_signers = self.getValidSigners(inner_path, new_content)\n                    signs_required = self.getSignsRequired(inner_path, new_content)\n\n                    if inner_path == \"content.json\" and len(valid_signers) > 1:  # Check signers_sign on root content.json\n                        signers_data = \"%s:%s\" % (signs_required, \",\".join(valid_signers))\n                        if not CryptBitcoin.verify(signers_data, self.site.address, new_content[\"signers_sign\"]):\n                            raise VerifyError(\"Invalid signers_sign!\")\n\n                    if inner_path != \"content.json\" and not self.verifyCert(inner_path, new_content):  # Check if cert valid\n                        raise VerifyError(\"Invalid cert!\")\n\n                    valid_signs = 0\n                    for address in valid_signers:\n                        if address in signs:\n                            valid_signs += CryptBitcoin.verify(sign_content, address, signs[address])\n                        if valid_signs >= signs_required:\n                            break  # Break if we has enough signs\n                    if valid_signs < signs_required:\n                        raise VerifyError(\"Valid signs: %s/%s\" % (valid_signs, signs_required))\n                    else:\n                        return True\n                else:  # Old style signing\n                    if CryptBitcoin.verify(sign_content, self.site.address, sign):\n                        return True\n                    else:\n                        raise VerifyError(\"Invalid old-style sign\")\n\n            except Exception, err:\n                self.log.warning(\"%s: verify sign error: %s\" % (inner_path, Debug.formatException(err)))\n                raise err\n\n        else:  # Check using sha512 hash\n            file_info = self.getFileInfo(inner_path)\n            if file_info:\n                if CryptHash.sha512sum(file) != file_info.get(\"sha512\", \"\"):\n                    raise VerifyError(\"Invalid hash\")\n\n                if file_info.get(\"size\", 0) != file.tell():\n                    raise VerifyError(\n                        \"File size does not match %s <> %s\" %\n                        (inner_path, file.tell(), file_info.get(\"size\", 0))\n                    )\n\n                return True\n\n            else:  # File not in content.json\n                raise VerifyError(\"File not in content.json\")\n\n    def optionalDownloaded(self, inner_path, hash, size=None, own=False):\n        if size is None:\n            size = self.site.storage.getSize(inner_path)\n        if type(hash) is int:\n            done = self.hashfield.appendHashId(hash)\n        else:\n            done = self.hashfield.appendHash(hash)\n        self.site.settings[\"optional_downloaded\"] += size\n        return done\n\n    def optionalRemove(self, inner_path, hash, size=None):\n        if size is None:\n            size = self.site.storage.getSize(inner_path)\n        if type(hash) is int:\n            done = self.hashfield.removeHashId(hash)\n        else:\n            done = self.hashfield.removeHash(hash)\n        self.site.settings[\"optional_downloaded\"] -= size\n        return done\n", "description": "ZeroNet - Decentralized websites using Bitcoin crypto and BitTorrent network", "file_name": "ContentManager.py", "id": "07fb66a71add3ef89e11dbed41d88d85", "language": "Python", "project_name": "ZeroNet", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/HelloZeroNet-ZeroNet/HelloZeroNet-ZeroNet-8828629/src/Content/ContentManager.py", "save_time": "", "source": "", "update_at": "2018-03-18T12:17:52Z", "url": "https://github.com/HelloZeroNet/ZeroNet", "wiki": true}