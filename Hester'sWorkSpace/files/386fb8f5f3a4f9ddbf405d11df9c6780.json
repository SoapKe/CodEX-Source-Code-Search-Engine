{"author": "Theano", "code": "from __future__ import absolute_import, print_function, division\nimport numpy as np\nimport theano\nimport theano.tensor as tt\nrng = np.random\n\nN = 400\nfeats = 784\nD = (rng.randn(N, feats), rng.randint(size=N, low=0, high=2))\ntraining_steps = 10000\n\n\nx = tt.matrix(\"x\")\ny = tt.vector(\"y\")\nw = theano.shared(rng.randn(feats), name=\"w\")\nb = theano.shared(0., name=\"b\")\nprint(\"Initial model:\")\nprint(w.get_value(), b.get_value())\n\n\np_1 = 1 / (1 + tt.exp(-tt.dot(x, w) - b))   \nprediction = p_1 > 0.5                      \nxent = -y * tt.log(p_1) - (1 - y) * tt.log(1 - p_1)  \ncost = xent.mean() + 0.01 * (w ** 2).sum()  \ngw, gb = tt.grad(cost, [w, b])\n\n\ntrain = theano.function(\n    inputs=[x, y],\n    outputs=[prediction, xent],\n    updates=[(w, w - 0.1 * gw),\n             (b, b - 0.1 * gb)],\n    name='train')\n\npredict = theano.function(inputs=[x], outputs=prediction,\n                          name='predict')\n\n\nfor i in range(training_steps):\n    pred, err = train(D[0], D[1])\n\nprint(\"Final model:\")\nprint(w.get_value(), b.get_value())\nprint(\"target values for D:\", D[1])\nprint(\"prediction on D:\", predict(D[0]))\n", "comments": "  declare theano symbolic variables    construct theano expression graph    probability target   1    the prediction thresholded    cross entropy loss    the cost minimize    compile    train ", "content": "from __future__ import absolute_import, print_function, division\nimport numpy as np\nimport theano\nimport theano.tensor as tt\nrng = np.random\n\nN = 400\nfeats = 784\nD = (rng.randn(N, feats), rng.randint(size=N, low=0, high=2))\ntraining_steps = 10000\n\n# Declare Theano symbolic variables\nx = tt.matrix(\"x\")\ny = tt.vector(\"y\")\nw = theano.shared(rng.randn(feats), name=\"w\")\nb = theano.shared(0., name=\"b\")\nprint(\"Initial model:\")\nprint(w.get_value(), b.get_value())\n\n# Construct Theano expression graph\np_1 = 1 / (1 + tt.exp(-tt.dot(x, w) - b))   # Probability that target = 1\nprediction = p_1 > 0.5                      # The prediction thresholded\nxent = -y * tt.log(p_1) - (1 - y) * tt.log(1 - p_1)  # Cross-entropy loss\ncost = xent.mean() + 0.01 * (w ** 2).sum()  # The cost to minimize\ngw, gb = tt.grad(cost, [w, b])\n\n# Compile\ntrain = theano.function(\n    inputs=[x, y],\n    outputs=[prediction, xent],\n    updates=[(w, w - 0.1 * gw),\n             (b, b - 0.1 * gb)],\n    name='train')\n\npredict = theano.function(inputs=[x], outputs=prediction,\n                          name='predict')\n\n# Train\nfor i in range(training_steps):\n    pred, err = train(D[0], D[1])\n\nprint(\"Final model:\")\nprint(w.get_value(), b.get_value())\nprint(\"target values for D:\", D[1])\nprint(\"prediction on D:\", predict(D[0]))\n", "description": "Theano is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation.", "file_name": "logreg.py", "id": "386fb8f5f3a4f9ddbf405d11df9c6780", "language": "Python", "project_name": "Theano", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/Theano-Theano/Theano-Theano-546067d/doc/omlw2014/logreg.py", "save_time": "", "source": "", "update_at": "2018-03-18T03:16:17Z", "url": "https://github.com/Theano/Theano", "wiki": true}