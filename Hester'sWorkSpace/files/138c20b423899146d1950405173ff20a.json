{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\"\"\"Create a dataset of SequenceExamples from NoteSequence protos.\n\nThis script will extract melodies from NoteSequence protos and save them to\nTensorFlow's SequenceExample protos for input to the melody RNN models.\n\"\"\"\n\nimport os\n\n internal imports\nimport tensorflow as tf\nimport magenta\n\nfrom magenta.models.melody_rnn import melody_rnn_config_flags\n\nfrom magenta.pipelines import dag_pipeline\nfrom magenta.pipelines import melody_pipelines\nfrom magenta.pipelines import note_sequence_pipelines\nfrom magenta.pipelines import pipeline\nfrom magenta.pipelines import pipelines_common\nfrom magenta.protobuf import music_pb2\n\nFLAGS = tf.app.flags.FLAGS\ntf.app.flags.DEFINE_string('input', None,\n                           'TFRecord to read NoteSequence protos from.')\ntf.app.flags.DEFINE_string('output_dir', None,\n                           'Directory to write training and eval TFRecord '\n                           'files. The TFRecord files are populated with '\n                           'SequenceExample protos.')\ntf.app.flags.DEFINE_float('eval_ratio', 0.1,\n                          'Fraction of input to set aside for eval set. '\n                          'Partition is randomly selected.')\ntf.app.flags.DEFINE_string('log', 'INFO',\n                           'The threshold for what messages will be logged '\n                           'DEBUG, INFO, WARN, ERROR, or FATAL.')\n\n\nclass EncoderPipeline(pipeline.Pipeline):\n  \"\"\"A Module that converts monophonic melodies to a model specific encoding.\"\"\"\n\n  def __init__(self, config, name):\n    \"\"\"Constructs an EncoderPipeline.\n\n    Args:\n      config: A MelodyRnnConfig that specifies the encoder/decoder, pitch range,\n          and what key to transpose into.\n      name: A unique pipeline name.\n    \"\"\"\n    super(EncoderPipeline, self).__init__(\n        input_type=magenta.music.Melody,\n        output_type=tf.train.SequenceExample,\n        name=name)\n    self._melody_encoder_decoder = config.encoder_decoder\n    self._min_note = config.min_note\n    self._max_note = config.max_note\n    self._transpose_to_key = config.transpose_to_key\n\n  def transform(self, melody):\n    melody.squash(\n        self._min_note,\n        self._max_note,\n        self._transpose_to_key)\n    encoded = self._melody_encoder_decoder.encode(melody)\n    return [encoded]\n\n\ndef get_pipeline(config, eval_ratio):\n  \"\"\"Returns the Pipeline instance which creates the RNN dataset.\n\n  Args:\n    config: A MelodyRnnConfig object.\n    eval_ratio: Fraction of input to set aside for evaluation set.\n\n  Returns:\n    A pipeline.Pipeline instance.\n  \"\"\"\n  partitioner = pipelines_common.RandomPartition(\n      music_pb2.NoteSequence,\n      ['eval_melodies', 'training_melodies'],\n      [eval_ratio])\n  dag = {partitioner: dag_pipeline.DagInput(music_pb2.NoteSequence)}\n\n  for mode in ['eval', 'training']:\n    time_change_splitter = note_sequence_pipelines.TimeChangeSplitter(\n        name='TimeChangeSplitter_' + mode)\n    quantizer = note_sequence_pipelines.Quantizer(\n        steps_per_quarter=config.steps_per_quarter, name='Quantizer_' + mode)\n    melody_extractor = melody_pipelines.MelodyExtractor(\n        min_bars=7, max_steps=512, min_unique_pitches=5,\n        gap_bars=1.0, ignore_polyphonic_notes=False,\n        name='MelodyExtractor_' + mode)\n    encoder_pipeline = EncoderPipeline(config, name='EncoderPipeline_' + mode)\n\n    dag[time_change_splitter] = partitioner[mode + '_melodies']\n    dag[quantizer] = time_change_splitter\n    dag[melody_extractor] = quantizer\n    dag[encoder_pipeline] = melody_extractor\n    dag[dag_pipeline.DagOutput(mode + '_melodies')] = encoder_pipeline\n\n  return dag_pipeline.DAGPipeline(dag)\n\n\ndef main(unused_argv):\n  tf.logging.set_verbosity(FLAGS.log)\n\n  config = melody_rnn_config_flags.config_from_flags()\n  pipeline_instance = get_pipeline(\n      config, FLAGS.eval_ratio)\n\n  FLAGS.input = os.path.expanduser(FLAGS.input)\n  FLAGS.output_dir = os.path.expanduser(FLAGS.output_dir)\n  pipeline.run_pipeline_serial(\n      pipeline_instance,\n      pipeline.tf_record_iterator(FLAGS.input, pipeline_instance.input_type),\n      FLAGS.output_dir)\n\n\ndef console_entry_point():\n  tf.app.run(main)\n\n\nif __name__ == '__main__':\n  console_entry_point()\n", "comments": "   create dataset sequenceexamples notesequence protos   this script extract melodies notesequence protos save tensorflow sequenceexample protos input melody rnn models       import os    internal imports import tensorflow tf import magenta  magenta models melody rnn import melody rnn config flags  magenta pipelines import dag pipeline magenta pipelines import melody pipelines magenta pipelines import note sequence pipelines magenta pipelines import pipeline magenta pipelines import pipelines common magenta protobuf import music pb2  flags   tf app flags flags tf app flags define string( input   none                              tfrecord read notesequence protos  ) tf app flags define string( output dir   none                              directory write training eval tfrecord                               files  the tfrecord files populated                               sequenceexample protos  ) tf app flags define float( eval ratio   0 1                             fraction input set aside eval set                               partition randomly selected  ) tf app flags define string( log    info                               the threshold messages logged                               debug  info  warn  error  fatal  )   class encoderpipeline(pipeline pipeline)       a module converts monophonic melodies model specific encoding        def   init  (self  config  name)         constructs encoderpipeline       args        config  a melodyrnnconfig specifies encoder decoder  pitch range            key transpose        name  a unique pipeline name              super(encoderpipeline  self)   init  (         input type magenta music melody          output type tf train sequenceexample          name name)     self  melody encoder decoder   config encoder decoder     self  min note   config min note     self  max note   config max note     self  transpose key   config transpose key    def transform(self  melody)      melody squash(         self  min note          self  max note          self  transpose key)     encoded   self  melody encoder decoder encode(melody)     return  encoded    def get pipeline(config  eval ratio)       returns pipeline instance creates rnn dataset     args      config  a melodyrnnconfig object      eval ratio  fraction input set aside evaluation set     returns      a pipeline pipeline instance           copyright 2016 google inc  all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license          http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license     internal imports ", "content": "# Copyright 2016 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Create a dataset of SequenceExamples from NoteSequence protos.\n\nThis script will extract melodies from NoteSequence protos and save them to\nTensorFlow's SequenceExample protos for input to the melody RNN models.\n\"\"\"\n\nimport os\n\n# internal imports\nimport tensorflow as tf\nimport magenta\n\nfrom magenta.models.melody_rnn import melody_rnn_config_flags\n\nfrom magenta.pipelines import dag_pipeline\nfrom magenta.pipelines import melody_pipelines\nfrom magenta.pipelines import note_sequence_pipelines\nfrom magenta.pipelines import pipeline\nfrom magenta.pipelines import pipelines_common\nfrom magenta.protobuf import music_pb2\n\nFLAGS = tf.app.flags.FLAGS\ntf.app.flags.DEFINE_string('input', None,\n                           'TFRecord to read NoteSequence protos from.')\ntf.app.flags.DEFINE_string('output_dir', None,\n                           'Directory to write training and eval TFRecord '\n                           'files. The TFRecord files are populated with '\n                           'SequenceExample protos.')\ntf.app.flags.DEFINE_float('eval_ratio', 0.1,\n                          'Fraction of input to set aside for eval set. '\n                          'Partition is randomly selected.')\ntf.app.flags.DEFINE_string('log', 'INFO',\n                           'The threshold for what messages will be logged '\n                           'DEBUG, INFO, WARN, ERROR, or FATAL.')\n\n\nclass EncoderPipeline(pipeline.Pipeline):\n  \"\"\"A Module that converts monophonic melodies to a model specific encoding.\"\"\"\n\n  def __init__(self, config, name):\n    \"\"\"Constructs an EncoderPipeline.\n\n    Args:\n      config: A MelodyRnnConfig that specifies the encoder/decoder, pitch range,\n          and what key to transpose into.\n      name: A unique pipeline name.\n    \"\"\"\n    super(EncoderPipeline, self).__init__(\n        input_type=magenta.music.Melody,\n        output_type=tf.train.SequenceExample,\n        name=name)\n    self._melody_encoder_decoder = config.encoder_decoder\n    self._min_note = config.min_note\n    self._max_note = config.max_note\n    self._transpose_to_key = config.transpose_to_key\n\n  def transform(self, melody):\n    melody.squash(\n        self._min_note,\n        self._max_note,\n        self._transpose_to_key)\n    encoded = self._melody_encoder_decoder.encode(melody)\n    return [encoded]\n\n\ndef get_pipeline(config, eval_ratio):\n  \"\"\"Returns the Pipeline instance which creates the RNN dataset.\n\n  Args:\n    config: A MelodyRnnConfig object.\n    eval_ratio: Fraction of input to set aside for evaluation set.\n\n  Returns:\n    A pipeline.Pipeline instance.\n  \"\"\"\n  partitioner = pipelines_common.RandomPartition(\n      music_pb2.NoteSequence,\n      ['eval_melodies', 'training_melodies'],\n      [eval_ratio])\n  dag = {partitioner: dag_pipeline.DagInput(music_pb2.NoteSequence)}\n\n  for mode in ['eval', 'training']:\n    time_change_splitter = note_sequence_pipelines.TimeChangeSplitter(\n        name='TimeChangeSplitter_' + mode)\n    quantizer = note_sequence_pipelines.Quantizer(\n        steps_per_quarter=config.steps_per_quarter, name='Quantizer_' + mode)\n    melody_extractor = melody_pipelines.MelodyExtractor(\n        min_bars=7, max_steps=512, min_unique_pitches=5,\n        gap_bars=1.0, ignore_polyphonic_notes=False,\n        name='MelodyExtractor_' + mode)\n    encoder_pipeline = EncoderPipeline(config, name='EncoderPipeline_' + mode)\n\n    dag[time_change_splitter] = partitioner[mode + '_melodies']\n    dag[quantizer] = time_change_splitter\n    dag[melody_extractor] = quantizer\n    dag[encoder_pipeline] = melody_extractor\n    dag[dag_pipeline.DagOutput(mode + '_melodies')] = encoder_pipeline\n\n  return dag_pipeline.DAGPipeline(dag)\n\n\ndef main(unused_argv):\n  tf.logging.set_verbosity(FLAGS.log)\n\n  config = melody_rnn_config_flags.config_from_flags()\n  pipeline_instance = get_pipeline(\n      config, FLAGS.eval_ratio)\n\n  FLAGS.input = os.path.expanduser(FLAGS.input)\n  FLAGS.output_dir = os.path.expanduser(FLAGS.output_dir)\n  pipeline.run_pipeline_serial(\n      pipeline_instance,\n      pipeline.tf_record_iterator(FLAGS.input, pipeline_instance.input_type),\n      FLAGS.output_dir)\n\n\ndef console_entry_point():\n  tf.app.run(main)\n\n\nif __name__ == '__main__':\n  console_entry_point()\n", "description": "Magenta: Music and Art Generation with Machine Intelligence", "file_name": "melody_rnn_create_dataset.py", "id": "138c20b423899146d1950405173ff20a", "language": "Python", "project_name": "magenta", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-magenta/tensorflow-magenta-c3eda3d/magenta/models/melody_rnn/melody_rnn_create_dataset.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:52:33Z", "url": "https://github.com/tensorflow/magenta", "wiki": false}