{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\n\"\"\"Image-to-text model and training configurations.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n\nclass ModelConfig(object):\n  \"\"\"Wrapper class for model hyperparameters.\"\"\"\n\n  def __init__(self):\n    \"\"\"Sets the default model hyperparameters.\"\"\"\n     File pattern of sharded TFRecord file containing SequenceExample protos.\n     Must be provided in training and evaluation modes.\n    self.input_file_pattern = None\n\n     Image format (\"jpeg\" or \"png\").\n    self.image_format = \"jpeg\"\n\n     Approximate number of values per input shard. Used to ensure sufficient\n     mixing between shards in training.\n    self.values_per_input_shard = 2300\n     Minimum number of shards to keep in the input queue.\n    self.input_queue_capacity_factor = 2\n     Number of threads for prefetching SequenceExample protos.\n    self.num_input_reader_threads = 1\n\n     Name of the SequenceExample context feature containing image data.\n    self.image_feature_name = \"image/data\"\n     Name of the SequenceExample feature list containing integer captions.\n    self.caption_feature_name = \"image/caption_ids\"\n\n     Number of unique words in the vocab (plus 1, for <UNK>).\n     The default value is larger than the expected actual vocab size to allow\n     for differences between tokenizer versions used in preprocessing. There is\n     no harm in using a value greater than the actual vocab size, but using a\n     value less than the actual vocab size will result in an error.\n    self.vocab_size = 12000\n\n     Number of threads for image preprocessing. Should be a multiple of 2.\n    self.num_preprocess_threads = 4\n\n     Batch size.\n    self.batch_size = 32\n\n     File containing an Inception v3 checkpoint to initialize the variables\n     of the Inception model. Must be provided when starting training for the\n     first time.\n    self.inception_checkpoint_file = None\n\n     Dimensions of Inception v3 input images.\n    self.image_height = 299\n    self.image_width = 299\n\n     Scale used to initialize model variables.\n    self.initializer_scale = 0.08\n\n     LSTM input and output dimensionality, respectively.\n    self.embedding_size = 512\n    self.num_lstm_units = 512\n\n     If < 1.0, the dropout keep probability applied to LSTM variables.\n    self.lstm_dropout_keep_prob = 0.7\n\n\nclass TrainingConfig(object):\n  \"\"\"Wrapper class for training hyperparameters.\"\"\"\n\n  def __init__(self):\n    \"\"\"Sets the default training hyperparameters.\"\"\"\n     Number of examples per epoch of training data.\n    self.num_examples_per_epoch = 586363\n\n     Optimizer for training the model.\n    self.optimizer = \"SGD\"\n\n     Learning rate for the initial phase of training.\n    self.initial_learning_rate = 2.0\n    self.learning_rate_decay_factor = 0.5\n    self.num_epochs_per_decay = 8.0\n\n     Learning rate when fine tuning the Inception v3 parameters.\n    self.train_inception_learning_rate = 0.0005\n\n     If not None, clip gradients to this value.\n    self.clip_gradients = 5.0\n\n     How many model checkpoints to keep.\n    self.max_checkpoints_to_keep = 5\n", "comments": "   image text model training configurations        future   import absolute import   future   import division   future   import print function   class modelconfig(object)       wrapper class model hyperparameters        def   init  (self)         sets default model hyperparameters           file pattern sharded tfrecord file containing sequenceexample protos        must provided training evaluation modes      self input file pattern   none        image format ( jpeg   png )      self image format    jpeg         approximate number values per input shard  used ensure sufficient       mixing shards training      self values per input shard   2300       minimum number shards keep input queue      self input queue capacity factor   2       number threads prefetching sequenceexample protos      self num input reader threads   1        name sequenceexample context feature containing image data      self image feature name    image data        name sequenceexample feature list containing integer captions      self caption feature name    image caption ids         number unique words vocab (plus 1   unk )        the default value larger expected actual vocab size allow       differences tokenizer versions used preprocessing  there       harm using value greater actual vocab size  using       value less actual vocab size result error      self vocab size   12000        number threads image preprocessing  should multiple 2      self num preprocess threads   4        batch size      self batch size   32        file containing inception v3 checkpoint initialize variables       inception model  must provided starting training       first time      self inception checkpoint file   none        dimensions inception v3 input images      self image height   299     self image width   299        scale used initialize model variables      self initializer scale   0 08        lstm input output dimensionality  respectively      self embedding size   512     self num lstm units   512        if   1 0  dropout keep probability applied lstm variables      self lstm dropout keep prob   0 7   class trainingconfig(object)       wrapper class training hyperparameters        def   init  (self)         sets default training hyperparameters        copyright 2016 the tensorflow authors  all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                       file pattern sharded tfrecord file containing sequenceexample protos     must provided training evaluation modes     image format ( jpeg   png )     approximate number values per input shard  used ensure sufficient    mixing shards training     minimum number shards keep input queue     number threads prefetching sequenceexample protos     name sequenceexample context feature containing image data     name sequenceexample feature list containing integer captions     number unique words vocab (plus 1   unk )     the default value larger expected actual vocab size allow    differences tokenizer versions used preprocessing  there    harm using value greater actual vocab size  using    value less actual vocab size result error     number threads image preprocessing  should multiple 2     batch size     file containing inception v3 checkpoint initialize variables    inception model  must provided starting training    first time     dimensions inception v3 input images     scale used initialize model variables     lstm input output dimensionality  respectively     if   1 0  dropout keep probability applied lstm variables     number examples per epoch training data     optimizer training model     learning rate initial phase training     learning rate fine tuning inception v3 parameters     if none  clip gradients value     how many model checkpoints keep  ", "content": "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n\"\"\"Image-to-text model and training configurations.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n\nclass ModelConfig(object):\n  \"\"\"Wrapper class for model hyperparameters.\"\"\"\n\n  def __init__(self):\n    \"\"\"Sets the default model hyperparameters.\"\"\"\n    # File pattern of sharded TFRecord file containing SequenceExample protos.\n    # Must be provided in training and evaluation modes.\n    self.input_file_pattern = None\n\n    # Image format (\"jpeg\" or \"png\").\n    self.image_format = \"jpeg\"\n\n    # Approximate number of values per input shard. Used to ensure sufficient\n    # mixing between shards in training.\n    self.values_per_input_shard = 2300\n    # Minimum number of shards to keep in the input queue.\n    self.input_queue_capacity_factor = 2\n    # Number of threads for prefetching SequenceExample protos.\n    self.num_input_reader_threads = 1\n\n    # Name of the SequenceExample context feature containing image data.\n    self.image_feature_name = \"image/data\"\n    # Name of the SequenceExample feature list containing integer captions.\n    self.caption_feature_name = \"image/caption_ids\"\n\n    # Number of unique words in the vocab (plus 1, for <UNK>).\n    # The default value is larger than the expected actual vocab size to allow\n    # for differences between tokenizer versions used in preprocessing. There is\n    # no harm in using a value greater than the actual vocab size, but using a\n    # value less than the actual vocab size will result in an error.\n    self.vocab_size = 12000\n\n    # Number of threads for image preprocessing. Should be a multiple of 2.\n    self.num_preprocess_threads = 4\n\n    # Batch size.\n    self.batch_size = 32\n\n    # File containing an Inception v3 checkpoint to initialize the variables\n    # of the Inception model. Must be provided when starting training for the\n    # first time.\n    self.inception_checkpoint_file = None\n\n    # Dimensions of Inception v3 input images.\n    self.image_height = 299\n    self.image_width = 299\n\n    # Scale used to initialize model variables.\n    self.initializer_scale = 0.08\n\n    # LSTM input and output dimensionality, respectively.\n    self.embedding_size = 512\n    self.num_lstm_units = 512\n\n    # If < 1.0, the dropout keep probability applied to LSTM variables.\n    self.lstm_dropout_keep_prob = 0.7\n\n\nclass TrainingConfig(object):\n  \"\"\"Wrapper class for training hyperparameters.\"\"\"\n\n  def __init__(self):\n    \"\"\"Sets the default training hyperparameters.\"\"\"\n    # Number of examples per epoch of training data.\n    self.num_examples_per_epoch = 586363\n\n    # Optimizer for training the model.\n    self.optimizer = \"SGD\"\n\n    # Learning rate for the initial phase of training.\n    self.initial_learning_rate = 2.0\n    self.learning_rate_decay_factor = 0.5\n    self.num_epochs_per_decay = 8.0\n\n    # Learning rate when fine tuning the Inception v3 parameters.\n    self.train_inception_learning_rate = 0.0005\n\n    # If not None, clip gradients to this value.\n    self.clip_gradients = 5.0\n\n    # How many model checkpoints to keep.\n    self.max_checkpoints_to_keep = 5\n", "description": "Models and examples built with TensorFlow", "file_name": "configuration.py", "id": "6576969fe2397efcee348231566292ae", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-models/tensorflow-models-086d914/research/im2txt/im2txt/configuration.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:59:19Z", "url": "https://github.com/tensorflow/models", "wiki": true}