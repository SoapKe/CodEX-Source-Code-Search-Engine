{"author": "tflearn", "code": "\n\nimport tensorflow as tf\nimport tflearn\n\n\n\n\n\n\nimport tflearn.datasets.mnist as mnist\ntrainX, trainY, testX, testY = mnist.load_data(one_hot=True)\n\n\nwith tf.Graph().as_default():\n\n    \n    X = tf.placeholder(\"float\", [None, 784])\n    Y = tf.placeholder(\"float\", [None, 10])\n\n    W1 = tf.Variable(tf.random_normal([784, 256]))\n    W2 = tf.Variable(tf.random_normal([256, 256]))\n    W3 = tf.Variable(tf.random_normal([256, 10]))\n    b1 = tf.Variable(tf.random_normal([256]))\n    b2 = tf.Variable(tf.random_normal([256]))\n    b3 = tf.Variable(tf.random_normal([10]))\n\n    \n    def dnn(x):\n        x = tf.nn.tanh(tf.add(tf.matmul(x, W1), b1))\n        x = tf.nn.tanh(tf.add(tf.matmul(x, W2), b2))\n        x = tf.add(tf.matmul(x, W3), b3)\n        return x\n\n    net = dnn(X)\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=net, labels=Y))\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n    accuracy = tf.reduce_mean(\n        tf.cast(tf.equal(tf.argmax(net, 1), tf.argmax(Y, 1)), tf.float32),\n        name='acc')\n\n    \n    # Define a training op (op for backprop, only need 1 in this model)\n    trainop = tflearn.TrainOp(loss=loss, optimizer=optimizer,\n                              metric=accuracy, batch_size=128)\n\n    \n    \n    \n    trainer = tflearn.Trainer(train_ops=trainop, tensorboard_verbose=0)\n    \n    trainer.fit({X: trainX, Y: trainY}, val_feed_dicts={X: testX, Y: testY},\n                n_epoch=10, show_metric=True)\n", "comments": "    this tutorial introduce combine tflearn tensorflow  using tflearn wrappers regular tensorflow expressions                                         utils  using tflearn trainer                                    loading mnist complete dataset    define dnn using tensorflow    model variables    multilayer perceptron    using tflearn trainer    define training op (op backprop  need 1 model)    create trainer  providing training ops  tensorboard logs stored     tmp tflearn logs   it possible change verbose level    details logs gradients  variables etc       training 10 epochs  ", "content": "\"\"\"\nThis tutorial will introduce how to combine TFLearn and Tensorflow, using\nTFLearn wrappers regular Tensorflow expressions.\n\"\"\"\n\nimport tensorflow as tf\nimport tflearn\n\n# ----------------------------\n# Utils: Using TFLearn Trainer\n# ----------------------------\n\n# Loading MNIST complete dataset\nimport tflearn.datasets.mnist as mnist\ntrainX, trainY, testX, testY = mnist.load_data(one_hot=True)\n\n# Define a dnn using Tensorflow\nwith tf.Graph().as_default():\n\n    # Model variables\n    X = tf.placeholder(\"float\", [None, 784])\n    Y = tf.placeholder(\"float\", [None, 10])\n\n    W1 = tf.Variable(tf.random_normal([784, 256]))\n    W2 = tf.Variable(tf.random_normal([256, 256]))\n    W3 = tf.Variable(tf.random_normal([256, 10]))\n    b1 = tf.Variable(tf.random_normal([256]))\n    b2 = tf.Variable(tf.random_normal([256]))\n    b3 = tf.Variable(tf.random_normal([10]))\n\n    # Multilayer perceptron\n    def dnn(x):\n        x = tf.nn.tanh(tf.add(tf.matmul(x, W1), b1))\n        x = tf.nn.tanh(tf.add(tf.matmul(x, W2), b2))\n        x = tf.add(tf.matmul(x, W3), b3)\n        return x\n\n    net = dnn(X)\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=net, labels=Y))\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n    accuracy = tf.reduce_mean(\n        tf.cast(tf.equal(tf.argmax(net, 1), tf.argmax(Y, 1)), tf.float32),\n        name='acc')\n\n    # Using TFLearn Trainer\n    # Define a training op (op for backprop, only need 1 in this model)\n    trainop = tflearn.TrainOp(loss=loss, optimizer=optimizer,\n                              metric=accuracy, batch_size=128)\n\n    # Create Trainer, providing all training ops. Tensorboard logs stored\n    # in /tmp/tflearn_logs/. It is possible to change verbose level for more\n    # details logs about gradients, variables etc...\n    trainer = tflearn.Trainer(train_ops=trainop, tensorboard_verbose=0)\n    # Training for 10 epochs.\n    trainer.fit({X: trainX, Y: trainY}, val_feed_dicts={X: testX, Y: testY},\n                n_epoch=10, show_metric=True)\n", "description": "Deep learning library featuring a higher-level API for TensorFlow.", "file_name": "trainer.py", "id": "0c2d9d907d2805a771908a5983e45811", "language": "Python", "project_name": "tflearn", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tflearn-tflearn/tflearn-tflearn-70fb38a/examples/extending_tensorflow/trainer.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:15:41Z", "url": "https://github.com/tflearn/tflearn", "wiki": true}