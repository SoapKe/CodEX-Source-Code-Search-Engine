{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\n\"\"\"Configs for stanford navigation environment.\n\nBase config for stanford navigation enviornment.\n\"\"\"\nimport numpy as np\nimport src.utils as utils\nimport datasets.nav_env as nav_env\n\ndef nav_env_base_config():\n  \"\"\"Returns the base config for stanford navigation environment.\n\n  Returns:\n    Base config for stanford navigation environment.\n  \"\"\"\n  robot = utils.Foo(radius=15,\n                    base=10,\n                    height=140,\n                    sensor_height=120,\n                    camera_elevation_degree=-15)\n\n  env = utils.Foo(padding=10,\n                  resolution=5,\n                  num_point_threshold=2,\n                  valid_min=-10,\n                  valid_max=200,\n                  n_samples_per_face=200)\n\n  camera_param = utils.Foo(width=225,\n                           height=225,\n                           z_near=0.05,\n                           z_far=20.0,\n                           fov=60.,\n                           modalities=['rgb'],\n                           img_channels=3)\n\n  data_augment = utils.Foo(lr_flip=0,\n                           delta_angle=0.5,\n                           delta_xy=4,\n                           relight=True,\n                           relight_fast=False, \n                           structured=False)  if True, uses the same perturb for the whole episode.\n\n  outputs = utils.Foo(images=True,\n                      rel_goal_loc=False,\n                      loc_on_map=True,\n                      gt_dist_to_goal=True,\n                      ego_maps=False,\n                      ego_goal_imgs=False,\n                      egomotion=False,\n                      visit_count=False,\n                      analytical_counts=False,\n                      node_ids=True,\n                      readout_maps=False)\n\n   class_map_names=['board', 'chair', 'door', 'sofa', 'table']\n  class_map_names = ['chair', 'door', 'table']\n  semantic_task = utils.Foo(class_map_names=class_map_names, pix_distance=16,\n                            sampling='uniform')\n  \n   time per iteration for cmp is 0.82 seconds per episode with 3.4s overhead per batch.\n  task_params = utils.Foo(max_dist=32,\n                          step_size=8,\n                          num_steps=40,\n                          num_actions=4,\n                          batch_size=4, \n                          building_seed=0,\n                          num_goals=1,\n                          img_height=None,\n                          img_width=None,\n                          img_channels=None,\n                          modalities=None,\n                          outputs=outputs,\n                          map_scales=[1.],\n                          map_crop_sizes=[64],\n                          rel_goal_loc_dim=4,\n                          base_class='Building',\n                          task='map+plan',\n                          n_ori=4,\n                          type='room_to_room_many',\n                          data_augment=data_augment,\n                          room_regex='^((?!hallway).)*$',\n                          toy_problem=False,\n                          map_channels=1,\n                          gt_coverage=False,\n                          input_type='maps',\n                          full_information=False,\n                          aux_delta_thetas=[],\n                          semantic_task=semantic_task,\n                          num_history_frames=0,\n                          node_ids_dim=1,\n                          perturbs_dim=4,\n                          map_resize_method='linear_noantialiasing',\n                          readout_maps_channels=1,\n                          readout_maps_scales=[],\n                          readout_maps_crop_sizes=[],\n                          n_views=1,\n                          reward_time_penalty=0.1,\n                          reward_at_goal=1.,\n                          discount_factor=0.99,\n                          rejection_sampling_M=100,\n                          min_dist=None)\n\n  navtask_args = utils.Foo(\n      building_names=['area1_gates_wingA_floor1_westpart'],\n      env_class=nav_env.VisualNavigationEnv,\n      robot=robot,\n      task_params=task_params,\n      env=env,\n      camera_param=camera_param,\n      cache_rooms=True)\n  return navtask_args\n\n", "comments": "   configs stanford navigation environment   base config stanford navigation enviornment      import numpy np import src utils utils import datasets nav env nav env  def nav env base config()       returns base config stanford navigation environment     returns      base config stanford navigation environment           copyright 2016 the tensorflow authors all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                       true  uses perturb whole episode     class map names   board    chair    door    sofa    table      time per iteration cmp 0 82 seconds per episode 3 4s overhead per batch  ", "content": "# Copyright 2016 The TensorFlow Authors All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n\"\"\"Configs for stanford navigation environment.\n\nBase config for stanford navigation enviornment.\n\"\"\"\nimport numpy as np\nimport src.utils as utils\nimport datasets.nav_env as nav_env\n\ndef nav_env_base_config():\n  \"\"\"Returns the base config for stanford navigation environment.\n\n  Returns:\n    Base config for stanford navigation environment.\n  \"\"\"\n  robot = utils.Foo(radius=15,\n                    base=10,\n                    height=140,\n                    sensor_height=120,\n                    camera_elevation_degree=-15)\n\n  env = utils.Foo(padding=10,\n                  resolution=5,\n                  num_point_threshold=2,\n                  valid_min=-10,\n                  valid_max=200,\n                  n_samples_per_face=200)\n\n  camera_param = utils.Foo(width=225,\n                           height=225,\n                           z_near=0.05,\n                           z_far=20.0,\n                           fov=60.,\n                           modalities=['rgb'],\n                           img_channels=3)\n\n  data_augment = utils.Foo(lr_flip=0,\n                           delta_angle=0.5,\n                           delta_xy=4,\n                           relight=True,\n                           relight_fast=False, \n                           structured=False) # if True, uses the same perturb for the whole episode.\n\n  outputs = utils.Foo(images=True,\n                      rel_goal_loc=False,\n                      loc_on_map=True,\n                      gt_dist_to_goal=True,\n                      ego_maps=False,\n                      ego_goal_imgs=False,\n                      egomotion=False,\n                      visit_count=False,\n                      analytical_counts=False,\n                      node_ids=True,\n                      readout_maps=False)\n\n  # class_map_names=['board', 'chair', 'door', 'sofa', 'table']\n  class_map_names = ['chair', 'door', 'table']\n  semantic_task = utils.Foo(class_map_names=class_map_names, pix_distance=16,\n                            sampling='uniform')\n  \n  # time per iteration for cmp is 0.82 seconds per episode with 3.4s overhead per batch.\n  task_params = utils.Foo(max_dist=32,\n                          step_size=8,\n                          num_steps=40,\n                          num_actions=4,\n                          batch_size=4, \n                          building_seed=0,\n                          num_goals=1,\n                          img_height=None,\n                          img_width=None,\n                          img_channels=None,\n                          modalities=None,\n                          outputs=outputs,\n                          map_scales=[1.],\n                          map_crop_sizes=[64],\n                          rel_goal_loc_dim=4,\n                          base_class='Building',\n                          task='map+plan',\n                          n_ori=4,\n                          type='room_to_room_many',\n                          data_augment=data_augment,\n                          room_regex='^((?!hallway).)*$',\n                          toy_problem=False,\n                          map_channels=1,\n                          gt_coverage=False,\n                          input_type='maps',\n                          full_information=False,\n                          aux_delta_thetas=[],\n                          semantic_task=semantic_task,\n                          num_history_frames=0,\n                          node_ids_dim=1,\n                          perturbs_dim=4,\n                          map_resize_method='linear_noantialiasing',\n                          readout_maps_channels=1,\n                          readout_maps_scales=[],\n                          readout_maps_crop_sizes=[],\n                          n_views=1,\n                          reward_time_penalty=0.1,\n                          reward_at_goal=1.,\n                          discount_factor=0.99,\n                          rejection_sampling_M=100,\n                          min_dist=None)\n\n  navtask_args = utils.Foo(\n      building_names=['area1_gates_wingA_floor1_westpart'],\n      env_class=nav_env.VisualNavigationEnv,\n      robot=robot,\n      task_params=task_params,\n      env=env,\n      camera_param=camera_param,\n      cache_rooms=True)\n  return navtask_args\n\n", "description": "Models and examples built with TensorFlow", "file_name": "nav_env_config.py", "id": "f816836e77ee37fc67e8518ece720165", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-models/tensorflow-models-086d914/research/cognitive_mapping_and_planning/datasets/nav_env_config.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:59:19Z", "url": "https://github.com/tensorflow/models", "wiki": true}