{"author": "scrapy", "code": "\nfrom __future__ import print_function\nfrom time import time\nfrom collections import deque\nfrom twisted.web.server import Site, NOT_DONE_YET\nfrom twisted.web.resource import Resource\nfrom twisted.internet import reactor\n\n\nclass Root(Resource):\n\n    def __init__(self):\n        Resource.__init__(self)\n        self.concurrent = 0\n        self.tail = deque(maxlen=100)\n        self._reset_stats()\n\n    def _reset_stats(self):\n        self.tail.clear()\n        self.start = self.lastmark = self.lasttime = time()\n\n    def getChild(self, request, name):\n        return self\n\n    def render(self, request):\n        now = time()\n        delta = now - self.lasttime\n\n        \n        if delta > 3: \n            self._reset_stats()\n            return ''\n\n        self.tail.appendleft(delta)\n        self.lasttime = now\n        self.concurrent += 1\n\n        if now - self.lastmark >= 3:\n            self.lastmark = now\n            qps = len(self.tail) / sum(self.tail)\n            print('samplesize={0} concurrent={1} qps={2:0.2f}'.format(len(self.tail), self.concurrent, qps))\n\n        if 'latency' in request.args:\n            latency = float(request.args['latency'][0])\n            reactor.callLater(latency, self._finish, request)\n            return NOT_DONE_YET\n\n        self.concurrent -= 1\n        return ''\n\n    def _finish(self, request):\n        self.concurrent -= 1\n        if not request.finished and not request._disconnected:\n            request.finish()\n\n\nroot = Root()\nfactory = Site(root)\nreactor.listenTCP(8880, factory)\nreactor.run()\n", "comments": "   usr bin env python    reset stats high iter request times caused client restarts    seconds ", "content": "#!/usr/bin/env python\nfrom __future__ import print_function\nfrom time import time\nfrom collections import deque\nfrom twisted.web.server import Site, NOT_DONE_YET\nfrom twisted.web.resource import Resource\nfrom twisted.internet import reactor\n\n\nclass Root(Resource):\n\n    def __init__(self):\n        Resource.__init__(self)\n        self.concurrent = 0\n        self.tail = deque(maxlen=100)\n        self._reset_stats()\n\n    def _reset_stats(self):\n        self.tail.clear()\n        self.start = self.lastmark = self.lasttime = time()\n\n    def getChild(self, request, name):\n        return self\n\n    def render(self, request):\n        now = time()\n        delta = now - self.lasttime\n\n        # reset stats on high iter-request times caused by client restarts\n        if delta > 3: # seconds\n            self._reset_stats()\n            return ''\n\n        self.tail.appendleft(delta)\n        self.lasttime = now\n        self.concurrent += 1\n\n        if now - self.lastmark >= 3:\n            self.lastmark = now\n            qps = len(self.tail) / sum(self.tail)\n            print('samplesize={0} concurrent={1} qps={2:0.2f}'.format(len(self.tail), self.concurrent, qps))\n\n        if 'latency' in request.args:\n            latency = float(request.args['latency'][0])\n            reactor.callLater(latency, self._finish, request)\n            return NOT_DONE_YET\n\n        self.concurrent -= 1\n        return ''\n\n    def _finish(self, request):\n        self.concurrent -= 1\n        if not request.finished and not request._disconnected:\n            request.finish()\n\n\nroot = Root()\nfactory = Site(root)\nreactor.listenTCP(8880, factory)\nreactor.run()\n", "description": "Scrapy, a fast high-level web crawling & scraping framework for Python.", "file_name": "qps-bench-server.py", "id": "8a636d600d4b68e857df2c8fd3ccc55c", "language": "Python", "project_name": "scrapy", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/scrapy-scrapy/scrapy-scrapy-6a7cdf9/extras/qps-bench-server.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:39:41Z", "url": "https://github.com/scrapy/scrapy", "wiki": true}