{"author": "NVIDIA", "code": "\nimport requests\n\ndef download_file_from_google_drive(id, destination):\n    URL = \"https://docs.google.com/uc?export=download\"\n\n    session = requests.Session()\n\n    response = session.get(URL, params = { 'id' : id }, stream = True)\n    token = get_confirm_token(response)\n\n    if token:\n        params = { 'id' : id, 'confirm' : token }\n        response = session.get(URL, params = params, stream = True)\n\n    save_response_content(response, destination)    \n\ndef get_confirm_token(response):\n    for key, value in response.cookies.items():\n        if key.startswith('download_warning'):\n            return value\n\n    return None\n\ndef save_response_content(response, destination):\n    CHUNK_SIZE = 32768\n\n    with open(destination, \"wb\") as f:\n        for chunk in response.iter_content(CHUNK_SIZE):\n            if chunk: \n                f.write(chunk)\n\nfile_id = '1ENgQm9TgabE1R99zhNf5q6meBvX6WFuq'\ndestination = './models.zip'\ndownload_file_from_google_drive(file_id, destination)", "comments": "  download code taken code taken https   stackoverflow com questions 25010369 wget curl large file google drive 39225039 39225039    filter keep alive new chunks ", "content": "# Download code taken from Code taken from https://stackoverflow.com/questions/25010369/wget-curl-large-file-from-google-drive/39225039#39225039\nimport requests\n\ndef download_file_from_google_drive(id, destination):\n    URL = \"https://docs.google.com/uc?export=download\"\n\n    session = requests.Session()\n\n    response = session.get(URL, params = { 'id' : id }, stream = True)\n    token = get_confirm_token(response)\n\n    if token:\n        params = { 'id' : id, 'confirm' : token }\n        response = session.get(URL, params = params, stream = True)\n\n    save_response_content(response, destination)    \n\ndef get_confirm_token(response):\n    for key, value in response.cookies.items():\n        if key.startswith('download_warning'):\n            return value\n\n    return None\n\ndef save_response_content(response, destination):\n    CHUNK_SIZE = 32768\n\n    with open(destination, \"wb\") as f:\n        for chunk in response.iter_content(CHUNK_SIZE):\n            if chunk: # filter out keep-alive new chunks\n                f.write(chunk)\n\nfile_id = '1ENgQm9TgabE1R99zhNf5q6meBvX6WFuq'\ndestination = './models.zip'\ndownload_file_from_google_drive(file_id, destination)", "description": "Style transfer, deep learning, feature transform", "file_name": "download_models.py", "id": "5b445efd9d739aad4e8016e1ec81f442", "language": "Python", "project_name": "FastPhotoStyle", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/NVIDIA-FastPhotoStyle/NVIDIA-FastPhotoStyle-208d4f6/download_models.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:35:44Z", "url": "https://github.com/NVIDIA/FastPhotoStyle", "wiki": true}