{"author": "getsentry", "code": "from __future__ import absolute_import\n\nfrom collections import defaultdict\nfrom mock import patch\n\nfrom sentry import tagstore\nfrom sentry.tagstore.models import GroupTagValue\nfrom sentry.tasks.merge import merge_group, rehash_group_events\nfrom sentry.models import Event, Group, GroupMeta, GroupRedirect, UserReport\nfrom sentry.similarity import _make_index_backend\nfrom sentry.testutils import TestCase\nfrom sentry.utils import redis\n\n\nindex = _make_index_backend(redis.clusters.get('default').get_local_client(0))\n\n\n@patch('sentry.similarity.features.index', new=index)\nclass MergeGroupTest(TestCase):\n    def test_merge_with_event_integrity(self):\n        project1 = self.create_project()\n        group1 = self.create_group(project1)\n        event1 = self.create_event('a' * 32, group=group1, data={'foo': 'bar'})\n        project2 = self.create_project()\n        group2 = self.create_group(project2)\n        event2 = self.create_event('b' * 32, group=group2, data={'foo': 'baz'})\n\n        with self.tasks():\n            merge_group(group1.id, group2.id)\n\n        assert not Group.objects.filter(id=group1.id).exists()\n\n        \n        \n        event1 = Event.objects.get(id=event1.id)\n        assert event1.group_id == group2.id\n        Event.objects.bind_nodes([event1], 'data')\n        assert event1.data['foo'] == 'bar'\n\n        event2 = Event.objects.get(id=event2.id)\n        assert event2.group_id == group2.id\n        Event.objects.bind_nodes([event2], 'data')\n        assert event2.data['foo'] == 'baz'\n\n    def test_merge_creates_redirect(self):\n        groups = [self.create_group() for _ in range(0, 3)]\n\n        with self.tasks():\n            merge_group(groups[0].id, groups[1].id)\n\n        assert not Group.objects.filter(id=groups[0].id).exists()\n        assert GroupRedirect.objects.filter(\n            group_id=groups[1].id,\n            previous_group_id=groups[0].id,\n        ).count() == 1\n\n        with self.tasks():\n            merge_group(groups[1].id, groups[2].id)\n\n        assert not Group.objects.filter(id=groups[1].id).exists()\n        assert GroupRedirect.objects.filter(\n            group_id=groups[2].id,\n        ).count() == 2\n\n    def test_merge_updates_tag_values_seen(self):\n        project = self.create_project()\n        target, other = [self.create_group(project) for _ in range(0, 2)]\n\n        data = {\n            'sentry:user': {\n                'id:1': {\n                    target: 2,\n                },\n                'id:2': {\n                    other: 3,\n                },\n                'id:3': {\n                    target: 1,\n                    other: 2,\n                },\n            },\n            'key': {\n                'foo': {\n                    other: 3,\n                },\n            },\n        }\n\n        input_group_tag_keys = defaultdict(int)  # [(group, key)] = values_seen\n        input_group_tag_values = defaultdict(int)  # [(group, key, value)] = times_seen\n        output_group_tag_keys = defaultdict(int)  # [key] = values_seen\n        output_group_tag_values = defaultdict(int)  # [(key, value)] = times_seen\n\n        for key, values in data.items():\n            output_group_tag_keys[key] = len(values)\n\n            for value, groups in values.items():\n                for group, count in groups.items():\n                    input_group_tag_keys[(group, key)] += 1\n                    input_group_tag_values[(group, key, value)] += count\n                    output_group_tag_values[(key, value)] += count\n\n        for ((group, key), values_seen) in input_group_tag_keys.items():\n            tagstore.create_group_tag_key(\n                project_id=project.id,\n                group_id=group.id,\n                environment_id=self.environment.id,\n                key=key,\n                values_seen=values_seen,\n            )\n\n        for ((group, key, value), times_seen) in input_group_tag_values.items():\n            tagstore.create_group_tag_value(\n                project_id=project.id,\n                group_id=group.id,\n                environment_id=self.environment.id,\n                key=key,\n                value=value,\n                times_seen=times_seen,\n            )\n\n        with self.tasks():\n            merge_group(other.id, target.id)\n\n        assert not Group.objects.filter(id=other.id).exists()\n        assert len(\n            tagstore.get_group_tag_keys(\n                other.project_id,\n                other.id,\n                environment_id=self.environment.id)) == 0\n        assert len(\n            GroupTagValue.objects.filter(\n                project_id=other.project_id,\n                group_id=other.id,\n            )) == 0\n\n        for key, values_seen in output_group_tag_keys.items():\n            assert tagstore.get_group_tag_key(\n                target.project_id, target.id, environment_id=self.environment.id, key=key).values_seen == values_seen\n\n        for (key, value), times_seen in output_group_tag_values.items():\n            assert tagstore.get_group_tag_value(\n                project_id=target.project_id,\n                group_id=target.id,\n                environment_id=self.environment.id,\n                key=key,\n                value=value,\n            ).times_seen == times_seen\n\n    def test_merge_with_group_meta(self):\n        project1 = self.create_project()\n        group1 = self.create_group(project1)\n        event1 = self.create_event('a' * 32, group=group1, data={'foo': 'bar'})\n        project2 = self.create_project()\n        group2 = self.create_group(project2)\n        event2 = self.create_event('b' * 32, group=group2, data={'foo': 'baz'})\n\n        GroupMeta.objects.create(\n            group=event1.group,\n            key='github:tid',\n            value='134',\n        )\n\n        GroupMeta.objects.create(\n            group=event1.group,\n            key='other:tid',\n            value='567',\n        )\n\n        GroupMeta.objects.create(\n            group=event2.group,\n            key='other:tid',\n            value='abc',\n        )\n\n        GroupMeta.objects.populate_cache([group1, group2])\n\n        assert GroupMeta.objects.get_value(group1, 'github:tid') == '134'\n        assert GroupMeta.objects.get_value(group2, 'other:tid') == 'abc'\n        assert not GroupMeta.objects.get_value(group2, 'github:tid')\n        assert GroupMeta.objects.get_value(group1, 'other:tid') == '567'\n\n        with self.tasks():\n            merge_group(group1.id, group2.id)\n\n        assert not Group.objects.filter(id=group1.id).exists()\n\n        GroupMeta.objects.clear_local_cache()\n        GroupMeta.objects.populate_cache([group1, group2])\n\n        assert not GroupMeta.objects.get_value(group1, 'github:tid')\n        assert not GroupMeta.objects.get_value(group1, 'other:tid')\n        assert GroupMeta.objects.get_value(group2, 'github:tid') == '134'\n        assert GroupMeta.objects.get_value(group2, 'other:tid') == 'abc'\n\n    def test_user_report_merge(self):\n        project1 = self.create_project()\n        group1 = self.create_group(project1)\n        event1 = self.create_event('a' * 32, group=group1, data={'foo': 'bar'})\n        project2 = self.create_project()\n        group2 = self.create_group(project2)\n        ur = UserReport.objects.create(project=project1, group=group1, event_id=event1.event_id)\n\n        with self.tasks():\n            merge_group(group1.id, group2.id)\n\n        assert not Group.objects.filter(id=group1.id).exists()\n\n        assert UserReport.objects.get(id=ur.id).group_id == group2.id\n\n\nclass RehashGroupEventsTest(TestCase):\n    def test_simple(self):\n        project = self.create_project()\n        group = self.create_group(project)\n        event1 = self.create_event('a' * 32, message='foo', group=group, data={})\n        event2 = self.create_event('b' * 32, message='foo', group=group, data={})\n        event3 = self.create_event('c' * 32, message='bar', group=group, data={})\n\n        with self.tasks():\n            rehash_group_events(group.id)\n\n        assert not Group.objects.filter(id=group.id).exists()\n\n        \n        \n        event1 = Event.objects.get(id=event1.id)\n        group1 = event1.group\n        assert sorted(Event.objects.filter(group_id=group1.id).values_list('id', flat=True)) == [\n            event1.id,\n            event2.id,\n        ]\n\n        event3 = Event.objects.get(id=event3.id)\n        group2 = event3.group\n        assert sorted(Event.objects.filter(group_id=group2.id).values_list('id', flat=True)) == [\n            event3.id,\n        ]\n", "comments": "  use default redis client cluster client similarity index    previously would error nodeintegrityerror due    reference check bound group     (group  key)    values seen     (group  key  value)    times seen     key    values seen     (key  value)    times seen    previously would error nodeintegrityerror due    reference check bound group ", "content": "from __future__ import absolute_import\n\nfrom collections import defaultdict\nfrom mock import patch\n\nfrom sentry import tagstore\nfrom sentry.tagstore.models import GroupTagValue\nfrom sentry.tasks.merge import merge_group, rehash_group_events\nfrom sentry.models import Event, Group, GroupMeta, GroupRedirect, UserReport\nfrom sentry.similarity import _make_index_backend\nfrom sentry.testutils import TestCase\nfrom sentry.utils import redis\n\n# Use the default redis client as a cluster client in the similarity index\nindex = _make_index_backend(redis.clusters.get('default').get_local_client(0))\n\n\n@patch('sentry.similarity.features.index', new=index)\nclass MergeGroupTest(TestCase):\n    def test_merge_with_event_integrity(self):\n        project1 = self.create_project()\n        group1 = self.create_group(project1)\n        event1 = self.create_event('a' * 32, group=group1, data={'foo': 'bar'})\n        project2 = self.create_project()\n        group2 = self.create_group(project2)\n        event2 = self.create_event('b' * 32, group=group2, data={'foo': 'baz'})\n\n        with self.tasks():\n            merge_group(group1.id, group2.id)\n\n        assert not Group.objects.filter(id=group1.id).exists()\n\n        # this previously would error with NodeIntegrityError due to the\n        # reference check being bound to a group\n        event1 = Event.objects.get(id=event1.id)\n        assert event1.group_id == group2.id\n        Event.objects.bind_nodes([event1], 'data')\n        assert event1.data['foo'] == 'bar'\n\n        event2 = Event.objects.get(id=event2.id)\n        assert event2.group_id == group2.id\n        Event.objects.bind_nodes([event2], 'data')\n        assert event2.data['foo'] == 'baz'\n\n    def test_merge_creates_redirect(self):\n        groups = [self.create_group() for _ in range(0, 3)]\n\n        with self.tasks():\n            merge_group(groups[0].id, groups[1].id)\n\n        assert not Group.objects.filter(id=groups[0].id).exists()\n        assert GroupRedirect.objects.filter(\n            group_id=groups[1].id,\n            previous_group_id=groups[0].id,\n        ).count() == 1\n\n        with self.tasks():\n            merge_group(groups[1].id, groups[2].id)\n\n        assert not Group.objects.filter(id=groups[1].id).exists()\n        assert GroupRedirect.objects.filter(\n            group_id=groups[2].id,\n        ).count() == 2\n\n    def test_merge_updates_tag_values_seen(self):\n        project = self.create_project()\n        target, other = [self.create_group(project) for _ in range(0, 2)]\n\n        data = {\n            'sentry:user': {\n                'id:1': {\n                    target: 2,\n                },\n                'id:2': {\n                    other: 3,\n                },\n                'id:3': {\n                    target: 1,\n                    other: 2,\n                },\n            },\n            'key': {\n                'foo': {\n                    other: 3,\n                },\n            },\n        }\n\n        input_group_tag_keys = defaultdict(int)  # [(group, key)] = values_seen\n        input_group_tag_values = defaultdict(int)  # [(group, key, value)] = times_seen\n        output_group_tag_keys = defaultdict(int)  # [key] = values_seen\n        output_group_tag_values = defaultdict(int)  # [(key, value)] = times_seen\n\n        for key, values in data.items():\n            output_group_tag_keys[key] = len(values)\n\n            for value, groups in values.items():\n                for group, count in groups.items():\n                    input_group_tag_keys[(group, key)] += 1\n                    input_group_tag_values[(group, key, value)] += count\n                    output_group_tag_values[(key, value)] += count\n\n        for ((group, key), values_seen) in input_group_tag_keys.items():\n            tagstore.create_group_tag_key(\n                project_id=project.id,\n                group_id=group.id,\n                environment_id=self.environment.id,\n                key=key,\n                values_seen=values_seen,\n            )\n\n        for ((group, key, value), times_seen) in input_group_tag_values.items():\n            tagstore.create_group_tag_value(\n                project_id=project.id,\n                group_id=group.id,\n                environment_id=self.environment.id,\n                key=key,\n                value=value,\n                times_seen=times_seen,\n            )\n\n        with self.tasks():\n            merge_group(other.id, target.id)\n\n        assert not Group.objects.filter(id=other.id).exists()\n        assert len(\n            tagstore.get_group_tag_keys(\n                other.project_id,\n                other.id,\n                environment_id=self.environment.id)) == 0\n        assert len(\n            GroupTagValue.objects.filter(\n                project_id=other.project_id,\n                group_id=other.id,\n            )) == 0\n\n        for key, values_seen in output_group_tag_keys.items():\n            assert tagstore.get_group_tag_key(\n                target.project_id, target.id, environment_id=self.environment.id, key=key).values_seen == values_seen\n\n        for (key, value), times_seen in output_group_tag_values.items():\n            assert tagstore.get_group_tag_value(\n                project_id=target.project_id,\n                group_id=target.id,\n                environment_id=self.environment.id,\n                key=key,\n                value=value,\n            ).times_seen == times_seen\n\n    def test_merge_with_group_meta(self):\n        project1 = self.create_project()\n        group1 = self.create_group(project1)\n        event1 = self.create_event('a' * 32, group=group1, data={'foo': 'bar'})\n        project2 = self.create_project()\n        group2 = self.create_group(project2)\n        event2 = self.create_event('b' * 32, group=group2, data={'foo': 'baz'})\n\n        GroupMeta.objects.create(\n            group=event1.group,\n            key='github:tid',\n            value='134',\n        )\n\n        GroupMeta.objects.create(\n            group=event1.group,\n            key='other:tid',\n            value='567',\n        )\n\n        GroupMeta.objects.create(\n            group=event2.group,\n            key='other:tid',\n            value='abc',\n        )\n\n        GroupMeta.objects.populate_cache([group1, group2])\n\n        assert GroupMeta.objects.get_value(group1, 'github:tid') == '134'\n        assert GroupMeta.objects.get_value(group2, 'other:tid') == 'abc'\n        assert not GroupMeta.objects.get_value(group2, 'github:tid')\n        assert GroupMeta.objects.get_value(group1, 'other:tid') == '567'\n\n        with self.tasks():\n            merge_group(group1.id, group2.id)\n\n        assert not Group.objects.filter(id=group1.id).exists()\n\n        GroupMeta.objects.clear_local_cache()\n        GroupMeta.objects.populate_cache([group1, group2])\n\n        assert not GroupMeta.objects.get_value(group1, 'github:tid')\n        assert not GroupMeta.objects.get_value(group1, 'other:tid')\n        assert GroupMeta.objects.get_value(group2, 'github:tid') == '134'\n        assert GroupMeta.objects.get_value(group2, 'other:tid') == 'abc'\n\n    def test_user_report_merge(self):\n        project1 = self.create_project()\n        group1 = self.create_group(project1)\n        event1 = self.create_event('a' * 32, group=group1, data={'foo': 'bar'})\n        project2 = self.create_project()\n        group2 = self.create_group(project2)\n        ur = UserReport.objects.create(project=project1, group=group1, event_id=event1.event_id)\n\n        with self.tasks():\n            merge_group(group1.id, group2.id)\n\n        assert not Group.objects.filter(id=group1.id).exists()\n\n        assert UserReport.objects.get(id=ur.id).group_id == group2.id\n\n\nclass RehashGroupEventsTest(TestCase):\n    def test_simple(self):\n        project = self.create_project()\n        group = self.create_group(project)\n        event1 = self.create_event('a' * 32, message='foo', group=group, data={})\n        event2 = self.create_event('b' * 32, message='foo', group=group, data={})\n        event3 = self.create_event('c' * 32, message='bar', group=group, data={})\n\n        with self.tasks():\n            rehash_group_events(group.id)\n\n        assert not Group.objects.filter(id=group.id).exists()\n\n        # this previously would error with NodeIntegrityError due to the\n        # reference check being bound to a group\n        event1 = Event.objects.get(id=event1.id)\n        group1 = event1.group\n        assert sorted(Event.objects.filter(group_id=group1.id).values_list('id', flat=True)) == [\n            event1.id,\n            event2.id,\n        ]\n\n        event3 = Event.objects.get(id=event3.id)\n        group2 = event3.group\n        assert sorted(Event.objects.filter(group_id=group2.id).values_list('id', flat=True)) == [\n            event3.id,\n        ]\n", "description": "Sentry is a cross-platform crash reporting and aggregation platform.", "file_name": "test_merge.py", "id": "1164bad300c80be3368b914dd27e8426", "language": "Python", "project_name": "sentry", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/getsentry-sentry/getsentry-sentry-6a9c7e2/tests/sentry/tasks/test_merge.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:23:24Z", "url": "https://github.com/getsentry/sentry", "wiki": false}