{"author": "HelloZeroNet", "code": "import sqlite3\nimport json\nimport time\nimport logging\nimport re\nimport os\nimport gevent\n\nfrom DbCursor import DbCursor\nfrom Config import config\nfrom util import SafeRe\nfrom util import helper\n\nopened_dbs = []\n\n\n\ndef dbCleanup():\n    while 1:\n        time.sleep(60 * 5)\n        for db in opened_dbs[:]:\n            idle = time.time() - db.last_query_time\n            if idle > 60 * 5:\n                db.close()\n\ngevent.spawn(dbCleanup)\n\n\nclass Db(object):\n\n    def __init__(self, schema, db_path):\n        self.db_path = db_path\n        self.db_dir = os.path.dirname(db_path) + \"/\"\n        self.schema = schema\n        self.schema[\"version\"] = self.schema.get(\"version\", 1)\n        self.conn = None\n        self.cur = None\n        self.log = logging.getLogger(\"Db:%s\" % schema[\"db_name\"])\n        self.table_names = None\n        self.collect_stats = False\n        self.foreign_keys = False\n        self.query_stats = {}\n        self.db_keyvalues = {}\n        self.delayed_queue = []\n        self.delayed_queue_thread = None\n        self.last_query_time = time.time()\n\n    def __repr__(self):\n        return \"<Db\n\n    def connect(self):\n        if self not in opened_dbs:\n            opened_dbs.append(self)\n        s = time.time()\n        if not os.path.isdir(self.db_dir):  \n            os.makedirs(self.db_dir)\n            self.log.debug(\"Created Db path: %s\" % self.db_dir)\n        if not os.path.isfile(self.db_path):\n            self.log.debug(\"Db file not exist yet: %s\" % self.db_path)\n        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)\n        self.conn.row_factory = sqlite3.Row\n        self.conn.isolation_level = None\n        self.cur = self.getCursor()\n        if config.db_mode == \"security\":\n            self.cur.execute(\"PRAGMA journal_mode = WAL\")\n            self.cur.execute(\"PRAGMA synchronous = NORMAL\")\n        else:\n            self.cur.execute(\"PRAGMA journal_mode = MEMORY\")\n            self.cur.execute(\"PRAGMA synchronous = OFF\")\n        if self.foreign_keys:\n            self.execute(\"PRAGMA foreign_keys = ON\")\n        self.log.debug(\n            \"Connected to %s in %.3fs (opened: %s, sqlite version: %s)...\" %\n            (self.db_path, time.time() - s, len(opened_dbs), sqlite3.version)\n        )\n\n    \n    def execute(self, query, params=None):\n        if not self.conn:\n            self.connect()\n        return self.cur.execute(query, params)\n\n    def insertOrUpdate(self, *args, **kwargs):\n        if not self.conn:\n            self.connect()\n        return self.cur.insertOrUpdate(*args, **kwargs)\n\n    def executeDelayed(self, *args, **kwargs):\n        if not self.delayed_queue_thread:\n            self.delayed_queue_thread = gevent.spawn_later(10, self.processDelayed)\n        self.delayed_queue.append((\"execute\", (args, kwargs)))\n\n    def insertOrUpdateDelayed(self, *args, **kwargs):\n        if not self.delayed_queue:\n            gevent.spawn_later(1, self.processDelayed)\n        self.delayed_queue.append((\"insertOrUpdate\", (args, kwargs)))\n\n    def processDelayed(self):\n        if not self.delayed_queue:\n            self.log.debug(\"processDelayed aborted\")\n            return\n        if not self.conn:\n            self.connect()\n\n        s = time.time()\n        cur = self.getCursor()\n        cur.execute(\"BEGIN\")\n        for command, params in self.delayed_queue:\n            if command == \"insertOrUpdate\":\n                cur.insertOrUpdate(*params[0], **params[1])\n            else:\n                cur.execute(*params[0], **params[1])\n\n        cur.execute(\"END\")\n        if len(self.delayed_queue) > 10:\n            self.log.debug(\"Processed %s delayed queue in %.3fs\" % (len(self.delayed_queue), time.time() - s))\n        self.delayed_queue = []\n        self.delayed_queue_thread = None\n\n    def close(self):\n        s = time.time()\n        if self.delayed_queue:\n            self.processDelayed()\n        if self in opened_dbs:\n            opened_dbs.remove(self)\n        if self.cur:\n            self.cur.close()\n        if self.conn:\n            self.conn.close()\n        self.conn = None\n        self.cur = None\n        self.log.debug(\"%s closed in %.3fs, opened: %s\" % (self.db_path, time.time() - s, len(opened_dbs)))\n\n    \n    \n    def getCursor(self):\n        if not self.conn:\n            self.connect()\n        return DbCursor(self.conn, self)\n\n    \n    \n    def getTableVersion(self, table_name):\n        if not self.db_keyvalues:  \n            try:\n                res = self.execute(\"SELECT * FROM keyvalue WHERE json_id=0\")  \n            except sqlite3.OperationalError, err:  \n                self.log.debug(\"Query error: %s\" % err)\n                return False\n\n            for row in res:\n                self.db_keyvalues[row[\"key\"]] = row[\"value\"]\n\n        return self.db_keyvalues.get(\"table.%s.version\" % table_name, 0)\n\n    \n    \n    def checkTables(self):\n        s = time.time()\n        changed_tables = []\n        cur = self.getCursor()\n\n        cur.execute(\"BEGIN\")\n\n        \n        \n        changed = cur.needTable(\"keyvalue\", [\n            [\"keyvalue_id\", \"INTEGER PRIMARY KEY AUTOINCREMENT\"],\n            [\"key\", \"TEXT\"],\n            [\"value\", \"INTEGER\"],\n            [\"json_id\", \"INTEGER\"],\n        ], [\n            \"CREATE UNIQUE INDEX key_id ON keyvalue(json_id, key)\"\n        ], version=self.schema[\"version\"])\n        if changed:\n            changed_tables.append(\"keyvalue\")\n\n        \n        if self.schema[\"version\"] == 1:\n            changed = cur.needTable(\"json\", [\n                [\"json_id\", \"INTEGER PRIMARY KEY AUTOINCREMENT\"],\n                [\"path\", \"VARCHAR(255)\"]\n            ], [\n                \"CREATE UNIQUE INDEX path ON json(path)\"\n            ], version=self.schema[\"version\"])\n        elif self.schema[\"version\"] == 2:\n            changed = cur.needTable(\"json\", [\n                [\"json_id\", \"INTEGER PRIMARY KEY AUTOINCREMENT\"],\n                [\"directory\", \"VARCHAR(255)\"],\n                [\"file_name\", \"VARCHAR(255)\"]\n            ], [\n                \"CREATE UNIQUE INDEX path ON json(directory, file_name)\"\n            ], version=self.schema[\"version\"])\n        elif self.schema[\"version\"] == 3:\n            changed = cur.needTable(\"json\", [\n                [\"json_id\", \"INTEGER PRIMARY KEY AUTOINCREMENT\"],\n                [\"site\", \"VARCHAR(255)\"],\n                [\"directory\", \"VARCHAR(255)\"],\n                [\"file_name\", \"VARCHAR(255)\"]\n            ], [\n                \"CREATE UNIQUE INDEX path ON json(directory, site, file_name)\"\n            ], version=self.schema[\"version\"])\n        if changed:\n            changed_tables.append(\"json\")\n\n        \n        for table_name, table_settings in self.schema.get(\"tables\", {}).items():\n            changed = cur.needTable(\n                table_name, table_settings[\"cols\"],\n                table_settings.get(\"indexes\", []), version=table_settings.get(\"schema_changed\", 0)\n            )\n            if changed:\n                changed_tables.append(table_name)\n\n        cur.execute(\"COMMIT\")\n        self.log.debug(\"Db check done in %.3fs, changed tables: %s\" % (time.time() - s, changed_tables))\n        if changed_tables:\n            self.db_keyvalues = {}  \n\n        return changed_tables\n\n    \n    \n    def updateJson(self, file_path, file=None, cur=None):\n        if not file_path.startswith(self.db_dir):\n            return False  \n        relative_path = file_path[len(self.db_dir):]  \n\n        \n        matched_maps = []\n        for match, map_settings in self.schema[\"maps\"].items():\n            try:\n                if SafeRe.match(match, relative_path):\n                    matched_maps.append(map_settings)\n            except SafeRe.UnsafePatternError as err:\n                self.log.error(err)\n\n        \n        if not matched_maps:\n            return False\n\n        \n        try:\n            if file is None:  \n                file = open(file_path, \"rb\")\n\n            if file is False:  \n                data = {}\n            else:\n                if file_path.endswith(\"json.gz\"):\n                    data = json.load(helper.limitedGzipFile(fileobj=file))\n                else:\n                    data = json.load(file)\n        except Exception, err:\n            self.log.debug(\"Json file %s load error: %s\" % (file_path, err))\n            data = {}\n\n        \n        if not cur:\n            cur = self.getCursor()\n            cur.execute(\"BEGIN\")\n            cur.logging = False\n            commit_after_done = True\n        else:\n            commit_after_done = False\n\n        \n        if not data or filter(lambda dbmap: \"to_keyvalue\" in dbmap or \"to_table\" in dbmap, matched_maps):\n            json_row = cur.getJsonRow(relative_path)\n\n        \n        for dbmap in matched_maps:\n            \n            if dbmap.get(\"to_keyvalue\"):\n                \n                res = cur.execute(\"SELECT * FROM keyvalue WHERE json_id = ?\", (json_row[\"json_id\"],))\n                current_keyvalue = {}\n                current_keyvalue_id = {}\n                for row in res:\n                    current_keyvalue[row[\"key\"]] = row[\"value\"]\n                    current_keyvalue_id[row[\"key\"]] = row[\"keyvalue_id\"]\n\n                for key in dbmap[\"to_keyvalue\"]:\n                    if key not in current_keyvalue:  \n                        cur.execute(\n                            \"INSERT INTO keyvalue ?\",\n                            {\"key\": key, \"value\": data.get(key), \"json_id\": json_row[\"json_id\"]}\n                        )\n                    elif data.get(key) != current_keyvalue[key]:  \n                        cur.execute(\n                            \"UPDATE keyvalue SET value = ? WHERE keyvalue_id = ?\",\n                            (data.get(key), current_keyvalue_id[key])\n                        )\n\n            \n            if dbmap.get(\"to_json_table\"):\n                directory, file_name = re.match(\"^(.*?)/*([^/]*)$\", relative_path).groups()\n                data_json_row = dict(cur.getJsonRow(directory + \"/\" + dbmap.get(\"file_name\", file_name)))\n                changed = False\n                for key in dbmap[\"to_json_table\"]:\n                    if data.get(key) != data_json_row.get(key):\n                        changed = True\n                if changed:\n                    \n                    data_json_row.update({key: val for key, val in data.iteritems() if key in dbmap[\"to_json_table\"]})\n                    cur.execute(\"INSERT OR REPLACE INTO json ?\", data_json_row)\n\n            \n            for table_settings in dbmap.get(\"to_table\", []):\n                if isinstance(table_settings, dict):  \n                    table_name = table_settings[\"table\"]  \n                    node = table_settings.get(\"node\", table_name)  \n                    key_col = table_settings.get(\"key_col\")  \n                    val_col = table_settings.get(\"val_col\")  \n                    import_cols = table_settings.get(\"import_cols\")\n                    replaces = table_settings.get(\"replaces\")\n                else:  \n                    table_name = table_settings\n                    node = table_settings\n                    key_col = None\n                    val_col = None\n                    import_cols = None\n                    replaces = None\n\n                \n                if not import_cols:\n                    import_cols = set(map(lambda item: item[0], self.schema[\"tables\"][table_name][\"cols\"]))\n\n                cur.execute(\"DELETE FROM %s WHERE json_id = ?\" % table_name, (json_row[\"json_id\"],))\n\n                if node not in data:\n                    continue\n\n                if key_col:  \n                    for key, val in data[node].iteritems():\n                        if val_col:  \n                            cur.execute(\n                                \"INSERT OR REPLACE INTO %s ?\" % table_name,\n                                {key_col: key, val_col: val, \"json_id\": json_row[\"json_id\"]}\n                            )\n                        else:  \n                            if isinstance(val, dict):  \n                                row = val\n                                if import_cols:\n                                    row = {key: row[key] for key in row if key in import_cols}  \n                                row[key_col] = key\n                                \n                                if replaces:\n                                    for replace_key, replace in replaces.iteritems():\n                                        if replace_key in row:\n                                            for replace_from, replace_to in replace.iteritems():\n                                                row[replace_key] = row[replace_key].replace(replace_from, replace_to)\n\n                                row[\"json_id\"] = json_row[\"json_id\"]\n                                cur.execute(\"INSERT OR REPLACE INTO %s ?\" % table_name, row)\n                            else:  \n                                for row in val:\n                                    row[key_col] = key\n                                    row[\"json_id\"] = json_row[\"json_id\"]\n                                    cur.execute(\"INSERT OR REPLACE INTO %s ?\" % table_name, row)\n                else:  \n                    for row in data[node]:\n                        row[\"json_id\"] = json_row[\"json_id\"]\n                        if import_cols:\n                            row = {key: row[key] for key in row if key in import_cols}  \n                        cur.execute(\"INSERT OR REPLACE INTO %s ?\" % table_name, row)\n\n        \n        if not data:\n            self.log.debug(\"Cleanup json row for %s\" % file_path)\n            cur.execute(\"DELETE FROM json WHERE json_id = %s\" % json_row[\"json_id\"])\n\n        if commit_after_done:\n            cur.execute(\"COMMIT\")\n        return True\n\n\nif __name__ == \"__main__\":\n    s = time.time()\n    console_log = logging.StreamHandler()\n    logging.getLogger('').setLevel(logging.DEBUG)\n    logging.getLogger('').addHandler(console_log)\n    console_log.setLevel(logging.DEBUG)\n    dbjson = Db(json.load(open(\"zerotalk.schema.json\")), \"data/users/zerotalk.db\")\n    dbjson.collect_stats = True\n    dbjson.checkTables()\n    cur = dbjson.getCursor()\n    cur.execute(\"BEGIN\")\n    cur.logging = False\n    dbjson.updateJson(\"data/users/content.json\", cur=cur)\n    for user_dir in os.listdir(\"data/users\"):\n        if os.path.isdir(\"data/users/%s\" % user_dir):\n            dbjson.updateJson(\"data/users/%s/data.json\" % user_dir, cur=cur)\n            \n    cur.logging = True\n    cur.execute(\"COMMIT\")\n    print \"Done in %.3fs\" % (time.time() - s)\n    for query, stats in sorted(dbjson.query_stats.items()):\n        print \"-\", query, stats\n", "comments": "close idle databases save memory %s:%s>\" % (id(self) self.db_path) directory exist yet execute query using dbcursor gets cursor object database return: cursor class get table version return: table version none exist get db keyvalues json_id = 0 internal keyvalues table exist check db tables return: <list> changed table names check internal tables check keyvalue table check json table check schema tables refresh table version cache update json file db return: true matched not db dir: skipping file path realative db file check filename matches mappings schema no match found file load json file open file file object passed file deleted no cursor specificed row current json file required check matched mappings schema insert non-relational key values get current values keyvalue exist yet db keyvalue different value insert data json table easier joins add custom col values insert data tables custom settings table name insert datas node keyname data json file map dict key col map dict value col simple settings fill import cols table cols map dict single value multi value single row filter row import_cols replace value necessary multi row map list filter row import_cols cleanup json row print \".\"", "content": "import sqlite3\nimport json\nimport time\nimport logging\nimport re\nimport os\nimport gevent\n\nfrom DbCursor import DbCursor\nfrom Config import config\nfrom util import SafeRe\nfrom util import helper\n\nopened_dbs = []\n\n\n# Close idle databases to save some memory\ndef dbCleanup():\n    while 1:\n        time.sleep(60 * 5)\n        for db in opened_dbs[:]:\n            idle = time.time() - db.last_query_time\n            if idle > 60 * 5:\n                db.close()\n\ngevent.spawn(dbCleanup)\n\n\nclass Db(object):\n\n    def __init__(self, schema, db_path):\n        self.db_path = db_path\n        self.db_dir = os.path.dirname(db_path) + \"/\"\n        self.schema = schema\n        self.schema[\"version\"] = self.schema.get(\"version\", 1)\n        self.conn = None\n        self.cur = None\n        self.log = logging.getLogger(\"Db:%s\" % schema[\"db_name\"])\n        self.table_names = None\n        self.collect_stats = False\n        self.foreign_keys = False\n        self.query_stats = {}\n        self.db_keyvalues = {}\n        self.delayed_queue = []\n        self.delayed_queue_thread = None\n        self.last_query_time = time.time()\n\n    def __repr__(self):\n        return \"<Db#%s:%s>\" % (id(self), self.db_path)\n\n    def connect(self):\n        if self not in opened_dbs:\n            opened_dbs.append(self)\n        s = time.time()\n        if not os.path.isdir(self.db_dir):  # Directory not exist yet\n            os.makedirs(self.db_dir)\n            self.log.debug(\"Created Db path: %s\" % self.db_dir)\n        if not os.path.isfile(self.db_path):\n            self.log.debug(\"Db file not exist yet: %s\" % self.db_path)\n        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)\n        self.conn.row_factory = sqlite3.Row\n        self.conn.isolation_level = None\n        self.cur = self.getCursor()\n        if config.db_mode == \"security\":\n            self.cur.execute(\"PRAGMA journal_mode = WAL\")\n            self.cur.execute(\"PRAGMA synchronous = NORMAL\")\n        else:\n            self.cur.execute(\"PRAGMA journal_mode = MEMORY\")\n            self.cur.execute(\"PRAGMA synchronous = OFF\")\n        if self.foreign_keys:\n            self.execute(\"PRAGMA foreign_keys = ON\")\n        self.log.debug(\n            \"Connected to %s in %.3fs (opened: %s, sqlite version: %s)...\" %\n            (self.db_path, time.time() - s, len(opened_dbs), sqlite3.version)\n        )\n\n    # Execute query using dbcursor\n    def execute(self, query, params=None):\n        if not self.conn:\n            self.connect()\n        return self.cur.execute(query, params)\n\n    def insertOrUpdate(self, *args, **kwargs):\n        if not self.conn:\n            self.connect()\n        return self.cur.insertOrUpdate(*args, **kwargs)\n\n    def executeDelayed(self, *args, **kwargs):\n        if not self.delayed_queue_thread:\n            self.delayed_queue_thread = gevent.spawn_later(10, self.processDelayed)\n        self.delayed_queue.append((\"execute\", (args, kwargs)))\n\n    def insertOrUpdateDelayed(self, *args, **kwargs):\n        if not self.delayed_queue:\n            gevent.spawn_later(1, self.processDelayed)\n        self.delayed_queue.append((\"insertOrUpdate\", (args, kwargs)))\n\n    def processDelayed(self):\n        if not self.delayed_queue:\n            self.log.debug(\"processDelayed aborted\")\n            return\n        if not self.conn:\n            self.connect()\n\n        s = time.time()\n        cur = self.getCursor()\n        cur.execute(\"BEGIN\")\n        for command, params in self.delayed_queue:\n            if command == \"insertOrUpdate\":\n                cur.insertOrUpdate(*params[0], **params[1])\n            else:\n                cur.execute(*params[0], **params[1])\n\n        cur.execute(\"END\")\n        if len(self.delayed_queue) > 10:\n            self.log.debug(\"Processed %s delayed queue in %.3fs\" % (len(self.delayed_queue), time.time() - s))\n        self.delayed_queue = []\n        self.delayed_queue_thread = None\n\n    def close(self):\n        s = time.time()\n        if self.delayed_queue:\n            self.processDelayed()\n        if self in opened_dbs:\n            opened_dbs.remove(self)\n        if self.cur:\n            self.cur.close()\n        if self.conn:\n            self.conn.close()\n        self.conn = None\n        self.cur = None\n        self.log.debug(\"%s closed in %.3fs, opened: %s\" % (self.db_path, time.time() - s, len(opened_dbs)))\n\n    # Gets a cursor object to database\n    # Return: Cursor class\n    def getCursor(self):\n        if not self.conn:\n            self.connect()\n        return DbCursor(self.conn, self)\n\n    # Get the table version\n    # Return: Table version or None if not exist\n    def getTableVersion(self, table_name):\n        if not self.db_keyvalues:  # Get db keyvalues\n            try:\n                res = self.execute(\"SELECT * FROM keyvalue WHERE json_id=0\")  # json_id = 0 is internal keyvalues\n            except sqlite3.OperationalError, err:  # Table not exist\n                self.log.debug(\"Query error: %s\" % err)\n                return False\n\n            for row in res:\n                self.db_keyvalues[row[\"key\"]] = row[\"value\"]\n\n        return self.db_keyvalues.get(\"table.%s.version\" % table_name, 0)\n\n    # Check Db tables\n    # Return: <list> Changed table names\n    def checkTables(self):\n        s = time.time()\n        changed_tables = []\n        cur = self.getCursor()\n\n        cur.execute(\"BEGIN\")\n\n        # Check internal tables\n        # Check keyvalue table\n        changed = cur.needTable(\"keyvalue\", [\n            [\"keyvalue_id\", \"INTEGER PRIMARY KEY AUTOINCREMENT\"],\n            [\"key\", \"TEXT\"],\n            [\"value\", \"INTEGER\"],\n            [\"json_id\", \"INTEGER\"],\n        ], [\n            \"CREATE UNIQUE INDEX key_id ON keyvalue(json_id, key)\"\n        ], version=self.schema[\"version\"])\n        if changed:\n            changed_tables.append(\"keyvalue\")\n\n        # Check json table\n        if self.schema[\"version\"] == 1:\n            changed = cur.needTable(\"json\", [\n                [\"json_id\", \"INTEGER PRIMARY KEY AUTOINCREMENT\"],\n                [\"path\", \"VARCHAR(255)\"]\n            ], [\n                \"CREATE UNIQUE INDEX path ON json(path)\"\n            ], version=self.schema[\"version\"])\n        elif self.schema[\"version\"] == 2:\n            changed = cur.needTable(\"json\", [\n                [\"json_id\", \"INTEGER PRIMARY KEY AUTOINCREMENT\"],\n                [\"directory\", \"VARCHAR(255)\"],\n                [\"file_name\", \"VARCHAR(255)\"]\n            ], [\n                \"CREATE UNIQUE INDEX path ON json(directory, file_name)\"\n            ], version=self.schema[\"version\"])\n        elif self.schema[\"version\"] == 3:\n            changed = cur.needTable(\"json\", [\n                [\"json_id\", \"INTEGER PRIMARY KEY AUTOINCREMENT\"],\n                [\"site\", \"VARCHAR(255)\"],\n                [\"directory\", \"VARCHAR(255)\"],\n                [\"file_name\", \"VARCHAR(255)\"]\n            ], [\n                \"CREATE UNIQUE INDEX path ON json(directory, site, file_name)\"\n            ], version=self.schema[\"version\"])\n        if changed:\n            changed_tables.append(\"json\")\n\n        # Check schema tables\n        for table_name, table_settings in self.schema.get(\"tables\", {}).items():\n            changed = cur.needTable(\n                table_name, table_settings[\"cols\"],\n                table_settings.get(\"indexes\", []), version=table_settings.get(\"schema_changed\", 0)\n            )\n            if changed:\n                changed_tables.append(table_name)\n\n        cur.execute(\"COMMIT\")\n        self.log.debug(\"Db check done in %.3fs, changed tables: %s\" % (time.time() - s, changed_tables))\n        if changed_tables:\n            self.db_keyvalues = {}  # Refresh table version cache\n\n        return changed_tables\n\n    # Update json file to db\n    # Return: True if matched\n    def updateJson(self, file_path, file=None, cur=None):\n        if not file_path.startswith(self.db_dir):\n            return False  # Not from the db dir: Skipping\n        relative_path = file_path[len(self.db_dir):]  # File path realative to db file\n\n        # Check if filename matches any of mappings in schema\n        matched_maps = []\n        for match, map_settings in self.schema[\"maps\"].items():\n            try:\n                if SafeRe.match(match, relative_path):\n                    matched_maps.append(map_settings)\n            except SafeRe.UnsafePatternError as err:\n                self.log.error(err)\n\n        # No match found for the file\n        if not matched_maps:\n            return False\n\n        # Load the json file\n        try:\n            if file is None:  # Open file is not file object passed\n                file = open(file_path, \"rb\")\n\n            if file is False:  # File deleted\n                data = {}\n            else:\n                if file_path.endswith(\"json.gz\"):\n                    data = json.load(helper.limitedGzipFile(fileobj=file))\n                else:\n                    data = json.load(file)\n        except Exception, err:\n            self.log.debug(\"Json file %s load error: %s\" % (file_path, err))\n            data = {}\n\n        # No cursor specificed\n        if not cur:\n            cur = self.getCursor()\n            cur.execute(\"BEGIN\")\n            cur.logging = False\n            commit_after_done = True\n        else:\n            commit_after_done = False\n\n        # Row for current json file if required\n        if not data or filter(lambda dbmap: \"to_keyvalue\" in dbmap or \"to_table\" in dbmap, matched_maps):\n            json_row = cur.getJsonRow(relative_path)\n\n        # Check matched mappings in schema\n        for dbmap in matched_maps:\n            # Insert non-relational key values\n            if dbmap.get(\"to_keyvalue\"):\n                # Get current values\n                res = cur.execute(\"SELECT * FROM keyvalue WHERE json_id = ?\", (json_row[\"json_id\"],))\n                current_keyvalue = {}\n                current_keyvalue_id = {}\n                for row in res:\n                    current_keyvalue[row[\"key\"]] = row[\"value\"]\n                    current_keyvalue_id[row[\"key\"]] = row[\"keyvalue_id\"]\n\n                for key in dbmap[\"to_keyvalue\"]:\n                    if key not in current_keyvalue:  # Keyvalue not exist yet in the db\n                        cur.execute(\n                            \"INSERT INTO keyvalue ?\",\n                            {\"key\": key, \"value\": data.get(key), \"json_id\": json_row[\"json_id\"]}\n                        )\n                    elif data.get(key) != current_keyvalue[key]:  # Keyvalue different value\n                        cur.execute(\n                            \"UPDATE keyvalue SET value = ? WHERE keyvalue_id = ?\",\n                            (data.get(key), current_keyvalue_id[key])\n                        )\n\n            # Insert data to json table for easier joins\n            if dbmap.get(\"to_json_table\"):\n                directory, file_name = re.match(\"^(.*?)/*([^/]*)$\", relative_path).groups()\n                data_json_row = dict(cur.getJsonRow(directory + \"/\" + dbmap.get(\"file_name\", file_name)))\n                changed = False\n                for key in dbmap[\"to_json_table\"]:\n                    if data.get(key) != data_json_row.get(key):\n                        changed = True\n                if changed:\n                    # Add the custom col values\n                    data_json_row.update({key: val for key, val in data.iteritems() if key in dbmap[\"to_json_table\"]})\n                    cur.execute(\"INSERT OR REPLACE INTO json ?\", data_json_row)\n\n            # Insert data to tables\n            for table_settings in dbmap.get(\"to_table\", []):\n                if isinstance(table_settings, dict):  # Custom settings\n                    table_name = table_settings[\"table\"]  # Table name to insert datas\n                    node = table_settings.get(\"node\", table_name)  # Node keyname in data json file\n                    key_col = table_settings.get(\"key_col\")  # Map dict key as this col\n                    val_col = table_settings.get(\"val_col\")  # Map dict value as this col\n                    import_cols = table_settings.get(\"import_cols\")\n                    replaces = table_settings.get(\"replaces\")\n                else:  # Simple settings\n                    table_name = table_settings\n                    node = table_settings\n                    key_col = None\n                    val_col = None\n                    import_cols = None\n                    replaces = None\n\n                # Fill import cols from table cols\n                if not import_cols:\n                    import_cols = set(map(lambda item: item[0], self.schema[\"tables\"][table_name][\"cols\"]))\n\n                cur.execute(\"DELETE FROM %s WHERE json_id = ?\" % table_name, (json_row[\"json_id\"],))\n\n                if node not in data:\n                    continue\n\n                if key_col:  # Map as dict\n                    for key, val in data[node].iteritems():\n                        if val_col:  # Single value\n                            cur.execute(\n                                \"INSERT OR REPLACE INTO %s ?\" % table_name,\n                                {key_col: key, val_col: val, \"json_id\": json_row[\"json_id\"]}\n                            )\n                        else:  # Multi value\n                            if isinstance(val, dict):  # Single row\n                                row = val\n                                if import_cols:\n                                    row = {key: row[key] for key in row if key in import_cols}  # Filter row by import_cols\n                                row[key_col] = key\n                                # Replace in value if necessary\n                                if replaces:\n                                    for replace_key, replace in replaces.iteritems():\n                                        if replace_key in row:\n                                            for replace_from, replace_to in replace.iteritems():\n                                                row[replace_key] = row[replace_key].replace(replace_from, replace_to)\n\n                                row[\"json_id\"] = json_row[\"json_id\"]\n                                cur.execute(\"INSERT OR REPLACE INTO %s ?\" % table_name, row)\n                            else:  # Multi row\n                                for row in val:\n                                    row[key_col] = key\n                                    row[\"json_id\"] = json_row[\"json_id\"]\n                                    cur.execute(\"INSERT OR REPLACE INTO %s ?\" % table_name, row)\n                else:  # Map as list\n                    for row in data[node]:\n                        row[\"json_id\"] = json_row[\"json_id\"]\n                        if import_cols:\n                            row = {key: row[key] for key in row if key in import_cols}  # Filter row by import_cols\n                        cur.execute(\"INSERT OR REPLACE INTO %s ?\" % table_name, row)\n\n        # Cleanup json row\n        if not data:\n            self.log.debug(\"Cleanup json row for %s\" % file_path)\n            cur.execute(\"DELETE FROM json WHERE json_id = %s\" % json_row[\"json_id\"])\n\n        if commit_after_done:\n            cur.execute(\"COMMIT\")\n        return True\n\n\nif __name__ == \"__main__\":\n    s = time.time()\n    console_log = logging.StreamHandler()\n    logging.getLogger('').setLevel(logging.DEBUG)\n    logging.getLogger('').addHandler(console_log)\n    console_log.setLevel(logging.DEBUG)\n    dbjson = Db(json.load(open(\"zerotalk.schema.json\")), \"data/users/zerotalk.db\")\n    dbjson.collect_stats = True\n    dbjson.checkTables()\n    cur = dbjson.getCursor()\n    cur.execute(\"BEGIN\")\n    cur.logging = False\n    dbjson.updateJson(\"data/users/content.json\", cur=cur)\n    for user_dir in os.listdir(\"data/users\"):\n        if os.path.isdir(\"data/users/%s\" % user_dir):\n            dbjson.updateJson(\"data/users/%s/data.json\" % user_dir, cur=cur)\n            # print \".\",\n    cur.logging = True\n    cur.execute(\"COMMIT\")\n    print \"Done in %.3fs\" % (time.time() - s)\n    for query, stats in sorted(dbjson.query_stats.items()):\n        print \"-\", query, stats\n", "description": "ZeroNet - Decentralized websites using Bitcoin crypto and BitTorrent network", "file_name": "Db.py", "id": "286817a0042196d4ce3a82cb13681a92", "language": "Python", "project_name": "ZeroNet", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/HelloZeroNet-ZeroNet/HelloZeroNet-ZeroNet-3bdb6a2/src/Db/Db.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:21:08Z", "url": "https://github.com/HelloZeroNet/ZeroNet", "wiki": true}