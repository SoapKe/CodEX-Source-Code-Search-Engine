{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\n\"\"\"Routine for decoding the CIFAR-10 binary file format.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom six.moves import xrange   pylint: disable=redefined-builtin\nimport tensorflow as tf\n\n Process images of this size. Note that this differs from the original CIFAR\n image size of 32 x 32. If one alters this number, then the entire model\n architecture will change and any model would need to be retrained.\nIMAGE_SIZE = 24\n\n Global constants describing the CIFAR-10 data set.\nNUM_CLASSES = 10\nNUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\nNUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n\n\ndef read_cifar10(filename_queue):\n  \"\"\"Reads and parses examples from CIFAR10 data files.\n\n  Recommendation: if you want N-way read parallelism, call this function\n  N times.  This will give you N independent Readers reading different\n  files & positions within those files, which will give better mixing of\n  examples.\n\n  Args:\n    filename_queue: A queue of strings with the filenames to read from.\n\n  Returns:\n    An object representing a single example, with the following fields:\n      height: number of rows in the result (32)\n      width: number of columns in the result (32)\n      depth: number of color channels in the result (3)\n      key: a scalar string Tensor describing the filename & record number\n        for this example.\n      label: an int32 Tensor with the label in the range 0..9.\n      uint8image: a [height, width, depth] uint8 Tensor with the image data\n  \"\"\"\n\n  class CIFAR10Record(object):\n    pass\n  result = CIFAR10Record()\n\n   Dimensions of the images in the CIFAR-10 dataset.\n   See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n   input format.\n  label_bytes = 1   2 for CIFAR-100\n  result.height = 32\n  result.width = 32\n  result.depth = 3\n  image_bytes = result.height * result.width * result.depth\n   Every record consists of a label followed by the image, with a\n   fixed number of bytes for each.\n  record_bytes = label_bytes + image_bytes\n\n   Read a record, getting filenames from the filename_queue.  No\n   header or footer in the CIFAR-10 format, so we leave header_bytes\n   and footer_bytes at their default of 0.\n  reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n  result.key, value = reader.read(filename_queue)\n\n   Convert from a string to a vector of uint8 that is record_bytes long.\n  record_bytes = tf.decode_raw(value, tf.uint8)\n\n   The first bytes represent the label, which we convert from uint8->int32.\n  result.label = tf.cast(\n      tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)\n\n   The remaining bytes after the label represent the image, which we reshape\n   from [depth * height * width] to [depth, height, width].\n  depth_major = tf.reshape(\n      tf.strided_slice(record_bytes, [label_bytes],\n                       [label_bytes + image_bytes]),\n      [result.depth, result.height, result.width])\n   Convert from [depth, height, width] to [height, width, depth].\n  result.uint8image = tf.transpose(depth_major, [1, 2, 0])\n\n  return result\n\n\ndef _generate_image_and_label_batch(image, label, min_queue_examples,\n                                    batch_size, shuffle):\n  \"\"\"Construct a queued batch of images and labels.\n\n  Args:\n    image: 3-D Tensor of [height, width, 3] of type.float32.\n    label: 1-D Tensor of type.int32\n    min_queue_examples: int32, minimum number of samples to retain\n      in the queue that provides of batches of examples.\n    batch_size: Number of images per batch.\n    shuffle: boolean indicating whether to use a shuffling queue.\n\n  Returns:\n    images: Images. 4D tensor of [batch_size, height, width, 3] size.\n    labels: Labels. 1D tensor of [batch_size] size.\n  \"\"\"\n   Create a queue that shuffles the examples, and then\n   read 'batch_size' images + labels from the example queue.\n  num_preprocess_threads = 16\n  if shuffle:\n    images, label_batch = tf.train.shuffle_batch(\n        [image, label],\n        batch_size=batch_size,\n        num_threads=num_preprocess_threads,\n        capacity=min_queue_examples + 3 * batch_size,\n        min_after_dequeue=min_queue_examples)\n  else:\n    images, label_batch = tf.train.batch(\n        [image, label],\n        batch_size=batch_size,\n        num_threads=num_preprocess_threads,\n        capacity=min_queue_examples + 3 * batch_size)\n\n   Display the training images in the visualizer.\n  tf.summary.image('images', images)\n\n  return images, tf.reshape(label_batch, [batch_size])\n\n\ndef distorted_inputs(data_dir, batch_size):\n  \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n\n  Args:\n    data_dir: Path to the CIFAR-10 data directory.\n    batch_size: Number of images per batch.\n\n  Returns:\n    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n    labels: Labels. 1D tensor of [batch_size] size.\n  \"\"\"\n  filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n               for i in xrange(1, 6)]\n  for f in filenames:\n    if not tf.gfile.Exists(f):\n      raise ValueError('Failed to find file: ' + f)\n\n   Create a queue that produces the filenames to read.\n  filename_queue = tf.train.string_input_producer(filenames)\n\n  with tf.name_scope('data_augmentation'):\n     Read examples from files in the filename queue.\n    read_input = read_cifar10(filename_queue)\n    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n\n    height = IMAGE_SIZE\n    width = IMAGE_SIZE\n\n     Image processing for training the network. Note the many random\n     distortions applied to the image.\n\n     Randomly crop a [height, width] section of the image.\n    distorted_image = tf.random_crop(reshaped_image, [height, width, 3])\n\n     Randomly flip the image horizontally.\n    distorted_image = tf.image.random_flip_left_right(distorted_image)\n\n     Because these operations are not commutative, consider randomizing\n     the order their operation.\n     NOTE: since per_image_standardization zeros the mean and makes\n     the stddev unit, this likely has no effect see tensorflow1458.\n    distorted_image = tf.image.random_brightness(distorted_image,\n                                                 max_delta=63)\n    distorted_image = tf.image.random_contrast(distorted_image,\n                                               lower=0.2, upper=1.8)\n\n     Subtract off the mean and divide by the variance of the pixels.\n    float_image = tf.image.per_image_standardization(distorted_image)\n\n     Set the shapes of tensors.\n    float_image.set_shape([height, width, 3])\n    read_input.label.set_shape([1])\n\n     Ensure that the random shuffling has good mixing properties.\n    min_fraction_of_examples_in_queue = 0.4\n    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN *\n                             min_fraction_of_examples_in_queue)\n    print ('Filling queue with %d CIFAR images before starting to train. '\n           'This will take a few minutes.' % min_queue_examples)\n\n   Generate a batch of images and labels by building up a queue of examples.\n  return _generate_image_and_label_batch(float_image, read_input.label,\n                                         min_queue_examples, batch_size,\n                                         shuffle=True)\n\n\ndef inputs(eval_data, data_dir, batch_size):\n  \"\"\"Construct input for CIFAR evaluation using the Reader ops.\n\n  Args:\n    eval_data: bool, indicating if one should use the train or eval data set.\n    data_dir: Path to the CIFAR-10 data directory.\n    batch_size: Number of images per batch.\n\n  Returns:\n    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n    labels: Labels. 1D tensor of [batch_size] size.\n  \"\"\"\n  if not eval_data:\n    filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n                 for i in xrange(1, 6)]\n    num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN\n  else:\n    filenames = [os.path.join(data_dir, 'test_batch.bin')]\n    num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n\n  for f in filenames:\n    if not tf.gfile.Exists(f):\n      raise ValueError('Failed to find file: ' + f)\n\n  with tf.name_scope('input'):\n     Create a queue that produces the filenames to read.\n    filename_queue = tf.train.string_input_producer(filenames)\n\n     Read examples from files in the filename queue.\n    read_input = read_cifar10(filename_queue)\n    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n\n    height = IMAGE_SIZE\n    width = IMAGE_SIZE\n\n     Image processing for evaluation.\n     Crop the central [height, width] of the image.\n    resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,\n                                                           height, width)\n\n     Subtract off the mean and divide by the variance of the pixels.\n    float_image = tf.image.per_image_standardization(resized_image)\n\n     Set the shapes of tensors.\n    float_image.set_shape([height, width, 3])\n    read_input.label.set_shape([1])\n\n     Ensure that the random shuffling has good mixing properties.\n    min_fraction_of_examples_in_queue = 0.4\n    min_queue_examples = int(num_examples_per_epoch *\n                             min_fraction_of_examples_in_queue)\n\n   Generate a batch of images and labels by building up a queue of examples.\n  return _generate_image_and_label_batch(float_image, read_input.label,\n                                         min_queue_examples, batch_size,\n                                         shuffle=False)\n", "comments": "   routine decoding cifar 10 binary file format        future   import absolute import   future   import division   future   import print function  import os  six moves import xrange    pylint  disable redefined builtin import tensorflow tf    process images size  note differs original cifar   image size 32 x 32  if one alters number  entire model   architecture change model would need retrained  image size   24    global constants describing cifar 10 data set  num classes   10 num examples per epoch for train   50000 num examples per epoch for eval   10000   def read cifar10(filename queue)       reads parses examples cifar10 data files     recommendation  want n way read parallelism  call function   n times   this give n independent readers reading different   files   positions within files  give better mixing   examples     args      filename queue  a queue strings filenames read     returns      an object representing single example  following fields        height  number rows result (32)       width  number columns result (32)       depth  number color channels result (3)       key  scalar string tensor describing filename   record number         example        label  int32 tensor label range 0  9        uint8image   height  width  depth  uint8 tensor image data          class cifar10record(object)      pass   result   cifar10record()      dimensions images cifar 10 dataset      see http   www cs toronto edu  kriz cifar html description     input format    label bytes   1    2 cifar 100   result height   32   result width   32   result depth   3   image bytes   result height   result width   result depth     every record consists label followed image      fixed number bytes    record bytes   label bytes   image bytes      read record  getting filenames filename queue   no     header footer cifar 10 format  leave header bytes     footer bytes default 0    reader   tf fixedlengthrecordreader(record bytes record bytes)   result key  value   reader read(filename queue)      convert string vector uint8 record bytes long    record bytes   tf decode raw(value  tf uint8)      the first bytes represent label  convert uint8  int32    result label   tf cast(       tf strided slice(record bytes   0    label bytes )  tf int32)      the remaining bytes label represent image  reshape      depth   height   width   depth  height  width     depth major   tf reshape(       tf strided slice(record bytes   label bytes                           label bytes   image bytes )         result depth  result height  result width )     convert  depth  height  width   height  width  depth     result uint8image   tf transpose(depth major   1  2  0 )    return result   def  generate image label batch(image  label  min queue examples                                      batch size  shuffle)       construct queued batch images labels     args      image  3 d tensor  height  width  3  type float32      label  1 d tensor type int32     min queue examples  int32  minimum number samples retain       queue provides batches examples      batch size  number images per batch      shuffle  boolean indicating whether use shuffling queue     returns      images  images  4d tensor  batch size  height  width  3  size      labels  labels  1d tensor  batch size  size            create queue shuffles examples      read  batch size  images   labels example queue    num preprocess threads   16   shuffle      images  label batch   tf train shuffle batch(          image  label           batch size batch size          num threads num preprocess threads          capacity min queue examples   3   batch size          min dequeue min queue examples)   else      images  label batch   tf train batch(          image  label           batch size batch size          num threads num preprocess threads          capacity min queue examples   3   batch size)      display training images visualizer    tf summary image( images   images)    return images  tf reshape(label batch   batch size )   def distorted inputs(data dir  batch size)       construct distorted input cifar training using reader ops     args      data dir  path cifar 10 data directory      batch size  number images per batch     returns      images  images  4d tensor  batch size  image size  image size  3  size      labels  labels  1d tensor  batch size  size          filenames    os path join(data dir   data batch  bin    i)                xrange(1  6)    f filenames      tf gfile exists(f)        raise valueerror( failed find file      f)      create queue produces filenames read    filename queue   tf train string input producer(filenames)    tf name scope( data augmentation )        read examples files filename queue      read input   read cifar10(filename queue)     reshaped image   tf cast(read input uint8image  tf float32)      height   image size     width   image size        image processing training network  note many random       distortions applied image         randomly crop  height  width  section image      distorted image   tf random crop(reshaped image   height  width  3 )        randomly flip image horizontally      distorted image   tf image random flip left right(distorted image)        because operations commutative  consider randomizing       order operation        note  since per image standardization zeros mean makes       stddev unit  likely effect see tensorflow 1458      distorted image   tf image random brightness(distorted image                                                   max delta 63)     distorted image   tf image random contrast(distorted image                                                 lower 0 2  upper 1 8)        subtract mean divide variance pixels      float image   tf image per image standardization(distorted image)        set shapes tensors      float image set shape( height  width  3 )     read input label set shape( 1 )        ensure random shuffling good mixing properties      min fraction examples queue   0 4     min queue examples   int(num examples per epoch for train                                min fraction examples queue)     print ( filling queue  cifar images starting train                this take minutes     min queue examples)      generate batch images labels building queue examples    return  generate image label batch(float image  read input label                                           min queue examples  batch size                                           shuffle true)   def inputs(eval data  data dir  batch size)       construct input cifar evaluation using reader ops     args      eval data  bool  indicating one use train eval data set      data dir  path cifar 10 data directory      batch size  number images per batch     returns      images  images  4d tensor  batch size  image size  image size  3  size      labels  labels  1d tensor  batch size  size           copyright 2015 the tensorflow authors  all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                       pylint  disable redefined builtin    process images size  note differs original cifar    image size 32 x 32  if one alters number  entire model    architecture change model would need retrained     global constants describing cifar 10 data set     dimensions images cifar 10 dataset     see http   www cs toronto edu  kriz cifar html description    input format     2 cifar 100    every record consists label followed image     fixed number bytes     read record  getting filenames filename queue   no    header footer cifar 10 format  leave header bytes    footer bytes default 0     convert string vector uint8 record bytes long     the first bytes represent label  convert uint8  int32     the remaining bytes label represent image  reshape     depth   height   width   depth  height  width      convert  depth  height  width   height  width  depth      create queue shuffles examples     read  batch size  images   labels example queue     display training images visualizer     create queue produces filenames read     read examples files filename queue     image processing training network  note many random    distortions applied image     randomly crop  height  width  section image     randomly flip image horizontally     because operations commutative  consider randomizing    order operation     note  since per image standardization zeros mean makes    stddev unit  likely effect see tensorflow 1458     subtract mean divide variance pixels     set shapes tensors     ensure random shuffling good mixing properties     generate batch images labels building queue examples     create queue produces filenames read     read examples files filename queue     image processing evaluation     crop central  height  width  image     subtract mean divide variance pixels     set shapes tensors     ensure random shuffling good mixing properties     generate batch images labels building queue examples  ", "content": "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n\"\"\"Routine for decoding the CIFAR-10 binary file format.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\nimport tensorflow as tf\n\n# Process images of this size. Note that this differs from the original CIFAR\n# image size of 32 x 32. If one alters this number, then the entire model\n# architecture will change and any model would need to be retrained.\nIMAGE_SIZE = 24\n\n# Global constants describing the CIFAR-10 data set.\nNUM_CLASSES = 10\nNUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\nNUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n\n\ndef read_cifar10(filename_queue):\n  \"\"\"Reads and parses examples from CIFAR10 data files.\n\n  Recommendation: if you want N-way read parallelism, call this function\n  N times.  This will give you N independent Readers reading different\n  files & positions within those files, which will give better mixing of\n  examples.\n\n  Args:\n    filename_queue: A queue of strings with the filenames to read from.\n\n  Returns:\n    An object representing a single example, with the following fields:\n      height: number of rows in the result (32)\n      width: number of columns in the result (32)\n      depth: number of color channels in the result (3)\n      key: a scalar string Tensor describing the filename & record number\n        for this example.\n      label: an int32 Tensor with the label in the range 0..9.\n      uint8image: a [height, width, depth] uint8 Tensor with the image data\n  \"\"\"\n\n  class CIFAR10Record(object):\n    pass\n  result = CIFAR10Record()\n\n  # Dimensions of the images in the CIFAR-10 dataset.\n  # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n  # input format.\n  label_bytes = 1  # 2 for CIFAR-100\n  result.height = 32\n  result.width = 32\n  result.depth = 3\n  image_bytes = result.height * result.width * result.depth\n  # Every record consists of a label followed by the image, with a\n  # fixed number of bytes for each.\n  record_bytes = label_bytes + image_bytes\n\n  # Read a record, getting filenames from the filename_queue.  No\n  # header or footer in the CIFAR-10 format, so we leave header_bytes\n  # and footer_bytes at their default of 0.\n  reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n  result.key, value = reader.read(filename_queue)\n\n  # Convert from a string to a vector of uint8 that is record_bytes long.\n  record_bytes = tf.decode_raw(value, tf.uint8)\n\n  # The first bytes represent the label, which we convert from uint8->int32.\n  result.label = tf.cast(\n      tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)\n\n  # The remaining bytes after the label represent the image, which we reshape\n  # from [depth * height * width] to [depth, height, width].\n  depth_major = tf.reshape(\n      tf.strided_slice(record_bytes, [label_bytes],\n                       [label_bytes + image_bytes]),\n      [result.depth, result.height, result.width])\n  # Convert from [depth, height, width] to [height, width, depth].\n  result.uint8image = tf.transpose(depth_major, [1, 2, 0])\n\n  return result\n\n\ndef _generate_image_and_label_batch(image, label, min_queue_examples,\n                                    batch_size, shuffle):\n  \"\"\"Construct a queued batch of images and labels.\n\n  Args:\n    image: 3-D Tensor of [height, width, 3] of type.float32.\n    label: 1-D Tensor of type.int32\n    min_queue_examples: int32, minimum number of samples to retain\n      in the queue that provides of batches of examples.\n    batch_size: Number of images per batch.\n    shuffle: boolean indicating whether to use a shuffling queue.\n\n  Returns:\n    images: Images. 4D tensor of [batch_size, height, width, 3] size.\n    labels: Labels. 1D tensor of [batch_size] size.\n  \"\"\"\n  # Create a queue that shuffles the examples, and then\n  # read 'batch_size' images + labels from the example queue.\n  num_preprocess_threads = 16\n  if shuffle:\n    images, label_batch = tf.train.shuffle_batch(\n        [image, label],\n        batch_size=batch_size,\n        num_threads=num_preprocess_threads,\n        capacity=min_queue_examples + 3 * batch_size,\n        min_after_dequeue=min_queue_examples)\n  else:\n    images, label_batch = tf.train.batch(\n        [image, label],\n        batch_size=batch_size,\n        num_threads=num_preprocess_threads,\n        capacity=min_queue_examples + 3 * batch_size)\n\n  # Display the training images in the visualizer.\n  tf.summary.image('images', images)\n\n  return images, tf.reshape(label_batch, [batch_size])\n\n\ndef distorted_inputs(data_dir, batch_size):\n  \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n\n  Args:\n    data_dir: Path to the CIFAR-10 data directory.\n    batch_size: Number of images per batch.\n\n  Returns:\n    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n    labels: Labels. 1D tensor of [batch_size] size.\n  \"\"\"\n  filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n               for i in xrange(1, 6)]\n  for f in filenames:\n    if not tf.gfile.Exists(f):\n      raise ValueError('Failed to find file: ' + f)\n\n  # Create a queue that produces the filenames to read.\n  filename_queue = tf.train.string_input_producer(filenames)\n\n  with tf.name_scope('data_augmentation'):\n    # Read examples from files in the filename queue.\n    read_input = read_cifar10(filename_queue)\n    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n\n    height = IMAGE_SIZE\n    width = IMAGE_SIZE\n\n    # Image processing for training the network. Note the many random\n    # distortions applied to the image.\n\n    # Randomly crop a [height, width] section of the image.\n    distorted_image = tf.random_crop(reshaped_image, [height, width, 3])\n\n    # Randomly flip the image horizontally.\n    distorted_image = tf.image.random_flip_left_right(distorted_image)\n\n    # Because these operations are not commutative, consider randomizing\n    # the order their operation.\n    # NOTE: since per_image_standardization zeros the mean and makes\n    # the stddev unit, this likely has no effect see tensorflow#1458.\n    distorted_image = tf.image.random_brightness(distorted_image,\n                                                 max_delta=63)\n    distorted_image = tf.image.random_contrast(distorted_image,\n                                               lower=0.2, upper=1.8)\n\n    # Subtract off the mean and divide by the variance of the pixels.\n    float_image = tf.image.per_image_standardization(distorted_image)\n\n    # Set the shapes of tensors.\n    float_image.set_shape([height, width, 3])\n    read_input.label.set_shape([1])\n\n    # Ensure that the random shuffling has good mixing properties.\n    min_fraction_of_examples_in_queue = 0.4\n    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN *\n                             min_fraction_of_examples_in_queue)\n    print ('Filling queue with %d CIFAR images before starting to train. '\n           'This will take a few minutes.' % min_queue_examples)\n\n  # Generate a batch of images and labels by building up a queue of examples.\n  return _generate_image_and_label_batch(float_image, read_input.label,\n                                         min_queue_examples, batch_size,\n                                         shuffle=True)\n\n\ndef inputs(eval_data, data_dir, batch_size):\n  \"\"\"Construct input for CIFAR evaluation using the Reader ops.\n\n  Args:\n    eval_data: bool, indicating if one should use the train or eval data set.\n    data_dir: Path to the CIFAR-10 data directory.\n    batch_size: Number of images per batch.\n\n  Returns:\n    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n    labels: Labels. 1D tensor of [batch_size] size.\n  \"\"\"\n  if not eval_data:\n    filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n                 for i in xrange(1, 6)]\n    num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN\n  else:\n    filenames = [os.path.join(data_dir, 'test_batch.bin')]\n    num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n\n  for f in filenames:\n    if not tf.gfile.Exists(f):\n      raise ValueError('Failed to find file: ' + f)\n\n  with tf.name_scope('input'):\n    # Create a queue that produces the filenames to read.\n    filename_queue = tf.train.string_input_producer(filenames)\n\n    # Read examples from files in the filename queue.\n    read_input = read_cifar10(filename_queue)\n    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n\n    height = IMAGE_SIZE\n    width = IMAGE_SIZE\n\n    # Image processing for evaluation.\n    # Crop the central [height, width] of the image.\n    resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,\n                                                           height, width)\n\n    # Subtract off the mean and divide by the variance of the pixels.\n    float_image = tf.image.per_image_standardization(resized_image)\n\n    # Set the shapes of tensors.\n    float_image.set_shape([height, width, 3])\n    read_input.label.set_shape([1])\n\n    # Ensure that the random shuffling has good mixing properties.\n    min_fraction_of_examples_in_queue = 0.4\n    min_queue_examples = int(num_examples_per_epoch *\n                             min_fraction_of_examples_in_queue)\n\n  # Generate a batch of images and labels by building up a queue of examples.\n  return _generate_image_and_label_batch(float_image, read_input.label,\n                                         min_queue_examples, batch_size,\n                                         shuffle=False)\n", "description": "Models and examples built with TensorFlow", "file_name": "cifar10_input.py", "id": "ef5a2c2b3d246bf275f10d20c4de63b6", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-models/tensorflow-models-086d914/tutorials/image/cifar10/cifar10_input.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:59:19Z", "url": "https://github.com/tensorflow/models", "wiki": true}