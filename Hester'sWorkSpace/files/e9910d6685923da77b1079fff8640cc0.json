{"author": "tensorflow", "code": "import numpy as np\nimport tensorflow as tf\n\n\nclass Autoencoder(object):\n\n    def __init__(self, n_layers, transfer_function=tf.nn.softplus, optimizer=tf.train.AdamOptimizer()):\n        self.n_layers = n_layers\n        self.transfer = transfer_function\n\n        network_weights = self._initialize_weights()\n        self.weights = network_weights\n\n        \n        self.x = tf.placeholder(tf.float32, [None, self.n_layers[0]])\n        self.hidden_encode = []\n        h = self.x\n        for layer in range(len(self.n_layers)-1):\n            h = self.transfer(\n                tf.add(tf.matmul(h, self.weights['encode'][layer]['w']),\n                       self.weights['encode'][layer]['b']))\n            self.hidden_encode.append(h)\n\n        self.hidden_recon = []\n        for layer in range(len(self.n_layers)-1):\n            h = self.transfer(\n                tf.add(tf.matmul(h, self.weights['recon'][layer]['w']),\n                       self.weights['recon'][layer]['b']))\n            self.hidden_recon.append(h)\n        self.reconstruction = self.hidden_recon[-1]\n\n        \n        self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n        self.optimizer = optimizer.minimize(self.cost)\n\n        init = tf.global_variables_initializer()\n        self.sess = tf.Session()\n        self.sess.run(init)\n\n\n    def _initialize_weights(self):\n        all_weights = dict()\n        \n        encoder_weights = []\n        for layer in range(len(self.n_layers)-1):\n            w = tf.Variable(\n                autoencoder.Utils.xavier_init(self.n_layers[layer],\n                                              self.n_layers[layer + 1]))\n            b = tf.Variable(tf.zeros([self.n_layers[layer+1]], dtype=tf.float32))\n            encoder_weights.append({'w': w, 'b': b})\n        \n        recon_weights = []\n        for layer in range(len(self.n_layers)-1, 0, -1):\n            w = tf.Variable(\n                autoencoder.Utils.xavier_init(self.n_layers[layer],\n                                              self.n_layers[layer - 1]))\n            b = tf.Variable(tf.zeros([self.n_layers[layer-1]], dtype=tf.float32))\n            recon_weights.append({'w': w, 'b': b})\n        all_weights['encode'] = encoder_weights\n        all_weights['recon'] = recon_weights\n        return all_weights\n\n    def partial_fit(self, X):\n        cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict={self.x: X})\n        return cost\n\n    def calc_total_cost(self, X):\n        return self.sess.run(self.cost, feed_dict={self.x: X})\n\n    def transform(self, X):\n        return self.sess.run(self.hidden_encode[-1], feed_dict={self.x: X})\n\n    def generate(self, hidden=None):\n        if hidden is None:\n            hidden = np.random.normal(size=self.weights['encode'][-1]['b'])\n        return self.sess.run(self.reconstruction, feed_dict={self.hidden_encode[-1]: hidden})\n\n    def reconstruct(self, X):\n        return self.sess.run(self.reconstruction, feed_dict={self.x: X})\n\n    def getWeights(self):\n        raise NotImplementedError\n        return self.sess.run(self.weights)\n\n    def getBiases(self):\n        raise NotImplementedError\n        return self.sess.run(self.weights)\n\n", "comments": "  model    cost    encoding network weights    recon network weights ", "content": "import numpy as np\nimport tensorflow as tf\n\n\nclass Autoencoder(object):\n\n    def __init__(self, n_layers, transfer_function=tf.nn.softplus, optimizer=tf.train.AdamOptimizer()):\n        self.n_layers = n_layers\n        self.transfer = transfer_function\n\n        network_weights = self._initialize_weights()\n        self.weights = network_weights\n\n        # model\n        self.x = tf.placeholder(tf.float32, [None, self.n_layers[0]])\n        self.hidden_encode = []\n        h = self.x\n        for layer in range(len(self.n_layers)-1):\n            h = self.transfer(\n                tf.add(tf.matmul(h, self.weights['encode'][layer]['w']),\n                       self.weights['encode'][layer]['b']))\n            self.hidden_encode.append(h)\n\n        self.hidden_recon = []\n        for layer in range(len(self.n_layers)-1):\n            h = self.transfer(\n                tf.add(tf.matmul(h, self.weights['recon'][layer]['w']),\n                       self.weights['recon'][layer]['b']))\n            self.hidden_recon.append(h)\n        self.reconstruction = self.hidden_recon[-1]\n\n        # cost\n        self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n        self.optimizer = optimizer.minimize(self.cost)\n\n        init = tf.global_variables_initializer()\n        self.sess = tf.Session()\n        self.sess.run(init)\n\n\n    def _initialize_weights(self):\n        all_weights = dict()\n        # Encoding network weights\n        encoder_weights = []\n        for layer in range(len(self.n_layers)-1):\n            w = tf.Variable(\n                autoencoder.Utils.xavier_init(self.n_layers[layer],\n                                              self.n_layers[layer + 1]))\n            b = tf.Variable(tf.zeros([self.n_layers[layer+1]], dtype=tf.float32))\n            encoder_weights.append({'w': w, 'b': b})\n        # Recon network weights\n        recon_weights = []\n        for layer in range(len(self.n_layers)-1, 0, -1):\n            w = tf.Variable(\n                autoencoder.Utils.xavier_init(self.n_layers[layer],\n                                              self.n_layers[layer - 1]))\n            b = tf.Variable(tf.zeros([self.n_layers[layer-1]], dtype=tf.float32))\n            recon_weights.append({'w': w, 'b': b})\n        all_weights['encode'] = encoder_weights\n        all_weights['recon'] = recon_weights\n        return all_weights\n\n    def partial_fit(self, X):\n        cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict={self.x: X})\n        return cost\n\n    def calc_total_cost(self, X):\n        return self.sess.run(self.cost, feed_dict={self.x: X})\n\n    def transform(self, X):\n        return self.sess.run(self.hidden_encode[-1], feed_dict={self.x: X})\n\n    def generate(self, hidden=None):\n        if hidden is None:\n            hidden = np.random.normal(size=self.weights['encode'][-1]['b'])\n        return self.sess.run(self.reconstruction, feed_dict={self.hidden_encode[-1]: hidden})\n\n    def reconstruct(self, X):\n        return self.sess.run(self.reconstruction, feed_dict={self.x: X})\n\n    def getWeights(self):\n        raise NotImplementedError\n        return self.sess.run(self.weights)\n\n    def getBiases(self):\n        raise NotImplementedError\n        return self.sess.run(self.weights)\n\n", "description": "Models and examples built with TensorFlow", "file_name": "Autoencoder.py", "id": "e9910d6685923da77b1079fff8640cc0", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tensorflow-models/tensorflow-models-7e4c66b/research/autoencoder/autoencoder_models/Autoencoder.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:59:36Z", "url": "https://github.com/tensorflow/models", "wiki": true}