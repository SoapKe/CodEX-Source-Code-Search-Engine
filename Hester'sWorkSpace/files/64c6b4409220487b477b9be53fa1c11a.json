{"author": "tflearn", "code": "from __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nimport tflearn\nimport unittest\nimport os\n\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.normalization import local_response_normalization\nfrom tflearn.layers.estimator import regression\n\nclass TestValidationMonitors(unittest.TestCase):\n    \"\"\"\n    Testing Validation Monitors\n    \"\"\"\n\n    def test_vm1(self):\n\n        with tf.Graph().as_default():\n            \n            import tflearn.datasets.mnist as mnist\n            X, Y, testX, testY = mnist.load_data(one_hot=True)\n            X = X.reshape([-1, 28, 28, 1])\n            testX = testX.reshape([-1, 28, 28, 1])\n            X = X[:10, :, :, :]\n            Y = Y[:10, :]\n            \n            \n            network = input_data(shape=[None, 28, 28, 1], name='input')\n            network = conv_2d(network, 32, 3, activation='relu', regularizer=\"L2\")\n            network = max_pool_2d(network, 2)\n            network = local_response_normalization(network)\n            network = conv_2d(network, 64, 3, activation='relu', regularizer=\"L2\")\n            network = max_pool_2d(network, 2)\n            network = local_response_normalization(network)\n            network = fully_connected(network, 128, activation='tanh')\n            network = dropout(network, 0.8)\n            network = fully_connected(network, 256, activation='tanh')\n            network = dropout(network, 0.8)\n    \n            \n             these varaibles are evaluated each time validation happens (eg at a snapshot)\n            \n            \n            \n             Here, we generate a dummy variable given by the sum over the current\n             network tensor, and a constant variable.  In practice, the validation\n             monitor may present useful information, like confusion matrix\n             entries, or an AUC metric.\n            with tf.name_scope('CustomMonitor'):\n                test_var = tf.reduce_sum(tf.cast(network, tf.float32), name=\"test_var\")\n                test_const = tf.constant(32.0, name=\"custom_constant\")\n    \n            print (\"network=%s, test_var=%s\" % (network, test_var))\n            network = fully_connected(network, 10, activation='softmax')\n            network = regression(network, optimizer='adam', learning_rate=0.01,\n                                 loss='categorical_crossentropy', name='target', validation_monitors=[test_var, test_const])\n            \n             Training\n            model = tflearn.DNN(network, tensorboard_verbose=3)\n            model.fit({'input': X}, {'target': Y}, n_epoch=1,\n                       validation_set=({'input': testX}, {'target': testY}),\n                       snapshot_step=10, show_metric=True, run_id='convnet_mnist')\n            \n             check for validation monitor variables\n            ats = tf.get_collection(\"Adam_testing_summaries\")\n            print (\"ats=%s\" % ats)\n            self.assertTrue(len(ats)==4)\t should be four variables being summarized: [loss, test_var, test_const, accuracy]\n            \n            session = model.session\n            print (\"session=%s\" % session)\n            trainer = model.trainer\n            print (\"train_ops = %s\" % trainer.train_ops)\n            top = trainer.train_ops[0]\n            vmtset = top.validation_monitors_T\n            print (\"validation_monitors_T = %s\" % vmtset)\n            with model.session.as_default():\n                ats_var_val = tflearn.variables.get_value(vmtset[0])\n                ats_const_val = tflearn.variables.get_value(vmtset[1])\n            print (\"summary values: var=%s, const=%s\" % (ats_var_val, ats_const_val))\n            self.assertTrue(ats_const_val==32)\t test to make sure the constant made it through\n    \n             TBD: parse the recorded tensorboard events and ensure the validation monitor variables show up there\n    \nclass TestValidationBatch(unittest.TestCase):\n    \"\"\"\n    Testing Validation Batch size specification\n    \"\"\"\n\n    def test_vbs1(self):\n\n        with tf.Graph().as_default():\n            \n            import tflearn.datasets.mnist as mnist\n            X, Y, testX, testY = mnist.load_data(one_hot=True)\n            X = X.reshape([-1, 28, 28, 1])\n            testX = testX.reshape([-1, 28, 28, 1])\n            X = X[:20, :, :, :]\n            Y = Y[:20, :]\n            testX = testX[:10, :, :, :]\n            testY = testY[:10, :]\n            \n            \n            network = input_data(shape=[None, 28, 28, 1], name='input')\n            network = conv_2d(network, 32, 3, activation='relu', regularizer=\"L2\")\n            network = max_pool_2d(network, 2)\n            network = local_response_normalization(network)\n            network = conv_2d(network, 64, 3, activation='relu', regularizer=\"L2\")\n            network = max_pool_2d(network, 2)\n            network = local_response_normalization(network)\n            network = fully_connected(network, 128, activation='tanh')\n            network = dropout(network, 0.8)\n            network = fully_connected(network, 256, activation='tanh')\n            network = dropout(network, 0.8)\n            network = fully_connected(network, 10, activation='softmax')\n            network = regression(network, optimizer='adam', learning_rate=0.01,\n                                 loss='categorical_crossentropy', name='target')\n            \n             Training\n            model = tflearn.DNN(network, tensorboard_verbose=3)\n            model.fit({'input': X}, {'target': Y}, n_epoch=1,\n                      batch_size=10,\n                      validation_set=({'input': testX}, {'target': testY}),\n                      validation_batch_size=5,\n                      snapshot_step=10, show_metric=True, run_id='convnet_mnist_vbs')\n    \n            self.assertEqual(model.train_ops[0].validation_batch_size, 5)\n            self.assertEqual(model.train_ops[0].batch_size, 10)\n    \nif __name__ == \"__main__\":\n    unittest.main()\n", "comments": "        testing validation monitors              def test vm1(self)           tf graph() default()                data loading preprocessing             import tflearn datasets mnist mnist             x  y  testx  testy   mnist load data(one hot true)             x   x reshape(  1  28  28  1 )             testx   testx reshape(  1  28  28  1 )             x   x  10                       y   y  10                                building convolutional network             network   input data(shape  none  28  28  1   name  input )             network   conv 2d(network  32  3  activation  relu   regularizer  l2 )             network   max pool 2d(network  2)             network   local response normalization(network)             network   conv 2d(network  64  3  activation  relu   regularizer  l2 )             network   max pool 2d(network  2)             network   local response normalization(network)             network   fully connected(network  128  activation  tanh )             network   dropout(network  0 8)             network   fully connected(network  256  activation  tanh )             network   dropout(network  0 8)                    construct two varaibles add additional  valiation monitors                varaibles evaluated time validation happens (eg snapshot)               results summarized output tensorboard events file                together accuracy loss plots                              here  generate dummy variable given sum current               network tensor  constant variable   in practice  validation               monitor may present useful information  like confusion matrix               entries  auc metric              tf name scope( custommonitor )                  test var   tf reduce sum(tf cast(network  tf float32)  name  test var )                 test const   tf constant(32 0  name  custom constant )                  print ( network   test var     (network  test var))             network   fully connected(network  10  activation  softmax )             network   regression(network  optimizer  adam   learning rate 0 01                                   loss  categorical crossentropy   name  target   validation monitors  test var  test const )                            training             model   tflearn dnn(network  tensorboard verbose 3)             model fit(  input   x     target   y   n epoch 1                         validation set (  input   testx     target   testy )                         snapshot step 10  show metric true  run id  convnet mnist )                            check validation monitor variables             ats   tf get collection( adam testing summaries )             print ( ats     ats)             self asserttrue(len(ats)  4)   four variables summarized   loss  test var  test const  accuracy                           session   model session             print ( session     session)             trainer   model trainer             print ( train ops       trainer train ops)             top   trainer train ops 0              vmtset   top validation monitors t             print ( validation monitors t       vmtset)             model session default()                  ats var val   tflearn variables get value(vmtset 0 )                 ats const val   tflearn variables get value(vmtset 1 )             print ( summary values  var   const     (ats var val  ats const val))             self asserttrue(ats const val  32)   test make sure constant made                    tbd  parse recorded tensorboard events ensure validation monitor variables show      class testvalidationbatch(unittest testcase)              testing validation batch size specification            data loading preprocessing    building convolutional network    construct two varaibles add additional  valiation monitors     varaibles evaluated time validation happens (eg snapshot)    results summarized output tensorboard events file     together accuracy loss plots        here  generate dummy variable given sum current    network tensor  constant variable   in practice  validation    monitor may present useful information  like confusion matrix    entries  auc metric     training    check validation monitor variables    four variables summarized   loss  test var  test const  accuracy     test make sure constant made    tbd  parse recorded tensorboard events ensure validation monitor variables show    data loading preprocessing    building convolutional network    training ", "content": "from __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nimport tflearn\nimport unittest\nimport os\n\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.normalization import local_response_normalization\nfrom tflearn.layers.estimator import regression\n\nclass TestValidationMonitors(unittest.TestCase):\n    \"\"\"\n    Testing Validation Monitors\n    \"\"\"\n\n    def test_vm1(self):\n\n        with tf.Graph().as_default():\n            # Data loading and preprocessing\n            import tflearn.datasets.mnist as mnist\n            X, Y, testX, testY = mnist.load_data(one_hot=True)\n            X = X.reshape([-1, 28, 28, 1])\n            testX = testX.reshape([-1, 28, 28, 1])\n            X = X[:10, :, :, :]\n            Y = Y[:10, :]\n            \n            # Building convolutional network\n            network = input_data(shape=[None, 28, 28, 1], name='input')\n            network = conv_2d(network, 32, 3, activation='relu', regularizer=\"L2\")\n            network = max_pool_2d(network, 2)\n            network = local_response_normalization(network)\n            network = conv_2d(network, 64, 3, activation='relu', regularizer=\"L2\")\n            network = max_pool_2d(network, 2)\n            network = local_response_normalization(network)\n            network = fully_connected(network, 128, activation='tanh')\n            network = dropout(network, 0.8)\n            network = fully_connected(network, 256, activation='tanh')\n            network = dropout(network, 0.8)\n    \n            # construct two varaibles to add as additional \"valiation monitors\"\n            # these varaibles are evaluated each time validation happens (eg at a snapshot)\n            # and the results are summarized and output to the tensorboard events file,\n            # together with the accuracy and loss plots.\n            #\n            # Here, we generate a dummy variable given by the sum over the current\n            # network tensor, and a constant variable.  In practice, the validation\n            # monitor may present useful information, like confusion matrix\n            # entries, or an AUC metric.\n            with tf.name_scope('CustomMonitor'):\n                test_var = tf.reduce_sum(tf.cast(network, tf.float32), name=\"test_var\")\n                test_const = tf.constant(32.0, name=\"custom_constant\")\n    \n            print (\"network=%s, test_var=%s\" % (network, test_var))\n            network = fully_connected(network, 10, activation='softmax')\n            network = regression(network, optimizer='adam', learning_rate=0.01,\n                                 loss='categorical_crossentropy', name='target', validation_monitors=[test_var, test_const])\n            \n            # Training\n            model = tflearn.DNN(network, tensorboard_verbose=3)\n            model.fit({'input': X}, {'target': Y}, n_epoch=1,\n                       validation_set=({'input': testX}, {'target': testY}),\n                       snapshot_step=10, show_metric=True, run_id='convnet_mnist')\n            \n            # check for validation monitor variables\n            ats = tf.get_collection(\"Adam_testing_summaries\")\n            print (\"ats=%s\" % ats)\n            self.assertTrue(len(ats)==4)\t# should be four variables being summarized: [loss, test_var, test_const, accuracy]\n            \n            session = model.session\n            print (\"session=%s\" % session)\n            trainer = model.trainer\n            print (\"train_ops = %s\" % trainer.train_ops)\n            top = trainer.train_ops[0]\n            vmtset = top.validation_monitors_T\n            print (\"validation_monitors_T = %s\" % vmtset)\n            with model.session.as_default():\n                ats_var_val = tflearn.variables.get_value(vmtset[0])\n                ats_const_val = tflearn.variables.get_value(vmtset[1])\n            print (\"summary values: var=%s, const=%s\" % (ats_var_val, ats_const_val))\n            self.assertTrue(ats_const_val==32)\t# test to make sure the constant made it through\n    \n            # TBD: parse the recorded tensorboard events and ensure the validation monitor variables show up there\n    \nclass TestValidationBatch(unittest.TestCase):\n    \"\"\"\n    Testing Validation Batch size specification\n    \"\"\"\n\n    def test_vbs1(self):\n\n        with tf.Graph().as_default():\n            # Data loading and preprocessing\n            import tflearn.datasets.mnist as mnist\n            X, Y, testX, testY = mnist.load_data(one_hot=True)\n            X = X.reshape([-1, 28, 28, 1])\n            testX = testX.reshape([-1, 28, 28, 1])\n            X = X[:20, :, :, :]\n            Y = Y[:20, :]\n            testX = testX[:10, :, :, :]\n            testY = testY[:10, :]\n            \n            # Building convolutional network\n            network = input_data(shape=[None, 28, 28, 1], name='input')\n            network = conv_2d(network, 32, 3, activation='relu', regularizer=\"L2\")\n            network = max_pool_2d(network, 2)\n            network = local_response_normalization(network)\n            network = conv_2d(network, 64, 3, activation='relu', regularizer=\"L2\")\n            network = max_pool_2d(network, 2)\n            network = local_response_normalization(network)\n            network = fully_connected(network, 128, activation='tanh')\n            network = dropout(network, 0.8)\n            network = fully_connected(network, 256, activation='tanh')\n            network = dropout(network, 0.8)\n            network = fully_connected(network, 10, activation='softmax')\n            network = regression(network, optimizer='adam', learning_rate=0.01,\n                                 loss='categorical_crossentropy', name='target')\n            \n            # Training\n            model = tflearn.DNN(network, tensorboard_verbose=3)\n            model.fit({'input': X}, {'target': Y}, n_epoch=1,\n                      batch_size=10,\n                      validation_set=({'input': testX}, {'target': testY}),\n                      validation_batch_size=5,\n                      snapshot_step=10, show_metric=True, run_id='convnet_mnist_vbs')\n    \n            self.assertEqual(model.train_ops[0].validation_batch_size, 5)\n            self.assertEqual(model.train_ops[0].batch_size, 10)\n    \nif __name__ == \"__main__\":\n    unittest.main()\n", "description": "Deep learning library featuring a higher-level API for TensorFlow.", "file_name": "test_validation_monitors.py", "id": "64c6b4409220487b477b9be53fa1c11a", "language": "Python", "project_name": "tflearn", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tflearn-tflearn/tflearn-tflearn-70fb38a/tests/test_validation_monitors.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:15:41Z", "url": "https://github.com/tflearn/tflearn", "wiki": true}