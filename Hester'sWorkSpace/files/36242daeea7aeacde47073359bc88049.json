{"author": "facebookresearch", "code": " Copyright (c) 2017-present, Facebook, Inc.\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport numpy as np\nimport unittest\n\nfrom caffe2.proto import caffe2_pb2\nfrom caffe2.python import core\nfrom caffe2.python import gradient_checker\nfrom caffe2.python import workspace\n\nimport utils.c2\nimport utils.logging\n\n\nclass BatchPermutationOpTest(unittest.TestCase):\n    def _run_op_test(self, X, I, check_grad=False):\n        with core.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA, 0)):\n            op = core.CreateOperator('BatchPermutation', ['X', 'I'], ['Y'])\n            workspace.FeedBlob('X', X)\n            workspace.FeedBlob('I', I)\n        workspace.RunOperatorOnce(op)\n        Y = workspace.FetchBlob('Y')\n\n        if check_grad:\n            gc = gradient_checker.GradientChecker(\n                stepsize=0.1,\n                threshold=0.001,\n                device_option=core.DeviceOption(caffe2_pb2.CUDA, 0)\n            )\n\n            res, grad, grad_estimated = gc.CheckSimple(op, [X, I], 0, [0])\n            self.assertTrue(res, 'Grad check failed')\n\n        Y_ref = X[I]\n        np.testing.assert_allclose(Y, Y_ref, rtol=1e-5, atol=1e-08)\n\n    def _run_speed_test(self, iters=5, N=1024):\n        \n        net = core.Net('test')\n        net.Proto().type = 'prof_dag'\n        net.Proto().num_workers = 2\n        Y = net.BatchPermutation(['X', 'I'], 'Y')\n        Y_flat = net.FlattenToVec([Y], 'Y_flat')\n        loss = net.AveragedLoss([Y_flat], 'loss')\n        net.AddGradientOperators([loss])\n        workspace.CreateNet(net)\n\n        X = np.random.randn(N, 256, 14, 14)\n        for _i in range(iters):\n            I = np.random.permutation(N)\n            workspace.FeedBlob('X', X.astype(np.float32))\n            workspace.FeedBlob('I', I.astype(np.int32))\n            workspace.RunNet(net.Proto().name)\n            np.testing.assert_allclose(\n                workspace.FetchBlob('Y'), X[I], rtol=1e-5, atol=1e-08\n            )\n\n    def test_forward_and_gradient(self):\n        A = np.random.randn(2, 3, 5, 7).astype(np.float32)\n        I = np.array([0, 1], dtype=np.int32)\n        self._run_op_test(A, I, check_grad=True)\n\n        A = np.random.randn(2, 3, 5, 7).astype(np.float32)\n        I = np.array([1, 0], dtype=np.int32)\n        self._run_op_test(A, I, check_grad=True)\n\n        A = np.random.randn(10, 3, 5, 7).astype(np.float32)\n        I = np.array(np.random.permutation(10), dtype=np.int32)\n        self._run_op_test(A, I, check_grad=True)\n\n    def test_size_exceptions(self):\n        A = np.random.randn(2, 256, 42, 86).astype(np.float32)\n        I = np.array(np.random.permutation(10), dtype=np.int32)\n        with self.assertRaises(RuntimeError):\n            self._run_op_test(A, I)\n\n     See doc string in _run_speed_test\n     def test_perf(self):\n         with core.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA, 0)):\n             self._run_speed_test()\n\n\nif __name__ == '__main__':\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    utils.c2.import_detectron_ops()\n    assert 'BatchPermutation' in workspace.RegisteredOperators()\n    utils.logging.setup_logging(__name__)\n    unittest.main()\n", "comments": "   this function provides example benchmark custom         operators using caffe2  prof dag  network execution type  please         note  prof dag  work  caffe2 must compiled profiling         support using   duse prof on  option passed  cmake  building         caffe2                 copyright (c) 2017 present  facebook  inc        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                     see doc string  run speed test    def test perf(self)         core devicescope(core deviceoption(caffe2 pb2 cuda  0))             self  run speed test() ", "content": "# Copyright (c) 2017-present, Facebook, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n##############################################################################\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport numpy as np\nimport unittest\n\nfrom caffe2.proto import caffe2_pb2\nfrom caffe2.python import core\nfrom caffe2.python import gradient_checker\nfrom caffe2.python import workspace\n\nimport utils.c2\nimport utils.logging\n\n\nclass BatchPermutationOpTest(unittest.TestCase):\n    def _run_op_test(self, X, I, check_grad=False):\n        with core.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA, 0)):\n            op = core.CreateOperator('BatchPermutation', ['X', 'I'], ['Y'])\n            workspace.FeedBlob('X', X)\n            workspace.FeedBlob('I', I)\n        workspace.RunOperatorOnce(op)\n        Y = workspace.FetchBlob('Y')\n\n        if check_grad:\n            gc = gradient_checker.GradientChecker(\n                stepsize=0.1,\n                threshold=0.001,\n                device_option=core.DeviceOption(caffe2_pb2.CUDA, 0)\n            )\n\n            res, grad, grad_estimated = gc.CheckSimple(op, [X, I], 0, [0])\n            self.assertTrue(res, 'Grad check failed')\n\n        Y_ref = X[I]\n        np.testing.assert_allclose(Y, Y_ref, rtol=1e-5, atol=1e-08)\n\n    def _run_speed_test(self, iters=5, N=1024):\n        \"\"\"This function provides an example of how to benchmark custom\n        operators using the Caffe2 'prof_dag' network execution type. Please\n        note that for 'prof_dag' to work, Caffe2 must be compiled with profiling\n        support using the `-DUSE_PROF=ON` option passed to `cmake` when building\n        Caffe2.\n        \"\"\"\n        net = core.Net('test')\n        net.Proto().type = 'prof_dag'\n        net.Proto().num_workers = 2\n        Y = net.BatchPermutation(['X', 'I'], 'Y')\n        Y_flat = net.FlattenToVec([Y], 'Y_flat')\n        loss = net.AveragedLoss([Y_flat], 'loss')\n        net.AddGradientOperators([loss])\n        workspace.CreateNet(net)\n\n        X = np.random.randn(N, 256, 14, 14)\n        for _i in range(iters):\n            I = np.random.permutation(N)\n            workspace.FeedBlob('X', X.astype(np.float32))\n            workspace.FeedBlob('I', I.astype(np.int32))\n            workspace.RunNet(net.Proto().name)\n            np.testing.assert_allclose(\n                workspace.FetchBlob('Y'), X[I], rtol=1e-5, atol=1e-08\n            )\n\n    def test_forward_and_gradient(self):\n        A = np.random.randn(2, 3, 5, 7).astype(np.float32)\n        I = np.array([0, 1], dtype=np.int32)\n        self._run_op_test(A, I, check_grad=True)\n\n        A = np.random.randn(2, 3, 5, 7).astype(np.float32)\n        I = np.array([1, 0], dtype=np.int32)\n        self._run_op_test(A, I, check_grad=True)\n\n        A = np.random.randn(10, 3, 5, 7).astype(np.float32)\n        I = np.array(np.random.permutation(10), dtype=np.int32)\n        self._run_op_test(A, I, check_grad=True)\n\n    def test_size_exceptions(self):\n        A = np.random.randn(2, 256, 42, 86).astype(np.float32)\n        I = np.array(np.random.permutation(10), dtype=np.int32)\n        with self.assertRaises(RuntimeError):\n            self._run_op_test(A, I)\n\n    # See doc string in _run_speed_test\n    # def test_perf(self):\n    #     with core.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA, 0)):\n    #         self._run_speed_test()\n\n\nif __name__ == '__main__':\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    utils.c2.import_detectron_ops()\n    assert 'BatchPermutation' in workspace.RegisteredOperators()\n    utils.logging.setup_logging(__name__)\n    unittest.main()\n", "description": "FAIR's research platform for object detection research, implementing popular algorithms like Mask R-CNN and RetinaNet.", "file_name": "test_batch_permutation_op.py", "id": "36242daeea7aeacde47073359bc88049", "language": "Python", "project_name": "Detectron", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/facebookresearch-Detectron/facebookresearch-Detectron-958b0ad/tests/test_batch_permutation_op.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:01:25Z", "url": "https://github.com/facebookresearch/Detectron", "wiki": false}