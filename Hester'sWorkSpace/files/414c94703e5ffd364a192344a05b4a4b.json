{"author": "chiphuyen", "code": "\"\"\" Load VGGNet weights needed for the implementation in TensorFlow\nof the paper A Neural Algorithm of Artistic Style (Gatys et al., 2016) \n\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: \"TensorFlow for Deep Learning Research\"\ncs20.stanford.edu\n\nFor more details, please read the assignment handout:\nhttps://docs.google.com/document/d/1FpueD-3mScnD0SJQDtwmOb1FrSwo1NGowkXzMwPoLH4/edit?usp=sharing\n\n\"\"\"\nimport numpy as np\nimport scipy.io\nimport tensorflow as tf\n\nimport utils\n\n\nVGG_DOWNLOAD_LINK = 'http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat'\nVGG_FILENAME = 'imagenet-vgg-verydeep-19.mat'\nEXPECTED_BYTES = 534904783\n\nclass VGG(object):\n    def __init__(self, input_img):\n        utils.download(VGG_DOWNLOAD_LINK, VGG_FILENAME, EXPECTED_BYTES)\n        self.vgg_layers = scipy.io.loadmat(VGG_FILENAME)['layers']\n        self.input_img = input_img\n        self.mean_pixels = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n\n    def _weights(self, layer_idx, expected_layer_name):\n        \"\"\" Return the weights and biases at layer_idx already trained by VGG\n        \"\"\"\n        W = self.vgg_layers[0][layer_idx][0][0][2][0][0]\n        b = self.vgg_layers[0][layer_idx][0][0][2][0][1]\n        layer_name = self.vgg_layers[0][layer_idx][0][0][0][0]\n        assert layer_name == expected_layer_name\n        return W, b.reshape(b.size)\n\n    def conv2d_relu(self, prev_layer, layer_idx, layer_name):\n        \"\"\" Create a convolution layer with RELU using the weights and\n        biases extracted from the VGG model at 'layer_idx'. You should use\n        the function _weights() defined above to extract weights and biases.\n\n        _weights() returns numpy arrays, so you have to convert them to TF tensors.\n\n        Don't forget to apply relu to the output from the convolution.\n        Inputs:\n            prev_layer: the output tensor from the previous layer\n            layer_idx: the index to current layer in vgg_layers\n            layer_name: the string that is the name of the current layer.\n                        It's used to specify variable_scope.\n        Hint for choosing strides size: \n            for small images, you probably don't want to skip any pixel\n        \"\"\"\n        \n        \n        out = None\n        \n        setattr(self, layer_name, out)\n\n    def avgpool(self, prev_layer, layer_name):\n        \"\"\" Create the average pooling layer. The paper suggests that \n        average pooling works better than max pooling.\n        \n        Input:\n            prev_layer: the output tensor from the previous layer\n            layer_name: the string that you want to name the layer.\n                        It's used to specify variable_scope.\n\n        Hint for choosing strides and kszie: choose what you feel appropriate\n        \"\"\"\n        \n        \n        out = None\n        \n        setattr(self, layer_name, out)\n\n    def load(self):\n        self.conv2d_relu(self.input_img, 0, 'conv1_1')\n        self.conv2d_relu(self.conv1_1, 2, 'conv1_2')\n        self.avgpool(self.conv1_2, 'avgpool1')\n        self.conv2d_relu(self.avgpool1, 5, 'conv2_1')\n        self.conv2d_relu(self.conv2_1, 7, 'conv2_2')\n        self.avgpool(self.conv2_2, 'avgpool2')\n        self.conv2d_relu(self.avgpool2, 10, 'conv3_1')\n        self.conv2d_relu(self.conv3_1, 12, 'conv3_2')\n        self.conv2d_relu(self.conv3_2, 14, 'conv3_3')\n        self.conv2d_relu(self.conv3_3, 16, 'conv3_4')\n        self.avgpool(self.conv3_4, 'avgpool3')\n        self.conv2d_relu(self.avgpool3, 19, 'conv4_1')\n        self.conv2d_relu(self.conv4_1, 21, 'conv4_2')\n        self.conv2d_relu(self.conv4_2, 23, 'conv4_3')\n        self.conv2d_relu(self.conv4_3, 25, 'conv4_4')\n        self.avgpool(self.conv4_4, 'avgpool4')\n        self.conv2d_relu(self.avgpool4, 28, 'conv5_1')\n        self.conv2d_relu(self.conv5_1, 30, 'conv5_2')\n        self.conv2d_relu(self.conv5_2, 32, 'conv5_3')\n        self.conv2d_relu(self.conv5_3, 34, 'conv5_4')\n        self.avgpool(self.conv5_4, 'avgpool5')", "comments": "    load vggnet weights needed implementation tensorflow paper a neural algorithm artistic style (gatys et al   2016)   created chip huyen (chiphuyen cs stanford edu) cs20   tensorflow deep learning research  cs20 stanford edu  for details  please read assignment handout  https   docs google com document 1fpued 3mscnd0sjqdtwmob1frswo1ngowkxzmwpolh4 edit usp sharing      import numpy np import scipy io import tensorflow tf  import utils    vgg 19 parameters file vgg download link    http   www vlfeat org matconvnet models imagenet vgg verydeep 19 mat  vgg filename    imagenet vgg verydeep 19 mat  expected bytes   534904783  class vgg(object)      def   init  (self  input img)          utils download(vgg download link  vgg filename  expected bytes)         self vgg layers   scipy io loadmat(vgg filename)  layers           self input img   input img         self mean pixels   np array( 123 68  116 779  103 939 ) reshape((1 1 1 3))      def  weights(self  layer idx  expected layer name)              return weights biases layer idx already trained vgg                     w   self vgg layers 0  layer idx  0  0  2  0  0          b   self vgg layers 0  layer idx  0  0  2  0  1          layer name   self vgg layers 0  layer idx  0  0  0  0          assert layer name    expected layer name         return w  b reshape(b size)      def conv2d relu(self  prev layer  layer idx  layer name)              create convolution layer relu using weights         biases extracted vgg model  layer idx   you use         function  weights() defined extract weights biases            weights() returns numpy arrays  convert tf tensors           don forget apply relu output convolution          inputs              prev layer  output tensor previous layer             layer idx  index current layer vgg layers             layer name  string name current layer                          it used specify variable scope          hint choosing strides size               small images  probably want skip pixel                                                                to do           none                                                 setattr(self  layer name  out)      def avgpool(self  prev layer  layer name)              create average pooling layer  the paper suggests          average pooling works better max pooling                   input              prev layer  output tensor previous layer             layer name  string want name layer                          it used specify variable scope           hint choosing strides kszie  choose feel appropriate                vgg 19 parameters file                                      to do                                                                       to do                                  ", "content": "\"\"\" Load VGGNet weights needed for the implementation in TensorFlow\nof the paper A Neural Algorithm of Artistic Style (Gatys et al., 2016) \n\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: \"TensorFlow for Deep Learning Research\"\ncs20.stanford.edu\n\nFor more details, please read the assignment handout:\nhttps://docs.google.com/document/d/1FpueD-3mScnD0SJQDtwmOb1FrSwo1NGowkXzMwPoLH4/edit?usp=sharing\n\n\"\"\"\nimport numpy as np\nimport scipy.io\nimport tensorflow as tf\n\nimport utils\n\n# VGG-19 parameters file\nVGG_DOWNLOAD_LINK = 'http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat'\nVGG_FILENAME = 'imagenet-vgg-verydeep-19.mat'\nEXPECTED_BYTES = 534904783\n\nclass VGG(object):\n    def __init__(self, input_img):\n        utils.download(VGG_DOWNLOAD_LINK, VGG_FILENAME, EXPECTED_BYTES)\n        self.vgg_layers = scipy.io.loadmat(VGG_FILENAME)['layers']\n        self.input_img = input_img\n        self.mean_pixels = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n\n    def _weights(self, layer_idx, expected_layer_name):\n        \"\"\" Return the weights and biases at layer_idx already trained by VGG\n        \"\"\"\n        W = self.vgg_layers[0][layer_idx][0][0][2][0][0]\n        b = self.vgg_layers[0][layer_idx][0][0][2][0][1]\n        layer_name = self.vgg_layers[0][layer_idx][0][0][0][0]\n        assert layer_name == expected_layer_name\n        return W, b.reshape(b.size)\n\n    def conv2d_relu(self, prev_layer, layer_idx, layer_name):\n        \"\"\" Create a convolution layer with RELU using the weights and\n        biases extracted from the VGG model at 'layer_idx'. You should use\n        the function _weights() defined above to extract weights and biases.\n\n        _weights() returns numpy arrays, so you have to convert them to TF tensors.\n\n        Don't forget to apply relu to the output from the convolution.\n        Inputs:\n            prev_layer: the output tensor from the previous layer\n            layer_idx: the index to current layer in vgg_layers\n            layer_name: the string that is the name of the current layer.\n                        It's used to specify variable_scope.\n        Hint for choosing strides size: \n            for small images, you probably don't want to skip any pixel\n        \"\"\"\n        ###############################\n        ## TO DO\n        out = None\n        ###############################\n        setattr(self, layer_name, out)\n\n    def avgpool(self, prev_layer, layer_name):\n        \"\"\" Create the average pooling layer. The paper suggests that \n        average pooling works better than max pooling.\n        \n        Input:\n            prev_layer: the output tensor from the previous layer\n            layer_name: the string that you want to name the layer.\n                        It's used to specify variable_scope.\n\n        Hint for choosing strides and kszie: choose what you feel appropriate\n        \"\"\"\n        ###############################\n        ## TO DO\n        out = None\n        ###############################\n        setattr(self, layer_name, out)\n\n    def load(self):\n        self.conv2d_relu(self.input_img, 0, 'conv1_1')\n        self.conv2d_relu(self.conv1_1, 2, 'conv1_2')\n        self.avgpool(self.conv1_2, 'avgpool1')\n        self.conv2d_relu(self.avgpool1, 5, 'conv2_1')\n        self.conv2d_relu(self.conv2_1, 7, 'conv2_2')\n        self.avgpool(self.conv2_2, 'avgpool2')\n        self.conv2d_relu(self.avgpool2, 10, 'conv3_1')\n        self.conv2d_relu(self.conv3_1, 12, 'conv3_2')\n        self.conv2d_relu(self.conv3_2, 14, 'conv3_3')\n        self.conv2d_relu(self.conv3_3, 16, 'conv3_4')\n        self.avgpool(self.conv3_4, 'avgpool3')\n        self.conv2d_relu(self.avgpool3, 19, 'conv4_1')\n        self.conv2d_relu(self.conv4_1, 21, 'conv4_2')\n        self.conv2d_relu(self.conv4_2, 23, 'conv4_3')\n        self.conv2d_relu(self.conv4_3, 25, 'conv4_4')\n        self.avgpool(self.conv4_4, 'avgpool4')\n        self.conv2d_relu(self.avgpool4, 28, 'conv5_1')\n        self.conv2d_relu(self.conv5_1, 30, 'conv5_2')\n        self.conv2d_relu(self.conv5_2, 32, 'conv5_3')\n        self.conv2d_relu(self.conv5_3, 34, 'conv5_4')\n        self.avgpool(self.conv5_4, 'avgpool5')", "description": "This repository contains code examples for the Stanford's course: TensorFlow for Deep Learning Research. ", "file_name": "load_vgg.py", "id": "414c94703e5ffd364a192344a05b4a4b", "language": "Python", "project_name": "stanford-tensorflow-tutorials", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/chiphuyen-stanford-tensorflow-tutorials/chiphuyen-stanford-tensorflow-tutorials-54c48f5/assignments/02_style_transfer/load_vgg.py", "save_time": "", "source": "", "update_at": "2018-03-18T15:38:24Z", "url": "https://github.com/chiphuyen/stanford-tensorflow-tutorials", "wiki": true}