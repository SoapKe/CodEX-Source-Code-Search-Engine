{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================\n\nr\"\"\"\nCode for plotting trajectories in the top view, and also plot first person views\nfrom saved trajectories. Does not run the network but only loads the mesh data\nto plot the view points.\n  CUDA_VISIBLE_DEVICES=0 LD_LIBRARY_PATH=/opt/cuda-8.0/lib64:/opt/cudnnv51/lib64\n  PYTHONPATH='.' PYOPENGL_PLATFORM=egl python scripts/script_plot_trajectory.py \\\n      --first_person --num_steps 40 \\\n      --config_name cmp.lmap_Msc.clip5.sbpd_d_r2r \\\n      --imset test --alsologtostderr --base_dir output --out_dir vis\n\n\"\"\"\nimport os, sys, numpy as np, copy\nimport matplotlib\nmatplotlib.use(\"Agg\")\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom matplotlib.gridspec import GridSpec\n\nimport tensorflow as tf\nfrom tensorflow.contrib import slim\nimport cv2\nimport logging\nfrom tensorflow.python.platform import gfile\nfrom tensorflow.python.platform import app\nfrom tensorflow.python.platform import flags\n\nfrom datasets import nav_env\nimport scripts.script_nav_agent_release as sna\nimport src.file_utils as fu\nfrom src import graph_utils\nfrom src import utils\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string('out_dir', 'vis', 'Directory where to store the output')\nflags.DEFINE_string('type', '', 'Optional type.')\nflags.DEFINE_bool('first_person', False, 'Visualize the first person view.')\nflags.DEFINE_bool('top_view', False, 'Visualize the trajectory in the top view.')\nflags.DEFINE_integer('num_steps', 40, 'Number of steps to run the model for.')\nflags.DEFINE_string('imset', 'test', '')\nflags.DEFINE_string('base_dir', 'output', 'Cache directory.')\n\ndef _get_suffix_str():\n  return ''\n\n\ndef _load_trajectory():\n  base_dir = FLAGS.base_dir\n  config_name = FLAGS.config_name+_get_suffix_str()\n\n  dir_name = os.path.join(base_dir, FLAGS.type, config_name)\n  logging.info('Waiting for snapshot in directory %s.', dir_name)\n  last_checkpoint = slim.evaluation.wait_for_new_checkpoint(dir_name, None)\n  checkpoint_iter = int(os.path.basename(last_checkpoint).split('-')[1])\n\n   Load the distances.\n  a = utils.load_variables(os.path.join(dir_name, 'bench_on_'+FLAGS.imset,\n                                        'all_locs_at_t_{:d}.pkl'.format(checkpoint_iter)))\n  return a\n\ndef _compute_hardness():\n   Load the stanford data to compute the hardness.\n  if FLAGS.type == '':\n    args = sna.get_args_for_config(FLAGS.config_name+'+bench_'+FLAGS.imset)\n  else:\n    args = sna.get_args_for_config(FLAGS.type+'.'+FLAGS.config_name+'+bench_'+FLAGS.imset)\n\n  args.navtask.logdir = None\n  R = lambda: nav_env.get_multiplexer_class(args.navtask, 0)\n  R = R()\n\n  rng_data = [np.random.RandomState(0), np.random.RandomState(0)]\n\n   Sample a room.\n  h_dists = []\n  gt_dists = []\n  for i in range(250):\n    e = R.sample_env(rng_data)\n    nodes = e.task.nodes\n\n     Initialize the agent.\n    init_env_state = e.reset(rng_data)\n\n    gt_dist_to_goal = [e.episode.dist_to_goal[0][j][s]\n                       for j, s in enumerate(e.episode.start_node_ids)]\n\n    for j in range(args.navtask.task_params.batch_size):\n      start_node_id = e.episode.start_node_ids[j]\n      end_node_id =e.episode.goal_node_ids[0][j]\n      h_dist = graph_utils.heuristic_fn_vec(\n          nodes[[start_node_id],:], nodes[[end_node_id], :],\n          n_ori=args.navtask.task_params.n_ori,\n          step_size=args.navtask.task_params.step_size)[0][0]\n      gt_dist = e.episode.dist_to_goal[0][j][start_node_id]\n      h_dists.append(h_dist)\n      gt_dists.append(gt_dist)\n\n  h_dists = np.array(h_dists)\n  gt_dists = np.array(gt_dists)\n  e = R.sample_env([np.random.RandomState(0), np.random.RandomState(0)])\n  input = e.get_common_data()\n  orig_maps = input['orig_maps'][0,0,:,:,0]\n  return h_dists, gt_dists, orig_maps\n\ndef plot_trajectory_first_person(dt, orig_maps, out_dir):\n  out_dir = os.path.join(out_dir, FLAGS.config_name+_get_suffix_str(),\n                         FLAGS.imset)\n  fu.makedirs(out_dir)\n\n   Load the model so that we can render.\n  plt.set_cmap('gray')\n  samples_per_action = 8; wait_at_action = 0;\n\n  Writer = animation.writers['mencoder']\n  writer = Writer(fps=3*(samples_per_action+wait_at_action),\n                  metadata=dict(artist='anonymous'), bitrate=1800)\n\n  args = sna.get_args_for_config(FLAGS.config_name + '+bench_'+FLAGS.imset)\n  args.navtask.logdir = None\n  navtask_ = copy.deepcopy(args.navtask)\n  navtask_.camera_param.modalities = ['rgb']\n  navtask_.task_params.modalities = ['rgb']\n  sz = 512\n  navtask_.camera_param.height = sz\n  navtask_.camera_param.width = sz\n  navtask_.task_params.img_height = sz\n  navtask_.task_params.img_width = sz\n  R = lambda: nav_env.get_multiplexer_class(navtask_, 0)\n  R = R()\n  b = R.buildings[0]\n\n  f = [0 for _ in range(wait_at_action)] + \\\n      [float(_)/samples_per_action for _ in range(samples_per_action)];\n\n   Generate things for it to render.\n  inds_to_do = []\n  inds_to_do += [1, 4, 10] 1291, 1268, 1273, 1289, 1302, 1426, 1413, 1449, 1399, 1390]\n\n  for i in inds_to_do:\n    fig = plt.figure(figsize=(10,8))\n    gs = GridSpec(3,4)\n    gs.update(wspace=0.05, hspace=0.05, left=0.0, top=0.97, right=1.0, bottom=0.)\n    ax = fig.add_subplot(gs[:,:-1])\n    ax1 = fig.add_subplot(gs[0,-1])\n    ax2 = fig.add_subplot(gs[1,-1])\n    ax3 = fig.add_subplot(gs[2,-1])\n    axes = [ax, ax1, ax2, ax3]\n     ax = fig.add_subplot(gs[:,:])\n     axes = [ax]\n    for ax in axes:\n      ax.set_axis_off()\n\n    node_ids = dt['all_node_ids'][i, :, 0]*1\n     Prune so that last node is not repeated more than 3 times?\n    if np.all(node_ids[-4:] == node_ids[-1]):\n      while node_ids[-4] == node_ids[-1]:\n        node_ids = node_ids[:-1]\n    num_steps = np.minimum(FLAGS.num_steps, len(node_ids))\n\n    xyt = b.to_actual_xyt_vec(b.task.nodes[node_ids])\n    xyt_diff = xyt[1:,:] - xyt[:-1:,:]\n    xyt_diff[:,2] = np.mod(xyt_diff[:,2], 4)\n    ind = np.where(xyt_diff[:,2] == 3)[0]\n    xyt_diff[ind, 2] = -1\n    xyt_diff = np.expand_dims(xyt_diff, axis=1)\n    to_cat = [xyt_diff*_ for _ in f]\n    perturbs_all = np.concatenate(to_cat, axis=1)\n    perturbs_all = np.concatenate([perturbs_all, np.zeros_like(perturbs_all[:,:,:1])], axis=2)\n    node_ids_all = np.expand_dims(node_ids, axis=1)*1\n    node_ids_all = np.concatenate([node_ids_all for _ in f], axis=1)\n    node_ids_all = np.reshape(node_ids_all[:-1,:], -1)\n    perturbs_all = np.reshape(perturbs_all, [-1, 4])\n    imgs = b.render_nodes(b.task.nodes[node_ids_all,:], perturb=perturbs_all)\n\n     Get action at each node.\n    actions = []\n    _, action_to_nodes = b.get_feasible_actions(node_ids)\n    for j in range(num_steps-1):\n      action_to_node = action_to_nodes[j]\n      node_to_action = dict(zip(action_to_node.values(), action_to_node.keys()))\n      actions.append(node_to_action[node_ids[j+1]])\n\n    def init_fn():\n      return fig,\n    gt_dist_to_goal = []\n\n     Render trajectories.\n    def worker(j):\n       Plot the image.\n      step_number = j/(samples_per_action + wait_at_action)\n      img = imgs[j]; ax = axes[0]; ax.clear(); ax.set_axis_off();\n      img = img.astype(np.uint8); ax.imshow(img);\n      tt = ax.set_title(\n          \"First Person View\\n\" +\n          \"Top corners show diagnostics (distance, agents' action) not input to agent.\",\n          fontsize=12)\n      plt.setp(tt, color='white')\n\n       Distance to goal.\n      t = 'Dist to Goal:\\n{:2d} steps'.format(int(dt['all_d_at_t'][i, step_number]))\n      t = ax.text(0.01, 0.99, t,\n          horizontalalignment='left',\n          verticalalignment='top',\n          fontsize=20, color='red',\n          transform=ax.transAxes, alpha=1.0)\n      t.set_bbox(dict(color='white', alpha=0.85, pad=-0.1))\n\n       Action to take.\n      action_latex = ['$\\odot$ ', '$\\curvearrowright$ ', '$\\curvearrowleft$ ', r'$\\Uparrow$ ']\n      t = ax.text(0.99, 0.99, action_latex[actions[step_number]],\n          horizontalalignment='right',\n          verticalalignment='top',\n          fontsize=40, color='green',\n          transform=ax.transAxes, alpha=1.0)\n      t.set_bbox(dict(color='white', alpha=0.85, pad=-0.1))\n\n\n       Plot the map top view.\n      ax = axes[-1]\n      if j == 0:\n         Plot the map\n        locs = dt['all_locs'][i,:num_steps,:]\n        goal_loc = dt['all_goal_locs'][i,:,:]\n        xymin = np.minimum(np.min(goal_loc, axis=0), np.min(locs, axis=0))\n        xymax = np.maximum(np.max(goal_loc, axis=0), np.max(locs, axis=0))\n        xy1 = (xymax+xymin)/2. - 0.7*np.maximum(np.max(xymax-xymin), 24)\n        xy2 = (xymax+xymin)/2. + 0.7*np.maximum(np.max(xymax-xymin), 24)\n\n        ax.set_axis_on()\n        ax.patch.set_facecolor((0.333, 0.333, 0.333))\n        ax.set_xticks([]); ax.set_yticks([]);\n        ax.imshow(orig_maps, origin='lower', vmin=-1.0, vmax=2.0)\n        ax.plot(goal_loc[:,0], goal_loc[:,1], 'g*', markersize=12)\n\n        locs = dt['all_locs'][i,:1,:]\n        ax.plot(locs[:,0], locs[:,1], 'b.', markersize=12)\n\n        ax.set_xlim([xy1[0], xy2[0]])\n        ax.set_ylim([xy1[1], xy2[1]])\n\n      locs = dt['all_locs'][i,step_number,:]\n      locs = np.expand_dims(locs, axis=0)\n      ax.plot(locs[:,0], locs[:,1], 'r.', alpha=1.0, linewidth=0, markersize=4)\n      tt = ax.set_title('Trajectory in topview', fontsize=14)\n      plt.setp(tt, color='white')\n      return fig,\n\n    line_ani = animation.FuncAnimation(fig, worker,\n                                       (num_steps-1)*(wait_at_action+samples_per_action),\n                                       interval=500, blit=True, init_func=init_fn)\n    tmp_file_name = 'tmp.mp4'\n    line_ani.save(tmp_file_name, writer=writer, savefig_kwargs={'facecolor':'black'})\n    out_file_name = os.path.join(out_dir, 'vis_{:04d}.mp4'.format(i))\n    print(out_file_name)\n\n    if fu.exists(out_file_name):\n      gfile.Remove(out_file_name)\n    gfile.Copy(tmp_file_name, out_file_name)\n    gfile.Remove(tmp_file_name)\n    plt.close(fig)\n\ndef plot_trajectory(dt, hardness, orig_maps, out_dir):\n  out_dir = os.path.join(out_dir, FLAGS.config_name+_get_suffix_str(),\n                         FLAGS.imset)\n  fu.makedirs(out_dir)\n  out_file = os.path.join(out_dir, 'all_locs_at_t.pkl')\n  dt['hardness'] = hardness\n  utils.save_variables(out_file, dt.values(), dt.keys(), overwrite=True)\n\n  Plot trajectories onto the maps\n  plt.set_cmap('gray')\n  for i in range(4000):\n    goal_loc = dt['all_goal_locs'][i, :, :]\n    locs = np.concatenate((dt['all_locs'][i,:,:],\n                           dt['all_locs'][i,:,:]), axis=0)\n    xymin = np.minimum(np.min(goal_loc, axis=0), np.min(locs, axis=0))\n    xymax = np.maximum(np.max(goal_loc, axis=0), np.max(locs, axis=0))\n    xy1 = (xymax+xymin)/2. - 1.*np.maximum(np.max(xymax-xymin), 24)\n    xy2 = (xymax+xymin)/2. + 1.*np.maximum(np.max(xymax-xymin), 24)\n\n    fig, ax = utils.tight_imshow_figure(plt, figsize=(6,6))\n    ax.set_axis_on()\n    ax.patch.set_facecolor((0.333, 0.333, 0.333))\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n    all_locs = dt['all_locs'][i,:,:]*1\n    uniq = np.where(np.any(all_locs[1:,:] != all_locs[:-1,:], axis=1))[0]+1\n    uniq = np.sort(uniq).tolist()\n    uniq.insert(0,0)\n    uniq = np.array(uniq)\n    all_locs = all_locs[uniq, :]\n\n    ax.plot(dt['all_locs'][i, 0, 0],\n            dt['all_locs'][i, 0, 1], 'b.', markersize=24)\n    ax.plot(dt['all_goal_locs'][i, 0, 0],\n            dt['all_goal_locs'][i, 0, 1], 'g*', markersize=19)\n    ax.plot(all_locs[:,0], all_locs[:,1], 'r', alpha=0.4, linewidth=2)\n    ax.scatter(all_locs[:,0], all_locs[:,1],\n               c=5+np.arange(all_locs.shape[0])*1./all_locs.shape[0],\n               cmap='Reds', s=30, linewidth=0)\n    ax.imshow(orig_maps, origin='lower', vmin=-1.0, vmax=2.0, aspect='equal')\n    ax.set_xlim([xy1[0], xy2[0]])\n    ax.set_ylim([xy1[1], xy2[1]])\n\n    file_name = os.path.join(out_dir, 'trajectory_{:04d}.png'.format(i))\n    print(file_name)\n    with fu.fopen(file_name, 'w') as f:\n      plt.savefig(f)\n    plt.close(fig)\n\n\ndef main(_):\n  a = _load_trajectory()\n  h_dists, gt_dists, orig_maps = _compute_hardness()\n  hardness = 1.-h_dists*1./ gt_dists\n\n  if FLAGS.top_view:\n    plot_trajectory(a, hardness, orig_maps, out_dir=FLAGS.out_dir)\n\n  if FLAGS.first_person:\n    plot_trajectory_first_person(a, orig_maps, out_dir=FLAGS.out_dir)\n\nif __name__ == '__main__':\n  app.run()\n", "comments": "    code plotting trajectories top view  also plot first person views saved trajectories  does run network loads mesh data plot view points    cuda visible devices 0 ld library path  opt cuda 8 0 lib64  opt cudnnv51 lib64   pythonpath     pyopengl platform egl python scripts script plot trajectory py           first person   num steps 40           config name cmp lmap msc clip5 sbpd r2r           imset test   alsologtostderr   base dir output   dir vis         copyright 2016 the tensorflow authors all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license                                                                                       load distances     load stanford data compute hardness     sample room     initialize agent     load model render     generate things render    1291  1268  1273  1289  1302  1426  1413  1449  1399  1390     ax   fig add subplot(gs     )    axes    ax     prune last node repeated 3 times     get action node     render trajectories     plot image     distance goal     action take     plot map top view     plot map   plot trajectories onto maps ", "content": "# Copyright 2016 The TensorFlow Authors All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nr\"\"\"\nCode for plotting trajectories in the top view, and also plot first person views\nfrom saved trajectories. Does not run the network but only loads the mesh data\nto plot the view points.\n  CUDA_VISIBLE_DEVICES=0 LD_LIBRARY_PATH=/opt/cuda-8.0/lib64:/opt/cudnnv51/lib64\n  PYTHONPATH='.' PYOPENGL_PLATFORM=egl python scripts/script_plot_trajectory.py \\\n      --first_person --num_steps 40 \\\n      --config_name cmp.lmap_Msc.clip5.sbpd_d_r2r \\\n      --imset test --alsologtostderr --base_dir output --out_dir vis\n\n\"\"\"\nimport os, sys, numpy as np, copy\nimport matplotlib\nmatplotlib.use(\"Agg\")\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom matplotlib.gridspec import GridSpec\n\nimport tensorflow as tf\nfrom tensorflow.contrib import slim\nimport cv2\nimport logging\nfrom tensorflow.python.platform import gfile\nfrom tensorflow.python.platform import app\nfrom tensorflow.python.platform import flags\n\nfrom datasets import nav_env\nimport scripts.script_nav_agent_release as sna\nimport src.file_utils as fu\nfrom src import graph_utils\nfrom src import utils\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string('out_dir', 'vis', 'Directory where to store the output')\nflags.DEFINE_string('type', '', 'Optional type.')\nflags.DEFINE_bool('first_person', False, 'Visualize the first person view.')\nflags.DEFINE_bool('top_view', False, 'Visualize the trajectory in the top view.')\nflags.DEFINE_integer('num_steps', 40, 'Number of steps to run the model for.')\nflags.DEFINE_string('imset', 'test', '')\nflags.DEFINE_string('base_dir', 'output', 'Cache directory.')\n\ndef _get_suffix_str():\n  return ''\n\n\ndef _load_trajectory():\n  base_dir = FLAGS.base_dir\n  config_name = FLAGS.config_name+_get_suffix_str()\n\n  dir_name = os.path.join(base_dir, FLAGS.type, config_name)\n  logging.info('Waiting for snapshot in directory %s.', dir_name)\n  last_checkpoint = slim.evaluation.wait_for_new_checkpoint(dir_name, None)\n  checkpoint_iter = int(os.path.basename(last_checkpoint).split('-')[1])\n\n  # Load the distances.\n  a = utils.load_variables(os.path.join(dir_name, 'bench_on_'+FLAGS.imset,\n                                        'all_locs_at_t_{:d}.pkl'.format(checkpoint_iter)))\n  return a\n\ndef _compute_hardness():\n  # Load the stanford data to compute the hardness.\n  if FLAGS.type == '':\n    args = sna.get_args_for_config(FLAGS.config_name+'+bench_'+FLAGS.imset)\n  else:\n    args = sna.get_args_for_config(FLAGS.type+'.'+FLAGS.config_name+'+bench_'+FLAGS.imset)\n\n  args.navtask.logdir = None\n  R = lambda: nav_env.get_multiplexer_class(args.navtask, 0)\n  R = R()\n\n  rng_data = [np.random.RandomState(0), np.random.RandomState(0)]\n\n  # Sample a room.\n  h_dists = []\n  gt_dists = []\n  for i in range(250):\n    e = R.sample_env(rng_data)\n    nodes = e.task.nodes\n\n    # Initialize the agent.\n    init_env_state = e.reset(rng_data)\n\n    gt_dist_to_goal = [e.episode.dist_to_goal[0][j][s]\n                       for j, s in enumerate(e.episode.start_node_ids)]\n\n    for j in range(args.navtask.task_params.batch_size):\n      start_node_id = e.episode.start_node_ids[j]\n      end_node_id =e.episode.goal_node_ids[0][j]\n      h_dist = graph_utils.heuristic_fn_vec(\n          nodes[[start_node_id],:], nodes[[end_node_id], :],\n          n_ori=args.navtask.task_params.n_ori,\n          step_size=args.navtask.task_params.step_size)[0][0]\n      gt_dist = e.episode.dist_to_goal[0][j][start_node_id]\n      h_dists.append(h_dist)\n      gt_dists.append(gt_dist)\n\n  h_dists = np.array(h_dists)\n  gt_dists = np.array(gt_dists)\n  e = R.sample_env([np.random.RandomState(0), np.random.RandomState(0)])\n  input = e.get_common_data()\n  orig_maps = input['orig_maps'][0,0,:,:,0]\n  return h_dists, gt_dists, orig_maps\n\ndef plot_trajectory_first_person(dt, orig_maps, out_dir):\n  out_dir = os.path.join(out_dir, FLAGS.config_name+_get_suffix_str(),\n                         FLAGS.imset)\n  fu.makedirs(out_dir)\n\n  # Load the model so that we can render.\n  plt.set_cmap('gray')\n  samples_per_action = 8; wait_at_action = 0;\n\n  Writer = animation.writers['mencoder']\n  writer = Writer(fps=3*(samples_per_action+wait_at_action),\n                  metadata=dict(artist='anonymous'), bitrate=1800)\n\n  args = sna.get_args_for_config(FLAGS.config_name + '+bench_'+FLAGS.imset)\n  args.navtask.logdir = None\n  navtask_ = copy.deepcopy(args.navtask)\n  navtask_.camera_param.modalities = ['rgb']\n  navtask_.task_params.modalities = ['rgb']\n  sz = 512\n  navtask_.camera_param.height = sz\n  navtask_.camera_param.width = sz\n  navtask_.task_params.img_height = sz\n  navtask_.task_params.img_width = sz\n  R = lambda: nav_env.get_multiplexer_class(navtask_, 0)\n  R = R()\n  b = R.buildings[0]\n\n  f = [0 for _ in range(wait_at_action)] + \\\n      [float(_)/samples_per_action for _ in range(samples_per_action)];\n\n  # Generate things for it to render.\n  inds_to_do = []\n  inds_to_do += [1, 4, 10] #1291, 1268, 1273, 1289, 1302, 1426, 1413, 1449, 1399, 1390]\n\n  for i in inds_to_do:\n    fig = plt.figure(figsize=(10,8))\n    gs = GridSpec(3,4)\n    gs.update(wspace=0.05, hspace=0.05, left=0.0, top=0.97, right=1.0, bottom=0.)\n    ax = fig.add_subplot(gs[:,:-1])\n    ax1 = fig.add_subplot(gs[0,-1])\n    ax2 = fig.add_subplot(gs[1,-1])\n    ax3 = fig.add_subplot(gs[2,-1])\n    axes = [ax, ax1, ax2, ax3]\n    # ax = fig.add_subplot(gs[:,:])\n    # axes = [ax]\n    for ax in axes:\n      ax.set_axis_off()\n\n    node_ids = dt['all_node_ids'][i, :, 0]*1\n    # Prune so that last node is not repeated more than 3 times?\n    if np.all(node_ids[-4:] == node_ids[-1]):\n      while node_ids[-4] == node_ids[-1]:\n        node_ids = node_ids[:-1]\n    num_steps = np.minimum(FLAGS.num_steps, len(node_ids))\n\n    xyt = b.to_actual_xyt_vec(b.task.nodes[node_ids])\n    xyt_diff = xyt[1:,:] - xyt[:-1:,:]\n    xyt_diff[:,2] = np.mod(xyt_diff[:,2], 4)\n    ind = np.where(xyt_diff[:,2] == 3)[0]\n    xyt_diff[ind, 2] = -1\n    xyt_diff = np.expand_dims(xyt_diff, axis=1)\n    to_cat = [xyt_diff*_ for _ in f]\n    perturbs_all = np.concatenate(to_cat, axis=1)\n    perturbs_all = np.concatenate([perturbs_all, np.zeros_like(perturbs_all[:,:,:1])], axis=2)\n    node_ids_all = np.expand_dims(node_ids, axis=1)*1\n    node_ids_all = np.concatenate([node_ids_all for _ in f], axis=1)\n    node_ids_all = np.reshape(node_ids_all[:-1,:], -1)\n    perturbs_all = np.reshape(perturbs_all, [-1, 4])\n    imgs = b.render_nodes(b.task.nodes[node_ids_all,:], perturb=perturbs_all)\n\n    # Get action at each node.\n    actions = []\n    _, action_to_nodes = b.get_feasible_actions(node_ids)\n    for j in range(num_steps-1):\n      action_to_node = action_to_nodes[j]\n      node_to_action = dict(zip(action_to_node.values(), action_to_node.keys()))\n      actions.append(node_to_action[node_ids[j+1]])\n\n    def init_fn():\n      return fig,\n    gt_dist_to_goal = []\n\n    # Render trajectories.\n    def worker(j):\n      # Plot the image.\n      step_number = j/(samples_per_action + wait_at_action)\n      img = imgs[j]; ax = axes[0]; ax.clear(); ax.set_axis_off();\n      img = img.astype(np.uint8); ax.imshow(img);\n      tt = ax.set_title(\n          \"First Person View\\n\" +\n          \"Top corners show diagnostics (distance, agents' action) not input to agent.\",\n          fontsize=12)\n      plt.setp(tt, color='white')\n\n      # Distance to goal.\n      t = 'Dist to Goal:\\n{:2d} steps'.format(int(dt['all_d_at_t'][i, step_number]))\n      t = ax.text(0.01, 0.99, t,\n          horizontalalignment='left',\n          verticalalignment='top',\n          fontsize=20, color='red',\n          transform=ax.transAxes, alpha=1.0)\n      t.set_bbox(dict(color='white', alpha=0.85, pad=-0.1))\n\n      # Action to take.\n      action_latex = ['$\\odot$ ', '$\\curvearrowright$ ', '$\\curvearrowleft$ ', r'$\\Uparrow$ ']\n      t = ax.text(0.99, 0.99, action_latex[actions[step_number]],\n          horizontalalignment='right',\n          verticalalignment='top',\n          fontsize=40, color='green',\n          transform=ax.transAxes, alpha=1.0)\n      t.set_bbox(dict(color='white', alpha=0.85, pad=-0.1))\n\n\n      # Plot the map top view.\n      ax = axes[-1]\n      if j == 0:\n        # Plot the map\n        locs = dt['all_locs'][i,:num_steps,:]\n        goal_loc = dt['all_goal_locs'][i,:,:]\n        xymin = np.minimum(np.min(goal_loc, axis=0), np.min(locs, axis=0))\n        xymax = np.maximum(np.max(goal_loc, axis=0), np.max(locs, axis=0))\n        xy1 = (xymax+xymin)/2. - 0.7*np.maximum(np.max(xymax-xymin), 24)\n        xy2 = (xymax+xymin)/2. + 0.7*np.maximum(np.max(xymax-xymin), 24)\n\n        ax.set_axis_on()\n        ax.patch.set_facecolor((0.333, 0.333, 0.333))\n        ax.set_xticks([]); ax.set_yticks([]);\n        ax.imshow(orig_maps, origin='lower', vmin=-1.0, vmax=2.0)\n        ax.plot(goal_loc[:,0], goal_loc[:,1], 'g*', markersize=12)\n\n        locs = dt['all_locs'][i,:1,:]\n        ax.plot(locs[:,0], locs[:,1], 'b.', markersize=12)\n\n        ax.set_xlim([xy1[0], xy2[0]])\n        ax.set_ylim([xy1[1], xy2[1]])\n\n      locs = dt['all_locs'][i,step_number,:]\n      locs = np.expand_dims(locs, axis=0)\n      ax.plot(locs[:,0], locs[:,1], 'r.', alpha=1.0, linewidth=0, markersize=4)\n      tt = ax.set_title('Trajectory in topview', fontsize=14)\n      plt.setp(tt, color='white')\n      return fig,\n\n    line_ani = animation.FuncAnimation(fig, worker,\n                                       (num_steps-1)*(wait_at_action+samples_per_action),\n                                       interval=500, blit=True, init_func=init_fn)\n    tmp_file_name = 'tmp.mp4'\n    line_ani.save(tmp_file_name, writer=writer, savefig_kwargs={'facecolor':'black'})\n    out_file_name = os.path.join(out_dir, 'vis_{:04d}.mp4'.format(i))\n    print(out_file_name)\n\n    if fu.exists(out_file_name):\n      gfile.Remove(out_file_name)\n    gfile.Copy(tmp_file_name, out_file_name)\n    gfile.Remove(tmp_file_name)\n    plt.close(fig)\n\ndef plot_trajectory(dt, hardness, orig_maps, out_dir):\n  out_dir = os.path.join(out_dir, FLAGS.config_name+_get_suffix_str(),\n                         FLAGS.imset)\n  fu.makedirs(out_dir)\n  out_file = os.path.join(out_dir, 'all_locs_at_t.pkl')\n  dt['hardness'] = hardness\n  utils.save_variables(out_file, dt.values(), dt.keys(), overwrite=True)\n\n  #Plot trajectories onto the maps\n  plt.set_cmap('gray')\n  for i in range(4000):\n    goal_loc = dt['all_goal_locs'][i, :, :]\n    locs = np.concatenate((dt['all_locs'][i,:,:],\n                           dt['all_locs'][i,:,:]), axis=0)\n    xymin = np.minimum(np.min(goal_loc, axis=0), np.min(locs, axis=0))\n    xymax = np.maximum(np.max(goal_loc, axis=0), np.max(locs, axis=0))\n    xy1 = (xymax+xymin)/2. - 1.*np.maximum(np.max(xymax-xymin), 24)\n    xy2 = (xymax+xymin)/2. + 1.*np.maximum(np.max(xymax-xymin), 24)\n\n    fig, ax = utils.tight_imshow_figure(plt, figsize=(6,6))\n    ax.set_axis_on()\n    ax.patch.set_facecolor((0.333, 0.333, 0.333))\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n    all_locs = dt['all_locs'][i,:,:]*1\n    uniq = np.where(np.any(all_locs[1:,:] != all_locs[:-1,:], axis=1))[0]+1\n    uniq = np.sort(uniq).tolist()\n    uniq.insert(0,0)\n    uniq = np.array(uniq)\n    all_locs = all_locs[uniq, :]\n\n    ax.plot(dt['all_locs'][i, 0, 0],\n            dt['all_locs'][i, 0, 1], 'b.', markersize=24)\n    ax.plot(dt['all_goal_locs'][i, 0, 0],\n            dt['all_goal_locs'][i, 0, 1], 'g*', markersize=19)\n    ax.plot(all_locs[:,0], all_locs[:,1], 'r', alpha=0.4, linewidth=2)\n    ax.scatter(all_locs[:,0], all_locs[:,1],\n               c=5+np.arange(all_locs.shape[0])*1./all_locs.shape[0],\n               cmap='Reds', s=30, linewidth=0)\n    ax.imshow(orig_maps, origin='lower', vmin=-1.0, vmax=2.0, aspect='equal')\n    ax.set_xlim([xy1[0], xy2[0]])\n    ax.set_ylim([xy1[1], xy2[1]])\n\n    file_name = os.path.join(out_dir, 'trajectory_{:04d}.png'.format(i))\n    print(file_name)\n    with fu.fopen(file_name, 'w') as f:\n      plt.savefig(f)\n    plt.close(fig)\n\n\ndef main(_):\n  a = _load_trajectory()\n  h_dists, gt_dists, orig_maps = _compute_hardness()\n  hardness = 1.-h_dists*1./ gt_dists\n\n  if FLAGS.top_view:\n    plot_trajectory(a, hardness, orig_maps, out_dir=FLAGS.out_dir)\n\n  if FLAGS.first_person:\n    plot_trajectory_first_person(a, orig_maps, out_dir=FLAGS.out_dir)\n\nif __name__ == '__main__':\n  app.run()\n", "description": "Models and examples built with TensorFlow", "file_name": "script_plot_trajectory.py", "id": "3f0c98a747902f0ea34cc7af1dab5dc6", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tensorflow-models/tensorflow-models-7e4c66b/research/cognitive_mapping_and_planning/scripts/script_plot_trajectory.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:59:36Z", "url": "https://github.com/tensorflow/models", "wiki": true}