{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\n\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys\n\nimport tensorflow as tf\n\nfrom astronet import models\nfrom astronet.util import config_util\nfrom astronet.util import configdict\nfrom astronet.util import estimator_util\n\nparser = argparse.ArgumentParser()\n\nparser.add_argument(\n    \"--model\", type=str, required=True, help=\"Name of the model class.\")\n\nparser.add_argument(\n    \"--config_name\",\n    type=str,\n    help=\"Name of the model and training configuration. Exactly one of \"\n    \"--config_name or --config_json is required.\")\n\nparser.add_argument(\n    \"--config_json\",\n    type=str,\n    help=\"JSON string or JSON file containing the model and training \"\n    \"configuration. Exactly one of --config_name or --config_json is required.\")\n\nparser.add_argument(\n    \"--train_files\",\n    type=str,\n    required=True,\n    help=\"Comma-separated list of file patterns matching the TFRecord files in \"\n    \"the training dataset.\")\n\nparser.add_argument(\n    \"--eval_files\",\n    type=str,\n    help=\"Comma-separated list of file patterns matching the TFRecord files in \"\n    \"the validation dataset.\")\n\nparser.add_argument(\n    \"--model_dir\",\n    type=str,\n    required=True,\n    help=\"Directory for model checkpoints and summaries.\")\n\nparser.add_argument(\n    \"--train_steps\",\n    type=int,\n    default=10000,\n    help=\"Total number of steps to train the model for.\")\n\nparser.add_argument(\n    \"--shuffle_buffer_size\",\n    type=int,\n    default=15000,\n    help=\"Size of the shuffle buffer for the training dataset.\")\n\n\ndef main(_):\n  model_class = models.get_model_class(FLAGS.model)\n\n   Look up the model configuration.\n  assert (FLAGS.config_name is None) != (FLAGS.config_json is None), (\n      \"Exactly one of --config_name or --config_json is required.\")\n  config = (\n      models.get_model_config(FLAGS.model, FLAGS.config_name)\n      if FLAGS.config_name else config_util.parse_json(FLAGS.config_json))\n\n  config = configdict.ConfigDict(config)\n  config_util.log_and_save_config(config, FLAGS.model_dir)\n\n   Create the estimator.\n  run_config = tf.estimator.RunConfig(keep_checkpoint_max=1)\n  estimator = estimator_util.create_estimator(model_class, config.hparams,\n                                              run_config, FLAGS.model_dir)\n\n   Create an input function that reads the training dataset. We iterate through\n   the dataset once at a time if we are alternating with evaluation, otherwise\n   we iterate infinitely.\n  train_input_fn = estimator_util.create_input_fn(\n      file_pattern=FLAGS.train_files,\n      input_config=config.inputs,\n      mode=tf.estimator.ModeKeys.TRAIN,\n      shuffle_values_buffer=FLAGS.shuffle_buffer_size,\n      repeat=1 if FLAGS.eval_files else None)\n\n  if not FLAGS.eval_files:\n    estimator.train(train_input_fn, max_steps=FLAGS.train_steps)\n  else:\n    eval_input_fn = estimator_util.create_input_fn(\n        file_pattern=FLAGS.eval_files,\n        input_config=config.inputs,\n        mode=tf.estimator.ModeKeys.EVAL)\n\n    for _ in estimator_util.continuous_train_and_eval(\n        estimator=estimator,\n        train_input_fn=train_input_fn,\n        eval_input_fn=eval_input_fn,\n        train_steps=FLAGS.train_steps):\n       continuous_train_and_eval() yields evaluation metrics after each\n       training epoch. We don't do anything here.\n      pass\n\n\nif __name__ == \"__main__\":\n  tf.logging.set_verbosity(tf.logging.INFO)\n  FLAGS, unparsed = parser.parse_known_args()\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n", "comments": "   script training astronet model        copyright 2018 the tensorflow authors        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license     look model configuration     create estimator     create input function reads training dataset  we iterate    dataset time alternating evaluation  otherwise    iterate infinitely     continuous train eval() yields evaluation metrics    training epoch  we anything  ", "content": "# Copyright 2018 The TensorFlow Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Script for training an AstroNet model.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys\n\nimport tensorflow as tf\n\nfrom astronet import models\nfrom astronet.util import config_util\nfrom astronet.util import configdict\nfrom astronet.util import estimator_util\n\nparser = argparse.ArgumentParser()\n\nparser.add_argument(\n    \"--model\", type=str, required=True, help=\"Name of the model class.\")\n\nparser.add_argument(\n    \"--config_name\",\n    type=str,\n    help=\"Name of the model and training configuration. Exactly one of \"\n    \"--config_name or --config_json is required.\")\n\nparser.add_argument(\n    \"--config_json\",\n    type=str,\n    help=\"JSON string or JSON file containing the model and training \"\n    \"configuration. Exactly one of --config_name or --config_json is required.\")\n\nparser.add_argument(\n    \"--train_files\",\n    type=str,\n    required=True,\n    help=\"Comma-separated list of file patterns matching the TFRecord files in \"\n    \"the training dataset.\")\n\nparser.add_argument(\n    \"--eval_files\",\n    type=str,\n    help=\"Comma-separated list of file patterns matching the TFRecord files in \"\n    \"the validation dataset.\")\n\nparser.add_argument(\n    \"--model_dir\",\n    type=str,\n    required=True,\n    help=\"Directory for model checkpoints and summaries.\")\n\nparser.add_argument(\n    \"--train_steps\",\n    type=int,\n    default=10000,\n    help=\"Total number of steps to train the model for.\")\n\nparser.add_argument(\n    \"--shuffle_buffer_size\",\n    type=int,\n    default=15000,\n    help=\"Size of the shuffle buffer for the training dataset.\")\n\n\ndef main(_):\n  model_class = models.get_model_class(FLAGS.model)\n\n  # Look up the model configuration.\n  assert (FLAGS.config_name is None) != (FLAGS.config_json is None), (\n      \"Exactly one of --config_name or --config_json is required.\")\n  config = (\n      models.get_model_config(FLAGS.model, FLAGS.config_name)\n      if FLAGS.config_name else config_util.parse_json(FLAGS.config_json))\n\n  config = configdict.ConfigDict(config)\n  config_util.log_and_save_config(config, FLAGS.model_dir)\n\n  # Create the estimator.\n  run_config = tf.estimator.RunConfig(keep_checkpoint_max=1)\n  estimator = estimator_util.create_estimator(model_class, config.hparams,\n                                              run_config, FLAGS.model_dir)\n\n  # Create an input function that reads the training dataset. We iterate through\n  # the dataset once at a time if we are alternating with evaluation, otherwise\n  # we iterate infinitely.\n  train_input_fn = estimator_util.create_input_fn(\n      file_pattern=FLAGS.train_files,\n      input_config=config.inputs,\n      mode=tf.estimator.ModeKeys.TRAIN,\n      shuffle_values_buffer=FLAGS.shuffle_buffer_size,\n      repeat=1 if FLAGS.eval_files else None)\n\n  if not FLAGS.eval_files:\n    estimator.train(train_input_fn, max_steps=FLAGS.train_steps)\n  else:\n    eval_input_fn = estimator_util.create_input_fn(\n        file_pattern=FLAGS.eval_files,\n        input_config=config.inputs,\n        mode=tf.estimator.ModeKeys.EVAL)\n\n    for _ in estimator_util.continuous_train_and_eval(\n        estimator=estimator,\n        train_input_fn=train_input_fn,\n        eval_input_fn=eval_input_fn,\n        train_steps=FLAGS.train_steps):\n      # continuous_train_and_eval() yields evaluation metrics after each\n      # training epoch. We don't do anything here.\n      pass\n\n\nif __name__ == \"__main__\":\n  tf.logging.set_verbosity(tf.logging.INFO)\n  FLAGS, unparsed = parser.parse_known_args()\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n", "description": "Models and examples built with TensorFlow", "file_name": "train.py", "id": "5e8043a8653db18b981c158805dcd614", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tensorflow-models/tensorflow-models-7e4c66b/research/astronet/astronet/train.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:59:36Z", "url": "https://github.com/tensorflow/models", "wiki": true}