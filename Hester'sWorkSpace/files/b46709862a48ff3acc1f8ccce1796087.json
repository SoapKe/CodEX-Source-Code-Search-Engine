{"author": "tensorflow", "code": "\"\"\"A script to run inference on a set of image files.\n\nNOTE \nit will work only for images which look more or less similar to french street\nnames. In order to apply it to images from a different distribution you need\nto retrain (or at least fine-tune) it using images from that distribution.\n\nNOTE \nto use tools and mechanisms provided by the TensorFlow Serving system to run\ninference on TensorFlow models in production:\nhttps://www.tensorflow.org/serving/serving_basic\n\nUsage:\npython demo_inference.py --batch_size=32 \\\n  --checkpoint=model.ckpt-399731\\\n  --image_path_pattern=./datasets/data/fsns/temp/fsns_train_%02d.png\n\"\"\"\nimport numpy as np\nimport PIL.Image\n\nimport tensorflow as tf\nfrom tensorflow.python.platform import flags\nfrom tensorflow.python.training import monitored_session\n\nimport common_flags\nimport datasets\nimport data_provider\n\nFLAGS = flags.FLAGS\ncommon_flags.define()\n\n\nflags.DEFINE_string('image_path_pattern', '',\n                    'A file pattern with a placeholder for the image index.')\n\n\ndef get_dataset_image_size(dataset_name):\n  \n  \n  ds_module = getattr(datasets, dataset_name)\n  height, width, _ = ds_module.DEFAULT_CONFIG['image_shape']\n  return width, height\n\n\ndef load_images(file_pattern, batch_size, dataset_name):\n  width, height = get_dataset_image_size(dataset_name)\n  images_actual_data = np.ndarray(shape=(batch_size, height, width, 3),\n                                  dtype='uint8')\n  for i in range(batch_size):\n    path = file_pattern % i\n    print(\"Reading %s\" % path)\n    pil_image = PIL.Image.open(tf.gfile.GFile(path))\n    images_actual_data[i, ...] = np.asarray(pil_image)\n  return images_actual_data\n\n\ndef create_model(batch_size, dataset_name):\n  width, height = get_dataset_image_size(dataset_name)\n  dataset = common_flags.create_dataset(split_name=FLAGS.split_name)\n  model = common_flags.create_model(\n    num_char_classes=dataset.num_char_classes,\n    seq_length=dataset.max_sequence_length,\n    num_views=dataset.num_of_views,\n    null_code=dataset.null_code,\n    charset=dataset.charset)\n  raw_images = tf.placeholder(tf.uint8, shape=[batch_size, height, width, 3])\n  images = tf.map_fn(data_provider.preprocess_image, raw_images,\n                     dtype=tf.float32)\n  endpoints = model.create_base(images, labels_one_hot=None)\n  return raw_images, endpoints\n\n\ndef run(checkpoint, batch_size, dataset_name, image_path_pattern):\n  images_placeholder, endpoints = create_model(batch_size,\n                                               dataset_name)\n  images_data = load_images(image_path_pattern, batch_size,\n                            dataset_name)\n  session_creator = monitored_session.ChiefSessionCreator(\n    checkpoint_filename_with_path=checkpoint)\n  with monitored_session.MonitoredSession(\n      session_creator=session_creator) as sess:\n    predictions = sess.run(endpoints.predicted_text,\n                           feed_dict={images_placeholder: images_data})\n  return predictions.tolist()\n\n\ndef main(_):\n  print(\"Predicted strings:\")\n  predictions = run(FLAGS.checkpoint, FLAGS.batch_size, FLAGS.dataset_name,\n                  FLAGS.image_path_pattern)\n  for line in predictions:\n    print(line)\n\n\nif __name__ == '__main__':\n  tf.app.run()\n", "comments": "   a script run inference set image files   note  1  the attention ocr model trained using fsns train dataset work images look less similar french street names  in order apply images different distribution need retrain (or least fine tune) using images distribution   note  2  this script exists demo purposes  it highly recommended use tools mechanisms provided tensorflow serving system run inference tensorflow models production  https   www tensorflow org serving serving basic  usage  python demo inference py   batch size 32       checkpoint model ckpt 399731      image path pattern   datasets data fsns temp fsns train  02d png       1  the attention ocr model trained using fsns train dataset   2  this script exists demo purposes  it highly recommended    e g    datasets data fsns temp fsns train  02d png    ideally info exposed dataset interface     but currently available means  ", "content": "\"\"\"A script to run inference on a set of image files.\n\nNOTE #1: The Attention OCR model was trained only using FSNS train dataset and\nit will work only for images which look more or less similar to french street\nnames. In order to apply it to images from a different distribution you need\nto retrain (or at least fine-tune) it using images from that distribution.\n\nNOTE #2: This script exists for demo purposes only. It is highly recommended\nto use tools and mechanisms provided by the TensorFlow Serving system to run\ninference on TensorFlow models in production:\nhttps://www.tensorflow.org/serving/serving_basic\n\nUsage:\npython demo_inference.py --batch_size=32 \\\n  --checkpoint=model.ckpt-399731\\\n  --image_path_pattern=./datasets/data/fsns/temp/fsns_train_%02d.png\n\"\"\"\nimport numpy as np\nimport PIL.Image\n\nimport tensorflow as tf\nfrom tensorflow.python.platform import flags\nfrom tensorflow.python.training import monitored_session\n\nimport common_flags\nimport datasets\nimport data_provider\n\nFLAGS = flags.FLAGS\ncommon_flags.define()\n\n# e.g. ./datasets/data/fsns/temp/fsns_train_%02d.png\nflags.DEFINE_string('image_path_pattern', '',\n                    'A file pattern with a placeholder for the image index.')\n\n\ndef get_dataset_image_size(dataset_name):\n  # Ideally this info should be exposed through the dataset interface itself.\n  # But currently it is not available by other means.\n  ds_module = getattr(datasets, dataset_name)\n  height, width, _ = ds_module.DEFAULT_CONFIG['image_shape']\n  return width, height\n\n\ndef load_images(file_pattern, batch_size, dataset_name):\n  width, height = get_dataset_image_size(dataset_name)\n  images_actual_data = np.ndarray(shape=(batch_size, height, width, 3),\n                                  dtype='uint8')\n  for i in range(batch_size):\n    path = file_pattern % i\n    print(\"Reading %s\" % path)\n    pil_image = PIL.Image.open(tf.gfile.GFile(path))\n    images_actual_data[i, ...] = np.asarray(pil_image)\n  return images_actual_data\n\n\ndef create_model(batch_size, dataset_name):\n  width, height = get_dataset_image_size(dataset_name)\n  dataset = common_flags.create_dataset(split_name=FLAGS.split_name)\n  model = common_flags.create_model(\n    num_char_classes=dataset.num_char_classes,\n    seq_length=dataset.max_sequence_length,\n    num_views=dataset.num_of_views,\n    null_code=dataset.null_code,\n    charset=dataset.charset)\n  raw_images = tf.placeholder(tf.uint8, shape=[batch_size, height, width, 3])\n  images = tf.map_fn(data_provider.preprocess_image, raw_images,\n                     dtype=tf.float32)\n  endpoints = model.create_base(images, labels_one_hot=None)\n  return raw_images, endpoints\n\n\ndef run(checkpoint, batch_size, dataset_name, image_path_pattern):\n  images_placeholder, endpoints = create_model(batch_size,\n                                               dataset_name)\n  images_data = load_images(image_path_pattern, batch_size,\n                            dataset_name)\n  session_creator = monitored_session.ChiefSessionCreator(\n    checkpoint_filename_with_path=checkpoint)\n  with monitored_session.MonitoredSession(\n      session_creator=session_creator) as sess:\n    predictions = sess.run(endpoints.predicted_text,\n                           feed_dict={images_placeholder: images_data})\n  return predictions.tolist()\n\n\ndef main(_):\n  print(\"Predicted strings:\")\n  predictions = run(FLAGS.checkpoint, FLAGS.batch_size, FLAGS.dataset_name,\n                  FLAGS.image_path_pattern)\n  for line in predictions:\n    print(line)\n\n\nif __name__ == '__main__':\n  tf.app.run()\n", "description": "Models and examples built with TensorFlow", "file_name": "demo_inference.py", "id": "b46709862a48ff3acc1f8ccce1796087", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tensorflow-models/tensorflow-models-7e4c66b/research/attention_ocr/python/demo_inference.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:59:36Z", "url": "https://github.com/tensorflow/models", "wiki": true}