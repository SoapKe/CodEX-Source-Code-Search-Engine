{"author": "deepfakes", "code": "\nimport time\nimport numpy\nfrom lib.training_data import TrainingDataGenerator, stack_images\n\nclass Trainer():\n    random_transform_args = {\n        'rotation_range': 10,\n        'zoom_range': 0.05,\n        'shift_range': 0.05,\n        'random_flip': 0.4,\n    }\n\n    def __init__(self, model, fn_A, fn_B, batch_size, *args):\n        self.batch_size = batch_size\n        self.model = model\n\n        generator = TrainingDataGenerator(self.random_transform_args, 160)\n        self.images_A = generator.minibatchAB(fn_A, self.batch_size)\n        self.images_B = generator.minibatchAB(fn_B, self.batch_size)\n\n    def train_one_step(self, iter, viewer):\n        epoch, warped_A, target_A = next(self.images_A)\n        epoch, warped_B, target_B = next(self.images_B)\n\n        loss_A = self.model.autoencoder_A.train_on_batch(warped_A, target_A)\n        loss_B = self.model.autoencoder_B.train_on_batch(warped_B, target_B)\n        print(\"[{0}] [#{1:05d}] loss_A: {2:.5f}, loss_B: {3:.5f}\".format(time.strftime(\"%H:%M:%S\"), iter, loss_A, loss_B),\n            end='\\r')\n\n        if viewer is not None:\n            viewer(self.show_sample(target_A[0:14], target_B[0:14]), \"training\")\n\n    def show_sample(self, test_A, test_B):\n        figure_A = numpy.stack([\n            test_A,\n            self.model.autoencoder_A.predict(test_A),\n            self.model.autoencoder_B.predict(test_A),\n        ], axis=1)\n        figure_B = numpy.stack([\n            test_B,\n            self.model.autoencoder_B.predict(test_B),\n            self.model.autoencoder_A.predict(test_B),\n        ], axis=1)\n\n        if test_A.shape[0] % 2 == 1:\n            figure_A = numpy.concatenate ([figure_A, numpy.expand_dims(figure_A[0],0) ])\n            figure_B = numpy.concatenate ([figure_B, numpy.expand_dims(figure_B[0],0) ])\n\n        figure = numpy.concatenate([figure_A, figure_B], axis=0)\n        w = 4\n        h = int( figure.shape[0] / w)\n        figure = figure.reshape((w, h) + figure.shape[1:])\n        figure = stack_images(figure)\n\n        return numpy.clip(figure * 255, 0, 255).astype('uint8')\n", "comments": "  1 05d   loss a   2  5f   loss b   3  5f   format(time strftime(  h  m  s )  iter  loss a  loss b)  ", "content": "\nimport time\nimport numpy\nfrom lib.training_data import TrainingDataGenerator, stack_images\n\nclass Trainer():\n    random_transform_args = {\n        'rotation_range': 10,\n        'zoom_range': 0.05,\n        'shift_range': 0.05,\n        'random_flip': 0.4,\n    }\n\n    def __init__(self, model, fn_A, fn_B, batch_size, *args):\n        self.batch_size = batch_size\n        self.model = model\n\n        generator = TrainingDataGenerator(self.random_transform_args, 160)\n        self.images_A = generator.minibatchAB(fn_A, self.batch_size)\n        self.images_B = generator.minibatchAB(fn_B, self.batch_size)\n\n    def train_one_step(self, iter, viewer):\n        epoch, warped_A, target_A = next(self.images_A)\n        epoch, warped_B, target_B = next(self.images_B)\n\n        loss_A = self.model.autoencoder_A.train_on_batch(warped_A, target_A)\n        loss_B = self.model.autoencoder_B.train_on_batch(warped_B, target_B)\n        print(\"[{0}] [#{1:05d}] loss_A: {2:.5f}, loss_B: {3:.5f}\".format(time.strftime(\"%H:%M:%S\"), iter, loss_A, loss_B),\n            end='\\r')\n\n        if viewer is not None:\n            viewer(self.show_sample(target_A[0:14], target_B[0:14]), \"training\")\n\n    def show_sample(self, test_A, test_B):\n        figure_A = numpy.stack([\n            test_A,\n            self.model.autoencoder_A.predict(test_A),\n            self.model.autoencoder_B.predict(test_A),\n        ], axis=1)\n        figure_B = numpy.stack([\n            test_B,\n            self.model.autoencoder_B.predict(test_B),\n            self.model.autoencoder_A.predict(test_B),\n        ], axis=1)\n\n        if test_A.shape[0] % 2 == 1:\n            figure_A = numpy.concatenate ([figure_A, numpy.expand_dims(figure_A[0],0) ])\n            figure_B = numpy.concatenate ([figure_B, numpy.expand_dims(figure_B[0],0) ])\n\n        figure = numpy.concatenate([figure_A, figure_B], axis=0)\n        w = 4\n        h = int( figure.shape[0] / w)\n        figure = figure.reshape((w, h) + figure.shape[1:])\n        figure = stack_images(figure)\n\n        return numpy.clip(figure * 255, 0, 255).astype('uint8')\n", "description": "Non official project based on original /r/Deepfakes thread. Many thanks to him!", "file_name": "Trainer.py", "id": "7c788b62f16277acee07c7cd2917f4f4", "language": "Python", "project_name": "faceswap", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/deepfakes-faceswap/deepfakes-faceswap-6ff64ef/plugins/Model_LowMem/Trainer.py", "save_time": "", "source": "", "update_at": "2018-03-18T16:27:43Z", "url": "https://github.com/deepfakes/faceswap", "wiki": true}