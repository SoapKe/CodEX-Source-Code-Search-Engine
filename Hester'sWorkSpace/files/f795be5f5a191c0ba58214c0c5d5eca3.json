{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\"\"\"Evaluates the N-styles style transfer model.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport ast\nimport os\n\n internal imports\nimport tensorflow as tf\n\nfrom magenta.models.image_stylization import image_utils\nfrom magenta.models.image_stylization import learning\nfrom magenta.models.image_stylization import model\n\nslim = tf.contrib.slim\n\n\nDEFAULT_CONTENT_WEIGHTS = '{\"vgg_16/conv3\": 1.0}'\nDEFAULT_STYLE_WEIGHTS = ('{\"vgg_16/conv1\": 1e-4, \"vgg_16/conv2\": 1e-4,'\n                         ' \"vgg_16/conv3\": 1e-4, \"vgg_16/conv4\": 1e-4}')\n\n\nflags = tf.app.flags\nflags.DEFINE_boolean('style_grid', False,\n                     'Whether to generate the style grid.')\nflags.DEFINE_boolean('style_crossover', False,\n                     'Whether to do a style crossover in the style grid.')\nflags.DEFINE_boolean('learning_curves', True,\n                     'Whether to evaluate learning curves for all styles.')\nflags.DEFINE_integer('batch_size', 16, 'Batch size')\nflags.DEFINE_integer('image_size', 256, 'Image size.')\nflags.DEFINE_integer('eval_interval_secs', 60,\n                     'Frequency, in seconds, at which evaluation is run.')\nflags.DEFINE_integer('num_evals', 32, 'Number of evaluations of the losses.')\nflags.DEFINE_integer('num_styles', None, 'Number of styles.')\nflags.DEFINE_string('content_weights', DEFAULT_CONTENT_WEIGHTS,\n                    'Content weights')\nflags.DEFINE_string('eval_dir', None,\n                    'Directory where the results are saved to.')\nflags.DEFINE_string('train_dir', None,\n                    'Directory for checkpoints and summaries')\nflags.DEFINE_string('master', '',\n                    'Name of the TensorFlow master to use.')\nflags.DEFINE_string('style_coefficients', None,\n                    'Scales the style weights conditioned on the style image.')\nflags.DEFINE_string('style_dataset_file', None, 'Style dataset file.')\nflags.DEFINE_string('style_weights', DEFAULT_STYLE_WEIGHTS,\n                    'Style weights')\nFLAGS = flags.FLAGS\n\n\ndef main(_):\n  with tf.Graph().as_default():\n     Create inputs in [0, 1], as expected by vgg_16.\n    inputs, _ = image_utils.imagenet_inputs(\n        FLAGS.batch_size, FLAGS.image_size)\n    evaluation_images = image_utils.load_evaluation_images(FLAGS.image_size)\n\n     Process style and weight flags\n    if FLAGS.style_coefficients is None:\n      style_coefficients = [1.0 for _ in range(FLAGS.num_styles)]\n    else:\n      style_coefficients = ast.literal_eval(FLAGS.style_coefficients)\n    if len(style_coefficients) != FLAGS.num_styles:\n      raise ValueError(\n          'number of style coefficients differs from number of styles')\n    content_weights = ast.literal_eval(FLAGS.content_weights)\n    style_weights = ast.literal_eval(FLAGS.style_weights)\n\n     Load style images.\n    style_images, labels, style_gram_matrices = image_utils.style_image_inputs(\n        os.path.expanduser(FLAGS.style_dataset_file),\n        batch_size=FLAGS.num_styles, image_size=FLAGS.image_size,\n        square_crop=True, shuffle=False)\n    labels = tf.unstack(labels)\n\n    def _create_normalizer_params(style_label):\n      \"\"\"Creates normalizer parameters from a style label.\"\"\"\n      return {'labels': tf.expand_dims(style_label, 0),\n              'num_categories': FLAGS.num_styles,\n              'center': True,\n              'scale': True}\n\n     Dummy call to simplify the reuse logic\n    model.transform(inputs, reuse=False,\n                    normalizer_params=_create_normalizer_params(labels[0]))\n\n    def _style_sweep(inputs):\n      \"\"\"Transfers all styles onto the input one at a time.\"\"\"\n      inputs = tf.expand_dims(inputs, 0)\n      stylized_inputs = [\n          model.transform(\n              inputs,\n              reuse=True,\n              normalizer_params=_create_normalizer_params(style_label))\n          for _, style_label in enumerate(labels)]\n      return tf.concat([inputs] + stylized_inputs, 0)\n\n    if FLAGS.style_grid:\n      style_row = tf.concat(\n          [tf.ones([1, FLAGS.image_size, FLAGS.image_size, 3]), style_images],\n          0)\n      stylized_training_example = _style_sweep(inputs[0])\n      stylized_evaluation_images = [\n          _style_sweep(image) for image in tf.unstack(evaluation_images)]\n      stylized_noise = _style_sweep(\n          tf.random_uniform([FLAGS.image_size, FLAGS.image_size, 3]))\n      stylized_style_images = [\n          _style_sweep(image) for image in tf.unstack(style_images)]\n      if FLAGS.style_crossover:\n        grid = tf.concat(\n            [style_row, stylized_training_example, stylized_noise] +\n            stylized_evaluation_images + stylized_style_images,\n            0)\n      else:\n        grid = tf.concat(\n            [style_row, stylized_training_example, stylized_noise] +\n            stylized_evaluation_images,\n            0)\n      tf.summary.image(\n          'Style Grid',\n          tf.cast(\n              image_utils.form_image_grid(\n                  grid,\n                  ([3 + evaluation_images.get_shape().as_list()[0] +\n                    FLAGS.num_styles, 1 + FLAGS.num_styles]\n                   if FLAGS.style_crossover\n                   else [3 + evaluation_images.get_shape().as_list()[0],\n                         1 + FLAGS.num_styles]),\n                  [FLAGS.image_size, FLAGS.image_size],\n                  3) * 255.0,\n              tf.uint8))\n\n    if FLAGS.learning_curves:\n      metrics = {}\n      for i, label in enumerate(labels):\n        gram_matrices = dict(\n            [(key, value[i: i + 1])\n             for key, value in style_gram_matrices.iteritems()])\n        stylized_inputs = model.transform(\n            inputs,\n            reuse=True,\n            normalizer_params=_create_normalizer_params(label))\n        _, loss_dict = learning.total_loss(\n            inputs, stylized_inputs, gram_matrices, content_weights,\n            style_weights, reuse=i > 0)\n        for key, value in loss_dict.iteritems():\n          metrics['{}_style_{}'.format(key, i)] = slim.metrics.streaming_mean(\n              value)\n\n      names_values, names_updates = slim.metrics.aggregate_metric_map(metrics)\n      for name, value in names_values.iteritems():\n        summary_op = tf.summary.scalar(name, value, [])\n        print_op = tf.Print(summary_op, [value], name)\n        tf.add_to_collection(tf.GraphKeys.SUMMARIES, print_op)\n      eval_op = names_updates.values()\n      num_evals = FLAGS.num_evals\n    else:\n      eval_op = None\n      num_evals = 1\n\n    slim.evaluation.evaluation_loop(\n        master=FLAGS.master,\n        checkpoint_dir=os.path.expanduser(FLAGS.train_dir),\n        logdir=os.path.expanduser(FLAGS.eval_dir),\n        eval_op=eval_op,\n        num_evals=num_evals,\n        eval_interval_secs=FLAGS.eval_interval_secs)\n\n\ndef console_entry_point():\n  tf.app.run(main)\n\n\nif __name__ == '__main__':\n  console_entry_point()\n", "comments": "   evaluates n styles style transfer model        future   import absolute import   future   import division   future   import print function  import ast import os    internal imports import tensorflow tf  magenta models image stylization import image utils magenta models image stylization import learning magenta models image stylization import model  slim   tf contrib slim   default content weights      vgg 16 conv3   1 0   default style weights   (   vgg 16 conv1   1e 4   vgg 16 conv2   1e 4                               vgg 16 conv3   1e 4   vgg 16 conv4   1e 4  )   flags   tf app flags flags define boolean( style grid   false                        whether generate style grid  ) flags define boolean( style crossover   false                        whether style crossover style grid  ) flags define boolean( learning curves   true                        whether evaluate learning curves styles  ) flags define integer( batch size   16   batch size ) flags define integer( image size   256   image size  ) flags define integer( eval interval secs   60                        frequency  seconds  evaluation run  ) flags define integer( num evals   32   number evaluations losses  ) flags define integer( num styles   none   number styles  ) flags define string( content weights   default content weights                       content weights ) flags define string( eval dir   none                       directory results saved  ) flags define string( train dir   none                       directory checkpoints summaries ) flags define string( master                            name tensorflow master use  ) flags define string( style coefficients   none                       scales style weights conditioned style image  ) flags define string( style dataset file   none   style dataset file  ) flags define string( style weights   default style weights                       style weights ) flags   flags flags   def main( )    tf graph() default()        create inputs  0  1   expected vgg 16      inputs      image utils imagenet inputs(         flags batch size  flags image size)     evaluation images   image utils load evaluation images(flags image size)        process style weight flags     flags style coefficients none        style coefficients    1 0   range(flags num styles)      else        style coefficients   ast literal eval(flags style coefficients)     len(style coefficients)    flags num styles        raise valueerror(            number style coefficients differs number styles )     content weights   ast literal eval(flags content weights)     style weights   ast literal eval(flags style weights)        load style images      style images  labels  style gram matrices   image utils style image inputs(         os path expanduser(flags style dataset file)          batch size flags num styles  image size flags image size          square crop true  shuffle false)     labels   tf unstack(labels)      def  create normalizer params(style label)           creates normalizer parameters style label           return   labels   tf expand dims(style label  0)                 num categories   flags num styles                 center   true                 scale   true         dummy call simplify reuse logic     model transform(inputs  reuse false                      normalizer params  create normalizer params(labels 0 ))      def  style sweep(inputs)           transfers styles onto input one time        copyright 2016 google inc  all rights reserved        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license          http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license     internal imports    create inputs  0  1   expected vgg 16     process style weight flags    load style images     dummy call simplify reuse logic ", "content": "# Copyright 2016 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Evaluates the N-styles style transfer model.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport ast\nimport os\n\n# internal imports\nimport tensorflow as tf\n\nfrom magenta.models.image_stylization import image_utils\nfrom magenta.models.image_stylization import learning\nfrom magenta.models.image_stylization import model\n\nslim = tf.contrib.slim\n\n\nDEFAULT_CONTENT_WEIGHTS = '{\"vgg_16/conv3\": 1.0}'\nDEFAULT_STYLE_WEIGHTS = ('{\"vgg_16/conv1\": 1e-4, \"vgg_16/conv2\": 1e-4,'\n                         ' \"vgg_16/conv3\": 1e-4, \"vgg_16/conv4\": 1e-4}')\n\n\nflags = tf.app.flags\nflags.DEFINE_boolean('style_grid', False,\n                     'Whether to generate the style grid.')\nflags.DEFINE_boolean('style_crossover', False,\n                     'Whether to do a style crossover in the style grid.')\nflags.DEFINE_boolean('learning_curves', True,\n                     'Whether to evaluate learning curves for all styles.')\nflags.DEFINE_integer('batch_size', 16, 'Batch size')\nflags.DEFINE_integer('image_size', 256, 'Image size.')\nflags.DEFINE_integer('eval_interval_secs', 60,\n                     'Frequency, in seconds, at which evaluation is run.')\nflags.DEFINE_integer('num_evals', 32, 'Number of evaluations of the losses.')\nflags.DEFINE_integer('num_styles', None, 'Number of styles.')\nflags.DEFINE_string('content_weights', DEFAULT_CONTENT_WEIGHTS,\n                    'Content weights')\nflags.DEFINE_string('eval_dir', None,\n                    'Directory where the results are saved to.')\nflags.DEFINE_string('train_dir', None,\n                    'Directory for checkpoints and summaries')\nflags.DEFINE_string('master', '',\n                    'Name of the TensorFlow master to use.')\nflags.DEFINE_string('style_coefficients', None,\n                    'Scales the style weights conditioned on the style image.')\nflags.DEFINE_string('style_dataset_file', None, 'Style dataset file.')\nflags.DEFINE_string('style_weights', DEFAULT_STYLE_WEIGHTS,\n                    'Style weights')\nFLAGS = flags.FLAGS\n\n\ndef main(_):\n  with tf.Graph().as_default():\n    # Create inputs in [0, 1], as expected by vgg_16.\n    inputs, _ = image_utils.imagenet_inputs(\n        FLAGS.batch_size, FLAGS.image_size)\n    evaluation_images = image_utils.load_evaluation_images(FLAGS.image_size)\n\n    # Process style and weight flags\n    if FLAGS.style_coefficients is None:\n      style_coefficients = [1.0 for _ in range(FLAGS.num_styles)]\n    else:\n      style_coefficients = ast.literal_eval(FLAGS.style_coefficients)\n    if len(style_coefficients) != FLAGS.num_styles:\n      raise ValueError(\n          'number of style coefficients differs from number of styles')\n    content_weights = ast.literal_eval(FLAGS.content_weights)\n    style_weights = ast.literal_eval(FLAGS.style_weights)\n\n    # Load style images.\n    style_images, labels, style_gram_matrices = image_utils.style_image_inputs(\n        os.path.expanduser(FLAGS.style_dataset_file),\n        batch_size=FLAGS.num_styles, image_size=FLAGS.image_size,\n        square_crop=True, shuffle=False)\n    labels = tf.unstack(labels)\n\n    def _create_normalizer_params(style_label):\n      \"\"\"Creates normalizer parameters from a style label.\"\"\"\n      return {'labels': tf.expand_dims(style_label, 0),\n              'num_categories': FLAGS.num_styles,\n              'center': True,\n              'scale': True}\n\n    # Dummy call to simplify the reuse logic\n    model.transform(inputs, reuse=False,\n                    normalizer_params=_create_normalizer_params(labels[0]))\n\n    def _style_sweep(inputs):\n      \"\"\"Transfers all styles onto the input one at a time.\"\"\"\n      inputs = tf.expand_dims(inputs, 0)\n      stylized_inputs = [\n          model.transform(\n              inputs,\n              reuse=True,\n              normalizer_params=_create_normalizer_params(style_label))\n          for _, style_label in enumerate(labels)]\n      return tf.concat([inputs] + stylized_inputs, 0)\n\n    if FLAGS.style_grid:\n      style_row = tf.concat(\n          [tf.ones([1, FLAGS.image_size, FLAGS.image_size, 3]), style_images],\n          0)\n      stylized_training_example = _style_sweep(inputs[0])\n      stylized_evaluation_images = [\n          _style_sweep(image) for image in tf.unstack(evaluation_images)]\n      stylized_noise = _style_sweep(\n          tf.random_uniform([FLAGS.image_size, FLAGS.image_size, 3]))\n      stylized_style_images = [\n          _style_sweep(image) for image in tf.unstack(style_images)]\n      if FLAGS.style_crossover:\n        grid = tf.concat(\n            [style_row, stylized_training_example, stylized_noise] +\n            stylized_evaluation_images + stylized_style_images,\n            0)\n      else:\n        grid = tf.concat(\n            [style_row, stylized_training_example, stylized_noise] +\n            stylized_evaluation_images,\n            0)\n      tf.summary.image(\n          'Style Grid',\n          tf.cast(\n              image_utils.form_image_grid(\n                  grid,\n                  ([3 + evaluation_images.get_shape().as_list()[0] +\n                    FLAGS.num_styles, 1 + FLAGS.num_styles]\n                   if FLAGS.style_crossover\n                   else [3 + evaluation_images.get_shape().as_list()[0],\n                         1 + FLAGS.num_styles]),\n                  [FLAGS.image_size, FLAGS.image_size],\n                  3) * 255.0,\n              tf.uint8))\n\n    if FLAGS.learning_curves:\n      metrics = {}\n      for i, label in enumerate(labels):\n        gram_matrices = dict(\n            [(key, value[i: i + 1])\n             for key, value in style_gram_matrices.iteritems()])\n        stylized_inputs = model.transform(\n            inputs,\n            reuse=True,\n            normalizer_params=_create_normalizer_params(label))\n        _, loss_dict = learning.total_loss(\n            inputs, stylized_inputs, gram_matrices, content_weights,\n            style_weights, reuse=i > 0)\n        for key, value in loss_dict.iteritems():\n          metrics['{}_style_{}'.format(key, i)] = slim.metrics.streaming_mean(\n              value)\n\n      names_values, names_updates = slim.metrics.aggregate_metric_map(metrics)\n      for name, value in names_values.iteritems():\n        summary_op = tf.summary.scalar(name, value, [])\n        print_op = tf.Print(summary_op, [value], name)\n        tf.add_to_collection(tf.GraphKeys.SUMMARIES, print_op)\n      eval_op = names_updates.values()\n      num_evals = FLAGS.num_evals\n    else:\n      eval_op = None\n      num_evals = 1\n\n    slim.evaluation.evaluation_loop(\n        master=FLAGS.master,\n        checkpoint_dir=os.path.expanduser(FLAGS.train_dir),\n        logdir=os.path.expanduser(FLAGS.eval_dir),\n        eval_op=eval_op,\n        num_evals=num_evals,\n        eval_interval_secs=FLAGS.eval_interval_secs)\n\n\ndef console_entry_point():\n  tf.app.run(main)\n\n\nif __name__ == '__main__':\n  console_entry_point()\n", "description": "Magenta: Music and Art Generation with Machine Intelligence", "file_name": "image_stylization_evaluate.py", "id": "f795be5f5a191c0ba58214c0c5d5eca3", "language": "Python", "project_name": "magenta", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tensorflow-magenta/tensorflow-magenta-ca73164/magenta/models/image_stylization/image_stylization_evaluate.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:00:14Z", "url": "https://github.com/tensorflow/magenta", "wiki": false}