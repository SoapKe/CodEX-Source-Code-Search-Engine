{"author": "tflearn", "code": "from __future__ import division, print_function, absolute_import\n\nfrom .utils import get_from_module\nimport tensorflow as tf\n\n\ndef get(identifier):\n    return get_from_module(identifier, globals(), 'metrics')\n\n\"\"\"\nMetric classes are meant to be used with TFLearn models (such as DNN). For\ndirect operations to be used with Tensorflow, see below (accuracy_op, ...).\n\"\"\"\n\n\n\n\n\n\nclass Metric(object):\n    \"\"\" Base Metric Class.\n\n    Metric class is meant to be used by TFLearn models class. It can be\n    first initialized with desired parameters, and a model class will\n    build it later using the given network output and targets.\n\n    Attributes:\n        tensor: `Tensor`. The metric tensor.\n\n    \"\"\"\n    def __init__(self, name=None):\n        self.name = name\n        self.tensor = None\n        self.built = False\n\n    def build(self, predictions, targets, inputs):\n        \"\"\" build.\n\n        Build metric method, with common arguments to all Metrics.\n\n        Arguments:\n            prediction: `Tensor`. The network to perform prediction.\n            targets: `Tensor`. The targets (labels).\n            inputs: `Tensor`. The input data.\n\n        \"\"\"\n        raise NotImplementedError\n\n    def get_tensor(self):\n        \"\"\" get_tensor.\n\n        Get the metric tensor.\n\n        Returns:\n            The metric `Tensor`.\n\n        \"\"\"\n        if not self.built:\n            raise Exception(\"Metric class Tensor hasn't be built. 'build' \"\n                            \"method must be invoked before using 'get_tensor'.\")\n        return self.tensor\n\n\nclass Accuracy(Metric):\n    \"\"\" Accuracy.\n\n    Computes the model accuracy.  The target predictions are assumed\n    to be logits.  \n\n    If the predictions tensor is 1D (ie shape [?], or [?, 1]), then the \n    labels are assumed to be binary (cast as float32), and accuracy is\n    computed based on the average number of equal binary outcomes,\n    thresholding predictions on logits > 0.  \n\n    Otherwise, accuracy is computed based on categorical outcomes,\n    and assumes the inputs (both the model predictions and the labels)\n    are one-hot encoded.  tf.argmax is used to obtain categorical\n    predictions, for equality comparison.\n\n    Examples:\n        ```python\n        \n        acc = Accuracy()\n        regression = regression(net, metric=acc)\n        ```\n\n    Arguments:\n        name: The name to display.\n\n    \"\"\"\n\n    def __init__(self, name=None):\n        super(Accuracy, self).__init__(name)\n\n    def build(self, predictions, targets, inputs=None):\n        \"\"\" Build accuracy, comparing predictions and targets. \"\"\"\n        self.built = True\n        pshape = predictions.get_shape()\n        if len(pshape)==1 or (len(pshape)==2 and int(pshape[1])==1):\n            self.name = self.name or \"binary_acc\"   \n            self.tensor = binary_accuracy_op(predictions, targets)\n        else:\n            self.name = self.name or \"acc\"   \t    \n            self.tensor = accuracy_op(predictions, targets)\n        \n        self.tensor.m_name = self.name\n\naccuracy = Accuracy\n\nclass Top_k(Metric):\n    \"\"\" Top-k.\n\n    Computes Top-k mean accuracy (whether the targets are in the top 'K'\n    predictions).\n\n    Examples:\n        ```python\n        \n        top5 = Top_k(k=5)\n        regression = regression(net, metric=top5)\n        ```\n\n    Arguments:\n        k: `int`. Number of top elements to look at for computing precision.\n        name: The name to display.\n\n    \"\"\"\n\n    def __init__(self, k=1, name=None):\n        super(Top_k, self).__init__(name)\n        self.name = \"top\" + str(k) if not name else name\n        self.k = k\n\n    def build(self, predictions, targets, inputs=None):\n        \"\"\" Build top-k accuracy, comparing top-k predictions and targets. \"\"\"\n        self.built = True\n        self.tensor = top_k_op(predictions, targets, self.k)\n        \n        self.tensor.m_name = self.name\n\ntop_k = Top_k\n\n\nclass R2(Metric):\n    \"\"\" Standard Error.\n\n    Computes coefficient of determination. Useful to evaluate a linear\n    regression.\n\n    Examples:\n        ```python\n        \n        r2 = R2()\n        regression = regression(net, metric=r2)\n        ```\n\n    Arguments:\n        name: The name to display.\n\n    \"\"\"\n\n    def __init__(self, name=None):\n        super(R2, self).__init__(name)\n        self.name = \"R2\" if not name else name\n\n    def build(self, predictions, targets, inputs=None):\n        \"\"\" Build standard error tensor. \"\"\"\n        self.built = True\n        self.tensor = r2_op(predictions, targets)\n        \n        self.tensor.m_name = self.name\n\n\nclass WeightedR2(Metric):\n    \"\"\" Weighted Standard Error.\n\n    Computes coefficient of determination. Useful to evaluate a linear\n    regression.\n\n    Examples:\n        ```python\n        \n        weighted_r2 = WeightedR2()\n        regression = regression(net, metric=weighted_r2)\n        ```\n\n    Arguments:\n        name: The name to display.\n\n    \"\"\"\n\n    def __init__(self, name=None):\n        super(WeightedR2, self).__init__(name)\n        self.name = \"R2\" if not name else name\n\n    def build(self, predictions, targets, inputs):\n        \"\"\" Build standard error tensor. \"\"\"\n        self.built = True\n        self.tensor = weighted_r2_op(predictions, targets, inputs)\n        \n        self.tensor.m_name = self.name\n\n\nclass Prediction_Counts(Metric):\n    \"\"\" Prints the count of each category of prediction that is present in the predictions.\n    Can be useful to see, for example, to see if the model only gives one type of predictions,\n    or if the predictions given are in the expected proportions \"\"\"\n\n    def __init__(self, inner_metric, name=None):\n        super(Prediction_Counts, self).__init__(name)\n        self.inner_metric = inner_metric\n\n    def build(self, predictions, targets, inputs=None):\n        \"\"\" Prints the number of each kind of prediction \"\"\"\n        self.built = True\n        pshape = predictions.get_shape()\n        self.inner_metric.build(predictions, targets, inputs)\n\n        with tf.name_scope(self.name):\n            if len(pshape) == 1 or (len(pshape) == 2 and int(pshape[1]) == 1):\n                self.name = self.name or \"binary_prediction_counts\"\n                y, idx, count = tf.unique_with_counts(tf.argmax(predictions))\n                self.tensor = tf.Print(self.inner_metric, [y, count], name=self.inner_metric.name)\n            else:\n                self.name = self.name or \"categorical_prediction_counts\"\n                y, idx, count = tf.unique_with_counts(tf.argmax(predictions, dimension=1))\n                self.tensor = tf.Print(self.inner_metric.tensor, [y, count], name=self.inner_metric.name)\n\nprediction_counts = Prediction_Counts\n\n\n\n\n\n\n\ndef accuracy_op(predictions, targets):\n    \"\"\" accuracy_op.\n\n    An op that calculates mean accuracy, assuming predictiosn are targets\n    are both one-hot encoded.\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) \n        y_true = placeholder(shape=[None, 10]) \n        acc_op = accuracy_op(y_pred, y_true)\n\n        \n        accuracy = sess.run(acc_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor`.\n        targets: `Tensor`.\n\n    Returns:\n        `Float`. The mean accuracy.\n\n    \"\"\"\n    if not isinstance(targets, tf.Tensor):\n        raise ValueError(\"mean_accuracy 'input' argument only accepts type \"\n                         \"Tensor, '\" + str(type(input)) + \"' given.\")\n\n    with tf.name_scope('Accuracy'):\n        correct_pred = tf.equal(tf.argmax(predictions, 1), tf.argmax(targets, 1))\n        acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n    return acc\n\n\ndef binary_accuracy_op(predictions, targets):\n    \"\"\" binary_accuracy_op.\n\n    An op that calculates mean accuracy, assuming predictions are logits, and\n    targets are binary encoded (and represented as int32).\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) \n        y_true = placeholder(shape=[None, 10]) \n        acc_op = binary_accuracy_op(y_pred, y_true)\n\n        \n        binary_accuracy = sess.run(acc_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor` of `float` type.\n        targets: `Tensor` of `float` type.\n\n    Returns:\n        `Float`. The mean accuracy.\n\n    \"\"\"\n    if not isinstance(targets, tf.Tensor):\n        raise ValueError(\"mean_accuracy 'input' argument only accepts type \"\n                         \"Tensor, '\" + str(type(input)) + \"' given.\")\n\n    with tf.name_scope('BinaryAccuracy'):\n        predictions = tf.cast(tf.greater(predictions, 0), tf.float32)\n        correct_pred = tf.equal(predictions, tf.cast(targets, tf.float32))\n        acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n    return acc\n\n\ndef top_k_op(predictions, targets, k=1):\n    \"\"\" top_k_op.\n\n    An op that calculates top-k mean accuracy.\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) \n        y_true = placeholder(shape=[None, 10]) \n        top3_op = top_k_op(y_pred, y_true, 3)\n\n        \n        top3_accuracy = sess.run(top3_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor`.\n        targets: `Tensor`.\n        k: `int`. Number of top elements to look at for computing precision.\n\n    Returns:\n        `Float`. The top-k mean accuracy.\n\n    \"\"\"\n    with tf.name_scope('Top_' + str(k)):\n        targets = tf.cast(targets, tf.int32)\n        correct_pred = tf.nn.in_top_k(predictions, tf.argmax(targets, 1), k)\n        acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n    return acc\n\n\ndef r2_op(predictions, targets):\n    \"\"\" r2_op.\n\n    An op that calculates the standard error.\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) \n        y_true = placeholder(shape=[None, 10]) \n        stderr_op = r2_op(y_pred, y_true)\n\n        \n        std_error = sess.run(stderr_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor`.\n        targets: `Tensor`.\n\n    Returns:\n        `Float`. The standard error.\n\n    \"\"\"\n    with tf.name_scope('StandardError'):\n        a = tf.reduce_sum(tf.square(predictions))\n        b = tf.reduce_sum(tf.square(targets))\n        return tf.divide(a, b)\n\n\ndef weighted_r2_op(predictions, targets, inputs):\n    \"\"\" weighted_r2_op.\n\n    An op that calculates the standard error.\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) \n        y_true = placeholder(shape=[None, 10]) \n        stderr_op = weighted_r2_op(y_pred, y_true, input_data)\n\n        \n        std_error = sess.run(stderr_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor`.\n        targets: `Tensor`.\n        inputs: `Tensor`.\n\n    Returns:\n        `Float`. The standard error.\n\n    \"\"\"\n    with tf.name_scope('WeightedStandardError'):\n        if hasattr(inputs, '__len__'):\n            inputs = tf.add_n(inputs)\n        if inputs.get_shape().as_list() != targets.get_shape().as_list():\n            raise Exception(\"Weighted R2 metric requires Inputs and Targets to \"\n                            \"have same shape.\")\n        a = tf.reduce_sum(tf.square(predictions - inputs))\n        b = tf.reduce_sum(tf.square(targets - inputs))\n        return tf.divide(a, b)\n", "comments": "    metric classes meant used tflearn models (such dnn)  for direct operations used tensorflow  see (accuracy op     )                          metric classes                    class metric(object)          base metric class       metric class meant used tflearn models class  it     first initialized desired parameters  model class     build later using given network output targets       attributes          tensor   tensor   the metric tensor               def   init  (self  name none)          self name   name         self tensor   none         self built   false      def build(self  predictions  targets  inputs)              build           build metric method  common arguments metrics           arguments              prediction   tensor   the network perform prediction              targets   tensor   the targets (labels)              inputs   tensor   the input data                       raise notimplementederror      def get tensor(self)              get tensor           get metric tensor           returns              the metric  tensor                        self built              raise exception( metric class tensor built   build                                 method must invoked using  get tensor   )         return self tensor   class accuracy(metric)          accuracy       computes model accuracy   the target predictions assumed     logits         if predictions tensor 1d (ie shape          1 )       labels assumed binary (cast float32)  accuracy     computed based average number equal binary outcomes      thresholding predictions logits   0         otherwise  accuracy computed based categorical outcomes      assumes inputs (both model predictions labels)     one hot encoded   tf argmax used obtain categorical     predictions  equality comparison       examples             python           to used tflearn estimators         acc   accuracy()         regression   regression(net  metric acc)                  arguments          name  the name display                def   init  (self  name none)          super(accuracy  self)   init  (name)      def build(self  predictions  targets  inputs none)              build accuracy  comparing predictions targets              self built   true         pshape   predictions get shape()         len(pshape)  1 (len(pshape)  2 int(pshape 1 )  1)              self name   self name  binary acc      clearly indicate binary accuracy used             self tensor   binary accuracy op(predictions  targets)         else              self name   self name  acc           traditional categorical accuracy             self tensor   accuracy op(predictions  targets)           add special name tensor  used monitors         self tensor name   self name  accuracy   accuracy  class top k(metric)          top k       computes top k mean accuracy (whether targets top  k      predictions)       examples             python           to used tflearn estimators         top5   top k(k 5)         regression   regression(net  metric top5)                  arguments          k   int   number top elements look computing precision          name  the name display                def   init  (self  k 1  name none)          super(top k  self)   init  (name)         self name    top    str(k) name else name         self k   k      def build(self  predictions  targets  inputs none)              build top k accuracy  comparing top k predictions targets              self built   true         self tensor   top k op(predictions  targets  self k)           add special name tensor  used monitors         self tensor name   self name  top k   top k   class r2(metric)          standard error       computes coefficient determination  useful evaluate linear     regression       examples             python           to used tflearn estimators         r2   r2()         regression   regression(net  metric r2)                  arguments          name  the name display                def   init  (self  name none)          super(r2  self)   init  (name)         self name    r2  name else name      def build(self  predictions  targets  inputs none)              build standard error tensor              self built   true         self tensor   r2 op(predictions  targets)           add special name tensor  used monitors         self tensor name   self name   class weightedr2(metric)          weighted standard error       computes coefficient determination  useful evaluate linear     regression       examples             python           to used tflearn estimators         weighted r2   weightedr2()         regression   regression(net  metric weighted r2)                  arguments          name  the name display                def   init  (self  name none)          super(weightedr2  self)   init  (name)         self name    r2  name else name      def build(self  predictions  targets  inputs)              build standard error tensor              self built   true         self tensor   weighted r2 op(predictions  targets  inputs)           add special name tensor  used monitors         self tensor name   self name   class prediction counts(metric)          prints count category prediction present predictions      can useful see  example  see model gives one type predictions      predictions given expected proportions          def   init  (self  inner metric  name none)          super(prediction counts  self)   init  (name)         self inner metric   inner metric      def build(self  predictions  targets  inputs none)              prints number kind prediction             self built   true         pshape   predictions get shape()         self inner metric build(predictions  targets  inputs)          tf name scope(self name)              len(pshape)    1 (len(pshape)    2 int(pshape 1 )    1)                  self name   self name  binary prediction counts                   idx  count   tf unique counts(tf argmax(predictions))                 self tensor   tf print(self inner metric    count   name self inner metric name)             else                  self name   self name  categorical prediction counts                   idx  count   tf unique counts(tf argmax(predictions  dimension 1))                 self tensor   tf print(self inner metric tensor    count   name self inner metric name)  prediction counts   prediction counts                  metric ops                def accuracy op(predictions  targets)          accuracy op       an op calculates mean accuracy  assuming predictiosn targets     one hot encoded       examples             python         input data   placeholder(shape  none  784 )         pred   network(input data)   apply ops         true   placeholder(shape  none  10 )   labels         acc op   accuracy op(y pred  true)            calculate accuracy feeding data x labels y         accuracy   sess run(acc op  feed dict  input data  x  true  y )                  arguments          predictions   tensor           targets   tensor        returns           float   the mean accuracy               isinstance(targets  tf tensor)          raise valueerror( mean accuracy  input  argument accepts type                             tensor       str(type(input))      given  )      tf name scope( accuracy )          correct pred   tf equal(tf argmax(predictions  1)  tf argmax(targets  1))         acc   tf reduce mean(tf cast(correct pred  tf float32))     return acc   def binary accuracy op(predictions  targets)          binary accuracy op       an op calculates mean accuracy  assuming predictions logits      targets binary encoded (and represented int32)       examples             python         input data   placeholder(shape  none  784 )         pred   network(input data)   apply ops         true   placeholder(shape  none  10 )   labels         acc op   binary accuracy op(y pred  true)            calculate accuracy feeding data x labels y         binary accuracy   sess run(acc op  feed dict  input data  x  true  y )                  arguments          predictions   tensor   float  type          targets   tensor   float  type       returns           float   the mean accuracy               isinstance(targets  tf tensor)          raise valueerror( mean accuracy  input  argument accepts type                             tensor       str(type(input))      given  )      tf name scope( binaryaccuracy )          predictions   tf cast(tf greater(predictions  0)  tf float32)         correct pred   tf equal(predictions  tf cast(targets  tf float32))         acc   tf reduce mean(tf cast(correct pred  tf float32))     return acc   def top k op(predictions  targets  k 1)          top k op       an op calculates top k mean accuracy       examples             python         input data   placeholder(shape  none  784 )         pred   network(input data)   apply ops         true   placeholder(shape  none  10 )   labels         top3 op   top k op(y pred  true  3)            calculate top 3 accuracy feeding data x labels y         top3 accuracy   sess run(top3 op  feed dict  input data  x  true  y )                  arguments          predictions   tensor           targets   tensor           k   int   number top elements look computing precision       returns           float   the top k mean accuracy               tf name scope( top     str(k))          targets   tf cast(targets  tf int32)         correct pred   tf nn top k(predictions  tf argmax(targets  1)  k)         acc   tf reduce mean(tf cast(correct pred  tf float32))     return acc   def r2 op(predictions  targets)          r2 op       an op calculates standard error       examples             python         input data   placeholder(shape  none  784 )         pred   network(input data)   apply ops         true   placeholder(shape  none  10 )   labels         stderr op   r2 op(y pred  true)            calculate standard error feeding data x labels y         std error   sess run(stderr op  feed dict  input data  x  true  y )                  arguments          predictions   tensor           targets   tensor        returns           float   the standard error               tf name scope( standarderror )            tf reduce sum(tf square(predictions))         b   tf reduce sum(tf square(targets))         return tf divide(a  b)   def weighted r2 op(predictions  targets  inputs)          weighted r2 op       an op calculates standard error       examples             python         input data   placeholder(shape  none  784 )         pred   network(input data)   apply ops         true   placeholder(shape  none  10 )   labels         stderr op   weighted r2 op(y pred  true  input data)            calculate standard error feeding data x labels y         std error   sess run(stderr op  feed dict  input data  x  true  y )                  arguments          predictions   tensor           targets   tensor           inputs   tensor        returns           float   the standard error                                metric classes                      to used tflearn estimators    clearly indicate binary accuracy used    traditional categorical accuracy    add special name tensor  used monitors    to used tflearn estimators    add special name tensor  used monitors    to used tflearn estimators    add special name tensor  used monitors    to used tflearn estimators    add special name tensor  used monitors                  metric ops                  apply ops    labels    calculate accuracy feeding data x labels y    apply ops    labels    calculate accuracy feeding data x labels y    apply ops    labels    calculate top 3 accuracy feeding data x labels y    apply ops    labels    calculate standard error feeding data x labels y    apply ops    labels    calculate standard error feeding data x labels y ", "content": "from __future__ import division, print_function, absolute_import\n\nfrom .utils import get_from_module\nimport tensorflow as tf\n\n\ndef get(identifier):\n    return get_from_module(identifier, globals(), 'metrics')\n\n\"\"\"\nMetric classes are meant to be used with TFLearn models (such as DNN). For\ndirect operations to be used with Tensorflow, see below (accuracy_op, ...).\n\"\"\"\n\n# --------------\n# Metric classes\n# --------------\n\n\nclass Metric(object):\n    \"\"\" Base Metric Class.\n\n    Metric class is meant to be used by TFLearn models class. It can be\n    first initialized with desired parameters, and a model class will\n    build it later using the given network output and targets.\n\n    Attributes:\n        tensor: `Tensor`. The metric tensor.\n\n    \"\"\"\n    def __init__(self, name=None):\n        self.name = name\n        self.tensor = None\n        self.built = False\n\n    def build(self, predictions, targets, inputs):\n        \"\"\" build.\n\n        Build metric method, with common arguments to all Metrics.\n\n        Arguments:\n            prediction: `Tensor`. The network to perform prediction.\n            targets: `Tensor`. The targets (labels).\n            inputs: `Tensor`. The input data.\n\n        \"\"\"\n        raise NotImplementedError\n\n    def get_tensor(self):\n        \"\"\" get_tensor.\n\n        Get the metric tensor.\n\n        Returns:\n            The metric `Tensor`.\n\n        \"\"\"\n        if not self.built:\n            raise Exception(\"Metric class Tensor hasn't be built. 'build' \"\n                            \"method must be invoked before using 'get_tensor'.\")\n        return self.tensor\n\n\nclass Accuracy(Metric):\n    \"\"\" Accuracy.\n\n    Computes the model accuracy.  The target predictions are assumed\n    to be logits.  \n\n    If the predictions tensor is 1D (ie shape [?], or [?, 1]), then the \n    labels are assumed to be binary (cast as float32), and accuracy is\n    computed based on the average number of equal binary outcomes,\n    thresholding predictions on logits > 0.  \n\n    Otherwise, accuracy is computed based on categorical outcomes,\n    and assumes the inputs (both the model predictions and the labels)\n    are one-hot encoded.  tf.argmax is used to obtain categorical\n    predictions, for equality comparison.\n\n    Examples:\n        ```python\n        # To be used with TFLearn estimators\n        acc = Accuracy()\n        regression = regression(net, metric=acc)\n        ```\n\n    Arguments:\n        name: The name to display.\n\n    \"\"\"\n\n    def __init__(self, name=None):\n        super(Accuracy, self).__init__(name)\n\n    def build(self, predictions, targets, inputs=None):\n        \"\"\" Build accuracy, comparing predictions and targets. \"\"\"\n        self.built = True\n        pshape = predictions.get_shape()\n        if len(pshape)==1 or (len(pshape)==2 and int(pshape[1])==1):\n            self.name = self.name or \"binary_acc\"   # clearly indicate binary accuracy being used\n            self.tensor = binary_accuracy_op(predictions, targets)\n        else:\n            self.name = self.name or \"acc\"   \t    # traditional categorical accuracy\n            self.tensor = accuracy_op(predictions, targets)\n        # Add a special name to that tensor, to be used by monitors\n        self.tensor.m_name = self.name\n\naccuracy = Accuracy\n\nclass Top_k(Metric):\n    \"\"\" Top-k.\n\n    Computes Top-k mean accuracy (whether the targets are in the top 'K'\n    predictions).\n\n    Examples:\n        ```python\n        # To be used with TFLearn estimators\n        top5 = Top_k(k=5)\n        regression = regression(net, metric=top5)\n        ```\n\n    Arguments:\n        k: `int`. Number of top elements to look at for computing precision.\n        name: The name to display.\n\n    \"\"\"\n\n    def __init__(self, k=1, name=None):\n        super(Top_k, self).__init__(name)\n        self.name = \"top\" + str(k) if not name else name\n        self.k = k\n\n    def build(self, predictions, targets, inputs=None):\n        \"\"\" Build top-k accuracy, comparing top-k predictions and targets. \"\"\"\n        self.built = True\n        self.tensor = top_k_op(predictions, targets, self.k)\n        # Add a special name to that tensor, to be used by monitors\n        self.tensor.m_name = self.name\n\ntop_k = Top_k\n\n\nclass R2(Metric):\n    \"\"\" Standard Error.\n\n    Computes coefficient of determination. Useful to evaluate a linear\n    regression.\n\n    Examples:\n        ```python\n        # To be used with TFLearn estimators\n        r2 = R2()\n        regression = regression(net, metric=r2)\n        ```\n\n    Arguments:\n        name: The name to display.\n\n    \"\"\"\n\n    def __init__(self, name=None):\n        super(R2, self).__init__(name)\n        self.name = \"R2\" if not name else name\n\n    def build(self, predictions, targets, inputs=None):\n        \"\"\" Build standard error tensor. \"\"\"\n        self.built = True\n        self.tensor = r2_op(predictions, targets)\n        # Add a special name to that tensor, to be used by monitors\n        self.tensor.m_name = self.name\n\n\nclass WeightedR2(Metric):\n    \"\"\" Weighted Standard Error.\n\n    Computes coefficient of determination. Useful to evaluate a linear\n    regression.\n\n    Examples:\n        ```python\n        # To be used with TFLearn estimators\n        weighted_r2 = WeightedR2()\n        regression = regression(net, metric=weighted_r2)\n        ```\n\n    Arguments:\n        name: The name to display.\n\n    \"\"\"\n\n    def __init__(self, name=None):\n        super(WeightedR2, self).__init__(name)\n        self.name = \"R2\" if not name else name\n\n    def build(self, predictions, targets, inputs):\n        \"\"\" Build standard error tensor. \"\"\"\n        self.built = True\n        self.tensor = weighted_r2_op(predictions, targets, inputs)\n        # Add a special name to that tensor, to be used by monitors\n        self.tensor.m_name = self.name\n\n\nclass Prediction_Counts(Metric):\n    \"\"\" Prints the count of each category of prediction that is present in the predictions.\n    Can be useful to see, for example, to see if the model only gives one type of predictions,\n    or if the predictions given are in the expected proportions \"\"\"\n\n    def __init__(self, inner_metric, name=None):\n        super(Prediction_Counts, self).__init__(name)\n        self.inner_metric = inner_metric\n\n    def build(self, predictions, targets, inputs=None):\n        \"\"\" Prints the number of each kind of prediction \"\"\"\n        self.built = True\n        pshape = predictions.get_shape()\n        self.inner_metric.build(predictions, targets, inputs)\n\n        with tf.name_scope(self.name):\n            if len(pshape) == 1 or (len(pshape) == 2 and int(pshape[1]) == 1):\n                self.name = self.name or \"binary_prediction_counts\"\n                y, idx, count = tf.unique_with_counts(tf.argmax(predictions))\n                self.tensor = tf.Print(self.inner_metric, [y, count], name=self.inner_metric.name)\n            else:\n                self.name = self.name or \"categorical_prediction_counts\"\n                y, idx, count = tf.unique_with_counts(tf.argmax(predictions, dimension=1))\n                self.tensor = tf.Print(self.inner_metric.tensor, [y, count], name=self.inner_metric.name)\n\nprediction_counts = Prediction_Counts\n\n\n# ----------\n# Metric ops\n# ----------\n\n\ndef accuracy_op(predictions, targets):\n    \"\"\" accuracy_op.\n\n    An op that calculates mean accuracy, assuming predictiosn are targets\n    are both one-hot encoded.\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) # Apply some ops\n        y_true = placeholder(shape=[None, 10]) # Labels\n        acc_op = accuracy_op(y_pred, y_true)\n\n        # Calculate accuracy by feeding data X and labels Y\n        accuracy = sess.run(acc_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor`.\n        targets: `Tensor`.\n\n    Returns:\n        `Float`. The mean accuracy.\n\n    \"\"\"\n    if not isinstance(targets, tf.Tensor):\n        raise ValueError(\"mean_accuracy 'input' argument only accepts type \"\n                         \"Tensor, '\" + str(type(input)) + \"' given.\")\n\n    with tf.name_scope('Accuracy'):\n        correct_pred = tf.equal(tf.argmax(predictions, 1), tf.argmax(targets, 1))\n        acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n    return acc\n\n\ndef binary_accuracy_op(predictions, targets):\n    \"\"\" binary_accuracy_op.\n\n    An op that calculates mean accuracy, assuming predictions are logits, and\n    targets are binary encoded (and represented as int32).\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) # Apply some ops\n        y_true = placeholder(shape=[None, 10]) # Labels\n        acc_op = binary_accuracy_op(y_pred, y_true)\n\n        # Calculate accuracy by feeding data X and labels Y\n        binary_accuracy = sess.run(acc_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor` of `float` type.\n        targets: `Tensor` of `float` type.\n\n    Returns:\n        `Float`. The mean accuracy.\n\n    \"\"\"\n    if not isinstance(targets, tf.Tensor):\n        raise ValueError(\"mean_accuracy 'input' argument only accepts type \"\n                         \"Tensor, '\" + str(type(input)) + \"' given.\")\n\n    with tf.name_scope('BinaryAccuracy'):\n        predictions = tf.cast(tf.greater(predictions, 0), tf.float32)\n        correct_pred = tf.equal(predictions, tf.cast(targets, tf.float32))\n        acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n    return acc\n\n\ndef top_k_op(predictions, targets, k=1):\n    \"\"\" top_k_op.\n\n    An op that calculates top-k mean accuracy.\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) # Apply some ops\n        y_true = placeholder(shape=[None, 10]) # Labels\n        top3_op = top_k_op(y_pred, y_true, 3)\n\n        # Calculate Top-3 accuracy by feeding data X and labels Y\n        top3_accuracy = sess.run(top3_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor`.\n        targets: `Tensor`.\n        k: `int`. Number of top elements to look at for computing precision.\n\n    Returns:\n        `Float`. The top-k mean accuracy.\n\n    \"\"\"\n    with tf.name_scope('Top_' + str(k)):\n        targets = tf.cast(targets, tf.int32)\n        correct_pred = tf.nn.in_top_k(predictions, tf.argmax(targets, 1), k)\n        acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n    return acc\n\n\ndef r2_op(predictions, targets):\n    \"\"\" r2_op.\n\n    An op that calculates the standard error.\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) # Apply some ops\n        y_true = placeholder(shape=[None, 10]) # Labels\n        stderr_op = r2_op(y_pred, y_true)\n\n        # Calculate standard error by feeding data X and labels Y\n        std_error = sess.run(stderr_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor`.\n        targets: `Tensor`.\n\n    Returns:\n        `Float`. The standard error.\n\n    \"\"\"\n    with tf.name_scope('StandardError'):\n        a = tf.reduce_sum(tf.square(predictions))\n        b = tf.reduce_sum(tf.square(targets))\n        return tf.divide(a, b)\n\n\ndef weighted_r2_op(predictions, targets, inputs):\n    \"\"\" weighted_r2_op.\n\n    An op that calculates the standard error.\n\n    Examples:\n        ```python\n        input_data = placeholder(shape=[None, 784])\n        y_pred = my_network(input_data) # Apply some ops\n        y_true = placeholder(shape=[None, 10]) # Labels\n        stderr_op = weighted_r2_op(y_pred, y_true, input_data)\n\n        # Calculate standard error by feeding data X and labels Y\n        std_error = sess.run(stderr_op, feed_dict={input_data: X, y_true: Y})\n        ```\n\n    Arguments:\n        predictions: `Tensor`.\n        targets: `Tensor`.\n        inputs: `Tensor`.\n\n    Returns:\n        `Float`. The standard error.\n\n    \"\"\"\n    with tf.name_scope('WeightedStandardError'):\n        if hasattr(inputs, '__len__'):\n            inputs = tf.add_n(inputs)\n        if inputs.get_shape().as_list() != targets.get_shape().as_list():\n            raise Exception(\"Weighted R2 metric requires Inputs and Targets to \"\n                            \"have same shape.\")\n        a = tf.reduce_sum(tf.square(predictions - inputs))\n        b = tf.reduce_sum(tf.square(targets - inputs))\n        return tf.divide(a, b)\n", "description": "Deep learning library featuring a higher-level API for TensorFlow.", "file_name": "metrics.py", "id": "ec510e690053d3a84abed0f3da046f86", "language": "Python", "project_name": "tflearn", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tflearn-tflearn/tflearn-tflearn-70fb38a/tflearn/metrics.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:15:41Z", "url": "https://github.com/tflearn/tflearn", "wiki": true}