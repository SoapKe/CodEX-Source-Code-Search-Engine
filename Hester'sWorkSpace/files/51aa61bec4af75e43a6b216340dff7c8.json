{"author": "tensorflow", "code": "\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n\n\"\"\"A model for classifying light curves using (locally) fully connected layers.\n\nNote that the first layer of each fully connected stack is optionally\nimplemented as a convolution with a wide kernel followed by pooling. This causes\ninvariance to small translations.\n\nSee the base class (in astro_model.py) for a description of the general\nframework of AstroModel and its subclasses.\n\nThe architecture of this model is:\n\n                       predictions ^ |                         logits ^ |                  (fully connected layers) ^ |                     pre_logits_concat ^ |                      (concatenate)\n^^^|||\n (locally fully connected 1)  (locally fully connected 2)  ...       |^^||||\n     time_series_feature_1      time_series_feature_2      ...  aux_features\n\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom astronet.astro_model import astro_model\n\n\nclass AstroFCModel(astro_model.AstroModel):\n  \"\"\"A model for classifying light curves using fully connected layers.\"\"\"\n\n  def __init__(self, features, labels, hparams, mode):\n    \"\"\"Basic setup. The actual TensorFlow graph is constructed in build().\n\n    Args:\n      features: A dictionary containing \"time_series_features\" and\n          \"aux_features\", each of which is a dictionary of named input Tensors.\n          All features have dtype float32 and shape [batch_size, length].\n      labels: An int64 Tensor with shape [batch_size]. May be None if mode is\n          tf.estimator.ModeKeys.PREDICT.\n      hparams: A ConfigDict of hyperparameters for building the model.\n      mode: A tf.estimator.ModeKeys to specify whether the graph should be built\n          for training, evaluation or prediction.\n\n    Raises:\n      ValueError: If mode is invalid.\n    \"\"\"\n    super(AstroFCModel, self).__init__(features, labels, hparams, mode)\n\n  def _build_local_fc_layers(self, inputs, hparams, scope):\n    \"\"\"Builds locally fully connected layers.\n\n    Note that the first layer of the fully connected stack is optionally\n    implemented as a convolution with a wide kernel followed by pooling. This\n    makes the fully connected stack invariant to small translations of its\n    input.\n\n    Args:\n      inputs: A Tensor of shape [batch_size, length].\n      hparams: Object containing hyperparameters.\n      scope: Name of the variable scope.\n\n    Returns:\n      A Tensor of shape [batch_size, hparams.local_layer_size].\n\n    Raises:\n      ValueError: If hparams.pooling_type is unrecognized.\n    \"\"\"\n    if hparams.num_local_layers == 0:\n      return inputs\n\n    net = inputs\n    with tf.variable_scope(scope):\n       First layer is optionally implemented as a wide convolution for\n       invariance to small translations.\n      if hparams.translation_delta > 0:\n        kernel_size = inputs.shape.as_list()[1] - 2 * hparams.translation_delta\n        net = tf.expand_dims(net, -1)   [batch, length, channels=1]\n        net = tf.layers.conv1d(\n            inputs=net,\n            filters=hparams.local_layer_size,\n            kernel_size=kernel_size,\n            padding=\"valid\",\n            activation=tf.nn.relu,\n            name=\"conv1d\")\n\n         net is [batch, length, num_filters], where length = 1 +\n         2 * translation_delta. Pool along the length dimension.\n        if hparams.pooling_type == \"max\":\n          net = tf.reduce_max(net, axis=1, name=\"max_pool\")\n        elif hparams.pooling_type == \"avg\":\n          net = tf.reduce_mean(net, axis=1, name=\"avg_pool\")\n        else:\n          raise ValueError(\"Unrecognized pooling_type: %s\" % hparams.pooling_type)\n\n        remaining_layers = hparams.num_local_layers - 1\n      else:\n        remaining_layers = hparams.num_local_layers\n\n       Remaining fully connected layers.\n      for i in range(remaining_layers):\n        net = tf.contrib.layers.fully_connected(\n            inputs=net,\n            num_outputs=hparams.local_layer_size,\n            activation_fn=tf.nn.relu,\n            scope=\"fully_connected_%d\" % (i + 1))\n\n        if hparams.dropout_rate > 0:\n          net = tf.layers.dropout(net, hparams.dropout_rate, training=self.is_training)\n\n    return net\n\n  def build_time_series_hidden_layers(self):\n    \"\"\"Builds hidden layers for the time series features.\n\n    Inputs:\n      self.time_series_features\n\n    Outputs:\n      self.time_series_hidden_layers\n    \"\"\"\n    time_series_hidden_layers = {}\n    for name, time_series in self.time_series_features.iteritems():\n      time_series_hidden_layers[name] = self._build_local_fc_layers(\n          inputs=time_series,\n          hparams=self.hparams.time_series_hidden[name],\n          scope=name + \"_hidden\")\n\n    self.time_series_hidden_layers = time_series_hidden_layers\n", "comments": "   a model classifying light curves using (locally) fully connected layers   note first layer fully connected stack optionally implemented convolution wide kernel followed pooling  this causes invariance small translations   see base class (in astro model py) description general framework astromodel subclasses   the architecture model                                         predictions                                                                                                                                logits                                                                                                                         (fully connected layers)                                                                                                                            pre logits concat                                                                                                                             (concatenate)                                                                                                                                                 (locally fully connected 1)  (locally fully connected 2)                                                                                                                                                                 time series feature 1      time series feature 2           aux features        future   import absolute import   future   import division   future   import print function  import tensorflow tf  astronet astro model import astro model   class astrofcmodel(astro model astromodel)       a model classifying light curves using fully connected layers        def   init  (self  features  labels  hparams  mode)         basic setup  the actual tensorflow graph constructed build()       args        features  a dictionary containing  time series features             aux features   dictionary named input tensors            all features dtype float32 shape  batch size  length         labels  an int64 tensor shape  batch size   may none mode           tf estimator modekeys predict        hparams  a configdict hyperparameters building model        mode  a tf estimator modekeys specify whether graph built           training  evaluation prediction       raises        valueerror  if mode invalid              super(astrofcmodel  self)   init  (features  labels  hparams  mode)    def  build local fc layers(self  inputs  hparams  scope)         builds locally fully connected layers       note first layer fully connected stack optionally     implemented convolution wide kernel followed pooling  this     makes fully connected stack invariant small translations     input       args        inputs  a tensor shape  batch size  length         hparams  object containing hyperparameters        scope  name variable scope       returns        a tensor shape  batch size  hparams local layer size        raises        valueerror  if hparams pooling type unrecognized              hparams num local layers    0        return inputs      net   inputs     tf variable scope(scope)          first layer optionally implemented wide convolution         invariance small translations        hparams translation delta   0          kernel size   inputs shape list() 1    2   hparams translation delta         net   tf expand dims(net   1)     batch  length  channels 1          net   tf layers conv1d(             inputs net              filters hparams local layer size              kernel size kernel size              padding  valid               activation tf nn relu              name  conv1d )            net  batch  length  num filters   length   1             2   translation delta  pool along length dimension          hparams pooling type     max             net   tf reduce max(net  axis 1  name  max pool )         elif hparams pooling type     avg             net   tf reduce mean(net  axis 1  name  avg pool )         else            raise valueerror(                unrecognized pooling type      hparams pooling type)          remaining layers   hparams num local layers   1       else          remaining layers   hparams num local layers          remaining fully connected layers        range(remaining layers)          net   tf contrib layers fully connected(             inputs net              num outputs hparams local layer size              activation fn tf nn relu              scope  fully connected     (i   1))          hparams dropout rate   0            net   tf layers dropout(               net  hparams dropout rate  training self training)      return net    def build time series hidden layers(self)         builds hidden layers time series features       inputs        self time series features      outputs        self time series hidden layers            copyright 2018 the tensorflow authors        licensed apache license  version 2 0 (the  license )     may use file except compliance license     you may obtain copy license           http   www apache org licenses license 2 0       unless required applicable law agreed writing  software    distributed license distributed  as is  basis     without warranties or conditions of any kind  either express implied     see license specific language governing permissions    limitations license     first layer optionally implemented wide convolution    invariance small translations      batch  length  channels 1     net  batch  length  num filters   length   1      2   translation delta  pool along length dimension     remaining fully connected layers  ", "content": "# Copyright 2018 The TensorFlow Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"A model for classifying light curves using (locally) fully connected layers.\n\nNote that the first layer of each fully connected stack is optionally\nimplemented as a convolution with a wide kernel followed by pooling. This causes\ninvariance to small translations.\n\nSee the base class (in astro_model.py) for a description of the general\nframework of AstroModel and its subclasses.\n\nThe architecture of this model is:\n\n\n                                     predictions\n                                          ^\n                                          |\n                                       logits\n                                          ^\n                                          |\n                                (fully connected layers)\n                                          ^\n                                          |\n                                   pre_logits_concat\n                                          ^\n                                          |\n                                    (concatenate)\n\n              ^                           ^                          ^\n              |                           |                          |\n (locally fully connected 1)  (locally fully connected 2)  ...       |\n              ^                           ^                          |\n              |                           |                          |\n     time_series_feature_1      time_series_feature_2      ...  aux_features\n\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom astronet.astro_model import astro_model\n\n\nclass AstroFCModel(astro_model.AstroModel):\n  \"\"\"A model for classifying light curves using fully connected layers.\"\"\"\n\n  def __init__(self, features, labels, hparams, mode):\n    \"\"\"Basic setup. The actual TensorFlow graph is constructed in build().\n\n    Args:\n      features: A dictionary containing \"time_series_features\" and\n          \"aux_features\", each of which is a dictionary of named input Tensors.\n          All features have dtype float32 and shape [batch_size, length].\n      labels: An int64 Tensor with shape [batch_size]. May be None if mode is\n          tf.estimator.ModeKeys.PREDICT.\n      hparams: A ConfigDict of hyperparameters for building the model.\n      mode: A tf.estimator.ModeKeys to specify whether the graph should be built\n          for training, evaluation or prediction.\n\n    Raises:\n      ValueError: If mode is invalid.\n    \"\"\"\n    super(AstroFCModel, self).__init__(features, labels, hparams, mode)\n\n  def _build_local_fc_layers(self, inputs, hparams, scope):\n    \"\"\"Builds locally fully connected layers.\n\n    Note that the first layer of the fully connected stack is optionally\n    implemented as a convolution with a wide kernel followed by pooling. This\n    makes the fully connected stack invariant to small translations of its\n    input.\n\n    Args:\n      inputs: A Tensor of shape [batch_size, length].\n      hparams: Object containing hyperparameters.\n      scope: Name of the variable scope.\n\n    Returns:\n      A Tensor of shape [batch_size, hparams.local_layer_size].\n\n    Raises:\n      ValueError: If hparams.pooling_type is unrecognized.\n    \"\"\"\n    if hparams.num_local_layers == 0:\n      return inputs\n\n    net = inputs\n    with tf.variable_scope(scope):\n      # First layer is optionally implemented as a wide convolution for\n      # invariance to small translations.\n      if hparams.translation_delta > 0:\n        kernel_size = inputs.shape.as_list()[1] - 2 * hparams.translation_delta\n        net = tf.expand_dims(net, -1)  # [batch, length, channels=1]\n        net = tf.layers.conv1d(\n            inputs=net,\n            filters=hparams.local_layer_size,\n            kernel_size=kernel_size,\n            padding=\"valid\",\n            activation=tf.nn.relu,\n            name=\"conv1d\")\n\n        # net is [batch, length, num_filters], where length = 1 +\n        # 2 * translation_delta. Pool along the length dimension.\n        if hparams.pooling_type == \"max\":\n          net = tf.reduce_max(net, axis=1, name=\"max_pool\")\n        elif hparams.pooling_type == \"avg\":\n          net = tf.reduce_mean(net, axis=1, name=\"avg_pool\")\n        else:\n          raise ValueError(\n              \"Unrecognized pooling_type: %s\" % hparams.pooling_type)\n\n        remaining_layers = hparams.num_local_layers - 1\n      else:\n        remaining_layers = hparams.num_local_layers\n\n      # Remaining fully connected layers.\n      for i in range(remaining_layers):\n        net = tf.contrib.layers.fully_connected(\n            inputs=net,\n            num_outputs=hparams.local_layer_size,\n            activation_fn=tf.nn.relu,\n            scope=\"fully_connected_%d\" % (i + 1))\n\n        if hparams.dropout_rate > 0:\n          net = tf.layers.dropout(\n              net, hparams.dropout_rate, training=self.is_training)\n\n    return net\n\n  def build_time_series_hidden_layers(self):\n    \"\"\"Builds hidden layers for the time series features.\n\n    Inputs:\n      self.time_series_features\n\n    Outputs:\n      self.time_series_hidden_layers\n    \"\"\"\n    time_series_hidden_layers = {}\n    for name, time_series in self.time_series_features.iteritems():\n      time_series_hidden_layers[name] = self._build_local_fc_layers(\n          inputs=time_series,\n          hparams=self.hparams.time_series_hidden[name],\n          scope=name + \"_hidden\")\n\n    self.time_series_hidden_layers = time_series_hidden_layers\n", "description": "Models and examples built with TensorFlow", "file_name": "astro_fc_model.py", "id": "51aa61bec4af75e43a6b216340dff7c8", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/network_test/tensorflow-models/tensorflow-models-086d914/research/astronet/astronet/astro_fc_model/astro_fc_model.py", "save_time": "", "source": "", "update_at": "2018-03-14T01:59:19Z", "url": "https://github.com/tensorflow/models", "wiki": true}