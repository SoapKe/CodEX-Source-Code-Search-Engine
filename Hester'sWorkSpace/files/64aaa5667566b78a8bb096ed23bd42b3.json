{"author": "rushter", "code": "import logging\nfrom itertools import combinations, islice\n\nimport numpy as np\ntry:\n    from sklearn.model_selection import train_test_split\nexcept ImportError:\n    from sklearn.cross_validation import train_test_split\n\nfrom mla.metrics import accuracy\nfrom mla.neuralnet import NeuralNet\nfrom mla.neuralnet.layers import Activation, TimeDistributedDense\nfrom mla.neuralnet.layers.recurrent import LSTM\nfrom mla.neuralnet.optimizers import Adam\n\nlogging.basicConfig(level=logging.DEBUG)\n\n\ndef addition_dataset(dim=10, n_samples=10000, batch_size=64):\n    \n    binary_format = '{:0' + str(dim) + 'b}'\n\n    \n    combs = list(islice(combinations(range(2 ** (dim - 1)), 2), n_samples))\n\n    \n    X = np.zeros((len(combs), dim, 2), dtype=np.uint8)\n    y = np.zeros((len(combs), dim, 1), dtype=np.uint8)\n\n    for i, (a, b) in enumerate(combs):\n        \n        X[i, :, 0] = list(reversed([int(x) for x in binary_format.format(a)]))\n        X[i, :, 1] = list(reversed([int(x) for x in binary_format.format(b)]))\n\n        # Generate target variable (a+b)\n        y[i, :, 0] = list(reversed([int(x) for x in binary_format.format(a + b)]))\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1111)\n\n    \n    train_b = (X_train.shape[0] // batch_size) * batch_size\n    test_b = (X_test.shape[0] // batch_size) * batch_size\n    X_train = X_train[0:train_b]\n    y_train = y_train[0:train_b]\n\n    X_test = X_test[0:test_b]\n    y_test = y_test[0:test_b]\n    return X_train, X_test, y_train, y_test\n\n\ndef addition_problem(ReccurentLayer):\n    X_train, X_test, y_train, y_test = addition_dataset(8, 5000)\n\n    print(X_train.shape, X_test.shape)\n    model = NeuralNet(\n        layers=[\n            ReccurentLayer,\n            TimeDistributedDense(1),\n            Activation('sigmoid'),\n        ],\n        loss='mse',\n        optimizer=Adam(),\n        metric='mse',\n        batch_size=64,\n        max_epochs=15,\n    )\n    model.fit(X_train, y_train)\n    predictions = np.round(model.predict(X_test))\n    predictions = np.packbits(predictions.astype(np.uint8))\n    y_test = np.packbits(y_test.astype(np.int))\n    print(accuracy(y_test, predictions))\n\n\n\n# addition_problem(RNN(16, parameters=Parameters(constraints={'W': SmallNorm(), 'U': SmallNorm()})))\n\naddition_problem(LSTM(16))\n", "comments": "   generate binary addition dataset      http   devankuleindiren com projects rnn arithmetic php            generate possible number combinations    initialize empty arrays    convert numbers binary format    generate target variable (a b)    round number examples batch processing    rnn    addition problem(rnn(16  parameters parameters(constraints   w   smallnorm()   u   smallnorm() )))    lstm ", "content": "import logging\nfrom itertools import combinations, islice\n\nimport numpy as np\ntry:\n    from sklearn.model_selection import train_test_split\nexcept ImportError:\n    from sklearn.cross_validation import train_test_split\n\nfrom mla.metrics import accuracy\nfrom mla.neuralnet import NeuralNet\nfrom mla.neuralnet.layers import Activation, TimeDistributedDense\nfrom mla.neuralnet.layers.recurrent import LSTM\nfrom mla.neuralnet.optimizers import Adam\n\nlogging.basicConfig(level=logging.DEBUG)\n\n\ndef addition_dataset(dim=10, n_samples=10000, batch_size=64):\n    \"\"\"Generate binary addition dataset.\n    http://devankuleindiren.com/Projects/rnn_arithmetic.php\n    \"\"\"\n    binary_format = '{:0' + str(dim) + 'b}'\n\n    # Generate all possible number combinations\n    combs = list(islice(combinations(range(2 ** (dim - 1)), 2), n_samples))\n\n    # Initialize empty arrays\n    X = np.zeros((len(combs), dim, 2), dtype=np.uint8)\n    y = np.zeros((len(combs), dim, 1), dtype=np.uint8)\n\n    for i, (a, b) in enumerate(combs):\n        # Convert numbers to binary format\n        X[i, :, 0] = list(reversed([int(x) for x in binary_format.format(a)]))\n        X[i, :, 1] = list(reversed([int(x) for x in binary_format.format(b)]))\n\n        # Generate target variable (a+b)\n        y[i, :, 0] = list(reversed([int(x) for x in binary_format.format(a + b)]))\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1111)\n\n    # Round number of examples for batch processing\n    train_b = (X_train.shape[0] // batch_size) * batch_size\n    test_b = (X_test.shape[0] // batch_size) * batch_size\n    X_train = X_train[0:train_b]\n    y_train = y_train[0:train_b]\n\n    X_test = X_test[0:test_b]\n    y_test = y_test[0:test_b]\n    return X_train, X_test, y_train, y_test\n\n\ndef addition_problem(ReccurentLayer):\n    X_train, X_test, y_train, y_test = addition_dataset(8, 5000)\n\n    print(X_train.shape, X_test.shape)\n    model = NeuralNet(\n        layers=[\n            ReccurentLayer,\n            TimeDistributedDense(1),\n            Activation('sigmoid'),\n        ],\n        loss='mse',\n        optimizer=Adam(),\n        metric='mse',\n        batch_size=64,\n        max_epochs=15,\n    )\n    model.fit(X_train, y_train)\n    predictions = np.round(model.predict(X_test))\n    predictions = np.packbits(predictions.astype(np.uint8))\n    y_test = np.packbits(y_test.astype(np.int))\n    print(accuracy(y_test, predictions))\n\n\n# RNN\n# addition_problem(RNN(16, parameters=Parameters(constraints={'W': SmallNorm(), 'U': SmallNorm()})))\n# LSTM\naddition_problem(LSTM(16))\n", "description": "Minimal and clean examples of machine learning algorithms", "file_name": "nnet_rnn_binary_add.py", "id": "64aaa5667566b78a8bb096ed23bd42b3", "language": "Python", "project_name": "MLAlgorithms", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/rushter-MLAlgorithms/rushter-MLAlgorithms-d398777/examples/nnet_rnn_binary_add.py", "save_time": "", "source": "", "update_at": "2018-03-18T15:25:48Z", "url": "https://github.com/rushter/MLAlgorithms", "wiki": false}