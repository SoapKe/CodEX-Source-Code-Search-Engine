{"author": "tensorflow", "code": "\n\n  Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License.\n\"\"\"An Example of a custom Estimator for the Iris dataset.\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport tensorflow as tf\n\nimport iris_data\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--batch_size', default=100, type=int, help='batch size')\nparser.add_argument('--train_steps', default=1000, type=int,\n                    help='number of training steps')\n\ndef my_model(features, labels, mode, params):\n    \"\"\"DNN with three hidden layers, and dropout of 0.1 probability.\"\"\"\n     Create three fully connected layers each layer having a dropout\n     probability of 0.1.\n    net = tf.feature_column.input_layer(features, params['feature_columns'])\n    for units in params['hidden_units']:\n        net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n\n     Compute logits (1 per class).\n    logits = tf.layers.dense(net, params['n_classes'], activation=None)\n\n     Compute predictions.\n    predicted_classes = tf.argmax(logits, 1)\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        predictions = {\n            'class_ids': predicted_classes[:, tf.newaxis],\n            'probabilities': tf.nn.softmax(logits),\n            'logits': logits,\n        }\n        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\n     Compute loss.\n    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\n     Compute evaluation metrics.\n    accuracy = tf.metrics.accuracy(labels=labels,\n                                   predictions=predicted_classes,\n                                   name='acc_op')\n    metrics = {'accuracy': accuracy}\n    tf.summary.scalar('accuracy', accuracy[1])\n\n    if mode == tf.estimator.ModeKeys.EVAL:\n        return tf.estimator.EstimatorSpec(\n            mode, loss=loss, eval_metric_ops=metrics)\n\n     Create training op.\n    assert mode == tf.estimator.ModeKeys.TRAIN\n\n    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n\n\ndef main(argv):\n    args = parser.parse_args(argv[1:])\n\n     Fetch the data\n    (train_x, train_y), (test_x, test_y) = iris_data.load_data()\n\n     Feature columns describe how to use the input.\n    my_feature_columns = []\n    for key in train_x.keys():\n        my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n\n     Build 2 hidden layer DNN with 10, 10 units respectively.\n    classifier = tf.estimator.Estimator(\n        model_fn=my_model,\n        params={\n            'feature_columns': my_feature_columns,\n             Two hidden layers of 10 nodes each.\n            'hidden_units': [10, 10],\n             The model must choose between 3 classes.\n            'n_classes': 3,\n        })\n\n     Train the Model.\n    classifier.train(\n        input_fn=lambda:iris_data.train_input_fn(train_x, train_y, args.batch_size),\n        steps=args.train_steps)\n\n     Evaluate the model.\n    eval_result = classifier.evaluate(\n        input_fn=lambda:iris_data.eval_input_fn(test_x, test_y, args.batch_size))\n\n    print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n\n     Generate predictions from the model\n    expected = ['Setosa', 'Versicolor', 'Virginica']\n    predict_x = {\n        'SepalLength': [5.1, 5.9, 6.9],\n        'SepalWidth': [3.3, 3.0, 3.1],\n        'PetalLength': [1.7, 4.2, 5.4],\n        'PetalWidth': [0.5, 1.5, 2.1],\n    }\n\n    predictions = classifier.predict(\n        input_fn=lambda:iris_data.eval_input_fn(predict_x,\n                                                labels=None,\n                                                batch_size=args.batch_size))\n\n    for pred_dict, expec in zip(predictions, expected):\n        template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n\n        class_id = pred_dict['class_ids'][0]\n        probability = pred_dict['probabilities'][class_id]\n\n        print(template.format(iris_data.SPECIES[class_id],\n                              100 * probability, expec))\n\n\nif __name__ == '__main__':\n    tf.logging.set_verbosity(tf.logging.INFO)\n    tf.app.run(main)\n", "comments": "   an example custom estimator iris dataset       future   import absolute import   future   import division   future   import print function  import argparse import tensorflow tf  import iris data  parser   argparse argumentparser() parser add argument(   batch size   default 100  type int  help  batch size ) parser add argument(   train steps   default 1000  type int                      help  number training steps )  def model(features  labels  mode  params)         dnn three hidden layers  dropout 0 1 probability         copyright 2016 the tensorflow authors  all rights reserved         licensed apache license  version 2 0 (the  license )      may use file except compliance license      you may obtain copy license         http   www apache org licenses license 2 0        unless required applicable law agreed writing  software     distributed license distributed  as is  basis      without warranties or conditions of any kind  either express implied      see license specific language governing permissions     limitations license     create three fully connected layers layer dropout    probability 0 1     compute logits (1 per class)     compute predictions     compute loss     compute evaluation metrics     create training op     fetch data    feature columns describe use input     build 2 hidden layer dnn 10  10 units respectively     two hidden layers 10 nodes     the model must choose 3 classes     train model     evaluate model     generate predictions model ", "content": "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n#  Licensed under the Apache License, Version 2.0 (the \"License\");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n\"\"\"An Example of a custom Estimator for the Iris dataset.\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport tensorflow as tf\n\nimport iris_data\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--batch_size', default=100, type=int, help='batch size')\nparser.add_argument('--train_steps', default=1000, type=int,\n                    help='number of training steps')\n\ndef my_model(features, labels, mode, params):\n    \"\"\"DNN with three hidden layers, and dropout of 0.1 probability.\"\"\"\n    # Create three fully connected layers each layer having a dropout\n    # probability of 0.1.\n    net = tf.feature_column.input_layer(features, params['feature_columns'])\n    for units in params['hidden_units']:\n        net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n\n    # Compute logits (1 per class).\n    logits = tf.layers.dense(net, params['n_classes'], activation=None)\n\n    # Compute predictions.\n    predicted_classes = tf.argmax(logits, 1)\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        predictions = {\n            'class_ids': predicted_classes[:, tf.newaxis],\n            'probabilities': tf.nn.softmax(logits),\n            'logits': logits,\n        }\n        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\n    # Compute loss.\n    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\n    # Compute evaluation metrics.\n    accuracy = tf.metrics.accuracy(labels=labels,\n                                   predictions=predicted_classes,\n                                   name='acc_op')\n    metrics = {'accuracy': accuracy}\n    tf.summary.scalar('accuracy', accuracy[1])\n\n    if mode == tf.estimator.ModeKeys.EVAL:\n        return tf.estimator.EstimatorSpec(\n            mode, loss=loss, eval_metric_ops=metrics)\n\n    # Create training op.\n    assert mode == tf.estimator.ModeKeys.TRAIN\n\n    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n\n\ndef main(argv):\n    args = parser.parse_args(argv[1:])\n\n    # Fetch the data\n    (train_x, train_y), (test_x, test_y) = iris_data.load_data()\n\n    # Feature columns describe how to use the input.\n    my_feature_columns = []\n    for key in train_x.keys():\n        my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n\n    # Build 2 hidden layer DNN with 10, 10 units respectively.\n    classifier = tf.estimator.Estimator(\n        model_fn=my_model,\n        params={\n            'feature_columns': my_feature_columns,\n            # Two hidden layers of 10 nodes each.\n            'hidden_units': [10, 10],\n            # The model must choose between 3 classes.\n            'n_classes': 3,\n        })\n\n    # Train the Model.\n    classifier.train(\n        input_fn=lambda:iris_data.train_input_fn(train_x, train_y, args.batch_size),\n        steps=args.train_steps)\n\n    # Evaluate the model.\n    eval_result = classifier.evaluate(\n        input_fn=lambda:iris_data.eval_input_fn(test_x, test_y, args.batch_size))\n\n    print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n\n    # Generate predictions from the model\n    expected = ['Setosa', 'Versicolor', 'Virginica']\n    predict_x = {\n        'SepalLength': [5.1, 5.9, 6.9],\n        'SepalWidth': [3.3, 3.0, 3.1],\n        'PetalLength': [1.7, 4.2, 5.4],\n        'PetalWidth': [0.5, 1.5, 2.1],\n    }\n\n    predictions = classifier.predict(\n        input_fn=lambda:iris_data.eval_input_fn(predict_x,\n                                                labels=None,\n                                                batch_size=args.batch_size))\n\n    for pred_dict, expec in zip(predictions, expected):\n        template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n\n        class_id = pred_dict['class_ids'][0]\n        probability = pred_dict['probabilities'][class_id]\n\n        print(template.format(iris_data.SPECIES[class_id],\n                              100 * probability, expec))\n\n\nif __name__ == '__main__':\n    tf.logging.set_verbosity(tf.logging.INFO)\n    tf.app.run(main)\n", "description": "Models and examples built with TensorFlow", "file_name": "custom_estimator.py", "id": "d18f4c2c1d5b559c7bba693aa17fa8e2", "language": "Python", "project_name": "models", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/tensorflow-models/tensorflow-models-7e4c66b/samples/core/get_started/custom_estimator.py", "save_time": "", "source": "", "update_at": "2018-03-18T13:59:36Z", "url": "https://github.com/tensorflow/models", "wiki": true}