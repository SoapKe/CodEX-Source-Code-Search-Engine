{"author": "yunjey", "code": "import os\nfrom torch.utils import data\nfrom torchvision import transforms\nfrom PIL import Image\n\n\nclass ImageFolder(data.Dataset):\n    \"\"\"Custom Dataset compatible with prebuilt DataLoader.\n    \n    This is just for tutorial. You can use the prebuilt torchvision.datasets.ImageFolder.\n    \"\"\"\n    def __init__(self, root, transform=None):\n        \"\"\"Initializes image paths and preprocessing module.\"\"\"\n        self.image_paths = list(map(lambda x: os.path.join(root, x), os.listdir(root)))\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        \"\"\"Reads an image from a file and preprocesses it and returns.\"\"\"\n        image_path = self.image_paths[index]\n        image = Image.open(image_path).convert('RGB')\n        if self.transform is not None:\n            image = self.transform(image)\n        return image\n    \n    def __len__(self):\n        \"\"\"Returns the total number of image files.\"\"\"\n        return len(self.image_paths)\n\n    \ndef get_loader(image_path, image_size, batch_size, num_workers=2):\n    \"\"\"Builds and returns Dataloader.\"\"\"\n    \n    transform = transforms.Compose([\n                    transforms.Scale(image_size),\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n    \n    dataset = ImageFolder(image_path, transform)\n    data_loader = data.DataLoader(dataset=dataset,\n                                  batch_size=batch_size,\n                                  shuffle=True,\n                                  num_workers=num_workers)\n    return data_loader", "comments": "   custom dataset compatible prebuilt dataloader           this tutorial  you use prebuilt torchvision datasets imagefolder              def   init  (self  root  transform none)             initializes image paths preprocessing module             self image paths   list(map(lambda x  os path join(root  x)  os listdir(root)))         self transform   transform              def   getitem  (self  index)             reads image file preprocesses returns             image path   self image paths index          image   image open(image path) convert( rgb )         self transform none              image   self transform(image)         return image          def   len  (self)             returns total number image files             return len(self image paths)       def get loader(image path  image size  batch size  num workers 2)         builds returns dataloader     ", "content": "import os\nfrom torch.utils import data\nfrom torchvision import transforms\nfrom PIL import Image\n\n\nclass ImageFolder(data.Dataset):\n    \"\"\"Custom Dataset compatible with prebuilt DataLoader.\n    \n    This is just for tutorial. You can use the prebuilt torchvision.datasets.ImageFolder.\n    \"\"\"\n    def __init__(self, root, transform=None):\n        \"\"\"Initializes image paths and preprocessing module.\"\"\"\n        self.image_paths = list(map(lambda x: os.path.join(root, x), os.listdir(root)))\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        \"\"\"Reads an image from a file and preprocesses it and returns.\"\"\"\n        image_path = self.image_paths[index]\n        image = Image.open(image_path).convert('RGB')\n        if self.transform is not None:\n            image = self.transform(image)\n        return image\n    \n    def __len__(self):\n        \"\"\"Returns the total number of image files.\"\"\"\n        return len(self.image_paths)\n\n    \ndef get_loader(image_path, image_size, batch_size, num_workers=2):\n    \"\"\"Builds and returns Dataloader.\"\"\"\n    \n    transform = transforms.Compose([\n                    transforms.Scale(image_size),\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n    \n    dataset = ImageFolder(image_path, transform)\n    data_loader = data.DataLoader(dataset=dataset,\n                                  batch_size=batch_size,\n                                  shuffle=True,\n                                  num_workers=num_workers)\n    return data_loader", "description": "PyTorch Tutorial for Deep Learning Researchers", "file_name": "data_loader.py", "id": "510985d08ecdce8aa679195f17cd4bb9", "language": "Python", "project_name": "pytorch-tutorial", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/yunjey-pytorch-tutorial/yunjey-pytorch-tutorial-6c785eb/tutorials/03-advanced/deep_convolutional_gan/data_loader.py", "save_time": "", "source": "", "update_at": "2018-03-18T14:24:45Z", "url": "https://github.com/yunjey/pytorch-tutorial", "wiki": true}