{"author": "aws", "code": "\n\n\n Licensed under the Apache License, Version 2.0 (the \"License\"). You\n may not use this file except in compliance with the License. A copy of\n the License is located at\n\n     http://aws.amazon.com/apache2.0/\n\n or in the \"license\" file accompanying this file. This file is\n distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n ANY KIND, either express or implied. See the License for the specific\n language governing permissions and limitations under the License.\nfrom awscli.testutils import BaseAWSCommandParamsTest\nfrom dateutil import parser, tz\n\n\nclass TestLSCommand(BaseAWSCommandParamsTest):\n\n    def test_operations_used_in_recursive_list(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [{\"CommonPrefixes\": [], \"Contents\": [\n            {\"Key\": \"foo/bar.txt\", \"Size\": 100,\n             \"LastModified\": time_utc}]}]\n        stdout, _, _ = self.run_cmd('s3 ls s3://bucket/ --recursive', expected_rc=0)\n        call_args = self.operations_called[0][1]\n         We should not be calling the args with any delimiter because we\n         want a recursive listing.\n        self.assertEqual(call_args['Prefix'], '')\n        self.assertEqual(call_args['Bucket'], 'bucket')\n        self.assertNotIn('delimiter', call_args)\n         Time is stored in UTC timezone, but the actual time displayed\n         is specific to your tzinfo, so shift the timezone to your local's.\n        time_local = parser.parse(time_utc).astimezone(tz.tzlocal())\n        self.assertEqual(\n            stdout, '%s        100 foo/bar.txt\\n'%time_local.strftime('%Y-%m-%d %H:%M:%S'))\n\n    def test_errors_out_with_extra_arguments(self):\n        stderr = self.run_cmd('s3 ls --extra-argument-foo', expected_rc=255)[1]\n        self.assertIn('Unknown options', stderr)\n        self.assertIn('--extra-argument-foo', stderr)\n\n    def test_operations_use_page_size(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [{\"CommonPrefixes\": [], \"Contents\": [\n            {\"Key\": \"foo/bar.txt\", \"Size\": 100,\n             \"LastModified\": time_utc}]}]\n        stdout, _, _ = self.run_cmd('s3 ls s3://bucket/ --page-size 8', expected_rc=0)\n        call_args = self.operations_called[0][1]\n         We should not be calling the args with any delimiter because we\n         want a recursive listing.\n        self.assertEqual(call_args['Prefix'], '')\n        self.assertEqual(call_args['Bucket'], 'bucket')\n         The page size gets translated to ``MaxKeys`` in the s3 model\n        self.assertEqual(call_args['MaxKeys'], 8)\n\n    def test_operations_use_page_size_recursive(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [{\"CommonPrefixes\": [], \"Contents\": [\n            {\"Key\": \"foo/bar.txt\", \"Size\": 100,\n             \"LastModified\": time_utc}]}]\n        stdout, _, _ = self.run_cmd('s3 ls s3://bucket/ --page-size 8 --recursive', expected_rc=0)\n        call_args = self.operations_called[0][1]\n         We should not be calling the args with any delimiter because we\n         want a recursive listing.\n        self.assertEqual(call_args['Prefix'], '')\n        self.assertEqual(call_args['Bucket'], 'bucket')\n         The page size gets translated to ``MaxKeys`` in the s3 model\n        self.assertEqual(call_args['MaxKeys'], 8)\n        self.assertNotIn('Delimiter', call_args)\n\n    def test_success_rc_has_prefixes_and_objects(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [\n            {\"CommonPrefixes\": [{\"Prefix\": \"foo/\"}],\n             \"Contents\": [{\"Key\": \"foo/bar.txt\", \"Size\": 100,\n                           \"LastModified\": time_utc}]}\n        ]\n        self.run_cmd('s3 ls s3://bucket/foo', expected_rc=0)\n\n    def test_success_rc_has_only_prefixes(self):\n        self.parsed_responses = [\n            {\"CommonPrefixes\": [{\"Prefix\": \"foo/\"}]}\n        ]\n        self.run_cmd('s3 ls s3://bucket/foo', expected_rc=0)\n\n    def test_success_rc_has_only_objects(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [\n            {\"Contents\": [{\"Key\": \"foo/bar.txt\", \"Size\": 100,\n             \"LastModified\": time_utc}]}\n        ]\n        self.run_cmd('s3 ls s3://bucket/foo', expected_rc=0)\n\n    def test_success_rc_with_pagination(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n         Pagination should not affect a successful return code of zero, even\n         if there are no results on the second page because there were\n         results in previous pages.\n        self.parsed_responses = [\n            {\"CommonPrefixes\": [{\"Prefix\": \"foo/\"}],\n             \"Contents\": [{\"Key\": \"foo/bar.txt\", \"Size\": 100,\n                           \"LastModified\": time_utc}]},\n            {}\n        ]\n        self.run_cmd('s3 ls s3://bucket/foo', expected_rc=0)\n\n    def test_success_rc_empty_bucket_no_key_given(self):\n         If no key has been provdided and the bucket is empty, it should\n         still return an rc of 0 since the user is not looking for an actual\n         object.\n        self.parsed_responses = [{}]\n        self.run_cmd('s3 ls s3://bucket', expected_rc=0)\n\n    def test_fail_rc_no_objects_nor_prefixes(self):\n        self.parsed_responses = [{}]\n        self.run_cmd('s3 ls s3://bucket/foo', expected_rc=1)\n\n    def test_human_readable_file_size(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [{\"CommonPrefixes\": [], \"Contents\": [\n            {\"Key\": \"onebyte.txt\", \"Size\": 1, \"LastModified\": time_utc},\n            {\"Key\": \"onekilobyte.txt\", \"Size\": 1024, \"LastModified\": time_utc},\n            {\"Key\": \"onemegabyte.txt\", \"Size\": 1024 ** 2, \"LastModified\": time_utc},\n            {\"Key\": \"onegigabyte.txt\", \"Size\": 1024 ** 3, \"LastModified\": time_utc},\n            {\"Key\": \"oneterabyte.txt\", \"Size\": 1024 ** 4, \"LastModified\": time_utc},\n            {\"Key\": \"onepetabyte.txt\", \"Size\": 1024 ** 5, \"LastModified\": time_utc} ]}]\n        stdout, _, _ = self.run_cmd('s3 ls s3://bucket/ --human-readable',\n                                    expected_rc=0)\n        call_args = self.operations_called[0][1]\n         Time is stored in UTC timezone, but the actual time displayed\n         is specific to your tzinfo, so shift the timezone to your local's.\n        time_local = parser.parse(time_utc).astimezone(tz.tzlocal())\n        time_fmt = time_local.strftime('%Y-%m-%d %H:%M:%S')\n        self.assertIn('%s     1 Byte onebyte.txt\\n' % time_fmt, stdout)\n        self.assertIn('%s    1.0 KiB onekilobyte.txt\\n' % time_fmt, stdout)\n        self.assertIn('%s    1.0 MiB onemegabyte.txt\\n' % time_fmt, stdout)\n        self.assertIn('%s    1.0 GiB onegigabyte.txt\\n' % time_fmt, stdout)\n        self.assertIn('%s    1.0 TiB oneterabyte.txt\\n' % time_fmt, stdout)\n        self.assertIn('%s    1.0 PiB onepetabyte.txt\\n' % time_fmt, stdout)\n\n    def test_summarize(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [{\"CommonPrefixes\": [], \"Contents\": [\n            {\"Key\": \"onebyte.txt\", \"Size\": 1, \"LastModified\": time_utc},\n            {\"Key\": \"onekilobyte.txt\", \"Size\": 1024, \"LastModified\": time_utc},\n            {\"Key\": \"onemegabyte.txt\", \"Size\": 1024 ** 2, \"LastModified\": time_utc},\n            {\"Key\": \"onegigabyte.txt\", \"Size\": 1024 ** 3, \"LastModified\": time_utc},\n            {\"Key\": \"oneterabyte.txt\", \"Size\": 1024 ** 4, \"LastModified\": time_utc},\n            {\"Key\": \"onepetabyte.txt\", \"Size\": 1024 ** 5, \"LastModified\": time_utc} ]}]\n        stdout, _, _ = self.run_cmd('s3 ls s3://bucket/ --summarize', expected_rc=0)\n        call_args = self.operations_called[0][1]\n         Time is stored in UTC timezone, but the actual time displayed\n         is specific to your tzinfo, so shift the timezone to your local's.\n        time_local = parser.parse(time_utc).astimezone(tz.tzlocal())\n        time_fmt = time_local.strftime('%Y-%m-%d %H:%M:%S')\n        self.assertIn('Total Objects: 6\\n', stdout)\n        self.assertIn('Total Size: 1127000493261825\\n', stdout)\n\n    def test_summarize_with_human_readable(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [{\"CommonPrefixes\": [], \"Contents\": [\n            {\"Key\": \"onebyte.txt\", \"Size\": 1, \"LastModified\": time_utc},\n            {\"Key\": \"onekilobyte.txt\", \"Size\": 1024, \"LastModified\": time_utc},\n            {\"Key\": \"onemegabyte.txt\", \"Size\": 1024 ** 2, \"LastModified\": time_utc},\n            {\"Key\": \"onegigabyte.txt\", \"Size\": 1024 ** 3, \"LastModified\": time_utc},\n            {\"Key\": \"oneterabyte.txt\", \"Size\": 1024 ** 4, \"LastModified\": time_utc},\n            {\"Key\": \"onepetabyte.txt\", \"Size\": 1024 ** 5, \"LastModified\": time_utc} ]}]\n        stdout, _, _ = self.run_cmd('s3 ls s3://bucket/ --human-readable --summarize', expected_rc=0)\n        call_args = self.operations_called[0][1]\n         Time is stored in UTC timezone, but the actual time displayed\n         is specific to your tzinfo, so shift the timezone to your local's.\n        time_local = parser.parse(time_utc).astimezone(tz.tzlocal())\n        time_fmt = time_local.strftime('%Y-%m-%d %H:%M:%S')\n        self.assertIn('Total Objects: 6\\n', stdout)\n        self.assertIn('Total Size: 1.0 PiB\\n', stdout)\n\n    def test_requester_pays(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [{\"CommonPrefixes\": [], \"Contents\": [\n            {\"Key\": \"onebyte.txt\", \"Size\": 1, \"LastModified\": time_utc},\n        ]}]\n        command = 's3 ls s3://mybucket/foo/ --request-payer requester'\n        self.assert_params_for_cmd(command, {\n            'Bucket': 'mybucket', 'Delimiter': '/',\n            'RequestPayer': 'requester', 'EncodingType': 'url',\n            'Prefix': 'foo/'\n        })\n\n    def test_requester_pays_with_no_args(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [{\"CommonPrefixes\": [], \"Contents\": [\n            {\"Key\": \"onebyte.txt\", \"Size\": 1, \"LastModified\": time_utc},\n        ]}]\n        command = 's3 ls s3://mybucket/foo/ --request-payer'\n        self.assert_params_for_cmd(command, {\n            'Bucket': 'mybucket', 'Delimiter': '/',\n            'RequestPayer': 'requester', 'EncodingType': 'url',\n            'Prefix': 'foo/'\n        })\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n", "comments": "   usr bin env python    copyright 2014 amazon com  inc  affiliates  all rights reserved        licensed apache license  version 2 0 (the  license )  you    may use file except compliance license  a copy    license located           http   aws amazon com apache2 0         license  file accompanying file  this file    distributed  as is  basis  without warranties or conditions of    any kind  either express implied  see license specific    language governing permissions limitations license     we calling args delimiter    want recursive listing     time stored utc timezone  actual time displayed    specific tzinfo  shift timezone local     we calling args delimiter    want recursive listing     the page size gets translated   maxkeys   s3 model    we calling args delimiter    want recursive listing     the page size gets translated   maxkeys   s3 model    pagination affect successful return code zero  even    results second page    results previous pages     if key provdided bucket empty     still return rc 0 since user looking actual    object     time stored utc timezone  actual time displayed    specific tzinfo  shift timezone local     time stored utc timezone  actual time displayed    specific tzinfo  shift timezone local     time stored utc timezone  actual time displayed    specific tzinfo  shift timezone local  ", "content": "#!/usr/bin/env python\n# Copyright 2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom awscli.testutils import BaseAWSCommandParamsTest\nfrom dateutil import parser, tz\n\n\nclass TestLSCommand(BaseAWSCommandParamsTest):\n\n    def test_operations_used_in_recursive_list(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [{\"CommonPrefixes\": [], \"Contents\": [\n            {\"Key\": \"foo/bar.txt\", \"Size\": 100,\n             \"LastModified\": time_utc}]}]\n        stdout, _, _ = self.run_cmd('s3 ls s3://bucket/ --recursive', expected_rc=0)\n        call_args = self.operations_called[0][1]\n        # We should not be calling the args with any delimiter because we\n        # want a recursive listing.\n        self.assertEqual(call_args['Prefix'], '')\n        self.assertEqual(call_args['Bucket'], 'bucket')\n        self.assertNotIn('delimiter', call_args)\n        # Time is stored in UTC timezone, but the actual time displayed\n        # is specific to your tzinfo, so shift the timezone to your local's.\n        time_local = parser.parse(time_utc).astimezone(tz.tzlocal())\n        self.assertEqual(\n            stdout, '%s        100 foo/bar.txt\\n'%time_local.strftime('%Y-%m-%d %H:%M:%S'))\n\n    def test_errors_out_with_extra_arguments(self):\n        stderr = self.run_cmd('s3 ls --extra-argument-foo', expected_rc=255)[1]\n        self.assertIn('Unknown options', stderr)\n        self.assertIn('--extra-argument-foo', stderr)\n\n    def test_operations_use_page_size(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [{\"CommonPrefixes\": [], \"Contents\": [\n            {\"Key\": \"foo/bar.txt\", \"Size\": 100,\n             \"LastModified\": time_utc}]}]\n        stdout, _, _ = self.run_cmd('s3 ls s3://bucket/ --page-size 8', expected_rc=0)\n        call_args = self.operations_called[0][1]\n        # We should not be calling the args with any delimiter because we\n        # want a recursive listing.\n        self.assertEqual(call_args['Prefix'], '')\n        self.assertEqual(call_args['Bucket'], 'bucket')\n        # The page size gets translated to ``MaxKeys`` in the s3 model\n        self.assertEqual(call_args['MaxKeys'], 8)\n\n    def test_operations_use_page_size_recursive(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [{\"CommonPrefixes\": [], \"Contents\": [\n            {\"Key\": \"foo/bar.txt\", \"Size\": 100,\n             \"LastModified\": time_utc}]}]\n        stdout, _, _ = self.run_cmd('s3 ls s3://bucket/ --page-size 8 --recursive', expected_rc=0)\n        call_args = self.operations_called[0][1]\n        # We should not be calling the args with any delimiter because we\n        # want a recursive listing.\n        self.assertEqual(call_args['Prefix'], '')\n        self.assertEqual(call_args['Bucket'], 'bucket')\n        # The page size gets translated to ``MaxKeys`` in the s3 model\n        self.assertEqual(call_args['MaxKeys'], 8)\n        self.assertNotIn('Delimiter', call_args)\n\n    def test_success_rc_has_prefixes_and_objects(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [\n            {\"CommonPrefixes\": [{\"Prefix\": \"foo/\"}],\n             \"Contents\": [{\"Key\": \"foo/bar.txt\", \"Size\": 100,\n                           \"LastModified\": time_utc}]}\n        ]\n        self.run_cmd('s3 ls s3://bucket/foo', expected_rc=0)\n\n    def test_success_rc_has_only_prefixes(self):\n        self.parsed_responses = [\n            {\"CommonPrefixes\": [{\"Prefix\": \"foo/\"}]}\n        ]\n        self.run_cmd('s3 ls s3://bucket/foo', expected_rc=0)\n\n    def test_success_rc_has_only_objects(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [\n            {\"Contents\": [{\"Key\": \"foo/bar.txt\", \"Size\": 100,\n             \"LastModified\": time_utc}]}\n        ]\n        self.run_cmd('s3 ls s3://bucket/foo', expected_rc=0)\n\n    def test_success_rc_with_pagination(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        # Pagination should not affect a successful return code of zero, even\n        # if there are no results on the second page because there were\n        # results in previous pages.\n        self.parsed_responses = [\n            {\"CommonPrefixes\": [{\"Prefix\": \"foo/\"}],\n             \"Contents\": [{\"Key\": \"foo/bar.txt\", \"Size\": 100,\n                           \"LastModified\": time_utc}]},\n            {}\n        ]\n        self.run_cmd('s3 ls s3://bucket/foo', expected_rc=0)\n\n    def test_success_rc_empty_bucket_no_key_given(self):\n        # If no key has been provdided and the bucket is empty, it should\n        # still return an rc of 0 since the user is not looking for an actual\n        # object.\n        self.parsed_responses = [{}]\n        self.run_cmd('s3 ls s3://bucket', expected_rc=0)\n\n    def test_fail_rc_no_objects_nor_prefixes(self):\n        self.parsed_responses = [{}]\n        self.run_cmd('s3 ls s3://bucket/foo', expected_rc=1)\n\n    def test_human_readable_file_size(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [{\"CommonPrefixes\": [], \"Contents\": [\n            {\"Key\": \"onebyte.txt\", \"Size\": 1, \"LastModified\": time_utc},\n            {\"Key\": \"onekilobyte.txt\", \"Size\": 1024, \"LastModified\": time_utc},\n            {\"Key\": \"onemegabyte.txt\", \"Size\": 1024 ** 2, \"LastModified\": time_utc},\n            {\"Key\": \"onegigabyte.txt\", \"Size\": 1024 ** 3, \"LastModified\": time_utc},\n            {\"Key\": \"oneterabyte.txt\", \"Size\": 1024 ** 4, \"LastModified\": time_utc},\n            {\"Key\": \"onepetabyte.txt\", \"Size\": 1024 ** 5, \"LastModified\": time_utc} ]}]\n        stdout, _, _ = self.run_cmd('s3 ls s3://bucket/ --human-readable',\n                                    expected_rc=0)\n        call_args = self.operations_called[0][1]\n        # Time is stored in UTC timezone, but the actual time displayed\n        # is specific to your tzinfo, so shift the timezone to your local's.\n        time_local = parser.parse(time_utc).astimezone(tz.tzlocal())\n        time_fmt = time_local.strftime('%Y-%m-%d %H:%M:%S')\n        self.assertIn('%s     1 Byte onebyte.txt\\n' % time_fmt, stdout)\n        self.assertIn('%s    1.0 KiB onekilobyte.txt\\n' % time_fmt, stdout)\n        self.assertIn('%s    1.0 MiB onemegabyte.txt\\n' % time_fmt, stdout)\n        self.assertIn('%s    1.0 GiB onegigabyte.txt\\n' % time_fmt, stdout)\n        self.assertIn('%s    1.0 TiB oneterabyte.txt\\n' % time_fmt, stdout)\n        self.assertIn('%s    1.0 PiB onepetabyte.txt\\n' % time_fmt, stdout)\n\n    def test_summarize(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [{\"CommonPrefixes\": [], \"Contents\": [\n            {\"Key\": \"onebyte.txt\", \"Size\": 1, \"LastModified\": time_utc},\n            {\"Key\": \"onekilobyte.txt\", \"Size\": 1024, \"LastModified\": time_utc},\n            {\"Key\": \"onemegabyte.txt\", \"Size\": 1024 ** 2, \"LastModified\": time_utc},\n            {\"Key\": \"onegigabyte.txt\", \"Size\": 1024 ** 3, \"LastModified\": time_utc},\n            {\"Key\": \"oneterabyte.txt\", \"Size\": 1024 ** 4, \"LastModified\": time_utc},\n            {\"Key\": \"onepetabyte.txt\", \"Size\": 1024 ** 5, \"LastModified\": time_utc} ]}]\n        stdout, _, _ = self.run_cmd('s3 ls s3://bucket/ --summarize', expected_rc=0)\n        call_args = self.operations_called[0][1]\n        # Time is stored in UTC timezone, but the actual time displayed\n        # is specific to your tzinfo, so shift the timezone to your local's.\n        time_local = parser.parse(time_utc).astimezone(tz.tzlocal())\n        time_fmt = time_local.strftime('%Y-%m-%d %H:%M:%S')\n        self.assertIn('Total Objects: 6\\n', stdout)\n        self.assertIn('Total Size: 1127000493261825\\n', stdout)\n\n    def test_summarize_with_human_readable(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [{\"CommonPrefixes\": [], \"Contents\": [\n            {\"Key\": \"onebyte.txt\", \"Size\": 1, \"LastModified\": time_utc},\n            {\"Key\": \"onekilobyte.txt\", \"Size\": 1024, \"LastModified\": time_utc},\n            {\"Key\": \"onemegabyte.txt\", \"Size\": 1024 ** 2, \"LastModified\": time_utc},\n            {\"Key\": \"onegigabyte.txt\", \"Size\": 1024 ** 3, \"LastModified\": time_utc},\n            {\"Key\": \"oneterabyte.txt\", \"Size\": 1024 ** 4, \"LastModified\": time_utc},\n            {\"Key\": \"onepetabyte.txt\", \"Size\": 1024 ** 5, \"LastModified\": time_utc} ]}]\n        stdout, _, _ = self.run_cmd('s3 ls s3://bucket/ --human-readable --summarize', expected_rc=0)\n        call_args = self.operations_called[0][1]\n        # Time is stored in UTC timezone, but the actual time displayed\n        # is specific to your tzinfo, so shift the timezone to your local's.\n        time_local = parser.parse(time_utc).astimezone(tz.tzlocal())\n        time_fmt = time_local.strftime('%Y-%m-%d %H:%M:%S')\n        self.assertIn('Total Objects: 6\\n', stdout)\n        self.assertIn('Total Size: 1.0 PiB\\n', stdout)\n\n    def test_requester_pays(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [{\"CommonPrefixes\": [], \"Contents\": [\n            {\"Key\": \"onebyte.txt\", \"Size\": 1, \"LastModified\": time_utc},\n        ]}]\n        command = 's3 ls s3://mybucket/foo/ --request-payer requester'\n        self.assert_params_for_cmd(command, {\n            'Bucket': 'mybucket', 'Delimiter': '/',\n            'RequestPayer': 'requester', 'EncodingType': 'url',\n            'Prefix': 'foo/'\n        })\n\n    def test_requester_pays_with_no_args(self):\n        time_utc = \"2014-01-09T20:45:49.000Z\"\n        self.parsed_responses = [{\"CommonPrefixes\": [], \"Contents\": [\n            {\"Key\": \"onebyte.txt\", \"Size\": 1, \"LastModified\": time_utc},\n        ]}]\n        command = 's3 ls s3://mybucket/foo/ --request-payer'\n        self.assert_params_for_cmd(command, {\n            'Bucket': 'mybucket', 'Delimiter': '/',\n            'RequestPayer': 'requester', 'EncodingType': 'url',\n            'Prefix': 'foo/'\n        })\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n", "description": "Universal Command Line Interface for Amazon Web Services", "file_name": "test_ls_command.py", "id": "3b82f0b61cc6f4c54732c4ad9f0b754c", "language": "Python", "project_name": "aws-cli", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/aws-aws-cli/aws-aws-cli-d705c60/tests/functional/s3/test_ls_command.py", "save_time": "", "source": "", "update_at": "2018-03-18T15:33:26Z", "url": "https://github.com/aws/aws-cli", "wiki": false}