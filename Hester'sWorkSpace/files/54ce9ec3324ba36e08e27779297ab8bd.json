{"author": "chiphuyen", "code": "\"\"\" Starter code for simple linear regression example using placeholders\nCreated by Chip Huyen (huyenn@cs.stanford.edu)\nCS20: \"TensorFlow for Deep Learning Research\"\ncs20.stanford.edu\nLecture 03\n\"\"\"\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL']='2'\nimport time\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nimport utils\n\nDATA_FILE = 'data/birth_life_2010.txt'\n\n\ndata, n_samples = utils.read_birth_life_data(DATA_FILE)\n\n# Step 2: create placeholders for X (birth rate) and Y (life expectancy)\n\nX, Y = None, None\n\n\n\n\n\n\nw, b = None, None\n\n\n\n\n\n\nY_predicted = None\n\n\n\n\n\nloss = None\n\n\n\n\n\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n\nstart = time.time()\n\n\n\n\n\n\nwith tf.Session() as sess:\n    \n    \n    \n    \n\n    \n    for i in range(100):\n        total_loss = 0\n        for x, y in data:\n            \n            \n            _, loss = \n            total_loss += loss\n\n        print('Epoch {0}: {1}'.format(i, total_loss/n_samples))\n\n    \n    \n    \n    \n    writer.close()\n    \n    \n    w_out, b_out = None, None\n    \n    \n    \n\nprint('Took: %f seconds' %(time.time() - start))\n\n\n# plt.plot(data[:,0], data[:,1], 'bo', label='Real data')\n# plt.plot(data[:,0], data[:,0] * w_out + b_out, 'r', label='Predicted data')\n()\n# plt.show()", "comments": "    starter code simple linear regression example using placeholders created chip huyen (huyenn cs stanford edu) cs20   tensorflow deep learning research  cs20 stanford edu lecture 03        step 1  read data  txt file    step 2  create placeholders x (birth rate) y (life expectancy)    remember x y scalars type float                                            to do                                                step 3  create weight bias  initialized 0 0    make sure use tf get variable                                            to do                                                step 4  build model predict y    e g  would derive y predicted given x  w  b                                            to do                                                step 5  use square error loss function                                            to do                                                step 6  using gradient descent learning rate 0 001 minimize loss    create filewriter write model graph tensorboard                                            to do                                                step 7  initialize necessary variables  case  w b                                            to do                                                step 8  train model 100 epochs    execute train op get value loss     don forget feed data placeholders             to do                 close writer done using                                            to do                                                step 9  output values w b                                            to do                                                uncomment following lines see plot     plt plot(data   0   data   1    bo   label  real data )    plt plot(data   0   data   0    w   b   r   label  predicted data )    plt legend() ", "content": "\"\"\" Starter code for simple linear regression example using placeholders\nCreated by Chip Huyen (huyenn@cs.stanford.edu)\nCS20: \"TensorFlow for Deep Learning Research\"\ncs20.stanford.edu\nLecture 03\n\"\"\"\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL']='2'\nimport time\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nimport utils\n\nDATA_FILE = 'data/birth_life_2010.txt'\n\n# Step 1: read in data from the .txt file\ndata, n_samples = utils.read_birth_life_data(DATA_FILE)\n\n# Step 2: create placeholders for X (birth rate) and Y (life expectancy)\n# Remember both X and Y are scalars with type float\nX, Y = None, None\n#############################\n########## TO DO ############\n#############################\n\n# Step 3: create weight and bias, initialized to 0.0\n# Make sure to use tf.get_variable\nw, b = None, None\n#############################\n########## TO DO ############\n#############################\n\n# Step 4: build model to predict Y\n# e.g. how would you derive at Y_predicted given X, w, and b\nY_predicted = None\n#############################\n########## TO DO ############\n#############################\n\n# Step 5: use the square error as the loss function\nloss = None\n#############################\n########## TO DO ############\n#############################\n\n# Step 6: using gradient descent with learning rate of 0.001 to minimize loss\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n\nstart = time.time()\n\n# Create a filewriter to write the model's graph to TensorBoard\n#############################\n########## TO DO ############\n#############################\n\nwith tf.Session() as sess:\n    # Step 7: initialize the necessary variables, in this case, w and b\n    #############################\n    ########## TO DO ############\n    #############################\n\n    # Step 8: train the model for 100 epochs\n    for i in range(100):\n        total_loss = 0\n        for x, y in data:\n            # Execute train_op and get the value of loss.\n            # Don't forget to feed in data for placeholders\n            _, loss = ########## TO DO ############\n            total_loss += loss\n\n        print('Epoch {0}: {1}'.format(i, total_loss/n_samples))\n\n    # close the writer when you're done using it\n    #############################\n    ########## TO DO ############\n    #############################\n    writer.close()\n    \n    # Step 9: output the values of w and b\n    w_out, b_out = None, None\n    #############################\n    ########## TO DO ############\n    #############################\n\nprint('Took: %f seconds' %(time.time() - start))\n\n# uncomment the following lines to see the plot \n# plt.plot(data[:,0], data[:,1], 'bo', label='Real data')\n# plt.plot(data[:,0], data[:,0] * w_out + b_out, 'r', label='Predicted data')\n# plt.legend()\n# plt.show()", "description": "This repository contains code examples for the Stanford's course: TensorFlow for Deep Learning Research. ", "file_name": "03_linreg_starter.py", "id": "54ce9ec3324ba36e08e27779297ab8bd", "language": "Python", "project_name": "stanford-tensorflow-tutorials", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/chiphuyen-stanford-tensorflow-tutorials/chiphuyen-stanford-tensorflow-tutorials-54c48f5/examples/03_linreg_starter.py", "save_time": "", "source": "", "update_at": "2018-03-18T15:38:24Z", "url": "https://github.com/chiphuyen/stanford-tensorflow-tutorials", "wiki": true}