{"author": "yunjey", "code": "import torch\nimport torch.nn as nn\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom logger import Logger\n\n\n\ndataset = dsets.MNIST(root='./data', \n                      train=True, \n                      transform=transforms.ToTensor(),  \n                      download=True)\n\n# Data Loader (Input Pipeline)\ndata_loader = torch.utils.data.DataLoader(dataset=dataset, \n                                          batch_size=100, \n                                          shuffle=True)\n\ndef to_np(x):\n    return x.data.cpu().numpy()\n\ndef to_var(x):\n    if torch.cuda.is_available():\n        x = x.cuda()\n    return Variable(x)    \n    \n# Neural Network Model (1 hidden layer)\nclass Net(nn.Module):\n    def __init__(self, input_size=784, hidden_size=500, num_classes=10):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size) \n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_size, num_classes)  \n    \n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.relu(out)\n        out = self.fc2(out)\n        return out\n\nnet = Net()\nif torch.cuda.is_available():\n    net.cuda()\n\n\nlogger = Logger('./logs')\n\n\ncriterion = nn.CrossEntropyLoss()  \noptimizer = torch.optim.Adam(net.parameters(), lr=0.00001)  \n\ndata_iter = iter(data_loader)\niter_per_epoch = len(data_loader)\ntotal_step = 50000\n\n\nfor step in range(total_step):\n    \n    \n    if (step+1) % iter_per_epoch == 0:\n        data_iter = iter(data_loader)\n\n    \n    images, labels = next(data_iter)\n    images, labels = to_var(images.view(images.size(0), -1)), to_var(labels)\n    \n    \n    optimizer.zero_grad()  \n    outputs = net(images)\n    loss = criterion(outputs, labels)\n    loss.backward()\n    optimizer.step()\n\n    \n    _, argmax = torch.max(outputs, 1)\n    accuracy = (labels == argmax.squeeze()).float().mean()\n\n    if (step+1) % 100 == 0:\n        print ('Step [%d/%d], Loss: %.4f, Acc: %.2f' \n               %(step+1, total_step, loss.data[0], accuracy.data[0]))\n\n        \n        # (1) Log the scalar values\n        info = {\n            'loss': loss.data[0],\n            'accuracy': accuracy.data[0]\n        }\n\n        for tag, value in info.items():\n            logger.scalar_summary(tag, value, step+1)\n\n        # (2) Log values and gradients of the parameters (histogram)\n        for tag, value in net.named_parameters():\n            tag = tag.replace('.', '/')\n            logger.histo_summary(tag, to_np(value), step+1)\n            logger.histo_summary(tag+'/grad', to_np(value.grad), step+1)\n\n        # (3) Log the images\n        info = {\n            'images': to_np(images.view(-1, 28, 28)[:10])\n        }\n\n        for tag, images in info.items():\n            logger.image_summary(tag, images, step+1)", "comments": "  mnist dataset     data loader (input pipeline)    neural network model (1 hidden layer)    set logger    loss optimizer    start training    reset data iter    fetch images labels convert variables    forward  backward optimize    zero gradient buffer    compute accuracy                tensorboard logging                  (1) log scalar values    (2) log values gradients parameters (histogram)    (3) log images ", "content": "import torch\nimport torch.nn as nn\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom logger import Logger\n\n\n# MNIST Dataset \ndataset = dsets.MNIST(root='./data', \n                      train=True, \n                      transform=transforms.ToTensor(),  \n                      download=True)\n\n# Data Loader (Input Pipeline)\ndata_loader = torch.utils.data.DataLoader(dataset=dataset, \n                                          batch_size=100, \n                                          shuffle=True)\n\ndef to_np(x):\n    return x.data.cpu().numpy()\n\ndef to_var(x):\n    if torch.cuda.is_available():\n        x = x.cuda()\n    return Variable(x)    \n    \n# Neural Network Model (1 hidden layer)\nclass Net(nn.Module):\n    def __init__(self, input_size=784, hidden_size=500, num_classes=10):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size) \n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_size, num_classes)  \n    \n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.relu(out)\n        out = self.fc2(out)\n        return out\n\nnet = Net()\nif torch.cuda.is_available():\n    net.cuda()\n\n# Set the logger\nlogger = Logger('./logs')\n\n# Loss and Optimizer\ncriterion = nn.CrossEntropyLoss()  \noptimizer = torch.optim.Adam(net.parameters(), lr=0.00001)  \n\ndata_iter = iter(data_loader)\niter_per_epoch = len(data_loader)\ntotal_step = 50000\n\n# Start training\nfor step in range(total_step):\n    \n    # Reset the data_iter\n    if (step+1) % iter_per_epoch == 0:\n        data_iter = iter(data_loader)\n\n    # Fetch the images and labels and convert them to variables\n    images, labels = next(data_iter)\n    images, labels = to_var(images.view(images.size(0), -1)), to_var(labels)\n    \n    # Forward, backward and optimize\n    optimizer.zero_grad()  # zero the gradient buffer\n    outputs = net(images)\n    loss = criterion(outputs, labels)\n    loss.backward()\n    optimizer.step()\n\n    # Compute accuracy\n    _, argmax = torch.max(outputs, 1)\n    accuracy = (labels == argmax.squeeze()).float().mean()\n\n    if (step+1) % 100 == 0:\n        print ('Step [%d/%d], Loss: %.4f, Acc: %.2f' \n               %(step+1, total_step, loss.data[0], accuracy.data[0]))\n\n        #============ TensorBoard logging ============#\n        # (1) Log the scalar values\n        info = {\n            'loss': loss.data[0],\n            'accuracy': accuracy.data[0]\n        }\n\n        for tag, value in info.items():\n            logger.scalar_summary(tag, value, step+1)\n\n        # (2) Log values and gradients of the parameters (histogram)\n        for tag, value in net.named_parameters():\n            tag = tag.replace('.', '/')\n            logger.histo_summary(tag, to_np(value), step+1)\n            logger.histo_summary(tag+'/grad', to_np(value.grad), step+1)\n\n        # (3) Log the images\n        info = {\n            'images': to_np(images.view(-1, 28, 28)[:10])\n        }\n\n        for tag, images in info.items():\n            logger.image_summary(tag, images, step+1)", "description": "PyTorch Tutorial for Deep Learning Researchers", "file_name": "main.py", "id": "c609019d9b7aa7f290cf43a49e10544f", "language": "Python", "project_name": "pytorch-tutorial", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/yunjey-pytorch-tutorial/yunjey-pytorch-tutorial-6c785eb/tutorials/04-utils/tensorboard/main.py", "save_time": "", "source": "", "update_at": "2018-03-18T14:24:45Z", "url": "https://github.com/yunjey/pytorch-tutorial", "wiki": true}